{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad0c80a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "try {\n",
       "require(['notebook/js/codecell'], function(codecell) {\n",
       "  codecell.CodeCell.options_default.highlight_modes[\n",
       "      'magic_text/x-csrc'] = {'reg':[/^%%microblaze/]};\n",
       "  Jupyter.notebook.events.one('kernel_ready.Kernel', function(){\n",
       "      Jupyter.notebook.get_cells().map(function(cell){\n",
       "          if (cell.cell_type == 'code'){ cell.auto_highlight(); } }) ;\n",
       "  });\n",
       "});\n",
       "} catch (e) {};\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "try {\n",
       "require(['notebook/js/codecell'], function(codecell) {\n",
       "  codecell.CodeCell.options_default.highlight_modes[\n",
       "      'magic_text/x-csrc'] = {'reg':[/^%%pybind11/]};\n",
       "  Jupyter.notebook.events.one('kernel_ready.Kernel', function(){\n",
       "      Jupyter.notebook.get_cells().map(function(cell){\n",
       "          if (cell.cell_type == 'code'){ cell.auto_highlight(); } }) ;\n",
       "  });\n",
       "});\n",
       "} catch (e) {};\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of test images: 100\n",
      "  Dimension of each picture: 150x150\n",
      "Classifying 100 digit pictures ...\n",
      "Overall accuracy: 0.13\n",
      "  Execution time/per picture: 3.3905ms\n",
      "      Throughput: 29.4944FPS\n",
      "Total number of test images: 100\n",
      "  Dimension of each picture: 150x150\n",
      "Classifying 100 digit pictures ...\n",
      "Overall accuracy: 0.09\n",
      "  Execution time/per picture: 4.7660ms\n",
      "      Throughput: 20.9819FPS\n",
      "Total number of test images: 100\n",
      "  Dimension of each picture: 150x150\n",
      "Classifying 100 digit pictures ...\n",
      "Overall accuracy: 0.12\n",
      "  Execution time/per picture: 3.2649ms\n",
      "      Throughput: 30.6293FPS\n",
      "Total number of test images: 100\n",
      "  Dimension of each picture: 150x150\n",
      "Classifying 100 digit pictures ...\n",
      "Overall accuracy: 0.1\n",
      "  Execution time/per picture: 3.6922ms\n",
      "      Throughput: 27.0838FPS\n",
      "Total number of test images: 100\n",
      "  Dimension of each picture: 184x184\n",
      "Classifying 100 digit pictures ...\n",
      "Overall accuracy: 0.1\n",
      "  Execution time/per picture: 4.2620ms\n",
      "      Throughput: 23.4631FPS\n",
      "Total number of test images: 100\n",
      "  Dimension of each picture: 184x184\n",
      "Classifying 100 digit pictures ...\n",
      "Overall accuracy: 0.11\n",
      "  Execution time/per picture: 3.0347ms\n",
      "      Throughput: 32.9525FPS\n",
      "Total number of test images: 100\n",
      "  Dimension of each picture: 184x184\n",
      "Classifying 100 digit pictures ...\n",
      "Overall accuracy: 0.1\n",
      "  Execution time/per picture: 5.2676ms\n",
      "      Throughput: 18.9841FPS\n",
      "Total number of test images: 100\n",
      "  Dimension of each picture: 184x184\n",
      "Classifying 100 digit pictures ...\n",
      "Overall accuracy: 0.08\n",
      "  Execution time/per picture: 5.4012ms\n",
      "      Throughput: 18.5145FPS\n",
      "Total number of test images: 100\n",
      "  Dimension of each picture: 218x218\n",
      "Classifying 100 digit pictures ...\n",
      "Overall accuracy: 0.07\n",
      "  Execution time/per picture: 6.8257ms\n",
      "      Throughput: 14.6506FPS\n",
      "Total number of test images: 100\n",
      "  Dimension of each picture: 218x218\n",
      "Classifying 100 digit pictures ...\n",
      "Overall accuracy: 0.1\n",
      "  Execution time/per picture: 5.8007ms\n",
      "      Throughput: 17.2393FPS\n",
      "Total number of test images: 100\n",
      "  Dimension of each picture: 218x218\n",
      "Classifying 100 digit pictures ...\n",
      "Overall accuracy: 0.11\n",
      "  Execution time/per picture: 7.7935ms\n",
      "      Throughput: 12.8312FPS\n",
      "Total number of test images: 100\n",
      "  Dimension of each picture: 218x218\n",
      "Classifying 100 digit pictures ...\n",
      "Overall accuracy: 0.1\n",
      "  Execution time/per picture: 5.1913ms\n",
      "      Throughput: 19.2629FPS\n",
      "Total number of test images: 100\n",
      "  Dimension of each picture: 252x252\n",
      "Classifying 100 digit pictures ...\n",
      "Overall accuracy: 0.09\n",
      "  Execution time/per picture: 7.4671ms\n",
      "      Throughput: 13.3921FPS\n",
      "Total number of test images: 100\n",
      "  Dimension of each picture: 252x252\n",
      "Classifying 100 digit pictures ...\n",
      "Overall accuracy: 0.1\n",
      "  Execution time/per picture: 9.1945ms\n",
      "      Throughput: 10.8760FPS\n",
      "Total number of test images: 100\n",
      "  Dimension of each picture: 252x252\n",
      "Classifying 100 digit pictures ...\n",
      "Overall accuracy: 0.12\n",
      "  Execution time/per picture: 6.7416ms\n",
      "      Throughput: 14.8332FPS\n",
      "Total number of test images: 100\n",
      "  Dimension of each picture: 252x252\n",
      "Classifying 100 digit pictures ...\n",
      "Overall accuracy: 0.14\n",
      "  Execution time/per picture: 7.6684ms\n",
      "      Throughput: 13.0405FPS\n",
      "Total number of test images: 100\n",
      "  Dimension of each picture: 286x286\n",
      "Classifying 100 digit pictures ...\n",
      "Overall accuracy: 0.16\n",
      "  Execution time/per picture: 10.2242ms\n",
      "      Throughput: 9.7807FPS\n",
      "Total number of test images: 100\n",
      "  Dimension of each picture: 286x286\n",
      "Classifying 100 digit pictures ...\n",
      "Overall accuracy: 0.13\n",
      "  Execution time/per picture: 9.7373ms\n",
      "      Throughput: 10.2698FPS\n",
      "Total number of test images: 100\n",
      "  Dimension of each picture: 286x286\n",
      "Classifying 100 digit pictures ...\n",
      "Overall accuracy: 0.08\n",
      "  Execution time/per picture: 12.1935ms\n",
      "      Throughput: 8.2011FPS\n",
      "Total number of test images: 100\n",
      "  Dimension of each picture: 286x286\n",
      "Classifying 100 digit pictures ...\n",
      "Overall accuracy: 0.07\n",
      "  Execution time/per picture: 12.0162ms\n",
      "      Throughput: 8.3221FPS\n",
      "Total number of test images: 100\n",
      "  Dimension of each picture: 320x320\n",
      "Classifying 100 digit pictures ...\n",
      "Overall accuracy: 0.13\n",
      "  Execution time/per picture: 17.0933ms\n",
      "      Throughput: 5.8502FPS\n",
      "Total number of test images: 100\n",
      "  Dimension of each picture: 320x320\n",
      "Classifying 100 digit pictures ...\n",
      "Overall accuracy: 0.14\n",
      "  Execution time/per picture: 10.3686ms\n",
      "      Throughput: 9.6445FPS\n",
      "Total number of test images: 100\n",
      "  Dimension of each picture: 320x320\n",
      "Classifying 100 digit pictures ...\n",
      "Overall accuracy: 0.12\n",
      "  Execution time/per picture: 13.5610ms\n",
      "      Throughput: 7.3741FPS\n",
      "Total number of test images: 100\n",
      "  Dimension of each picture: 320x320\n",
      "Classifying 100 digit pictures ...\n",
      "Overall accuracy: 0.14\n",
      "  Execution time/per picture: 14.6561ms\n",
      "      Throughput: 6.8231FPS\n",
      "Total number of test images: 100\n",
      "  Dimension of each picture: 354x354\n",
      "Classifying 100 digit pictures ...\n",
      "Overall accuracy: 0.13\n",
      "  Execution time/per picture: 17.4233ms\n",
      "      Throughput: 5.7395FPS\n",
      "Total number of test images: 100\n",
      "  Dimension of each picture: 354x354\n",
      "Classifying 100 digit pictures ...\n",
      "Overall accuracy: 0.16\n",
      "  Execution time/per picture: 14.5121ms\n",
      "      Throughput: 6.8908FPS\n",
      "Total number of test images: 100\n",
      "  Dimension of each picture: 354x354\n",
      "Classifying 100 digit pictures ...\n",
      "Overall accuracy: 0.06\n",
      "  Execution time/per picture: 17.9251ms\n",
      "      Throughput: 5.5788FPS\n",
      "Total number of test images: 100\n",
      "  Dimension of each picture: 354x354\n",
      "Classifying 100 digit pictures ...\n",
      "Overall accuracy: 0.06\n",
      "  Execution time/per picture: 16.7207ms\n",
      "      Throughput: 5.9806FPS\n",
      "Total number of test images: 100\n",
      "  Dimension of each picture: 388x388\n",
      "Classifying 100 digit pictures ...\n",
      "Overall accuracy: 0.12\n",
      "  Execution time/per picture: 20.3743ms\n",
      "      Throughput: 4.9081FPS\n",
      "Total number of test images: 100\n",
      "  Dimension of each picture: 388x388\n",
      "Classifying 100 digit pictures ...\n"
     ]
    }
   ],
   "source": [
    "from pynq_dpu import DpuOverlay\n",
    "from time import time\n",
    "import numpy as np\n",
    "\n",
    "from six.moves import urllib\n",
    "import csv\n",
    "import os\n",
    "from itertools import product\n",
    "\n",
    "\n",
    "model_num = 0\n",
    "with open(\"model_result_synthetic.csv\",\"w\") as csvfile: \n",
    "    writer = csv.writer(csvfile)\n",
    "    writer.writerow([\"index\",\"input_horizontal\",\"input_vertical\",\"step\",\"Execution time\",\"Throughout\"])\n",
    "\n",
    "path = \"./xmodel_synthetic\"\n",
    "files= os.listdir(path) \n",
    "\n",
    "\n",
    "input_shape_range =range(48,512,34)\n",
    "step_range =range(1,11,1)            \n",
    "for shape_x,step in product(input_shape_range,step_range):\n",
    "    shape_y = shape_x\n",
    "    file = \"synthetic_{input_x}_{input_y}_{step}.xmodel\".format(input_x=shape_x,input_y=shape_y,step=step)\n",
    "    if file in files: \n",
    "        model_name = str(file)\n",
    "        if not os.path.isdir(file): \n",
    "            #Prepare the overlay\n",
    "            overlay = DpuOverlay(\"dpu.bit\")\n",
    "            overlay.load_model(\"./xmodel_synthetic/{}\".format(file))\n",
    "\n",
    "            opener = urllib.request.build_opener()\n",
    "            opener.addheaders = [('User-agent', 'Mozilla/5.0')]\n",
    "            urllib.request.install_opener(opener)\n",
    "\n",
    "            #load test data\n",
    "\n",
    "            test_data = np.random.randint(0,255,size=[100,shape_x,shape_y,1])\n",
    "            test_label = np.random.randint(0,10,size=[100,])\n",
    "            test_data = test_data.astype('float32')\n",
    "            test_data /= 255.0\n",
    "            \n",
    "            print(\"Total number of test images: {}\".format(test_data.shape[0]))\n",
    "            print(\"  Dimension of each picture: {}x{}\".format(test_data.shape[1],\n",
    "                                                              test_data.shape[2]))\n",
    "\n",
    "            #use VART \n",
    "            dpu = overlay.runner\n",
    "\n",
    "            inputTensors = dpu.get_input_tensors()\n",
    "            outputTensors = dpu.get_output_tensors()\n",
    "\n",
    "            shapeIn = tuple(inputTensors[0].dims)\n",
    "            shapeOut = tuple(outputTensors[0].dims)\n",
    "            outputSize = int(outputTensors[0].get_data_size() / shapeIn[0])\n",
    "\n",
    "            softmax = np.empty(outputSize)\n",
    "\n",
    "            output_data = [np.empty(shapeOut, dtype=np.float32, order=\"C\")]\n",
    "            input_data = [np.empty(shapeIn, dtype=np.float32, order=\"C\")]\n",
    "            image = input_data[0]\n",
    "\n",
    "            def calculate_softmax(data):\n",
    "                result = np.exp(data)\n",
    "                return result\n",
    "\n",
    "\n",
    "            #Run DPU to make predictions\n",
    "\n",
    "            total = test_data.shape[0]\n",
    "            predictions = np.empty_like(test_label)\n",
    "            print(\"Classifying {} digit pictures ...\".format(total))\n",
    "\n",
    "            start = time()\n",
    "            for i in range(total):\n",
    "                image[0,...] = test_data[i]\n",
    "                job_id = dpu.execute_async(input_data, output_data)\n",
    "                dpu.wait(job_id)\n",
    "                temp = [j.reshape(1, outputSize) for j in output_data]\n",
    "                softmax = calculate_softmax(temp[0][0])\n",
    "                predictions[i] = softmax.argmax()\n",
    "\n",
    "            stop = time()\n",
    "            correct = np.sum(predictions==test_label)\n",
    "            execution_time = (stop-start)*10\n",
    "            print(\"Overall accuracy: {}\".format(correct/total))\n",
    "            print(\"  Execution time/per picture: {:.4f}ms\".format(execution_time))\n",
    "            print(\"      Throughput: {:.4f}FPS\".format(total/execution_time))\n",
    "\n",
    "\n",
    "            with open(\"model_result_synthetic.csv\",\"a+\") as csvfile: \n",
    "                writer = csv.writer(csvfile)\n",
    "                writer.writerows([[model_num,shape_x,shape_y,step,execution_time,total/execution_time],])\n",
    "                model_num += 1\n",
    "\n",
    "\n",
    "            #clean up \n",
    "            del overlay\n",
    "            del dpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90539ecc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
