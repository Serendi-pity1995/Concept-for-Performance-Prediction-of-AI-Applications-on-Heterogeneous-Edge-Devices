{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "55bcac1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 9  5 10 10  9 10  8  8  1  6  5  4  4  7  4  5  8  7  1  3  9  7  5  5\n",
      "  2  5  7  8  1  3 10  9  4  6  5  4  1  6  7  8  9  8  6  5 10 10  1 10\n",
      "  1  9  9  4  3 10  9  9  5  8  5  8]\n",
      "(60,)\n",
      "<class 'numpy.ndarray'>\n",
      "(60,)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from tensorflow.keras import datasets,models,layers\n",
    "from tensorflow_model_optimization.quantization.keras import vitis_quantize\n",
    "\n",
    "from keras.layers import Dense, Conv2D,  MaxPool2D, Flatten, GlobalAveragePooling2D,  BatchNormalization, Layer, Add\n",
    "from keras.models import Sequential\n",
    "from keras.models import Model\n",
    "\n",
    "\n",
    "X_train=np.random.randint(0,255,size=[60,32,32,3])\n",
    "Y_train=np.random.randint(1,11,size=[60,])\n",
    "X_test=np.random.randint(0,255,size=[60,32,32,3])\n",
    "Y_test=np.random.randint(1,11,size=[60,])\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "X_train /= 255.0\n",
    "X_test /= 255.0\n",
    "print(Y_train)\n",
    "print(Y_train.shape)\n",
    "print(type(Y_train))\n",
    "\n",
    "# from sklearn.preprocessing import OneHotEncoder\n",
    "# encoder = OneHotEncoder()\n",
    "# encoder.fit(Y_train)\n",
    "# Y_train = encoder.transform(Y_train).toarray()\n",
    "# Y_test = encoder.transform(Y_test).toarray()\n",
    "\n",
    "print(Y_train.shape)\n",
    "class ResnetBlock(Model):\n",
    "    \"\"\"\n",
    "    A standard resnet block.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, channels: int, down_sample=False):\n",
    "        \"\"\"\n",
    "        channels: same as number of convolution kernels\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "\n",
    "        self.__channels = channels\n",
    "        self.__down_sample = down_sample\n",
    "        self.__strides = [2, 1] if down_sample else [1, 1]\n",
    "\n",
    "        KERNEL_SIZE = (3, 3)\n",
    "        # use He initialization, instead of Xavier (a.k.a 'glorot_uniform' in Keras), as suggested in [2]\n",
    "        INIT_SCHEME = \"he_normal\"\n",
    "\n",
    "        self.conv_1 = Conv2D(self.__channels, strides=self.__strides[0],\n",
    "                             kernel_size=KERNEL_SIZE, padding=\"same\", kernel_initializer=INIT_SCHEME)\n",
    "        self.bn_1 = BatchNormalization()\n",
    "        self.conv_2 = Conv2D(self.__channels, strides=self.__strides[1],\n",
    "                             kernel_size=KERNEL_SIZE, padding=\"same\", kernel_initializer=INIT_SCHEME)\n",
    "        self.bn_2 = BatchNormalization()\n",
    "        self.merge = Add()\n",
    "\n",
    "        if self.__down_sample:\n",
    "            # perform down sampling using stride of 2, according to [1].\n",
    "            self.res_conv = Conv2D(\n",
    "                self.__channels, strides=2, kernel_size=(1, 1), kernel_initializer=INIT_SCHEME, padding=\"same\")\n",
    "            self.res_bn = BatchNormalization()\n",
    "\n",
    "    def call(self, inputs):\n",
    "        res = inputs\n",
    "\n",
    "        x = self.conv_1(inputs)\n",
    "        x = self.bn_1(x)\n",
    "        x = tf.nn.relu(x)\n",
    "        x = self.conv_2(x)\n",
    "        x = self.bn_2(x)\n",
    "\n",
    "        if self.__down_sample:\n",
    "            res = self.res_conv(res)\n",
    "            res = self.res_bn(res)\n",
    "\n",
    "        # if not perform down sample, then add a shortcut directly\n",
    "        x = self.merge([x, res])\n",
    "        out = tf.nn.relu(x)\n",
    "        return out\n",
    "\n",
    "shape_range =range(224,512,32)\n",
    "for shape_x in shape_range:\n",
    "    shape_y = shape_x\n",
    "    X_train=np.random.randint(0,255,size=[60,shape_x,shape_y,1])\n",
    "    Y_train=np.random.randint(0,10,size=[60,])\n",
    "    X_test=np.random.randint(0,255,size=[60,shape_x,shape_y,1])\n",
    "    Y_test=np.random.randint(0,10,size=[60,])\n",
    "    X_train = X_train.astype('float32')\n",
    "    X_test = X_test.astype('float32')\n",
    "    X_train /= 255.0\n",
    "    X_test /= 255.0\n",
    "    \n",
    "    inputs = Input(shape=(shape_x, shape_y, 1))\n",
    "    conv1 = Conv2D(64, (7, 7), strides=2, padding=\"same\", kernel_initializer=\"he_normal\")(inputs)\n",
    "    init_bn = BatchNormalization()(conv1)\n",
    "    pool1 = MaxPooling2D(pool_size=(2, 2), strides=2, padding=\"same\")(init_bn)\n",
    "    res_1_1 = ResnetBlock(64)(pool1)\n",
    "    res_1_2 = ResnetBlock(64)(res_1_1)\n",
    "    res_2_1 = ResnetBlock(128, down_sample=True)(res_1_2)\n",
    "    res_2_2 = Re\n",
    "    \n",
    "class ResNet18(Model):\n",
    "\n",
    "    def __init__(self, num_classes, **kwargs):\n",
    "        \"\"\"\n",
    "            num_classes: number of classes in specific classification task.\n",
    "        \"\"\"\n",
    "        super().__init__(**kwargs)\n",
    "        self.conv_1 = Conv2D(64, (7, 7), strides=2,\n",
    "                             padding=\"same\", kernel_initializer=\"he_normal\")\n",
    "        self.init_bn = BatchNormalization()\n",
    "        self.pool_2 = MaxPool2D(pool_size=(2, 2), strides=2, padding=\"same\")\n",
    "        self.res_1_1 = ResnetBlock(64)\n",
    "        self.res_1_2 = ResnetBlock(64)\n",
    "        self.res_2_1 = ResnetBlock(128, down_sample=True)\n",
    "        self.res_2_2 = ResnetBlock(128)\n",
    "        self.res_3_1 = ResnetBlock(256, down_sample=True)\n",
    "        self.res_3_2 = ResnetBlock(256)\n",
    "        self.res_4_1 = ResnetBlock(512, down_sample=True)\n",
    "        self.res_4_2 = ResnetBlock(512)\n",
    "        self.avg_pool = GlobalAveragePooling2D()\n",
    "        self.flat = Flatten()\n",
    "        self.fc = Dense(num_classes, activation=\"softmax\")\n",
    "\n",
    "    def call(self, inputs):\n",
    "        out = self.conv_1(inputs)\n",
    "        out = self.init_bn(out)\n",
    "        out = tf.nn.relu(out)\n",
    "        out = self.pool_2(out)\n",
    "        for res_block in [self.res_1_1, self.res_1_2, self.res_2_1, self.res_2_2, self.res_3_1, self.res_3_2, self.res_4_1, self.res_4_2]:\n",
    "            out = res_block(out)\n",
    "        out = self.avg_pool(out)\n",
    "        out = self.flat(out)\n",
    "        out = self.fc(out)\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f273d6e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"res_net18_8\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_160 (Conv2D)          multiple                  9472      \n",
      "_________________________________________________________________\n",
      "batch_normalization_160 (Bat multiple                  256       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2 multiple                  0         \n",
      "_________________________________________________________________\n",
      "resnet_block_64 (ResnetBlock multiple                  74368     \n",
      "_________________________________________________________________\n",
      "resnet_block_65 (ResnetBlock multiple                  74368     \n",
      "_________________________________________________________________\n",
      "resnet_block_66 (ResnetBlock multiple                  231296    \n",
      "_________________________________________________________________\n",
      "resnet_block_67 (ResnetBlock multiple                  296192    \n",
      "_________________________________________________________________\n",
      "resnet_block_68 (ResnetBlock multiple                  921344    \n",
      "_________________________________________________________________\n",
      "resnet_block_69 (ResnetBlock multiple                  1182208   \n",
      "_________________________________________________________________\n",
      "resnet_block_70 (ResnetBlock multiple                  3677696   \n",
      "_________________________________________________________________\n",
      "resnet_block_71 (ResnetBlock multiple                  4723712   \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_8 ( multiple                  0         \n",
      "_________________________________________________________________\n",
      "flatten_8 (Flatten)          multiple                  0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              multiple                  5130      \n",
      "=================================================================\n",
      "Total params: 11,196,042\n",
      "Trainable params: 11,186,442\n",
      "Non-trainable params: 9,600\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-20 17:38:41.079572: W tensorflow/core/framework/op_kernel.cc:1692] OP_REQUIRES failed at sparse_xent_op.cc:114 : Invalid argument: Received a label value of 10 which is outside the valid range of [0, 10).  Label values: 1 10 10 10 5 8 5 1 8 6 8 1 7 6 5 5 6 4 7 5 9 4 5 6 5 9 5 8 4 4 9 10\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": " Received a label value of 10 which is outside the valid range of [0, 10).  Label values: 1 10 10 10 5 8 5 1 8 6 8 1 7 6 5 5 6 4 7 5 9 4 5 6 5 9 5 8 4 4 9 10\n\t [[node sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits (defined at tmp/ipykernel_483/2954320012.py:9) ]] [Op:__inference_train_function_35970]\n\nFunction call stack:\ntrain_function\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_483/2954320012.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/vitis_ai/conda/envs/vitis-ai-tensorflow2/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1182\u001b[0m                 _r=1):\n\u001b[1;32m   1183\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1184\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1185\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1186\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/vitis_ai/conda/envs/vitis-ai-tensorflow2/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    883\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    884\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 885\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    886\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    887\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/vitis_ai/conda/envs/vitis-ai-tensorflow2/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    948\u001b[0m         \u001b[0;31m# Lifting succeeded, so variables are initialized and we can run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m         \u001b[0;31m# stateless function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 950\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    951\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    952\u001b[0m       \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfiltered_flat_args\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/vitis_ai/conda/envs/vitis-ai-tensorflow2/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3038\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   3039\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 3040\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   3041\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3042\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/vitis_ai/conda/envs/vitis-ai-tensorflow2/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1962\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1963\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1964\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1965\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1966\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/vitis_ai/conda/envs/vitis-ai-tensorflow2/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    594\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    595\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 596\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    597\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    598\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m/opt/vitis_ai/conda/envs/vitis-ai-tensorflow2/lib/python3.7/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m:  Received a label value of 10 which is outside the valid range of [0, 10).  Label values: 1 10 10 10 5 8 5 1 8 6 8 1 7 6 5 5 6 4 7 5 9 4 5 6 5 9 5 8 4 4 9 10\n\t [[node sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits (defined at tmp/ipykernel_483/2954320012.py:9) ]] [Op:__inference_train_function_35970]\n\nFunction call stack:\ntrain_function\n"
     ]
    }
   ],
   "source": [
    "model = ResNet18(10)\n",
    "model.build(input_shape = (None,32,32,3))\n",
    "#use categorical_crossentropy since the label is one-hot encoded\n",
    "\n",
    "# opt = SGD(learning_rate=0.1,momentum=0.9,decay = 1e-04) #parameters suggested by He [1]\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "model.summary()\n",
    "\n",
    "history = model.fit(X_train, Y_train, epochs=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0aa93466",
   "metadata": {},
   "outputs": [
    {
     "ename": "NotImplementedError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_483/1746715856.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mquantizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvitis_quantize\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mVitisQuantizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;31m# quantized_model = quantizer.quantize_model(calib_dataset = X_test[1:8], weight_bit=8, activation_bit=8)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# #quantized_model.compile(loss='sparse_categorical_crossentropy', metrics=[\"accuracy\"])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/vitis_ai/conda/envs/vitis-ai-tensorflow2/lib/python3.7/site-packages/tensorflow_model_optimization/python/core/quantization/keras/vitis/vitis_quantize.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, float_model, quantize_strategy, custom_quantize_strategy, custom_objects)\u001b[0m\n\u001b[1;32m    178\u001b[0m     \u001b[0;31m# Custom objects\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcustom_objects\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcustom_objects\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 180\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_custom_objects\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    181\u001b[0m     self.custom_layer_type = [\n\u001b[1;32m    182\u001b[0m         \u001b[0ml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/vitis_ai/conda/envs/vitis-ai-tensorflow2/lib/python3.7/site-packages/tensorflow_model_optimization/python/core/quantization/keras/vitis/vitis_quantize.py\u001b[0m in \u001b[0;36m_check_custom_objects\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    427\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    428\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_check_custom_objects\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 429\u001b[0;31m     \u001b[0mcustom_layer_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_find_unregistered_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    430\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcustom_layer_type\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    431\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcustom_objects\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/vitis_ai/conda/envs/vitis-ai-tensorflow2/lib/python3.7/site-packages/tensorflow_model_optimization/python/core/quantization/keras/vitis/vitis_quantize.py\u001b[0m in \u001b[0;36m_find_unregistered_layer\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    410\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_find_unregistered_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    411\u001b[0m     \u001b[0mcustom_layer_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 412\u001b[0;31m     \u001b[0mmodel_config\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_float_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    413\u001b[0m     \u001b[0mtf_version\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__version__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    414\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf_version\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf_version\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m6\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/vitis_ai/conda/envs/vitis-ai-tensorflow2/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mget_config\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   2384\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2385\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mget_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2386\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mNotImplementedError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2387\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2388\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mclassmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNotImplementedError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from tensorflow_model_optimization.quantization.keras import vitis_quantize\n",
    "import os\n",
    "model.get_weights()[0].dtype\n",
    "quantizer = vitis_quantize.VitisQuantizer(model)\n",
    "# quantized_model = quantizer.quantize_model(calib_dataset = X_test[1:8], weight_bit=8, activation_bit=8)\n",
    "# #quantized_model.compile(loss='sparse_categorical_crossentropy', metrics=[\"accuracy\"])\n",
    "# quantized_model.save('tf2_mnist_classifier_quantized.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9918583a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[6]\n",
      " [9]\n",
      " [9]\n",
      " ...\n",
      " [9]\n",
      " [1]\n",
      " [1]]\n",
      "<class 'numpy.ndarray'>\n",
      "(40000, 10)\n",
      "[[0. 0. 0. ... 0. 0. 1.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [1. 0. 0. ... 0. 0. 0.]\n",
      " [1. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 1. ... 0. 0. 0.]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from tensorflow.keras import datasets,models,layers\n",
    "# Adding TF Cifar10 Data ..\n",
    "from keras.datasets import cifar10\n",
    "(X_train, Y_train), (X_test, Y_test) = cifar10.load_data()\n",
    "# Drawing sample . \n",
    "print(Y_train)\n",
    "print(type(Y_train))\n",
    "plt.imshow(X_train[42])\n",
    "# Normalize the data.\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "X_train /= 255.0\n",
    "X_test /= 255.0\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_val, Y_train, Y_val = train_test_split(X_train, Y_train, test_size = 0.2,shuffle = True)\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "encoder = OneHotEncoder()\n",
    "encoder.fit(Y_train)\n",
    "Y_train = encoder.transform(Y_train).toarray()\n",
    "Y_test = encoder.transform(Y_test).toarray()\n",
    "Y_val =  encoder.transform(Y_val).toarray()\n",
    "\n",
    "print(Y_train.shape)\n",
    "print(Y_train)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "823ef1e8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
