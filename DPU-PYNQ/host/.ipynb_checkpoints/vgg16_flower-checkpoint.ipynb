{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5af846b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/vitis-ai-user/.keras/datasets/flower_photos\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
    "import pathlib\n",
    "data_root_orig = tf.keras.utils.get_file(origin='https://storage.googleapis.com/download.tensorflow.org/example_images/flower_photos.tgz',\n",
    "                                         fname='flower_photos', untar=True)\n",
    "data_root = pathlib.Path(data_root_orig)\n",
    "print(data_root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "79b79512",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['daisy', 'dandelion', 'roses', 'sunflowers', 'tulips']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_names = sorted(item.name for item in data_root.glob('*/') if item.is_dir())\n",
    "label_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "32217ce2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3670"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "all_image_paths = list(data_root.glob('*/*'))\n",
    "all_image_paths = [str(path) for path in all_image_paths]\n",
    "random.shuffle(all_image_paths)\n",
    "\n",
    "image_count = len(all_image_paths)\n",
    "image_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8ea03074",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_to_index = dict((name, index) for index, name in enumerate(label_names))\n",
    "label_to_index\n",
    "all_image_labels = [label_to_index[pathlib.Path(path).parent.name]\n",
    "                    for path in all_image_paths]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f37c40f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 10 labels indices:  [1, 2, 2, 3, 3, 2, 0, 1, 1, 4]\n"
     ]
    }
   ],
   "source": [
    "print(\"First 10 labels indices: \", all_image_labels[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "256fa6e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tf.Tensor: shape=(), dtype=string, numpy=b'\\xff\\xd8\\xff\\xe0\\x00\\x10JFIF\\x00\\x01\\x01\\x00\\x00\\x01\\x00...\n",
      "(240, 240, 3)\n",
      "<dtype: 'uint8'>\n"
     ]
    }
   ],
   "source": [
    "img_path = all_image_paths[0]\n",
    "img_raw = tf.io.read_file(img_path)\n",
    "print(repr(img_raw)[:100]+\"...\")\n",
    "img_tensor = tf.image.decode_image(img_raw)\n",
    "\n",
    "print(img_tensor.shape)\n",
    "print(img_tensor.dtype)\n",
    "\n",
    "img_final = tf.image.resize(img_tensor, [192, 192])\n",
    "img_final = img_final/255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d68838d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_image(image):\n",
    "    \n",
    "    image = tf.image.decode_jpeg(image, channels=3)\n",
    "    image = tf.image.resize(image, [192, 192])\n",
    "    image /= 255.0  # normalize to [0,1] range\n",
    "\n",
    "    return image\n",
    "\n",
    "def load_and_preprocess_image(path):\n",
    "    image= tf.io.read_file(path)\n",
    "    return preprocess_image(image)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "662f7c72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /tmp/ipykernel_765/1087477554.py:16: shuffle_and_repeat (from tensorflow.python.data.experimental.ops.shuffle_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.Dataset.shuffle(buffer_size, seed)` followed by `tf.data.Dataset.repeat(count)`. Static tf.data optimizations will take care of using the fused implementation.\n"
     ]
    }
   ],
   "source": [
    "ds = tf.data.Dataset.from_tensor_slices((all_image_paths, all_image_labels))\n",
    "def load_and_preprocess_from_path_label(path, label):\n",
    "      return load_and_preprocess_image(path), label\n",
    "image_label_ds = ds.map(load_and_preprocess_from_path_label)\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "# 设置一个和数据集大小一致的 shuffle buffer size（随机缓冲区大小）以保证数据\n",
    "# 被充分打乱。\n",
    "ds = image_label_ds.shuffle(buffer_size=image_count)\n",
    "ds = ds.repeat()\n",
    "ds = ds.batch(BATCH_SIZE)\n",
    "# 当模型在训练的时候，`prefetch` 使数据集在后台取得 batch。\n",
    "ds = ds.prefetch(buffer_size=AUTOTUNE)\n",
    "\n",
    "ds = image_label_ds.apply(\n",
    "  tf.data.experimental.shuffle_and_repeat(buffer_size=image_count))\n",
    "ds = ds.batch(BATCH_SIZE)\n",
    "ds = ds.prefetch(buffer_size=AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f4ea6bba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2000 images belonging to 2 classes.\n",
      "Found 1000 images belonging to 2 classes.\n",
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         [(None, 192, 192, 3)]     0         \n",
      "_________________________________________________________________\n",
      "conv2d_13 (Conv2D)           (None, 192, 192, 64)      1792      \n",
      "_________________________________________________________________\n",
      "conv2d_14 (Conv2D)           (None, 192, 192, 64)      36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 96, 96, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_15 (Conv2D)           (None, 96, 96, 128)       73856     \n",
      "_________________________________________________________________\n",
      "conv2d_16 (Conv2D)           (None, 96, 96, 128)       147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2 (None, 48, 48, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_17 (Conv2D)           (None, 48, 48, 256)       295168    \n",
      "_________________________________________________________________\n",
      "conv2d_18 (Conv2D)           (None, 48, 48, 256)       590080    \n",
      "_________________________________________________________________\n",
      "conv2d_19 (Conv2D)           (None, 48, 48, 256)       590080    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2 (None, 24, 24, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_20 (Conv2D)           (None, 24, 24, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "conv2d_21 (Conv2D)           (None, 24, 24, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "conv2d_22 (Conv2D)           (None, 24, 24, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2 (None, 12, 12, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_23 (Conv2D)           (None, 12, 12, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "conv2d_24 (Conv2D)           (None, 12, 12, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "conv2d_25 (Conv2D)           (None, 12, 12, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "max_pooling2d_9 (MaxPooling2 (None, 6, 6, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 18432)             0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 4096)              75501568  \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 4096)              16781312  \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 5)                 20485     \n",
      "=================================================================\n",
      "Total params: 107,018,053\n",
      "Trainable params: 107,018,053\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-03 13:31:45.259129: I tensorflow/core/grappler/devices.cc:66] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0\n",
      "2022-03-03 13:31:45.259261: I tensorflow/core/grappler/clusters/single_machine.cc:357] Starting new session\n",
      "2022-03-03 13:31:45.263163: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:1137] Optimization results for grappler item: graph_to_optimize\n",
      "  function_optimizer: function_optimizer did nothing. time = 0.011ms.\n",
      "  function_optimizer: function_optimizer did nothing. time = 0.002ms.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=========================Options=============================\n",
      "-max_depth                  10000\n",
      "-min_bytes                  0\n",
      "-min_peak_bytes             0\n",
      "-min_residual_bytes         0\n",
      "-min_output_bytes           0\n",
      "-min_micros                 0\n",
      "-min_accelerator_micros     0\n",
      "-min_cpu_micros             0\n",
      "-min_params                 0\n",
      "-min_float_ops              1\n",
      "-min_occurrence             0\n",
      "-step                       -1\n",
      "-order_by                   float_ops\n",
      "-account_type_regexes       .*\n",
      "-start_name_regexes         .*\n",
      "-trim_name_regexes          \n",
      "-show_name_regexes          .*\n",
      "-hide_name_regexes          \n",
      "-account_displayed_op_only  true\n",
      "-select                     float_ops\n",
      "-output                     stdout:\n",
      "\n",
      "==================Model Analysis Report======================\n",
      "\n",
      "Doc:\n",
      "scope: The nodes in the model graph are organized by their names, which is hierarchical like filesystem.\n",
      "flops: Number of float operations. Note: Please read the implementation for the math behind it.\n",
      "\n",
      "Profile:\n",
      "node name | # float_ops\n",
      "_TFProfRoot (--/22.75b flops)\n",
      "  model_1/conv2d_14/Conv2D (2.72b/2.72b flops)\n",
      "  model_1/conv2d_16/Conv2D (2.72b/2.72b flops)\n",
      "  model_1/conv2d_22/Conv2D (2.72b/2.72b flops)\n",
      "  model_1/conv2d_21/Conv2D (2.72b/2.72b flops)\n",
      "  model_1/conv2d_18/Conv2D (2.72b/2.72b flops)\n",
      "  model_1/conv2d_19/Conv2D (2.72b/2.72b flops)\n",
      "  model_1/conv2d_15/Conv2D (1.36b/1.36b flops)\n",
      "  model_1/conv2d_17/Conv2D (1.36b/1.36b flops)\n",
      "  model_1/conv2d_20/Conv2D (1.36b/1.36b flops)\n",
      "  model_1/conv2d_25/Conv2D (679.48m/679.48m flops)\n",
      "  model_1/conv2d_24/Conv2D (679.48m/679.48m flops)\n",
      "  model_1/conv2d_23/Conv2D (679.48m/679.48m flops)\n",
      "  model_1/dense_3/MatMul (150.99m/150.99m flops)\n",
      "  model_1/conv2d_13/Conv2D (127.40m/127.40m flops)\n",
      "  model_1/dense_4/MatMul (33.55m/33.55m flops)\n",
      "  model_1/conv2d_14/BiasAdd (2.36m/2.36m flops)\n",
      "  model_1/conv2d_13/BiasAdd (2.36m/2.36m flops)\n",
      "  model_1/max_pooling2d_5/MaxPool (2.36m/2.36m flops)\n",
      "  model_1/conv2d_16/BiasAdd (1.18m/1.18m flops)\n",
      "  model_1/conv2d_15/BiasAdd (1.18m/1.18m flops)\n",
      "  model_1/max_pooling2d_6/MaxPool (1.18m/1.18m flops)\n",
      "  model_1/conv2d_19/BiasAdd (589.82k/589.82k flops)\n",
      "  model_1/conv2d_18/BiasAdd (589.82k/589.82k flops)\n",
      "  model_1/conv2d_17/BiasAdd (589.82k/589.82k flops)\n",
      "  model_1/max_pooling2d_7/MaxPool (589.82k/589.82k flops)\n",
      "  model_1/conv2d_21/BiasAdd (294.91k/294.91k flops)\n",
      "  model_1/conv2d_22/BiasAdd (294.91k/294.91k flops)\n",
      "  model_1/conv2d_20/BiasAdd (294.91k/294.91k flops)\n",
      "  model_1/max_pooling2d_8/MaxPool (294.91k/294.91k flops)\n",
      "  model_1/max_pooling2d_9/MaxPool (73.73k/73.73k flops)\n",
      "  model_1/conv2d_25/BiasAdd (73.73k/73.73k flops)\n",
      "  model_1/conv2d_24/BiasAdd (73.73k/73.73k flops)\n",
      "  model_1/conv2d_23/BiasAdd (73.73k/73.73k flops)\n",
      "  model_1/dense_5/MatMul (40.96k/40.96k flops)\n",
      "  model_1/dense_4/BiasAdd (4.10k/4.10k flops)\n",
      "  model_1/dense_3/BiasAdd (4.10k/4.10k flops)\n",
      "  model_1/dense_5/Softmax (25/25 flops)\n",
      "  model_1/dense_5/BiasAdd (5/5 flops)\n",
      "\n",
      "======================End of Report==========================\n",
      "FLOPS: 22.7 G\n",
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-03 13:32:02.758134: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 58s 18s/step - loss: 7.7871 - accuracy: 0.1458\n",
      "Epoch 2/5\n",
      "3/3 [==============================] - 51s 17s/step - loss: 1.6020 - accuracy: 0.2812\n",
      "Epoch 3/5\n",
      "3/3 [==============================] - 53s 17s/step - loss: 1.8658 - accuracy: 0.2917\n",
      "Epoch 4/5\n",
      "3/3 [==============================] - 52s 17s/step - loss: 1.5902 - accuracy: 0.3438\n",
      "Epoch 5/5\n",
      "3/3 [==============================] - 53s 18s/step - loss: 1.6036 - accuracy: 0.2500\n"
     ]
    }
   ],
   "source": [
    "import keras,os\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Dense, Conv2D, MaxPooling2D , Flatten\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import numpy as np\n",
    "from keras_flops import get_flops\n",
    "\n",
    "trdata = ImageDataGenerator()\n",
    "traindata = trdata.flow_from_directory(directory=\"cats_and_dogs_filtered/train\",target_size=(224,224))\n",
    "tsdata = ImageDataGenerator()\n",
    "testdata = tsdata.flow_from_directory(directory=\"cats_and_dogs_filtered/validation\", target_size=(224,224))\n",
    "inputs = Input(shape=(192, 192, 3))\n",
    "\n",
    "# 卷积层和最大池化层\n",
    "conv1 = Conv2D(64, (3,3), padding='same', activation='relu')(inputs)\n",
    "conv2 = Conv2D(64, (3,3), padding='same', activation='relu')(conv1)\n",
    "pool1 = MaxPooling2D(pool_size=2)(conv2)\n",
    "\n",
    "conv3 = Conv2D(128, (3,3), padding='same', activation='relu')(pool1)\n",
    "conv4 = Conv2D(128, (3,3), padding='same', activation='relu')(conv3)\n",
    "pool2 = MaxPooling2D(pool_size=2)(conv4)\n",
    "\n",
    "conv5 = Conv2D(256, (3,3), padding='same', activation='relu')(pool2)\n",
    "conv6 = Conv2D(256, (3,3), padding='same', activation='relu')(conv5)\n",
    "conv7 = Conv2D(256, (3,3), padding='same', activation='relu')(conv6)\n",
    "pool3 = MaxPooling2D(pool_size=2)(conv7)\n",
    "\n",
    "conv8 = Conv2D(512, (3,3), padding='same', activation='relu')(pool3)\n",
    "conv9 = Conv2D(512, (3,3), padding='same', activation='relu')(conv8)\n",
    "conv10 = Conv2D(512, (3,3), padding='same', activation='relu')(conv9)\n",
    "pool4 = MaxPooling2D(pool_size=2)(conv10)\n",
    "\n",
    "conv11 = Conv2D(512, (3,3), padding='same', activation='relu')(pool4)\n",
    "conv12 = Conv2D(512, (3,3), padding='same', activation='relu')(conv11)\n",
    "conv13 = Conv2D(512, (3,3), padding='same', activation='relu')(conv12)\n",
    "pool5 = MaxPooling2D(pool_size=2)(conv13)\n",
    "\n",
    "# 扁平层\n",
    "flat = Flatten()(pool5)\n",
    "\n",
    "# 全联接层\n",
    "fc1 = Dense(4096, activation='relu')(flat)\n",
    "fc2 = Dense(4096, activation='relu')(fc1)\n",
    "\n",
    "# 输出层\n",
    "outputs = Dense(5, activation='softmax')(fc2)\n",
    "\n",
    "\n",
    "my_VGG16_model = Model(inputs=inputs, outputs=outputs)\n",
    "my_VGG16_model.summary()\n",
    "flops = get_flops(my_VGG16_model, batch_size=1)\n",
    "print(f\"FLOPS: {flops / 10 ** 9:.03} G\")\n",
    "\n",
    "my_VGG16_model.compile(optimizer='adam',\n",
    "              loss=\"sparse_categorical_crossentropy\", \n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history = my_VGG16_model.fit(ds, epochs=5,steps_per_epoch=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24728f7d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
