{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d7bf9a47",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-30 16:44:40.997562: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/xilinx/xrt/lib:/usr/lib:/usr/lib/x86_64-linux-gnu:/usr/local/lib:/opt/vitis_ai/conda/envs/vitis-ai-tensorflow/lib\n",
      "2022-03-30 16:44:40.997579: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(224, 224, 1)\n",
      "[0 1 2 3 4 5 6 7 8 9]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-30 16:44:42.102586: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/xilinx/xrt/lib:/usr/lib:/usr/lib/x86_64-linux-gnu:/usr/local/lib:/opt/vitis_ai/conda/envs/vitis-ai-tensorflow/lib\n",
      "2022-03-30 16:44:42.102618: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2022-03-30 16:44:42.102632: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:163] no NVIDIA GPU device is present: /dev/nvidia0 does not exist\n",
      "2022-03-30 16:44:42.102776: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"GoogLeNet\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 224, 224, 1) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d (Conv2D)                 (None, 109, 109, 64) 3200        input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D)    (None, 54, 54, 64)   0           conv2d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 54, 54, 64)   4160        max_pooling2d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 54, 54, 192)  110784      conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 26, 26, 192)  0           conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 26, 26, 96)   18528       max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 26, 26, 16)   3088        max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 26, 26, 192)  0           max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 26, 26, 64)   12352       max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 26, 26, 128)  110720      conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 26, 26, 32)   12832       conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 26, 26, 32)   6176        max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 26, 26, 256)  0           conv2d_3[0][0]                   \n",
      "                                                                 conv2d_5[0][0]                   \n",
      "                                                                 conv2d_7[0][0]                   \n",
      "                                                                 conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 26, 26, 128)  32896       concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 26, 26, 32)   8224        concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)  (None, 26, 26, 256)  0           concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 26, 26, 128)  32896       concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 26, 26, 192)  221376      conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 26, 26, 96)   76896       conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, 26, 26, 64)   16448       max_pooling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 26, 26, 480)  0           conv2d_9[0][0]                   \n",
      "                                                                 conv2d_11[0][0]                  \n",
      "                                                                 conv2d_13[0][0]                  \n",
      "                                                                 conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2D)  (None, 12, 12, 480)  0           concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)              (None, 12, 12, 96)   46176       max_pooling2d_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_18 (Conv2D)              (None, 12, 12, 16)   7696        max_pooling2d_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2D)  (None, 12, 12, 480)  0           max_pooling2d_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, 12, 12, 192)  92352       max_pooling2d_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)              (None, 12, 12, 208)  179920      conv2d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_19 (Conv2D)              (None, 12, 12, 48)   19248       conv2d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_20 (Conv2D)              (None, 12, 12, 64)   30784       max_pooling2d_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 12, 12, 512)  0           conv2d_15[0][0]                  \n",
      "                                                                 conv2d_17[0][0]                  \n",
      "                                                                 conv2d_19[0][0]                  \n",
      "                                                                 conv2d_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_23 (Conv2D)              (None, 12, 12, 112)  57456       concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_25 (Conv2D)              (None, 12, 12, 24)   12312       concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2D)  (None, 12, 12, 512)  0           concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_22 (Conv2D)              (None, 12, 12, 160)  82080       concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_24 (Conv2D)              (None, 12, 12, 224)  226016      conv2d_23[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_26 (Conv2D)              (None, 12, 12, 64)   38464       conv2d_25[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_27 (Conv2D)              (None, 12, 12, 64)   32832       max_pooling2d_6[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 12, 12, 512)  0           conv2d_22[0][0]                  \n",
      "                                                                 conv2d_24[0][0]                  \n",
      "                                                                 conv2d_26[0][0]                  \n",
      "                                                                 conv2d_27[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_29 (Conv2D)              (None, 12, 12, 128)  65664       concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_31 (Conv2D)              (None, 12, 12, 24)   12312       concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2D)  (None, 12, 12, 512)  0           concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_28 (Conv2D)              (None, 12, 12, 128)  65664       concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_30 (Conv2D)              (None, 12, 12, 256)  295168      conv2d_29[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_32 (Conv2D)              (None, 12, 12, 64)   38464       conv2d_31[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_33 (Conv2D)              (None, 12, 12, 64)   32832       max_pooling2d_7[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)     (None, 12, 12, 512)  0           conv2d_28[0][0]                  \n",
      "                                                                 conv2d_30[0][0]                  \n",
      "                                                                 conv2d_32[0][0]                  \n",
      "                                                                 conv2d_33[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_35 (Conv2D)              (None, 12, 12, 144)  73872       concatenate_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_37 (Conv2D)              (None, 12, 12, 32)   16416       concatenate_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2D)  (None, 12, 12, 512)  0           concatenate_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_34 (Conv2D)              (None, 12, 12, 112)  57456       concatenate_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_36 (Conv2D)              (None, 12, 12, 288)  373536      conv2d_35[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_38 (Conv2D)              (None, 12, 12, 64)   51264       conv2d_37[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_39 (Conv2D)              (None, 12, 12, 64)   32832       max_pooling2d_8[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_5 (Concatenate)     (None, 12, 12, 528)  0           conv2d_34[0][0]                  \n",
      "                                                                 conv2d_36[0][0]                  \n",
      "                                                                 conv2d_38[0][0]                  \n",
      "                                                                 conv2d_39[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_42 (Conv2D)              (None, 12, 12, 160)  84640       concatenate_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_44 (Conv2D)              (None, 12, 12, 32)   16928       concatenate_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_9 (MaxPooling2D)  (None, 12, 12, 528)  0           concatenate_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_41 (Conv2D)              (None, 12, 12, 256)  135424      concatenate_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_43 (Conv2D)              (None, 12, 12, 320)  461120      conv2d_42[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_45 (Conv2D)              (None, 12, 12, 128)  102528      conv2d_44[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_46 (Conv2D)              (None, 12, 12, 128)  67712       max_pooling2d_9[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_6 (Concatenate)     (None, 12, 12, 832)  0           conv2d_41[0][0]                  \n",
      "                                                                 conv2d_43[0][0]                  \n",
      "                                                                 conv2d_45[0][0]                  \n",
      "                                                                 conv2d_46[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_10 (MaxPooling2D) (None, 5, 5, 832)    0           concatenate_6[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_48 (Conv2D)              (None, 5, 5, 160)    133280      max_pooling2d_10[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_50 (Conv2D)              (None, 5, 5, 32)     26656       max_pooling2d_10[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_11 (MaxPooling2D) (None, 5, 5, 832)    0           max_pooling2d_10[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_47 (Conv2D)              (None, 5, 5, 256)    213248      max_pooling2d_10[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_49 (Conv2D)              (None, 5, 5, 320)    461120      conv2d_48[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_51 (Conv2D)              (None, 5, 5, 128)    102528      conv2d_50[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_52 (Conv2D)              (None, 5, 5, 128)    106624      max_pooling2d_11[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_7 (Concatenate)     (None, 5, 5, 832)    0           conv2d_47[0][0]                  \n",
      "                                                                 conv2d_49[0][0]                  \n",
      "                                                                 conv2d_51[0][0]                  \n",
      "                                                                 conv2d_52[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_54 (Conv2D)              (None, 5, 5, 192)    159936      concatenate_7[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_56 (Conv2D)              (None, 5, 5, 48)     39984       concatenate_7[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_12 (MaxPooling2D) (None, 5, 5, 832)    0           concatenate_7[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d (AveragePooli (None, 3, 3, 512)    0           concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_1 (AveragePoo (None, 3, 3, 528)    0           concatenate_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_53 (Conv2D)              (None, 5, 5, 384)    319872      concatenate_7[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_55 (Conv2D)              (None, 5, 5, 384)    663936      conv2d_54[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_57 (Conv2D)              (None, 5, 5, 128)    153728      conv2d_56[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_58 (Conv2D)              (None, 5, 5, 128)    106624      max_pooling2d_12[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_21 (Conv2D)              (None, 3, 3, 128)    65664       average_pooling2d[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_40 (Conv2D)              (None, 3, 3, 128)    67712       average_pooling2d_1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_8 (Concatenate)     (None, 5, 5, 1024)   0           conv2d_53[0][0]                  \n",
      "                                                                 conv2d_55[0][0]                  \n",
      "                                                                 conv2d_57[0][0]                  \n",
      "                                                                 conv2d_58[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 1152)         0           conv2d_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 1152)         0           conv2d_40[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "GAPL (GlobalAveragePooling2D)   (None, 1024)         0           concatenate_8[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 1024)         1180672     flatten[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 1024)         1180672     flatten_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 1024)         0           GAPL[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 1024)         0           dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 1024)         0           dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 1000)         1025000     dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 10)           10250       dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 1000)         1025000     dropout_1[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 10,522,250\n",
      "Trainable params: 10,522,250\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-30 16:44:43.092151: I tensorflow/core/grappler/devices.cc:66] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0\n",
      "2022-03-30 16:44:43.092302: I tensorflow/core/grappler/clusters/single_machine.cc:357] Starting new session\n",
      "2022-03-30 16:44:43.122560: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:1137] Optimization results for grappler item: graph_to_optimize\n",
      "  function_optimizer: function_optimizer did nothing. time = 0.018ms.\n",
      "  function_optimizer: function_optimizer did nothing. time = 0.002ms.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /opt/vitis_ai/conda/envs/vitis-ai-tensorflow2/lib/python3.7/site-packages/tensorflow/python/ops/nn_ops.py:5063: tensor_shape_from_node_def_name (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.compat.v1.graph_util.tensor_shape_from_node_def_name`\n",
      "\n",
      "=========================Options=============================\n",
      "-max_depth                  10000\n",
      "-min_bytes                  0\n",
      "-min_peak_bytes             0\n",
      "-min_residual_bytes         0\n",
      "-min_output_bytes           0\n",
      "-min_micros                 0\n",
      "-min_accelerator_micros     0\n",
      "-min_cpu_micros             0\n",
      "-min_params                 0\n",
      "-min_float_ops              1\n",
      "-min_occurrence             0\n",
      "-step                       -1\n",
      "-order_by                   float_ops\n",
      "-account_type_regexes       .*\n",
      "-start_name_regexes         .*\n",
      "-trim_name_regexes          \n",
      "-show_name_regexes          .*\n",
      "-hide_name_regexes          \n",
      "-account_displayed_op_only  true\n",
      "-select                     float_ops\n",
      "-output                     stdout:\n",
      "\n",
      "==================Model Analysis Report======================\n",
      "\n",
      "Doc:\n",
      "scope: The nodes in the model graph are organized by their names, which is hierarchical like filesystem.\n",
      "flops: Number of float operations. Note: Please read the implementation for the math behind it.\n",
      "\n",
      "Profile:\n",
      "node name | # float_ops\n",
      "_TFProfRoot (--/2.45b flops)\n",
      "  GoogLeNet/conv2d_2/Conv2D (644.97m/644.97m flops)\n",
      "  GoogLeNet/conv2d_11/Conv2D (299.04m/299.04m flops)\n",
      "  GoogLeNet/conv2d_5/Conv2D (149.52m/149.52m flops)\n",
      "  GoogLeNet/conv2d_43/Conv2D (132.71m/132.71m flops)\n",
      "  GoogLeNet/conv2d_36/Conv2D (107.50m/107.50m flops)\n",
      "  GoogLeNet/conv2d_13/Conv2D (103.83m/103.83m flops)\n",
      "  GoogLeNet/conv2d_30/Conv2D (84.93m/84.93m flops)\n",
      "  GoogLeNet/conv2d/Conv2D (74.52m/74.52m flops)\n",
      "  GoogLeNet/conv2d_24/Conv2D (65.03m/65.03m flops)\n",
      "  GoogLeNet/conv2d_17/Conv2D (51.76m/51.76m flops)\n",
      "  GoogLeNet/conv2d_9/Conv2D (44.30m/44.30m flops)\n",
      "  GoogLeNet/conv2d_10/Conv2D (44.30m/44.30m flops)\n",
      "  GoogLeNet/conv2d_41/Conv2D (38.93m/38.93m flops)\n",
      "  GoogLeNet/conv2d_55/Conv2D (33.18m/33.18m flops)\n",
      "  GoogLeNet/conv2d_45/Conv2D (29.49m/29.49m flops)\n",
      "  GoogLeNet/conv2d_15/Conv2D (26.54m/26.54m flops)\n",
      "  GoogLeNet/conv2d_4/Conv2D (24.92m/24.92m flops)\n",
      "  GoogLeNet/conv2d_42/Conv2D (24.33m/24.33m flops)\n",
      "  GoogLeNet/conv2d_1/Conv2D (23.89m/23.89m flops)\n",
      "  GoogLeNet/conv2d_22/Conv2D (23.59m/23.59m flops)\n",
      "  GoogLeNet/conv2d_49/Conv2D (23.04m/23.04m flops)\n",
      "  GoogLeNet/conv2d_14/Conv2D (22.15m/22.15m flops)\n",
      "  GoogLeNet/conv2d_35/Conv2D (21.23m/21.23m flops)\n",
      "  GoogLeNet/conv2d_46/Conv2D (19.46m/19.46m flops)\n",
      "  GoogLeNet/conv2d_28/Conv2D (18.87m/18.87m flops)\n",
      "  GoogLeNet/conv2d_29/Conv2D (18.87m/18.87m flops)\n",
      "  GoogLeNet/conv2d_7/Conv2D (17.31m/17.31m flops)\n",
      "  GoogLeNet/conv2d_3/Conv2D (16.61m/16.61m flops)\n",
      "  GoogLeNet/conv2d_23/Conv2D (16.52m/16.52m flops)\n",
      "  GoogLeNet/conv2d_34/Conv2D (16.52m/16.52m flops)\n",
      "  GoogLeNet/conv2d_53/Conv2D (15.97m/15.97m flops)\n",
      "  GoogLeNet/conv2d_38/Conv2D (14.75m/14.75m flops)\n",
      "  GoogLeNet/conv2d_16/Conv2D (13.27m/13.27m flops)\n",
      "  GoogLeNet/conv2d_12/Conv2D (11.08m/11.08m flops)\n",
      "  GoogLeNet/conv2d_32/Conv2D (11.06m/11.06m flops)\n",
      "  GoogLeNet/conv2d_26/Conv2D (11.06m/11.06m flops)\n",
      "  GoogLeNet/conv2d_47/Conv2D (10.65m/10.65m flops)\n",
      "  GoogLeNet/conv2d_33/Conv2D (9.44m/9.44m flops)\n",
      "  GoogLeNet/conv2d_39/Conv2D (9.44m/9.44m flops)\n",
      "  GoogLeNet/conv2d_27/Conv2D (9.44m/9.44m flops)\n",
      "  GoogLeNet/conv2d_20/Conv2D (8.85m/8.85m flops)\n",
      "  GoogLeNet/conv2d_8/Conv2D (8.31m/8.31m flops)\n",
      "  GoogLeNet/conv2d_54/Conv2D (7.99m/7.99m flops)\n",
      "  GoogLeNet/conv2d_57/Conv2D (7.68m/7.68m flops)\n",
      "  GoogLeNet/conv2d_48/Conv2D (6.66m/6.66m flops)\n",
      "  GoogLeNet/conv2d_19/Conv2D (5.53m/5.53m flops)\n",
      "  GoogLeNet/conv2d_58/Conv2D (5.32m/5.32m flops)\n",
      "  GoogLeNet/conv2d_52/Conv2D (5.32m/5.32m flops)\n",
      "  GoogLeNet/conv2d_51/Conv2D (5.12m/5.12m flops)\n",
      "  GoogLeNet/conv2d_44/Conv2D (4.87m/4.87m flops)\n",
      "  GoogLeNet/conv2d_37/Conv2D (4.72m/4.72m flops)\n",
      "  GoogLeNet/conv2d_6/Conv2D (4.15m/4.15m flops)\n",
      "  GoogLeNet/conv2d_25/Conv2D (3.54m/3.54m flops)\n",
      "  GoogLeNet/conv2d_31/Conv2D (3.54m/3.54m flops)\n",
      "  GoogLeNet/dense/MatMul (2.36m/2.36m flops)\n",
      "  GoogLeNet/dense_2/MatMul (2.36m/2.36m flops)\n",
      "  GoogLeNet/conv2d_18/Conv2D (2.21m/2.21m flops)\n",
      "  GoogLeNet/dense_3/MatMul (2.05m/2.05m flops)\n",
      "  GoogLeNet/dense_4/MatMul (2.05m/2.05m flops)\n",
      "  GoogLeNet/conv2d_56/Conv2D (2.00m/2.00m flops)\n",
      "  GoogLeNet/max_pooling2d/MaxPool (1.68m/1.68m flops)\n",
      "  GoogLeNet/max_pooling2d_3/MaxPool (1.56m/1.56m flops)\n",
      "  GoogLeNet/conv2d_50/Conv2D (1.33m/1.33m flops)\n",
      "  GoogLeNet/conv2d_40/Conv2D (1.22m/1.22m flops)\n",
      "  GoogLeNet/conv2d_21/Conv2D (1.18m/1.18m flops)\n",
      "  GoogLeNet/max_pooling2d_1/MaxPool (1.17m/1.17m flops)\n",
      "  GoogLeNet/max_pooling2d_2/MaxPool (1.17m/1.17m flops)\n",
      "  GoogLeNet/conv2d/BiasAdd (760.38k/760.38k flops)\n",
      "  GoogLeNet/max_pooling2d_9/MaxPool (684.29k/684.29k flops)\n",
      "  GoogLeNet/max_pooling2d_7/MaxPool (663.55k/663.55k flops)\n",
      "  GoogLeNet/max_pooling2d_6/MaxPool (663.55k/663.55k flops)\n",
      "  GoogLeNet/max_pooling2d_8/MaxPool (663.55k/663.55k flops)\n",
      "  GoogLeNet/max_pooling2d_4/MaxPool (622.08k/622.08k flops)\n",
      "  GoogLeNet/max_pooling2d_5/MaxPool (622.08k/622.08k flops)\n",
      "  GoogLeNet/conv2d_2/BiasAdd (559.87k/559.87k flops)\n",
      "  GoogLeNet/max_pooling2d_12/MaxPool (187.20k/187.20k flops)\n",
      "  GoogLeNet/max_pooling2d_11/MaxPool (187.20k/187.20k flops)\n",
      "  GoogLeNet/max_pooling2d_10/MaxPool (187.20k/187.20k flops)\n",
      "  GoogLeNet/conv2d_1/BiasAdd (186.62k/186.62k flops)\n",
      "  GoogLeNet/conv2d_11/BiasAdd (129.79k/129.79k flops)\n",
      "  GoogLeNet/average_pooling2d_1/AvgPool (118.80k/118.80k flops)\n",
      "  GoogLeNet/average_pooling2d/AvgPool (115.20k/115.20k flops)\n",
      "  GoogLeNet/conv2d_10/BiasAdd (86.53k/86.53k flops)\n",
      "  GoogLeNet/conv2d_9/BiasAdd (86.53k/86.53k flops)\n",
      "  GoogLeNet/conv2d_5/BiasAdd (86.53k/86.53k flops)\n",
      "  GoogLeNet/conv2d_13/BiasAdd (64.90k/64.90k flops)\n",
      "  GoogLeNet/conv2d_4/BiasAdd (64.90k/64.90k flops)\n",
      "  GoogLeNet/conv2d_43/BiasAdd (46.08k/46.08k flops)\n",
      "  GoogLeNet/conv2d_14/BiasAdd (43.26k/43.26k flops)\n",
      "  GoogLeNet/conv2d_3/BiasAdd (43.26k/43.26k flops)\n",
      "  GoogLeNet/conv2d_36/BiasAdd (41.47k/41.47k flops)\n",
      "  GoogLeNet/conv2d_41/BiasAdd (36.86k/36.86k flops)\n",
      "  GoogLeNet/conv2d_30/BiasAdd (36.86k/36.86k flops)\n",
      "  GoogLeNet/conv2d_24/BiasAdd (32.26k/32.26k flops)\n",
      "  GoogLeNet/conv2d_17/BiasAdd (29.95k/29.95k flops)\n",
      "  GoogLeNet/conv2d_15/BiasAdd (27.65k/27.65k flops)\n",
      "  GoogLeNet/GAPL/Mean (25.60k/25.60k flops)\n",
      "  GoogLeNet/conv2d_22/BiasAdd (23.04k/23.04k flops)\n",
      "  GoogLeNet/conv2d_42/BiasAdd (23.04k/23.04k flops)\n",
      "  GoogLeNet/conv2d_12/BiasAdd (21.63k/21.63k flops)\n",
      "  GoogLeNet/conv2d_8/BiasAdd (21.63k/21.63k flops)\n",
      "  GoogLeNet/conv2d_7/BiasAdd (21.63k/21.63k flops)\n",
      "  GoogLeNet/conv2d_35/BiasAdd (20.74k/20.74k flops)\n",
      "  GoogLeNet/dense_1/MatMul (20.48k/20.48k flops)\n",
      "  GoogLeNet/conv2d_45/BiasAdd (18.43k/18.43k flops)\n",
      "  GoogLeNet/conv2d_28/BiasAdd (18.43k/18.43k flops)\n",
      "  GoogLeNet/conv2d_29/BiasAdd (18.43k/18.43k flops)\n",
      "  GoogLeNet/conv2d_46/BiasAdd (18.43k/18.43k flops)\n",
      "  GoogLeNet/conv2d_34/BiasAdd (16.13k/16.13k flops)\n",
      "  GoogLeNet/conv2d_23/BiasAdd (16.13k/16.13k flops)\n",
      "  GoogLeNet/conv2d_16/BiasAdd (13.82k/13.82k flops)\n",
      "  GoogLeNet/conv2d_6/BiasAdd (10.82k/10.82k flops)\n",
      "  GoogLeNet/conv2d_55/BiasAdd (9.60k/9.60k flops)\n",
      "  GoogLeNet/conv2d_53/BiasAdd (9.60k/9.60k flops)\n",
      "  GoogLeNet/conv2d_32/BiasAdd (9.22k/9.22k flops10.52\n",
      "2.45\n",
      ")\n",
      "  GoogLeNet/conv2d_33/BiasAdd (9.22k/9.22k flops)\n",
      "  GoogLeNet/conv2d_39/BiasAdd (9.22k/9.22k flops)\n",
      "  GoogLeNet/conv2d_38/BiasAdd (9.22k/9.22k flops)\n",
      "  GoogLeNet/conv2d_27/BiasAdd (9.22k/9.22k flops)\n",
      "  GoogLeNet/conv2d_20/BiasAdd (9.22k/9.22k flops)\n",
      "  GoogLeNet/conv2d_26/BiasAdd (9.22k/9.22k flops)\n",
      "  GoogLeNet/conv2d_49/BiasAdd (8.00k/8.00k flops)\n",
      "  GoogLeNet/conv2d_19/BiasAdd (6.91k/6.91k flops)\n",
      "  GoogLeNet/conv2d_47/BiasAdd (6.40k/6.40k flops)\n",
      "  GoogLeNet/dense_4/Softmax (5.00k/5.00k flops)\n",
      "  GoogLeNet/dense_3/Softmax (5.00k/5.00k flops)\n",
      "  GoogLeNet/conv2d_54/BiasAdd (4.80k/4.80k flops)\n",
      "  GoogLeNet/conv2d_44/BiasAdd (4.61k/4.61k flops)\n",
      "  GoogLeNet/conv2d_37/BiasAdd (4.61k/4.61k flops)\n",
      "  GoogLeNet/conv2d_48/BiasAdd (4.00k/4.00k flops)\n",
      "  GoogLeNet/conv2d_25/BiasAdd (3.46k/3.46k flops)\n",
      "  GoogLeNet/conv2d_31/BiasAdd (3.46k/3.46k flops)\n",
      "  GoogLeNet/conv2d_51/BiasAdd (3.20k/3.20k flops)\n",
      "  GoogLeNet/conv2d_52/BiasAdd (3.20k/3.20k flops)\n",
      "  GoogLeNet/conv2d_57/BiasAdd (3.20k/3.20k flops)\n",
      "  GoogLeNet/conv2d_58/BiasAdd (3.20k/3.20k flops)\n",
      "  GoogLeNet/conv2d_18/BiasAdd (2.30k/2.30k flops)\n",
      "  GoogLeNet/conv2d_56/BiasAdd (1.20k/1.20k flops)\n",
      "  GoogLeNet/conv2d_40/BiasAdd (1.15k/1.15k flops)\n",
      "  GoogLeNet/conv2d_21/BiasAdd (1.15k/1.15k flops)\n",
      "  GoogLeNet/dense/BiasAdd (1.02k/1.02k flops)\n",
      "  GoogLeNet/dense_2/BiasAdd (1.02k/1.02k flops)\n",
      "  GoogLeNet/dense_4/BiasAdd (1.00k/1.00k flops)\n",
      "  GoogLeNet/dense_3/BiasAdd (1.00k/1.00k flops)\n",
      "  GoogLeNet/conv2d_50/BiasAdd (800/800 flops)\n",
      "  GoogLeNet/dense_1/Softmax (50/50 flops)\n",
      "  GoogLeNet/dense_1/BiasAdd (10/10 flops)\n",
      "\n",
      "======================End of Report==========================\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Input, Conv2D, MaxPooling2D, AveragePooling2D, Flatten, GlobalAveragePooling2D, Dense, Dropout\n",
    "from keras.layers.merge import concatenate\n",
    "from keras_flops import get_flops\n",
    "import numpy as np\n",
    "import os\n",
    "from tensorflow_model_optimization.quantization.keras import vitis_quantize\n",
    "shape_x = 224\n",
    "shape_y = 224\n",
    "\n",
    "X_train=np.random.randint(0,255,size=[60,shape_x,shape_y,1])\n",
    "Y_train=np.random.randint(0,10,size=[60,])\n",
    "X_test=np.random.randint(0,255,size=[60,shape_x,shape_y,1])\n",
    "Y_test=np.random.randint(0,10,size=[60,])\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "X_train /= 255.0\n",
    "X_test /= 255.0\n",
    "\n",
    "nRows,nCols,nDims = X_train.shape[1:]\n",
    "input_shape = (nRows, nCols, nDims)\n",
    "classes = np.unique(Y_train)\n",
    "nClasses = len(classes)\n",
    "print(input_shape)\n",
    "print(classes)\n",
    "def Inception_block(input_layer, f1, f2_conv1, f2_conv3, f3_conv1, f3_conv5, f4): \n",
    "  # Input: \n",
    "  # - f1: number of filters of the 1x1 convolutional layer in the first path\n",
    "  # - f2_conv1, f2_conv3 are number of filters corresponding to the 1x1 and 3x3 convolutional layers in the second path\n",
    "  # - f3_conv1, f3_conv5 are the number of filters corresponding to the 1x1 and 5x5  convolutional layer in the third path\n",
    "  # - f4: number of filters of the 1x1 convolutional layer in the fourth path\n",
    "\n",
    "  # 1st path:\n",
    "  path1 = Conv2D(filters=f1, kernel_size = (1,1), padding = 'same', activation = 'relu')(input_layer)\n",
    "\n",
    "  # 2nd path\n",
    "  path2 = Conv2D(filters = f2_conv1, kernel_size = (1,1), padding = 'same', activation = 'relu')(input_layer)\n",
    "  path2 = Conv2D(filters = f2_conv3, kernel_size = (3,3), padding = 'same', activation = 'relu')(path2)\n",
    "\n",
    "  # 3rd path\n",
    "  path3 = Conv2D(filters = f3_conv1, kernel_size = (1,1), padding = 'same', activation = 'relu')(input_layer)\n",
    "  path3 = Conv2D(filters = f3_conv5, kernel_size = (5,5), padding = 'same', activation = 'relu')(path3)\n",
    "\n",
    "  # 4th path\n",
    "  path4 = MaxPooling2D((3,3), strides= (1,1), padding = 'same')(input_layer)\n",
    "  path4 = Conv2D(filters = f4, kernel_size = (1,1), padding = 'same', activation = 'relu')(path4)\n",
    "\n",
    "  output_layer = concatenate([path1, path2, path3, path4], axis = -1)\n",
    "\n",
    "  return output_layer\n",
    "\n",
    "def GoogLeNet(input_shape):\n",
    "  # input layer \n",
    "  input_layer = Input(input_shape)\n",
    "\n",
    "  # convolutional layer: filters = 64, kernel_size = (7,7), strides = 2\n",
    "  X = Conv2D(filters = 64, kernel_size = (7,7), strides = 2, padding = 'valid', activation = 'relu')(input_layer)\n",
    "\n",
    "  # max-pooling layer: pool_size = (3,3), strides = 2\n",
    "  X = MaxPooling2D(pool_size = (3,3), strides = 2)(X)\n",
    "\n",
    "  # convolutional layer: filters = 64, strides = 1\n",
    "  X = Conv2D(filters = 64, kernel_size = (1,1), strides = 1, padding = 'same', activation = 'relu')(X)\n",
    "\n",
    "  # convolutional layer: filters = 192, kernel_size = (3,3)\n",
    "  X = Conv2D(filters = 192, kernel_size = (3,3), padding = 'same', activation = 'relu')(X)\n",
    "\n",
    "  # max-pooling layer: pool_size = (3,3), strides = 2\n",
    "  X = MaxPooling2D(pool_size= (3,3), strides = 2)(X)\n",
    "\n",
    "  # 1st Inception block\n",
    "  X = Inception_block(X, f1 = 64, f2_conv1 = 96, f2_conv3 = 128, f3_conv1 = 16, f3_conv5 = 32, f4 = 32)\n",
    "\n",
    "  # 2nd Inception block\n",
    "  X = Inception_block(X, f1 = 128, f2_conv1 = 128, f2_conv3 = 192, f3_conv1 = 32, f3_conv5 = 96, f4 = 64)\n",
    "\n",
    "  # max-pooling layer: pool_size = (3,3), strides = 2\n",
    "  X = MaxPooling2D(pool_size= (3,3), strides = 2)(X)\n",
    "\n",
    "  # 3rd Inception block\n",
    "  X = Inception_block(X, f1 = 192, f2_conv1 = 96, f2_conv3 = 208, f3_conv1 = 16, f3_conv5 = 48, f4 = 64)\n",
    "\n",
    "  # Extra network 1:\n",
    "  X1 = AveragePooling2D(pool_size = (5,5), strides = 3)(X)\n",
    "  X1 = Conv2D(filters = 128, kernel_size = (1,1), padding = 'same', activation = 'relu')(X1)\n",
    "  X1 = Flatten()(X1)\n",
    "  X1 = Dense(1024, activation = 'relu')(X1)\n",
    "  X1 = Dropout(0.7)(X1)\n",
    "  X1 = Dense(10, activation = 'softmax')(X1)\n",
    "\n",
    "  \n",
    "  # 4th Inception block\n",
    "  X = Inception_block(X, f1 = 160, f2_conv1 = 112, f2_conv3 = 224, f3_conv1 = 24, f3_conv5 = 64, f4 = 64)\n",
    "\n",
    "  # 5th Inception block\n",
    "  X = Inception_block(X, f1 = 128, f2_conv1 = 128, f2_conv3 = 256, f3_conv1 = 24, f3_conv5 = 64, f4 = 64)\n",
    "\n",
    "  # 6th Inception block\n",
    "  X = Inception_block(X, f1 = 112, f2_conv1 = 144, f2_conv3 = 288, f3_conv1 = 32, f3_conv5 = 64, f4 = 64)\n",
    "\n",
    "  # Extra network 2:\n",
    "  X2 = AveragePooling2D(pool_size = (5,5), strides = 3)(X)\n",
    "  X2 = Conv2D(filters = 128, kernel_size = (1,1), padding = 'same', activation = 'relu')(X2)\n",
    "  X2 = Flatten()(X2)\n",
    "  X2 = Dense(1024, activation = 'relu')(X2)\n",
    "  X2 = Dropout(0.7)(X2)\n",
    "  X2 = Dense(1000, activation = 'softmax')(X2)\n",
    "  \n",
    "  \n",
    "  # 7th Inception block\n",
    "  X = Inception_block(X, f1 = 256, f2_conv1 = 160, f2_conv3 = 320, f3_conv1 = 32, \n",
    "                      f3_conv5 = 128, f4 = 128)\n",
    "\n",
    "  # max-pooling layer: pool_size = (3,3), strides = 2\n",
    "  X = MaxPooling2D(pool_size = (3,3), strides = 2)(X)\n",
    "\n",
    "  # 8th Inception block\n",
    "  X = Inception_block(X, f1 = 256, f2_conv1 = 160, f2_conv3 = 320, f3_conv1 = 32, f3_conv5 = 128, f4 = 128)\n",
    "\n",
    "  # 9th Inception block\n",
    "  X = Inception_block(X, f1 = 384, f2_conv1 = 192, f2_conv3 = 384, f3_conv1 = 48, f3_conv5 = 128, f4 = 128)\n",
    "\n",
    "  # Global Average pooling layer \n",
    "  X = GlobalAveragePooling2D(name = 'GAPL')(X)\n",
    "\n",
    "  # Dropoutlayer \n",
    "  X = Dropout(0.4)(X)\n",
    "\n",
    "  # output layer \n",
    " \n",
    "  X = Dense(1000, activation = 'softmax')(X)\n",
    "  \n",
    "  # model\n",
    "  model = Model(input_layer, [X, X1, X2], name = 'GoogLeNet')\n",
    "\n",
    "  return model\n",
    "input_shape = (shape_x, shape_y, 1)\n",
    "model = GoogLeNet(input_shape)\n",
    "model.summary()\n",
    "Total_params = round(model.count_params()/10 ** 6,2)\n",
    "FLOPs = round(get_flops(model, batch_size=1)/10 ** 9,2)\n",
    "print(Total_params)\n",
    "print(FLOPs)\n",
    "\n",
    "# model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "# history = model.fit(X_train, Y_train, epochs=1)\n",
    "# model.get_weights()[0].dtype\n",
    "# quantizer = vitis_quantize.VitisQuantizer(model)\n",
    "# quantized_model = quantizer.quantize_model(calib_dataset = X_test[1:8], weight_bit=8, activation_bit=8)\n",
    "# quantized_model.compile(loss='sparse_categorical_crossentropy', metrics=[\"accuracy\"])\n",
    "# quantized_model.save('tf2_mnist_classifier_quantized.h5')\n",
    "# !vai_c_tensorflow2 \\\n",
    "# --model ./tf2_mnist_classifier_quantized.h5 \\\n",
    "# --arch ./arch.json \\\n",
    "# --output_dir ./xmodel_GoogLeNet \\\n",
    "# --net_name deploy\n",
    "# os.rename(\"./xmodel_GoogLeNet/deploy.xmodel\",\"./xmodel_GoogLeNet/GoogLeNet_{shape_x}_{shape_y}.xmodel\".format(shape_x=shape_x,shape_y=shape_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c644ec09",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-31 07:20:46.301447: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/xilinx/xrt/lib:/usr/lib:/usr/lib/x86_64-linux-gnu:/usr/local/lib:/opt/vitis_ai/conda/envs/vitis-ai-tensorflow/lib\n",
      "2022-03-31 07:20:46.301480: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2022-03-31 07:20:47.385332: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/xilinx/xrt/lib:/usr/lib:/usr/lib/x86_64-linux-gnu:/usr/local/lib:/opt/vitis_ai/conda/envs/vitis-ai-tensorflow/lib\n",
      "2022-03-31 07:20:47.385364: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2022-03-31 07:20:47.385382: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:163] no NVIDIA GPU device is present: /dev/nvidia0 does not exist\n",
      "2022-03-31 07:20:47.385522: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Negative dimension size caused by subtracting 5 from 4 for '{{node average_pooling2d/AvgPool}} = AvgPool[T=DT_FLOAT, data_format=\"NHWC\", ksize=[1, 5, 5, 1], padding=\"VALID\", strides=[1, 3, 3, 1]](Placeholder)' with input shapes: [?,4,4,512].",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m/opt/vitis_ai/conda/envs/vitis-ai-tensorflow2/lib/python3.7/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_create_c_op\u001b[0;34m(graph, node_def, inputs, control_inputs, op_def)\u001b[0m\n\u001b[1;32m   1879\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1880\u001b[0;31m     \u001b[0mc_op\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpywrap_tf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_FinishOperation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop_desc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1881\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInvalidArgumentError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Negative dimension size caused by subtracting 5 from 4 for '{{node average_pooling2d/AvgPool}} = AvgPool[T=DT_FLOAT, data_format=\"NHWC\", ksize=[1, 5, 5, 1], padding=\"VALID\", strides=[1, 3, 3, 1]](Placeholder)' with input shapes: [?,4,4,512].",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_239/907787938.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    136\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m     \u001b[0minput_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mshape_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 138\u001b[0;31m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGoogLeNet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    139\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m \u001b[0;31m# Total_params = round(model.count_params()/10 ** 6,2)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_239/907787938.py\u001b[0m in \u001b[0;36mGoogLeNet\u001b[0;34m(input_shape)\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m   \u001b[0;31m# Extra network 1:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 68\u001b[0;31m   \u001b[0mX1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAveragePooling2D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpool_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstrides\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     69\u001b[0m   \u001b[0mX1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mConv2D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilters\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'same'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'relu'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m   \u001b[0mX1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFlatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/vitis_ai/conda/envs/vitis-ai-tensorflow2/lib/python3.7/site-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    975\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_in_functional_construction_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    976\u001b[0m       return self._functional_construction_call(inputs, args, kwargs,\n\u001b[0;32m--> 977\u001b[0;31m                                                 input_list)\n\u001b[0m\u001b[1;32m    978\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    979\u001b[0m     \u001b[0;31m# Maintains info about the `Layer.call` stack.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/vitis_ai/conda/envs/vitis-ai-tensorflow2/lib/python3.7/site-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m_functional_construction_call\u001b[0;34m(self, inputs, args, kwargs, input_list)\u001b[0m\n\u001b[1;32m   1113\u001b[0m       \u001b[0;31m# Check input assumptions set after layer building, e.g. input shape.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1114\u001b[0m       outputs = self._keras_tensor_symbolic_call(\n\u001b[0;32m-> 1115\u001b[0;31m           inputs, input_masks, args, kwargs)\n\u001b[0m\u001b[1;32m   1116\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1117\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0moutputs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/vitis_ai/conda/envs/vitis-ai-tensorflow2/lib/python3.7/site-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m_keras_tensor_symbolic_call\u001b[0;34m(self, inputs, input_masks, args, kwargs)\u001b[0m\n\u001b[1;32m    846\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeras_tensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mKerasTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_signature\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    847\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 848\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_infer_output_signature\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_masks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    849\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    850\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_infer_output_signature\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_masks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/vitis_ai/conda/envs/vitis-ai-tensorflow2/lib/python3.7/site-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m_infer_output_signature\u001b[0;34m(self, inputs, args, kwargs, input_masks)\u001b[0m\n\u001b[1;32m    886\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_build\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    887\u001b[0m           \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_cast_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 888\u001b[0;31m           \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    889\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    890\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle_activity_regularization\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/vitis_ai/conda/envs/vitis-ai-tensorflow2/lib/python3.7/site-packages/keras/layers/pooling.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    358\u001b[0m         \u001b[0mstrides\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstrides\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    359\u001b[0m         \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpadding\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 360\u001b[0;31m         data_format=conv_utils.convert_data_format(self.data_format, 4))\n\u001b[0m\u001b[1;32m    361\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    362\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/vitis_ai/conda/envs/vitis-ai-tensorflow2/lib/python3.7/site-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    204\u001b[0m     \u001b[0;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 206\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    207\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m       \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/vitis_ai/conda/envs/vitis-ai-tensorflow2/lib/python3.7/site-packages/tensorflow/python/ops/nn_ops.py\u001b[0m in \u001b[0;36mavg_pool_v2\u001b[0;34m(input, ksize, strides, padding, data_format, name)\u001b[0m\n\u001b[1;32m   4413\u001b[0m       \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpadding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4414\u001b[0m       \u001b[0mdata_format\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata_format\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4415\u001b[0;31m       name=name)\n\u001b[0m\u001b[1;32m   4416\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4417\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/vitis_ai/conda/envs/vitis-ai-tensorflow2/lib/python3.7/site-packages/tensorflow/python/ops/gen_nn_ops.py\u001b[0m in \u001b[0;36mavg_pool\u001b[0;34m(value, ksize, strides, padding, data_format, name)\u001b[0m\n\u001b[1;32m     83\u001b[0m   _, _, _op, _outputs = _op_def_library._apply_op_helper(\n\u001b[1;32m     84\u001b[0m         \u001b[0;34m\"AvgPool\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mksize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mksize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstrides\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstrides\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpadding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 85\u001b[0;31m                    data_format=data_format, name=name)\n\u001b[0m\u001b[1;32m     86\u001b[0m   \u001b[0m_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0m_execute\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmust_record_gradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/vitis_ai/conda/envs/vitis-ai-tensorflow2/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py\u001b[0m in \u001b[0;36m_apply_op_helper\u001b[0;34m(op_type_name, name, **keywords)\u001b[0m\n\u001b[1;32m    748\u001b[0m       op = g._create_op_internal(op_type_name, inputs, dtypes=None,\n\u001b[1;32m    749\u001b[0m                                  \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscope\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_types\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_types\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 750\u001b[0;31m                                  attrs=attr_protos, op_def=op_def)\n\u001b[0m\u001b[1;32m    751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    752\u001b[0m     \u001b[0;31m# `outputs` is returned as a separate return value so that the output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/vitis_ai/conda/envs/vitis-ai-tensorflow2/lib/python3.7/site-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36m_create_op_internal\u001b[0;34m(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_device)\u001b[0m\n\u001b[1;32m    599\u001b[0m     return super(FuncGraph, self)._create_op_internal(  # pylint: disable=protected-access\n\u001b[1;32m    600\u001b[0m         \u001b[0mop_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtypes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_types\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop_def\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 601\u001b[0;31m         compute_device)\n\u001b[0m\u001b[1;32m    602\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    603\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mcapture\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/vitis_ai/conda/envs/vitis-ai-tensorflow2/lib/python3.7/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_create_op_internal\u001b[0;34m(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_device)\u001b[0m\n\u001b[1;32m   3567\u001b[0m           \u001b[0minput_types\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_types\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3568\u001b[0m           \u001b[0moriginal_op\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_default_original_op\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3569\u001b[0;31m           op_def=op_def)\n\u001b[0m\u001b[1;32m   3570\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_op_helper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompute_device\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcompute_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3571\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/vitis_ai/conda/envs/vitis-ai-tensorflow2/lib/python3.7/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, node_def, g, inputs, output_types, control_inputs, input_types, original_op, op_def)\u001b[0m\n\u001b[1;32m   2040\u001b[0m         \u001b[0mop_def\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_op_def\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2041\u001b[0m       self._c_op = _create_c_op(self._graph, node_def, inputs,\n\u001b[0;32m-> 2042\u001b[0;31m                                 control_input_ops, op_def)\n\u001b[0m\u001b[1;32m   2043\u001b[0m       \u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_str\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2044\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/vitis_ai/conda/envs/vitis-ai-tensorflow2/lib/python3.7/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_create_c_op\u001b[0;34m(graph, node_def, inputs, control_inputs, op_def)\u001b[0m\n\u001b[1;32m   1881\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInvalidArgumentError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1882\u001b[0m     \u001b[0;31m# Convert to ValueError for backwards compatibility.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1883\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1884\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1885\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mc_op\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Negative dimension size caused by subtracting 5 from 4 for '{{node average_pooling2d/AvgPool}} = AvgPool[T=DT_FLOAT, data_format=\"NHWC\", ksize=[1, 5, 5, 1], padding=\"VALID\", strides=[1, 3, 3, 1]](Placeholder)' with input shapes: [?,4,4,512]."
     ]
    }
   ],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Input, Conv2D, MaxPooling2D, AveragePooling2D, Flatten, GlobalAveragePooling2D, Dense, Dropout\n",
    "from keras.layers.merge import concatenate\n",
    "#from keras_flops import get_flops\n",
    "import numpy as np\n",
    "import os\n",
    "from tensorflow_model_optimization.quantization.keras import vitis_quantize\n",
    "\n",
    "\n",
    "def Inception_block(input_layer, f1, f2_conv1, f2_conv3, f3_conv1, f3_conv5, f4): \n",
    "  # Input: \n",
    "  # - f1: number of filters of the 1x1 convolutional layer in the first path\n",
    "  # - f2_conv1, f2_conv3 are number of filters corresponding to the 1x1 and 3x3 convolutional layers in the second path\n",
    "  # - f3_conv1, f3_conv5 are the number of filters corresponding to the 1x1 and 5x5  convolutional layer in the third path\n",
    "  # - f4: number of filters of the 1x1 convolutional layer in the fourth path\n",
    "\n",
    "  # 1st path:\n",
    "  path1 = Conv2D(filters=f1, kernel_size = (1,1), padding = 'same', activation = 'relu')(input_layer)\n",
    "\n",
    "  # 2nd path\n",
    "  path2 = Conv2D(filters = f2_conv1, kernel_size = (1,1), padding = 'same', activation = 'relu')(input_layer)\n",
    "  path2 = Conv2D(filters = f2_conv3, kernel_size = (3,3), padding = 'same', activation = 'relu')(path2)\n",
    "\n",
    "  # 3rd path\n",
    "  path3 = Conv2D(filters = f3_conv1, kernel_size = (1,1), padding = 'same', activation = 'relu')(input_layer)\n",
    "  path3 = Conv2D(filters = f3_conv5, kernel_size = (5,5), padding = 'same', activation = 'relu')(path3)\n",
    "\n",
    "  # 4th path\n",
    "  path4 = MaxPooling2D((3,3), strides= (1,1), padding = 'same')(input_layer)\n",
    "  path4 = Conv2D(filters = f4, kernel_size = (1,1), padding = 'same', activation = 'relu')(path4)\n",
    "\n",
    "  output_layer = concatenate([path1, path2, path3, path4], axis = -1)\n",
    "\n",
    "  return output_layer\n",
    "\n",
    "def GoogLeNet(input_shape):\n",
    "  # input layer \n",
    "  input_layer = Input(input_shape)\n",
    "\n",
    "  # convolutional layer: filters = 64, kernel_size = (7,7), strides = 2\n",
    "  X = Conv2D(filters = 64, kernel_size = (7,7), strides = 2, padding = 'valid', activation = 'relu')(input_layer)\n",
    "\n",
    "  # max-pooling layer: pool_size = (3,3), strides = 2\n",
    "  X = MaxPooling2D(pool_size = (3,3), strides = 2)(X)\n",
    "\n",
    "  # convolutional layer: filters = 64, strides = 1\n",
    "  X = Conv2D(filters = 64, kernel_size = (1,1), strides = 1, padding = 'same', activation = 'relu')(X)\n",
    "\n",
    "  # convolutional layer: filters = 192, kernel_size = (3,3)\n",
    "  X = Conv2D(filters = 192, kernel_size = (3,3), padding = 'same', activation = 'relu')(X)\n",
    "\n",
    "  # max-pooling layer: pool_size = (3,3), strides = 2\n",
    "  X = MaxPooling2D(pool_size= (3,3), strides = 2)(X)\n",
    "\n",
    "  # 1st Inception block\n",
    "  X = Inception_block(X, f1 = 64, f2_conv1 = 96, f2_conv3 = 128, f3_conv1 = 16, f3_conv5 = 32, f4 = 32)\n",
    "\n",
    "  # 2nd Inception block\n",
    "  X = Inception_block(X, f1 = 128, f2_conv1 = 128, f2_conv3 = 192, f3_conv1 = 32, f3_conv5 = 96, f4 = 64)\n",
    "\n",
    "  # max-pooling layer: pool_size = (3,3), strides = 2\n",
    "  X = MaxPooling2D(pool_size= (3,3), strides = 2)(X)\n",
    "\n",
    "  # 3rd Inception block\n",
    "  X = Inception_block(X, f1 = 192, f2_conv1 = 96, f2_conv3 = 208, f3_conv1 = 16, f3_conv5 = 48, f4 = 64)\n",
    "\n",
    "  # Extra network 1:\n",
    "  X1 = AveragePooling2D(pool_size = (5,5), strides = 3)(X)\n",
    "  X1 = Conv2D(filters = 128, kernel_size = (1,1), padding = 'same', activation = 'relu')(X1)\n",
    "  X1 = Flatten()(X1)\n",
    "  X1 = Dense(1024, activation = 'relu')(X1)\n",
    "  X1 = Dropout(0.7)(X1)\n",
    "  X1 = Dense(10, activation = 'softmax')(X1)\n",
    "\n",
    "  \n",
    "  # 4th Inception block\n",
    "  X = Inception_block(X, f1 = 160, f2_conv1 = 112, f2_conv3 = 224, f3_conv1 = 24, f3_conv5 = 64, f4 = 64)\n",
    "\n",
    "  # 5th Inception block\n",
    "  X = Inception_block(X, f1 = 128, f2_conv1 = 128, f2_conv3 = 256, f3_conv1 = 24, f3_conv5 = 64, f4 = 64)\n",
    "\n",
    "  # 6th Inception block\n",
    "  X = Inception_block(X, f1 = 112, f2_conv1 = 144, f2_conv3 = 288, f3_conv1 = 32, f3_conv5 = 64, f4 = 64)\n",
    "\n",
    "  # Extra network 2:\n",
    "  X2 = AveragePooling2D(pool_size = (5,5), strides = 3)(X)\n",
    "  X2 = Conv2D(filters = 128, kernel_size = (1,1), padding = 'same', activation = 'relu')(X2)\n",
    "  X2 = Flatten()(X2)\n",
    "  X2 = Dense(1024, activation = 'relu')(X2)\n",
    "  X2 = Dropout(0.7)(X2)\n",
    "  X2 = Dense(1000, activation = 'softmax')(X2)\n",
    "  \n",
    "  \n",
    "  # 7th Inception block\n",
    "  X = Inception_block(X, f1 = 256, f2_conv1 = 160, f2_conv3 = 320, f3_conv1 = 32, \n",
    "                      f3_conv5 = 128, f4 = 128)\n",
    "\n",
    "  # max-pooling layer: pool_size = (3,3), strides = 2\n",
    "  X = MaxPooling2D(pool_size = (3,3), strides = 2)(X)\n",
    "\n",
    "  # 8th Inception block\n",
    "  X = Inception_block(X, f1 = 256, f2_conv1 = 160, f2_conv3 = 320, f3_conv1 = 32, f3_conv5 = 128, f4 = 128)\n",
    "\n",
    "  # 9th Inception block\n",
    "  X = Inception_block(X, f1 = 384, f2_conv1 = 192, f2_conv3 = 384, f3_conv1 = 48, f3_conv5 = 128, f4 = 128)\n",
    "\n",
    "  # Global Average pooling layer \n",
    "  X = GlobalAveragePooling2D(name = 'GAPL')(X)\n",
    "\n",
    "  # Dropoutlayer \n",
    "  X = Dropout(0.4)(X)\n",
    "\n",
    "  # output layer \n",
    " \n",
    "  X = Dense(1000, activation = 'softmax')(X)\n",
    "  \n",
    "  # model\n",
    "  model = Model(input_layer, [X, X1, X2], name = 'GoogLeNet')\n",
    "\n",
    "  return model\n",
    "\n",
    "shape_range =range(96,224,32)\n",
    "for shape_x in shape_range:\n",
    "    shape_y = shape_x\n",
    "    X_train=np.random.randint(0,255,size=[60,shape_x,shape_y,1])\n",
    "    Y_train=np.random.randint(0,10,size=[60,])\n",
    "    X_test=np.random.randint(0,255,size=[60,shape_x,shape_y,1])\n",
    "    Y_test=np.random.randint(0,10,size=[60,])\n",
    "    X_train = X_train.astype('float32')\n",
    "    X_test = X_test.astype('float32')\n",
    "    X_train /= 255.0\n",
    "    X_test /= 255.0\n",
    "\n",
    "    classes = np.unique(Y_train)\n",
    "    nClasses = len(classes)\n",
    "    \n",
    "    input_shape = (shape_x, shape_y, 1)\n",
    "    model = GoogLeNet(input_shape)\n",
    "    model.summary()\n",
    "# Total_params = round(model.count_params()/10 ** 6,2)\n",
    "# FLOPs = round(get_flops(model, batch_size=1)/10 ** 9,2)\n",
    "# print(Total_params)\n",
    "# print(FLOPs)\n",
    "\n",
    "    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "    history = model.fit(X_train, Y_train, epochs=1)\n",
    "    model.get_weights()[0].dtype\n",
    "    quantizer = vitis_quantize.VitisQuantizer(model)\n",
    "    quantized_model = quantizer.quantize_model(calib_dataset = X_test[1:8], weight_bit=8, activation_bit=8)\n",
    "    quantized_model.compile(loss='sparse_categorical_crossentropy', metrics=[\"accuracy\"])\n",
    "    quantized_model.save('tf2_mnist_classifier_quantized.h5')\n",
    "    !vai_c_tensorflow2 \\\n",
    "    --model ./tf2_mnist_classifier_quantized.h5 \\\n",
    "    --arch ./arch.json \\\n",
    "    --output_dir ./xmodel_GoogLeNet \\\n",
    "    --net_name deploy\n",
    "    os.rename(\"./xmodel_GoogLeNet/deploy.xmodel\",\"./xmodel_GoogLeNet/GoogLeNet_{shape_x}_{shape_y}.xmodel\".format(shape_x=shape_x,shape_y=shape_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26463dee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b57e33fc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39d98be8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
