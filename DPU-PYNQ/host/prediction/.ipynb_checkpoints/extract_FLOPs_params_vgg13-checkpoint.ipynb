{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "40ed86f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-12 08:50:40.728647: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/xilinx/xrt/lib:/usr/lib:/usr/lib/x86_64-linux-gnu:/usr/local/lib:/opt/vitis_ai/conda/envs/vitis-ai-tensorflow/lib\n",
      "2022-04-12 08:50:40.728664: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'keras_flops'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_4836/3167290778.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mInput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mConv2D\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMaxPooling2D\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFlatten\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDense\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mZeroPadding2D\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDropout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mActivation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mitertools\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mproduct\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras_flops\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mget_flops\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'keras_flops'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import csv\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Conv2D, MaxPooling2D, Flatten, Dense, ZeroPadding2D, Dropout, Activation\n",
    "from itertools import product\n",
    "from keras_flops import get_flops\n",
    "\n",
    "\n",
    "model_num = 1\n",
    "input_shape_range =range(32,160,32)\n",
    "\n",
    "with open(\"para_count_vgg13.csv\",\"w\") as csvfile:\n",
    "         writer = csv.writer(csvfile)\n",
    "         writer.writerows([[\"model_num\", \"input_horizontal\", \"input_vertical\", \"FLOPs\", \"Total_params\", \"Memory\"],])\n",
    "          \n",
    "for shape_x in input_shape_range:\n",
    "    \n",
    "    shape_y = shape_x\n",
    "\n",
    "    inputs = Input(shape=(shape_x, shape_y, 1))\n",
    "\n",
    "    conv1 = Conv2D(64, (3,3), padding='same', activation='relu')(inputs)\n",
    "    conv2 = Conv2D(64, (3,3), padding='same', activation='relu')(conv1)\n",
    "    pool1 = MaxPooling2D(pool_size=2)(conv2)\n",
    "    \n",
    "    conv3 = Conv2D(128, (3,3), padding='same', activation='relu')(pool1)\n",
    "    conv4 = Conv2D(128, (3,3), padding='same', activation='relu')(conv3)\n",
    "    pool2 = MaxPooling2D(pool_size=2)(conv4)\n",
    "    \n",
    "    conv5 = Conv2D(256, (3,3), padding='same', activation='relu')(pool2)\n",
    "    conv6 = Conv2D(256, (3,3), padding='same', activation='relu')(conv5)\n",
    "    pool3 = MaxPooling2D(pool_size=2)(conv6)\n",
    "\n",
    "    conv7 = Conv2D(512, (3,3), padding='same', activation='relu')(pool3)\n",
    "    conv8 = Conv2D(512, (3,3), padding='same', activation='relu')(conv7)\n",
    "    pool4 = MaxPooling2D(pool_size=2)(conv8)\n",
    "\n",
    "    conv9 = Conv2D(512, (3,3), padding='same', activation='relu')(pool4)\n",
    "    conv10 = Conv2D(512, (3,3), padding='same', activation='relu')(conv9)\n",
    "    pool5 = MaxPooling2D(pool_size=2)(conv10)\n",
    "    \n",
    "    flat = Flatten()(pool5)\n",
    "    fc1 = Dense(3072, activation='relu')(flat)\n",
    "    drop1 = Dropout(0.5)(fc1)\n",
    "    fc2 = Dense(3072, activation='relu')(drop1)\n",
    "    drop2 = Dropout(0.5)(fc2)\n",
    "\n",
    "    outputs = Dense(10, activation='softmax')(drop2)\n",
    "\n",
    "\n",
    "    model = Model(inputs=inputs, outputs=outputs)\n",
    "    # how to compute the memory allocated by the activations of a model\n",
    "    batch = 1\n",
    "    shapes_count = int(np.sum([np.prod(np.array([s if isinstance(s, int) \n",
    "    else 1 for s in l.output_shape])) \n",
    "    for l in model.layers]))\n",
    "    memory = (shapes_count * 4 * batch)/10**6\n",
    "    print(memory)\n",
    "    \n",
    "    Total_params = round(model.count_params()/10 ** 6,2)\n",
    "    FLOPs = round(get_flops(model, batch_size=1)/10 ** 9,2)\n",
    "    with open(\"para_count_vgg13.csv\",\"a+\") as csvfile:\n",
    "        writer = csv.writer(csvfile)\n",
    "        writer.writerows([[model_num, shape_x, shape_y, FLOPs, Total_params, memory],])\n",
    "\n",
    "        model_num = model_num + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c6e892ce",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'keras_flops'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_4283/2589937901.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mInput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mConv2D\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMaxPooling2D\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFlatten\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDense\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mZeroPadding2D\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDropout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mActivation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mitertools\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mproduct\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras_flops\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mget_flops\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'keras_flops'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import csv\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Conv2D, MaxPooling2D, Flatten, Dense, ZeroPadding2D, Dropout, Activation\n",
    "from itertools import product\n",
    "from keras_flops import get_flops\n",
    "\n",
    "\n",
    "model_num = 1\n",
    "input_shape_range =range(32,512,32)\n",
    "\n",
    "with open(\"para_count_vgg13.csv\",\"w\") as csvfile:\n",
    "         writer = csv.writer(csvfile)\n",
    "         writer.writerows([[\"model_num\", \"input_horizontal\", \"input_vertical\", \"step\", \"number of layers\", \"FLOPs\", \"Total_params\", \"Memory\"],])\n",
    "path = \"../vgg13_h5\" #文件夹目录\n",
    "files= os.listdir(path) #得到文件夹下的所有文件名称\n",
    "\n",
    "for shape_x in input_shape_range:\n",
    "    shape_y = shape_x\n",
    "    for step in range(1,11):\n",
    "        file = \"vgg13_{input_x}_{input_y}_{step}.h5\".format(input_x=shape_x,input_y=shape_y,step=step)\n",
    "        if file in files: #遍历文件夹\n",
    "            model_name = str(file)\n",
    "            if not os.path.isdir(file): #判断是否是文件夹，不是文件夹才打开\n",
    "                model = keras.models.load_model(\"../vgg13_h5/{}\".format(model_name))\n",
    "\n",
    "                # how to compute the memory allocated by the activations of a model\n",
    "                batch = 1\n",
    "                shapes_count = int(np.sum([np.prod(np.array([s if isinstance(s, int) \n",
    "                else 1 for s in l.output_shape])) \n",
    "                for l in model.layers]))\n",
    "                memory = (shapes_count * 4 * batch)/10**6\n",
    "                print(memory)\n",
    "                layers_length = len(model.layers)\n",
    "                Total_params = round(model.count_params()/10 ** 6,2)\n",
    "                FLOPs = round(get_flops(model, batch_size=1)/10 ** 9,2)\n",
    "                with open(\"para_count_vgg13.csv\",\"a+\") as csvfile:\n",
    "                    writer = csv.writer(csvfile)\n",
    "                    writer.writerows([[model_num, shape_x, shape_y, step, layers_length, FLOPs, Total_params, memory],])\n",
    "\n",
    "                    model_num = model_num + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14f739e1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
