{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "346d61cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-02 04:13:27.512510: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/xilinx/xrt/lib:/usr/lib:/usr/lib/x86_64-linux-gnu:/usr/local/lib:/opt/vitis_ai/conda/envs/vitis-ai-tensorflow/lib\n",
      "2022-04-02 04:13:27.512541: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version: 2.6.0\n",
      "1.259564\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-02 04:13:28.539733: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/xilinx/xrt/lib:/usr/lib:/usr/lib/x86_64-linux-gnu:/usr/local/lib:/opt/vitis_ai/conda/envs/vitis-ai-tensorflow/lib\n",
      "2022-04-02 04:13:28.539750: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2022-04-02 04:13:28.539764: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:163] no NVIDIA GPU device is present: /dev/nvidia0 does not exist\n",
      "2022-04-02 04:13:28.539890: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.486316\n",
      "3.713068\n",
      "4.93982\n",
      "6.166572\n",
      "7.393324\n",
      "8.620076\n",
      "9.846828\n",
      "11.07358\n",
      "12.300332\n",
      "13.527084\n",
      "14.753836\n",
      "15.980588\n",
      "17.20734\n",
      "18.434092\n",
      "2.486316\n",
      "4.93982\n",
      "7.393324\n",
      "9.846828\n",
      "12.300332\n",
      "14.753836\n",
      "17.20734\n",
      "19.660844\n",
      "22.114348\n",
      "24.567852\n",
      "27.021356\n",
      "29.47486\n",
      "31.928364\n",
      "34.381868\n",
      "36.835372\n",
      "3.713068\n",
      "7.393324\n",
      "11.07358\n",
      "14.753836\n",
      "18.434092\n",
      "22.114348\n",
      "25.794604\n",
      "29.47486\n",
      "33.155116\n",
      "36.835372\n",
      "40.515628\n",
      "44.195884\n",
      "47.87614\n",
      "51.556396\n",
      "55.236652\n",
      "4.93982\n",
      "9.846828\n",
      "14.753836\n",
      "19.660844\n",
      "24.567852\n",
      "29.47486\n",
      "34.381868\n",
      "39.288876\n",
      "44.195884\n",
      "49.102892\n",
      "54.0099\n",
      "58.916908\n",
      "63.823916\n",
      "68.730924\n",
      "73.637932\n",
      "6.166572\n",
      "12.300332\n",
      "18.434092\n",
      "24.567852\n",
      "30.701612\n",
      "36.835372\n",
      "42.969132\n",
      "49.102892\n",
      "55.236652\n",
      "61.370412\n",
      "67.504172\n",
      "73.637932\n",
      "79.771692\n",
      "85.905452\n",
      "92.039212\n",
      "7.393324\n",
      "14.753836\n",
      "22.114348\n",
      "29.47486\n",
      "36.835372\n",
      "44.195884\n",
      "51.556396\n",
      "58.916908\n",
      "66.27742\n",
      "73.637932\n",
      "80.998444\n",
      "88.358956\n",
      "95.719468\n",
      "103.07998\n",
      "110.440492\n",
      "8.620076\n",
      "17.20734\n",
      "25.794604\n",
      "34.381868\n",
      "42.969132\n",
      "51.556396\n",
      "60.14366\n",
      "68.730924\n",
      "77.318188\n",
      "85.905452\n",
      "94.492716\n",
      "103.07998\n",
      "111.667244\n",
      "120.254508\n",
      "128.841772\n",
      "9.846828\n",
      "19.660844\n",
      "29.47486\n",
      "39.288876\n",
      "49.102892\n",
      "58.916908\n",
      "68.730924\n",
      "78.54494\n",
      "88.358956\n",
      "98.172972\n",
      "107.986988\n",
      "117.801004\n",
      "127.61502\n",
      "137.429036\n",
      "147.243052\n",
      "11.07358\n",
      "22.114348\n",
      "33.155116\n",
      "44.195884\n",
      "55.236652\n",
      "66.27742\n",
      "77.318188\n",
      "88.358956\n",
      "99.399724\n",
      "110.440492\n",
      "121.48126\n",
      "132.522028\n",
      "143.562796\n",
      "154.603564\n",
      "165.644332\n",
      "12.300332\n",
      "24.567852\n",
      "36.835372\n",
      "49.102892\n",
      "61.370412\n",
      "73.637932\n",
      "85.905452\n",
      "98.172972\n",
      "110.440492\n",
      "122.708012\n",
      "134.975532\n",
      "147.243052\n",
      "159.510572\n",
      "171.778092\n",
      "184.045612\n",
      "13.527084\n",
      "27.021356\n",
      "40.515628\n",
      "54.0099\n",
      "67.504172\n",
      "80.998444\n",
      "94.492716\n",
      "107.986988\n",
      "121.48126\n",
      "134.975532\n",
      "148.469804\n",
      "161.964076\n",
      "175.458348\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_350/860500545.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m     \u001b[0mconv11\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mConv2D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m512\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'same'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'relu'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpool4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m     \u001b[0mconv12\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mConv2D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m512\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'same'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'relu'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconv11\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m     \u001b[0mconv13\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mConv2D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m256\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'same'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'relu'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconv12\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m     \u001b[0mpool5\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMaxPooling2D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpool_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconv13\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/vitis_ai/conda/envs/vitis-ai-tensorflow2/lib/python3.7/site-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    975\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_in_functional_construction_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    976\u001b[0m       return self._functional_construction_call(inputs, args, kwargs,\n\u001b[0;32m--> 977\u001b[0;31m                                                 input_list)\n\u001b[0m\u001b[1;32m    978\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    979\u001b[0m     \u001b[0;31m# Maintains info about the `Layer.call` stack.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/vitis_ai/conda/envs/vitis-ai-tensorflow2/lib/python3.7/site-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m_functional_construction_call\u001b[0;34m(self, inputs, args, kwargs, input_list)\u001b[0m\n\u001b[1;32m   1126\u001b[0m       \u001b[0;31m# Node connectivity does not special-case the first argument.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1127\u001b[0m       outputs = self._set_connectivity_metadata((inputs,) + args, kwargs,\n\u001b[0;32m-> 1128\u001b[0;31m                                                 outputs)\n\u001b[0m\u001b[1;32m   1129\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1130\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/vitis_ai/conda/envs/vitis-ai-tensorflow2/lib/python3.7/site-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m_set_connectivity_metadata\u001b[0;34m(self, args, kwargs, outputs)\u001b[0m\n\u001b[1;32m   2589\u001b[0m     \u001b[0;31m# `_outbound_nodes` of the layers that produced the inputs to this\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2590\u001b[0m     \u001b[0;31m# layer call.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2591\u001b[0;31m     \u001b[0mnode_module\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcall_args\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcall_kwargs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2592\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2593\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/vitis_ai/conda/envs/vitis-ai-tensorflow2/lib/python3.7/site-packages/keras/engine/node.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, layer, call_args, call_kwargs, outputs)\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0;31m# Wire up Node to Layers.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_inbound_nodes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mkt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras_inputs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m       \u001b[0minbound_layer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_keras_history\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/vitis_ai/conda/envs/vitis-ai-tensorflow2/lib/python3.7/site-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m_inbound_nodes\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   2255\u001b[0m   \u001b[0;31m##############################################################################\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2256\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2257\u001b[0;31m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2258\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_inbound_nodes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2259\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_inbound_nodes_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "import csv\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Conv2D, MaxPooling2D, Flatten, Dense\n",
    "from itertools import product\n",
    "from keras_flops import get_flops\n",
    "print(\"TensorFlow version:\", tf.__version__)\n",
    "\n",
    "model_num = 1\n",
    "input_horizontal =range(32,512,32)\n",
    "input_vertical =range(32,512,32)\n",
    "with open(\"para_count_vgg16.csv\",\"w\") as csvfile:\n",
    "         writer = csv.writer(csvfile)\n",
    "         writer.writerows([[\"model_num\", \"input_horizontal\", \"input_vertical\", \"FLOPs\", \"Total_params\"],])\n",
    "          \n",
    "for input_x, input_y in product(input_horizontal, input_vertical):\n",
    "\n",
    "\n",
    "\n",
    "    inputs = Input(shape=(input_x, input_y, 1))\n",
    "\n",
    "    # 卷积层和最大池化层\n",
    "    conv1 = Conv2D(64, (3,3), padding='same', activation='relu')(inputs)\n",
    "    conv2 = Conv2D(64, (3,3), padding='same', activation='relu')(conv1)\n",
    "    pool1 = MaxPooling2D(pool_size=2)(conv2)\n",
    "\n",
    "    conv3 = Conv2D(128, (3,3), padding='same', activation='relu')(pool1)\n",
    "    conv4 = Conv2D(128, (3,3), padding='same', activation='relu')(conv3)\n",
    "    pool2 = MaxPooling2D(pool_size=2)(conv4)\n",
    "\n",
    "    conv5 = Conv2D(256, (3,3), padding='same', activation='relu')(pool2)\n",
    "    conv6 = Conv2D(256, (3,3), padding='same', activation='relu')(conv5)\n",
    "    conv7 = Conv2D(256, (3,3), padding='same', activation='relu')(conv6)\n",
    "    pool3 = MaxPooling2D(pool_size=2)(conv7)\n",
    "\n",
    "    conv8 = Conv2D(512, (3,3), padding='same', activation='relu')(pool3)\n",
    "    conv9 = Conv2D(512, (3,3), padding='same', activation='relu')(conv8)\n",
    "    conv10 = Conv2D(512, (3,3), padding='same', activation='relu')(conv9)\n",
    "    pool4 = MaxPooling2D(pool_size=2)(conv10)\n",
    "\n",
    "    conv11 = Conv2D(512, (3,3), padding='same', activation='relu')(pool4)\n",
    "    conv12 = Conv2D(512, (3,3), padding='same', activation='relu')(conv11)\n",
    "    conv13 = Conv2D(256, (3,3), padding='same', activation='relu')(conv12)\n",
    "    pool5 = MaxPooling2D(pool_size=2)(conv13)\n",
    "\n",
    "    # 扁平层\n",
    "    flat = Flatten()(pool5)\n",
    "\n",
    "    # 全联接层\n",
    "    fc1 = Dense(4096, activation='relu')(flat)\n",
    "    fc2 = Dense(4096, activation='relu')(fc1)\n",
    "\n",
    "    # 输出层\n",
    "    outputs = Dense(10, activation='softmax')(fc2)\n",
    "\n",
    "\n",
    "    model = Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "    \n",
    "    Total_params = round(model.count_params()/10 ** 6,2)\n",
    "    FLOPs = round(get_flops(model, batch_size=1)/10 ** 9,2)\n",
    "    with open(\"para_count_vgg16.csv\",\"a+\") as csvfile:\n",
    "        writer = csv.writer(csvfile)\n",
    "        writer.writerows([[model_num, input_x, input_y, FLOPs, Total_params],])\n",
    "\n",
    "        model_num = model_num + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0a79322e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version: 2.6.0\n",
      "1.259564\n",
      "4.93982\n",
      "11.07358\n",
      "19.660844\n",
      "30.701612\n",
      "44.195884\n",
      "60.14366\n",
      "78.54494\n",
      "99.399724\n",
      "122.708012\n",
      "148.469804\n",
      "176.6851\n",
      "207.3539\n",
      "240.476204\n",
      "276.052012\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import csv\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Conv2D, MaxPooling2D, Flatten, Dense\n",
    "from itertools import product\n",
    "from keras_flops import get_flops\n",
    "print(\"TensorFlow version:\", tf.__version__)\n",
    "\n",
    "model_num = 1\n",
    "input_shape_range =range(32,512,32)\n",
    "\n",
    "with open(\"para_count_vgg16.csv\",\"w\") as csvfile:\n",
    "         writer = csv.writer(csvfile)\n",
    "         writer.writerows([[\"model_num\", \"input_horizontal\", \"input_vertical\", \"FLOPs\", \"Total_params\", \"Memory\"],])\n",
    "          \n",
    "for input_x in input_shape_range:\n",
    "    input_y = input_x\n",
    "    inputs = Input(shape=(input_x, input_y, 1))\n",
    "\n",
    "    # 卷积层和最大池化层\n",
    "    conv1 = Conv2D(64, (3,3), padding='same', activation='relu')(inputs)\n",
    "    conv2 = Conv2D(64, (3,3), padding='same', activation='relu')(conv1)\n",
    "    pool1 = MaxPooling2D(pool_size=2)(conv2)\n",
    "\n",
    "    conv3 = Conv2D(128, (3,3), padding='same', activation='relu')(pool1)\n",
    "    conv4 = Conv2D(128, (3,3), padding='same', activation='relu')(conv3)\n",
    "    pool2 = MaxPooling2D(pool_size=2)(conv4)\n",
    "\n",
    "    conv5 = Conv2D(256, (3,3), padding='same', activation='relu')(pool2)\n",
    "    conv6 = Conv2D(256, (3,3), padding='same', activation='relu')(conv5)\n",
    "    conv7 = Conv2D(256, (3,3), padding='same', activation='relu')(conv6)\n",
    "    pool3 = MaxPooling2D(pool_size=2)(conv7)\n",
    "\n",
    "    conv8 = Conv2D(512, (3,3), padding='same', activation='relu')(pool3)\n",
    "    conv9 = Conv2D(512, (3,3), padding='same', activation='relu')(conv8)\n",
    "    conv10 = Conv2D(512, (3,3), padding='same', activation='relu')(conv9)\n",
    "    pool4 = MaxPooling2D(pool_size=2)(conv10)\n",
    "\n",
    "    conv11 = Conv2D(512, (3,3), padding='same', activation='relu')(pool4)\n",
    "    conv12 = Conv2D(512, (3,3), padding='same', activation='relu')(conv11)\n",
    "    conv13 = Conv2D(256, (3,3), padding='same', activation='relu')(conv12)\n",
    "    pool5 = MaxPooling2D(pool_size=2)(conv13)\n",
    "\n",
    "    # 扁平层\n",
    "    flat = Flatten()(pool5)\n",
    "\n",
    "    # 全联接层\n",
    "    fc1 = Dense(4096, activation='relu')(flat)\n",
    "    fc2 = Dense(4096, activation='relu')(fc1)\n",
    "\n",
    "    # 输出层\n",
    "    outputs = Dense(10, activation='softmax')(fc2)\n",
    "\n",
    "\n",
    "    model = Model(inputs=inputs, outputs=outputs)\n",
    "    # how to compute the memory allocated by the activations of a model\n",
    "    batch = 1\n",
    "    shapes_count = int(np.sum([np.prod(np.array([s if isinstance(s, int) \n",
    "    else 1 for s in l.output_shape])) \n",
    "    for l in model.layers]))\n",
    "    memory = (shapes_count * 4 * batch)/10**6\n",
    "    print(memory)\n",
    "    \n",
    "    Total_params = round(model.count_params()/10 ** 6,2)\n",
    "    FLOPs = round(get_flops(model, batch_size=1)/10 ** 9,2)\n",
    "    with open(\"para_count_vgg16.csv\",\"a+\") as csvfile:\n",
    "        writer = csv.writer(csvfile)\n",
    "        writer.writerows([[model_num, input_x, input_y, FLOPs, Total_params, memory],])\n",
    "\n",
    "        model_num = model_num + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c8efca5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-11 17:24:12.441722: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/xilinx/xrt/lib:/usr/lib:/usr/lib/x86_64-linux-gnu:/usr/local/lib:/opt/vitis_ai/conda/envs/vitis-ai-tensorflow/lib\n",
      "2022-04-11 17:24:12.441738: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'keras_flops'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_2869/3999000396.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mInput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mConv2D\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMaxPooling2D\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFlatten\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDense\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mitertools\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mproduct\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras_flops\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mget_flops\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'keras_flops'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import csv\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Conv2D, MaxPooling2D, Flatten, Dense\n",
    "from itertools import product\n",
    "from keras_flops import get_flops\n",
    "import keras\n",
    "\n",
    "model_num = 1\n",
    "input_shape_range =range(32,512,32)\n",
    "\n",
    "with open(\"para_count_vgg16.csv\",\"w\") as csvfile:\n",
    "         writer = csv.writer(csvfile)\n",
    "         writer.writerows([[\"model_num\", \"input_horizontal\", \"input_vertical\",\"step\",\"number of layers\",\"FLOPs\", \"Total_params\", \"Memory\"],])\n",
    "          \n",
    "path = \"../vgg16_h5\" #文件夹目录\n",
    "files= os.listdir(path) #得到文件夹下的所有文件名称\n",
    "print(files)\n",
    "for shape_x in input_shape_range:\n",
    "    shape_y = shape_x\n",
    "    for step in range(1,11):\n",
    "        file = \"vgg16_{input_x}_{input_y}_{step}.h5\".format(input_x=shape_x,input_y=shape_y,step=step)\n",
    "        if file in files: #遍历文件夹\n",
    "            model_name = str(file)\n",
    "            if not os.path.isdir(file): #判断是否是文件夹，不是文件夹才打开\n",
    "                model = keras.models.load_model(\"../vgg16_h5/{}\".format(model_name))\n",
    "                # how to compute the memory allocated by the activations of a model\n",
    "                batch = 1\n",
    "                shapes_count = int(np.sum([np.prod(np.array([s if isinstance(s, int) \n",
    "                else 1 for s in l.output_shape])) \n",
    "                for l in model.layers]))\n",
    "                memory = (shapes_count * 4 * batch)/10**6\n",
    "                print(memory)\n",
    "                layers_length = len(model.layers)\n",
    "                Total_params = round(model.count_params()/10 ** 6,2)\n",
    "                FLOPs = round(get_flops(model, batch_size=1)/10 ** 9,2)\n",
    "                with open(\"para_count_vgg16.csv\",\"a+\") as csvfile:\n",
    "                    writer = csv.writer(csvfile)\n",
    "                    writer.writerows([[model_num, shape_x, shape_y, step, layers_length, FLOPs, Total_params, memory],])\n",
    "\n",
    "                    model_num = model_num + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32f42752",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
