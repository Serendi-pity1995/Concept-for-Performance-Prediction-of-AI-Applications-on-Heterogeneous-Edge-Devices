{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "56337522",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-02 06:40:50.498355: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/xilinx/xrt/lib:/usr/lib:/usr/lib/x86_64-linux-gnu:/usr/local/lib:/opt/vitis_ai/conda/envs/vitis-ai-tensorflow/lib\n",
      "2022-04-02 06:40:50.498387: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2022-04-02 06:40:51.525501: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/xilinx/xrt/lib:/usr/lib:/usr/lib/x86_64-linux-gnu:/usr/local/lib:/opt/vitis_ai/conda/envs/vitis-ai-tensorflow/lib\n",
      "2022-04-02 06:40:51.525532: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2022-04-02 06:40:51.525547: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:163] no NVIDIA GPU device is present: /dev/nvidia0 does not exist\n",
      "2022-04-02 06:40:51.525743: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 192, 192, 1)]     0         \n",
      "_________________________________________________________________\n",
      "conv2d (Conv2D)              (None, 96, 96, 32)        320       \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 96, 96, 32)        128       \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 96, 96, 32)        0         \n",
      "_________________________________________________________________\n",
      "depthwise_conv2d (DepthwiseC (None, 96, 96, 32)        320       \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 96, 96, 32)        128       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 96, 96, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 96, 96, 64)        2112      \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 96, 96, 64)        256       \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 96, 96, 64)        0         \n",
      "_________________________________________________________________\n",
      "depthwise_conv2d_1 (Depthwis (None, 48, 48, 64)        640       \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 48, 48, 64)        256       \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 48, 48, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 48, 48, 128)       8320      \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 48, 48, 128)       512       \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 48, 48, 128)       0         \n",
      "_________________________________________________________________\n",
      "depthwise_conv2d_2 (Depthwis (None, 48, 48, 128)       1280      \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 48, 48, 128)       512       \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 48, 48, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 48, 48, 128)       16512     \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 48, 48, 128)       512       \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 48, 48, 128)       0         \n",
      "_________________________________________________________________\n",
      "depthwise_conv2d_3 (Depthwis (None, 24, 24, 128)       1280      \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (None, 24, 24, 128)       512       \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 24, 24, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 24, 24, 256)       33024     \n",
      "_________________________________________________________________\n",
      "batch_normalization_8 (Batch (None, 24, 24, 256)       1024      \n",
      "_________________________________________________________________\n",
      "activation_8 (Activation)    (None, 24, 24, 256)       0         \n",
      "_________________________________________________________________\n",
      "depthwise_conv2d_4 (Depthwis (None, 24, 24, 256)       2560      \n",
      "_________________________________________________________________\n",
      "batch_normalization_9 (Batch (None, 24, 24, 256)       1024      \n",
      "_________________________________________________________________\n",
      "activation_9 (Activation)    (None, 24, 24, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 24, 24, 256)       65792     \n",
      "_________________________________________________________________\n",
      "batch_normalization_10 (Batc (None, 24, 24, 256)       1024      \n",
      "_________________________________________________________________\n",
      "activation_10 (Activation)   (None, 24, 24, 256)       0         \n",
      "_________________________________________________________________\n",
      "depthwise_conv2d_5 (Depthwis (None, 12, 12, 256)       2560      \n",
      "_________________________________________________________________\n",
      "batch_normalization_11 (Batc (None, 12, 12, 256)       1024      \n",
      "_________________________________________________________________\n",
      "activation_11 (Activation)   (None, 12, 12, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 12, 12, 512)       131584    \n",
      "_________________________________________________________________\n",
      "batch_normalization_12 (Batc (None, 12, 12, 512)       2048      \n",
      "_________________________________________________________________\n",
      "activation_12 (Activation)   (None, 12, 12, 512)       0         \n",
      "_________________________________________________________________\n",
      "depthwise_conv2d_6 (Depthwis (None, 12, 12, 512)       5120      \n",
      "_________________________________________________________________\n",
      "batch_normalization_13 (Batc (None, 12, 12, 512)       2048      \n",
      "_________________________________________________________________\n",
      "activation_13 (Activation)   (None, 12, 12, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 12, 12, 512)       262656    \n",
      "_________________________________________________________________\n",
      "batch_normalization_14 (Batc (None, 12, 12, 512)       2048      \n",
      "_________________________________________________________________\n",
      "activation_14 (Activation)   (None, 12, 12, 512)       0         \n",
      "_________________________________________________________________\n",
      "depthwise_conv2d_7 (Depthwis (None, 12, 12, 512)       5120      \n",
      "_________________________________________________________________\n",
      "batch_normalization_15 (Batc (None, 12, 12, 512)       2048      \n",
      "_________________________________________________________________\n",
      "activation_15 (Activation)   (None, 12, 12, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 12, 12, 512)       262656    \n",
      "_________________________________________________________________\n",
      "batch_normalization_16 (Batc (None, 12, 12, 512)       2048      \n",
      "_________________________________________________________________\n",
      "activation_16 (Activation)   (None, 12, 12, 512)       0         \n",
      "_________________________________________________________________\n",
      "depthwise_conv2d_8 (Depthwis (None, 12, 12, 512)       5120      \n",
      "_________________________________________________________________\n",
      "batch_normalization_17 (Batc (None, 12, 12, 512)       2048      \n",
      "_________________________________________________________________\n",
      "activation_17 (Activation)   (None, 12, 12, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 12, 12, 512)       262656    \n",
      "_________________________________________________________________\n",
      "batch_normalization_18 (Batc (None, 12, 12, 512)       2048      \n",
      "_________________________________________________________________\n",
      "activation_18 (Activation)   (None, 12, 12, 512)       0         \n",
      "_________________________________________________________________\n",
      "depthwise_conv2d_9 (Depthwis (None, 12, 12, 512)       5120      \n",
      "_________________________________________________________________\n",
      "batch_normalization_19 (Batc (None, 12, 12, 512)       2048      \n",
      "_________________________________________________________________\n",
      "activation_19 (Activation)   (None, 12, 12, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_10 (Conv2D)           (None, 12, 12, 512)       262656    \n",
      "_________________________________________________________________\n",
      "batch_normalization_20 (Batc (None, 12, 12, 512)       2048      \n",
      "_________________________________________________________________\n",
      "activation_20 (Activation)   (None, 12, 12, 512)       0         \n",
      "_________________________________________________________________\n",
      "depthwise_conv2d_10 (Depthwi (None, 12, 12, 512)       5120      \n",
      "_________________________________________________________________\n",
      "batch_normalization_21 (Batc (None, 12, 12, 512)       2048      \n",
      "_________________________________________________________________\n",
      "activation_21 (Activation)   (None, 12, 12, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_11 (Conv2D)           (None, 12, 12, 512)       262656    \n",
      "_________________________________________________________________\n",
      "batch_normalization_22 (Batc (None, 12, 12, 512)       2048      \n",
      "_________________________________________________________________\n",
      "activation_22 (Activation)   (None, 12, 12, 512)       0         \n",
      "_________________________________________________________________\n",
      "depthwise_conv2d_11 (Depthwi (None, 6, 6, 512)         5120      \n",
      "_________________________________________________________________\n",
      "batch_normalization_23 (Batc (None, 6, 6, 512)         2048      \n",
      "_________________________________________________________________\n",
      "activation_23 (Activation)   (None, 6, 6, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_12 (Conv2D)           (None, 6, 6, 1024)        525312    \n",
      "_________________________________________________________________\n",
      "batch_normalization_24 (Batc (None, 6, 6, 1024)        4096      \n",
      "_________________________________________________________________\n",
      "activation_24 (Activation)   (None, 6, 6, 1024)        0         \n",
      "_________________________________________________________________\n",
      "depthwise_conv2d_12 (Depthwi (None, 6, 6, 1024)        10240     \n",
      "_________________________________________________________________\n",
      "batch_normalization_25 (Batc (None, 6, 6, 1024)        4096      \n",
      "_________________________________________________________________\n",
      "activation_25 (Activation)   (None, 6, 6, 1024)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_13 (Conv2D)           (None, 6, 6, 1024)        1049600   \n",
      "_________________________________________________________________\n",
      "batch_normalization_26 (Batc (None, 6, 6, 1024)        4096      \n",
      "_________________________________________________________________\n",
      "activation_26 (Activation)   (None, 6, 6, 1024)        0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d (Gl (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 10)                10250     \n",
      "=================================================================\n",
      "Total params: 3,249,482\n",
      "Trainable params: 3,227,594\n",
      "Non-trainable params: 21,888\n",
      "_________________________________________________________________\n",
      "44.462124\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-02 06:40:52.436740: I tensorflow/core/grappler/devices.cc:66] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0\n",
      "2022-04-02 06:40:52.436885: I tensorflow/core/grappler/clusters/single_machine.cc:357] Starting new session\n",
      "2022-04-02 06:40:52.457871: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:1137] Optimization results for grappler item: graph_to_optimize\n",
      "  function_optimizer: function_optimizer did nothing. time = 0.008ms.\n",
      "  function_optimizer: function_optimizer did nothing. time = 0.001ms.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /opt/vitis_ai/conda/envs/vitis-ai-tensorflow2/lib/python3.7/site-packages/tensorflow/python/ops/nn_ops.py:5063: tensor_shape_from_node_def_name (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.compat.v1.graph_util.tensor_shape_from_node_def_name`\n",
      "\n",
      "=========================Options=============================\n",
      "-max_depth                  10000\n",
      "-min_bytes                  0\n",
      "-min_peak_bytes             0\n",
      "-min_residual_bytes         0\n",
      "-min_output_bytes           0\n",
      "-min_micros                 0\n",
      "-min_accelerator_micros     0\n",
      "-min_cpu_micros             0\n",
      "-min_params                 0\n",
      "-min_float_ops              1\n",
      "-min_occurrence             0\n",
      "-step                       -1\n",
      "-order_by                   float_ops\n",
      "-account_type_regexes       .*\n",
      "-start_name_regexes         .*\n",
      "-trim_name_regexes          \n",
      "-show_name_regexes          .*\n",
      "-hide_name_regexes          \n",
      "-account_displayed_op_only  true\n",
      "-select                     float_ops\n",
      "-output                     stdout:\n",
      "\n",
      "==================Model Analysis Report======================\n",
      "\n",
      "Doc:\n",
      "scope: The nodes in the model graph are organized by their names, which is hierarchical like filesystem.\n",
      "flops: Number of float operations. Note: Please read the implementation for the math behind it.\n",
      "\n",
      "Profile:\n",
      "node name | # float_ops\n",
      "_TFProfRoot (--/834.82m flops)\n",
      "  model/conv2d_10/Conv2D (75.50m/75.50m flops)\n",
      "  model/conv2d_11/Conv2D (75.50m/75.50m flops)\n",
      "  model/conv2d_13/Conv2D (75.50m/75.50m flops)\n",
      "  model/conv2d_3/Conv2D (75.50m/75.50m flops)\n",
      "  model/conv2d_5/Conv2D (75.50m/75.50m flops)\n",
      "  model/conv2d_7/Conv2D (75.50m/75.50m flops)\n",
      "  model/conv2d_8/Conv2D (75.50m/75.50m flops)\n",
      "  model/conv2d_9/Conv2D (75.50m/75.50m flops)\n",
      "  model/conv2d_1/Conv2D (37.75m/37.75m flops)\n",
      "  model/conv2d_12/Conv2D (37.75m/37.75m flops)\n",
      "  model/conv2d_2/Conv2D (37.75m/37.75m flops)\n",
      "  model/conv2d_4/Conv2D (37.75m/37.75m flops)\n",
      "  model/conv2d_6/Conv2D (37.75m/37.75m flops)\n",
      "  model/depthwise_conv2d_2/depthwise (5.31m/5.31m flops)\n",
      "  model/depthwise_conv2d/depthwise (5.31m/5.31m flops)\n",
      "  model/conv2d/Conv2D (5.31m/5.31m flops)\n",
      "  model/depthwise_conv2d_1/depthwise (2.65m/2.65m flops)\n",
      "  model/depthwise_conv2d_4/depthwise (2.65m/2.65m flops)\n",
      "  model/depthwise_conv2d_10/depthwise (1.33m/1.33m flops)\n",
      "  model/depthwise_conv2d_3/depthwise (1.33m/1.33m flops)\n",
      "  model/depthwise_conv2d_9/depthwise (1.33m/1.33m flops)\n",
      "  model/depthwise_conv2d_6/depthwise (1.33m/1.33m flops)\n",
      "  model/depthwise_conv2d_7/depthwise (1.33m/1.33m flops)\n",
      "  model/depthwise_conv2d_8/depthwise (1.33m/1.33m flops)\n",
      "  model/batch_normalization_2/FusedBatchNormV3 (1.18m/1.18m flops)\n",
      "  model/depthwise_conv2d_12/depthwise (663.55k/663.55k flops)\n",
      "  model/depthwise_conv2d_5/depthwise (663.55k/663.55k flops)\n",
      "  model/batch_normalization_5/FusedBatchNormV3 (590.59k/590.59k flops)\n",
      "  model/batch_normalization_6/FusedBatchNormV3 (590.59k/590.59k flops)\n",
      "  model/batch_normalization_4/FusedBatchNormV3 (590.59k/590.59k flops)\n",
      "  model/batch_normalization_1/FusedBatchNormV3 (590.02k/590.02k flops)\n",
      "  model/batch_normalization/FusedBatchNormV3 (590.02k/590.02k flops)\n",
      "  model/conv2d_1/BiasAdd (589.82k/589.82k flops)\n",
      "  model/depthwise_conv2d_11/depthwise (331.78k/331.78k flops)\n",
      "  model/batch_normalization_10/FusedBatchNormV3 (296.45k/296.45k flops)\n",
      "  model/batch_normalization_9/FusedBatchNormV3 (296.45k/296.45k flops)\n",
      "  model/batch_normalization_8/FusedBatchNormV3 (296.45k/296.45k flops)\n",
      "  model/batch_normalization_3/FusedBatchNormV3 (295.30k/295.30k flops)\n",
      "  model/depthwise_conv2d/BiasAdd (294.91k/294.91k flops)\n",
      "  model/depthwise_conv2d_2/BiasAdd (294.91k/294.91k flops)\n",
      "  model/conv2d_3/BiasAdd (294.91k/294.91k flops)\n",
      "  model/conv2d_2/BiasAdd (294.91k/294.91k flops)\n",
      "  model/conv2d/BiasAdd (294.91k/294.91k flops)\n",
      "  model/batch_normalization_18/FusedBatchNormV3 (150.53k/150.53k flops)\n",
      "  model/batch_normalization_12/FusedBatchNormV3 (150.53k/150.53k flops)\n",
      "  model/batch_normalization_13/FusedBatchNormV3 (150.53k/150.53k flops)\n",
      "  model/batch_normalization_14/FusedBatchNormV3 (150.53k/150.53k flops)\n",
      "  model/batch_normalization_15/FusedBatchNormV3 (150.53k/150.53k flops)\n",
      "  model/batch_normalization_16/FusedBatchNormV3 (150.53k/150.53k flops)\n",
      "  model/batch_normalization_17/FusedBatchNormV3 (150.53k/150.53k flops)\n",
      "  model/batch_normalization_19/FusedBatchNormV3 (150.53k/150.53k flops)\n",
      "  model/batch_normalization_20/FusedBatchNormV3 (150.53k/150.53k flops)\n",
      "  model/batch_normalization_21/FusedBatchNormV3 (150.53k/150.53k flops)\n",
      "  model/batch_normalization_22/FusedBatchNormV3 (150.53k/150.53k flops)\n",
      "  model/batch_normalization_7/FusedBatchNormV3 (148.22k/148.22k flops)\n",
      "  model/conv2d_4/BiasAdd (147.46k/147.46k flops)\n",
      "  model/conv2d_5/BiasAdd (147.46k/147.46k flops)\n",
      "  model/depthwise_conv2d_4/BiasAdd (147.46k/147.46k flops)\n",
      "  model/depthwise_conv2d_1/BiasAdd (147.46k/147.46k flops)\n",
      "  model/batch_normalization_24/FusedBatchNormV3 (79.87k/79.87k flops)\n",
      "  model/batch_normalization_26/FusedBatchNormV3 (79.87k/79.87k flops)\n",
      "  model/batch_normalization_25/FusedBatchNormV3 (79.87k/79.87k flops)\n",
      "  model/batch_normalization_11/FusedBatchNormV3 (75.26k/75.26k flops)\n",
      "  model/depthwise_conv2d_10/BiasAdd (73.73k/73.73k flops)\n",
      "  model/conv2d_11/BiasAdd (73.73k/73.73k flops)\n",
      "  model/depthwise_conv2d_9/BiasAdd (73.73k/73.73k flops)\n",
      "  model/depthwise_conv2d_8/BiasAdd (73.73k/73.73k flops)\n",
      "  model/conv2d_7/BiasAdd (73.73k/73.73k flops)\n",
      "  model/conv2d_9/BiasAdd (73.73k/73.73k flops)\n",
      "  model/depthwise_conv2d_3/BiasAdd (73.73k/73.73k flops)\n",
      "  model/conv2d_6/BiasAdd (73.73k/73.73k flops)\n",
      "  model/conv2d_8/BiasAdd (73.73k/73.73k flops)\n",
      "  model/conv2d_10/BiasAdd (73.73k/73.73k flops)\n",
      "  model/depthwise_conv2d_7/BiasAdd (73.73k/73.73k flops)\n",
      "  model/depthwise_conv2d_6/BiasAdd (73.73k/73.73k flops)\n",
      "  model/batch_normalization_23/FusedBatchNormV3 (39.94k/39.94k flops)\n",
      "  model/depthwise_conv2d_5/BiasAdd (36.86k/36.86k flops)\n",
      "  model/conv2d_12/BiasAdd (36.86k/36.86k flops)\n",
      "  model/depthwise_conv2d_12/BiasAdd (36.86k/36.86k flops)\n",
      "  model/conv2d_13/BiasAdd (36.86k/36.86k flops)\n",
      "  model/global_average_pooling2d/Mean (36.86k/36.86k flops)\n",
      "  model/dense/MatMul (20.48k/20.48k flops)\n",
      "  model/depthwise_conv2d_11/BiasAdd (18.43k/18.43k flops)\n",
      "  model/dense/Softmax (50/50 flops)\n",
      "  model/dense/BiasAdd (10/10 flops)\n",
      "\n",
      "======================End of Report==========================\n",
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         [(None, 224, 224, 1)]     0         \n",
      "_________________________________________________________________\n",
      "conv2d_14 (Conv2D)           (None, 112, 112, 32)      320       \n",
      "_________________________________________________________________\n",
      "batch_normalization_27 (Batc (None, 112, 112, 32)      128       \n",
      "_________________________________________________________________\n",
      "activation_27 (Activation)   (None, 112, 112, 32)      0         \n",
      "_________________________________________________________________\n",
      "depthwise_conv2d_13 (Depthwi (None, 112, 112, 32)      320       \n",
      "_________________________________________________________________\n",
      "batch_normalization_28 (Batc (None, 112, 112, 32)      128       \n",
      "_________________________________________________________________\n",
      "activation_28 (Activation)   (None, 112, 112, 32)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_15 (Conv2D)           (None, 112, 112, 64)      2112      \n",
      "_________________________________________________________________\n",
      "batch_normalization_29 (Batc (None, 112, 112, 64)      256       \n",
      "_________________________________________________________________\n",
      "activation_29 (Activation)   (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "depthwise_conv2d_14 (Depthwi (None, 56, 56, 64)        640       \n",
      "_________________________________________________________________\n",
      "batch_normalization_30 (Batc (None, 56, 56, 64)        256       \n",
      "_________________________________________________________________\n",
      "activation_30 (Activation)   (None, 56, 56, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_16 (Conv2D)           (None, 56, 56, 128)       8320      \n",
      "_________________________________________________________________\n",
      "batch_normalization_31 (Batc (None, 56, 56, 128)       512       \n",
      "_________________________________________________________________\n",
      "activation_31 (Activation)   (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "depthwise_conv2d_15 (Depthwi (None, 56, 56, 128)       1280      \n",
      "_________________________________________________________________\n",
      "batch_normalization_32 (Batc (None, 56, 56, 128)       512       \n",
      "_________________________________________________________________\n",
      "activation_32 (Activation)   (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_17 (Conv2D)           (None, 56, 56, 128)       16512     \n",
      "_________________________________________________________________\n",
      "batch_normalization_33 (Batc (None, 56, 56, 128)       512       \n",
      "_________________________________________________________________\n",
      "activation_33 (Activation)   (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "depthwise_conv2d_16 (Depthwi (None, 28, 28, 128)       1280      \n",
      "_________________________________________________________________\n",
      "batch_normalization_34 (Batc (None, 28, 28, 128)       512       \n",
      "_________________________________________________________________\n",
      "activation_34 (Activation)   (None, 28, 28, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_18 (Conv2D)           (None, 28, 28, 256)       33024     \n",
      "_________________________________________________________________\n",
      "batch_normalization_35 (Batc (None, 28, 28, 256)       1024      \n",
      "_________________________________________________________________\n",
      "activation_35 (Activation)   (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "depthwise_conv2d_17 (Depthwi (None, 28, 28, 256)       2560      \n",
      "_________________________________________________________________\n",
      "batch_normalization_36 (Batc (None, 28, 28, 256)       1024      \n",
      "_________________________________________________________________\n",
      "activation_36 (Activation)   (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_19 (Conv2D)           (None, 28, 28, 256)       65792     \n",
      "_________________________________________________________________\n",
      "batch_normalization_37 (Batc (None, 28, 28, 256)       1024      \n",
      "_________________________________________________________________\n",
      "activation_37 (Activation)   (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "depthwise_conv2d_18 (Depthwi (None, 14, 14, 256)       2560      \n",
      "_________________________________________________________________\n",
      "batch_normalization_38 (Batc (None, 14, 14, 256)       1024      \n",
      "_________________________________________________________________\n",
      "activation_38 (Activation)   (None, 14, 14, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_20 (Conv2D)           (None, 14, 14, 512)       131584    \n",
      "_________________________________________________________________\n",
      "batch_normalization_39 (Batc (None, 14, 14, 512)       2048      \n",
      "_________________________________________________________________\n",
      "activation_39 (Activation)   (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "depthwise_conv2d_19 (Depthwi (None, 14, 14, 512)       5120      \n",
      "_________________________________________________________________\n",
      "batch_normalization_40 (Batc (None, 14, 14, 512)       2048      \n",
      "_________________________________________________________________\n",
      "activation_40 (Activation)   (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_21 (Conv2D)           (None, 14, 14, 512)       262656    \n",
      "_________________________________________________________________\n",
      "batch_normalization_41 (Batc (None, 14, 14, 512)       2048      \n",
      "_________________________________________________________________\n",
      "activation_41 (Activation)   (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "depthwise_conv2d_20 (Depthwi (None, 14, 14, 512)       5120      \n",
      "_________________________________________________________________\n",
      "batch_normalization_42 (Batc (None, 14, 14, 512)       2048      \n",
      "_________________________________________________________________\n",
      "activation_42 (Activation)   (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_22 (Conv2D)           (None, 14, 14, 512)       262656    \n",
      "_________________________________________________________________\n",
      "batch_normalization_43 (Batc (None, 14, 14, 512)       2048      \n",
      "_________________________________________________________________\n",
      "activation_43 (Activation)   (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "depthwise_conv2d_21 (Depthwi (None, 14, 14, 512)       5120      \n",
      "_________________________________________________________________\n",
      "batch_normalization_44 (Batc (None, 14, 14, 512)       2048      \n",
      "_________________________________________________________________\n",
      "activation_44 (Activation)   (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_23 (Conv2D)           (None, 14, 14, 512)       262656    \n",
      "_________________________________________________________________\n",
      "batch_normalization_45 (Batc (None, 14, 14, 512)       2048      \n",
      "_________________________________________________________________\n",
      "activation_45 (Activation)   (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "depthwise_conv2d_22 (Depthwi (None, 14, 14, 512)       5120      \n",
      "_________________________________________________________________\n",
      "batch_normalization_46 (Batc (None, 14, 14, 512)       2048      \n",
      "_________________________________________________________________\n",
      "activation_46 (Activation)   (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_24 (Conv2D)           (None, 14, 14, 512)       262656    \n",
      "_________________________________________________________________\n",
      "batch_normalization_47 (Batc (None, 14, 14, 512)       2048      \n",
      "_________________________________________________________________\n",
      "activation_47 (Activation)   (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "depthwise_conv2d_23 (Depthwi (None, 14, 14, 512)       5120      \n",
      "_________________________________________________________________\n",
      "batch_normalization_48 (Batc (None, 14, 14, 512)       2048      \n",
      "_________________________________________________________________\n",
      "activation_48 (Activation)   (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_25 (Conv2D)           (None, 14, 14, 512)       262656    \n",
      "_________________________________________________________________\n",
      "batch_normalization_49 (Batc (None, 14, 14, 512)       2048      \n",
      "_________________________________________________________________\n",
      "activation_49 (Activation)   (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "depthwise_conv2d_24 (Depthwi (None, 7, 7, 512)         5120      \n",
      "_________________________________________________________________\n",
      "batch_normalization_50 (Batc (None, 7, 7, 512)         2048      \n",
      "_________________________________________________________________\n",
      "activation_50 (Activation)   (None, 7, 7, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_26 (Conv2D)           (None, 7, 7, 1024)        525312    \n",
      "_________________________________________________________________\n",
      "batch_normalization_51 (Batc (None, 7, 7, 1024)        4096      \n",
      "_________________________________________________________________\n",
      "activation_51 (Activation)   (None, 7, 7, 1024)        0         \n",
      "_________________________________________________________________\n",
      "depthwise_conv2d_25 (Depthwi (None, 7, 7, 1024)        10240     \n",
      "_________________________________________________________________\n",
      "batch_normalization_52 (Batc (None, 7, 7, 1024)        4096      \n",
      "_________________________________________________________________\n",
      "activation_52 (Activation)   (None, 7, 7, 1024)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_27 (Conv2D)           (None, 7, 7, 1024)        1049600   \n",
      "_________________________________________________________________\n",
      "batch_normalization_53 (Batc (None, 7, 7, 1024)        4096      \n",
      "_________________________________________________________________\n",
      "activation_53 (Activation)   (None, 7, 7, 1024)        0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_1 ( (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                10250     \n",
      "=================================================================\n",
      "Total params: 3,249,482\n",
      "Trainable params: 3,227,594\n",
      "Non-trainable params: 21,888\n",
      "_________________________________________________________________\n",
      "60.516396\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-02 06:40:53.412153: I tensorflow/core/grappler/devices.cc:66] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0\n",
      "2022-04-02 06:40:53.412267: I tensorflow/core/grappler/clusters/single_machine.cc:357] Starting new session\n",
      "2022-04-02 06:40:53.416386: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:1137] Optimization results for grappler item: graph_to_optimize\n",
      "  function_optimizer: function_optimizer did nothing. time = 0.005ms.\n",
      "  function_optimizer: function_optimizer did nothing. time = 0.001ms.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=========================Options=============================\n",
      "-max_depth                  10000\n",
      "-min_bytes                  0\n",
      "-min_peak_bytes             0\n",
      "-min_residual_bytes         0\n",
      "-min_output_bytes           0\n",
      "-min_micros                 0\n",
      "-min_accelerator_micros     0\n",
      "-min_cpu_micros             0\n",
      "-min_params                 0\n",
      "-min_float_ops              1\n",
      "-min_occurrence             0\n",
      "-step                       -1\n",
      "-order_by                   float_ops\n",
      "-account_type_regexes       .*\n",
      "-start_name_regexes         .*\n",
      "-trim_name_regexes          \n",
      "-show_name_regexes          .*\n",
      "-hide_name_regexes          \n",
      "-account_displayed_op_only  true\n",
      "-select                     float_ops\n",
      "-output                     stdout:\n",
      "\n",
      "==================Model Analysis Report======================\n",
      "\n",
      "Doc:\n",
      "scope: The nodes in the model graph are organized by their names, which is hierarchical like filesystem.\n",
      "flops: Number of float operations. Note: Please read the implementation for the math behind it.\n",
      "\n",
      "Profile:\n",
      "node name | # float_ops\n",
      "_TFProfRoot (--/1.14b flops)\n",
      "  model_1/conv2d_27/Conv2D (102.76m/102.76m flops)\n",
      "  model_1/conv2d_25/Conv2D (102.76m/102.76m flops)\n",
      "  model_1/conv2d_17/Conv2D (102.76m/102.76m flops)\n",
      "  model_1/conv2d_24/Conv2D (102.76m/102.76m flops)\n",
      "  model_1/conv2d_19/Conv2D (102.76m/102.76m flops)\n",
      "  model_1/conv2d_23/Conv2D (102.76m/102.76m flops)\n",
      "  model_1/conv2d_21/Conv2D (102.76m/102.76m flops)\n",
      "  model_1/conv2d_22/Conv2D (102.76m/102.76m flops)\n",
      "  model_1/conv2d_15/Conv2D (51.38m/51.38m flops)\n",
      "  model_1/conv2d_26/Conv2D (51.38m/51.38m flops)\n",
      "  model_1/conv2d_20/Conv2D (51.38m/51.38m flops)\n",
      "  model_1/conv2d_18/Conv2D (51.38m/51.38m flops)\n",
      "  model_1/conv2d_16/Conv2D (51.38m/51.38m flops)\n",
      "  model_1/conv2d_14/Conv2D (7.23m/7.23m flops)\n",
      "  model_1/depthwise_conv2d_15/depthwise (7.23m/7.23m flops)\n",
      "  model_1/depthwise_conv2d_13/depthwise (7.23m/7.23m flops)\n",
      "  model_1/depthwise_conv2d_14/depthwise (3.61m/3.61m flops)\n",
      "  model_1/depthwise_conv2d_17/depthwise (3.61m/3.61m flops)\n",
      "  model_1/depthwise_conv2d_16/depthwise (1.81m/1.81m flops)\n",
      "  model_1/depthwise_conv2d_19/depthwise (1.81m/1.81m flops)\n",
      "  model_1/depthwise_conv2d_20/depthwise (1.81m/1.81m flops)\n",
      "  model_1/depthwise_conv2d_21/depthwise (1.81m/1.81m flops)\n",
      "  model_1/depthwise_conv2d_22/depthwise (1.81m/1.81m flops)\n",
      "  model_1/depthwise_conv2d_23/depthwise (1.81m/1.81m flops)\n",
      "  model_1/batch_normalization_29/FusedBatchNormV3 (1.61m/1.61m flops)\n",
      "  model_1/depthwise_conv2d_18/depthwise (903.17k/903.17k flops)\n",
      "  model_1/depthwise_conv2d_25/depthwise (903.17k/903.17k flops)\n",
      "  model_1/batch_normalization_33/FusedBatchNormV3 (803.58k/803.58k flops)\n",
      "  model_1/batch_normalization_32/FusedBatchNormV3 (803.58k/803.58k flops)\n",
      "  model_1/batch_normalization_31/FusedBatchNormV3 (803.58k/803.58k flops)\n",
      "  model_1/batch_normalization_28/FusedBatchNormV3 (803.01k/803.01k flops)\n",
      "  model_1/batch_normalization_27/FusedBatchNormV3 (803.01k/803.01k flops)\n",
      "  model_1/conv2d_15/BiasAdd (802.82k/802.82k flops)\n",
      "  model_1/depthwise_conv2d_24/depthwise (451.58k/451.58k flops)\n",
      "  model_1/batch_normalization_35/FusedBatchNormV3 (402.94k/402.94k flops)\n",
      "  model_1/batch_normalization_36/FusedBatchNormV3 (402.94k/402.94k flops)\n",
      "  model_1/batch_normalization_37/FusedBatchNormV3 (402.94k/402.94k flops)\n",
      "  model_1/batch_normalization_30/FusedBatchNormV3 (401.79k/401.79k flops)\n",
      "  model_1/depthwise_conv2d_13/BiasAdd (401.41k/401.41k flops)\n",
      "  model_1/depthwise_conv2d_15/BiasAdd (401.41k/401.41k flops)\n",
      "  model_1/conv2d_16/BiasAdd (401.41k/401.41k flops)\n",
      "  model_1/conv2d_14/BiasAdd (401.41k/401.41k flops)\n",
      "  model_1/conv2d_17/BiasAdd (401.41k/401.41k flops)\n",
      "  model_1/batch_normalization_42/FusedBatchNormV3 (203.78k/203.78k flops)\n",
      "  model_1/batch_normalization_43/FusedBatchNormV3 (203.78k/203.78k flops)\n",
      "  model_1/batch_normalization_41/FusedBatchNormV3 (203.78k/203.78k flops)\n",
      "  model_1/batch_normalization_40/FusedBatchNormV3 (203.78k/203.78k flops)\n",
      "  model_1/batch_normalization_44/FusedBatchNormV3 (203.78k/203.78k flops)\n",
      "  model_1/batch_normalization_45/FusedBatchNormV3 (203.78k/203.78k flops)\n",
      "  model_1/batch_normalization_46/FusedBatchNormV3 (203.78k/203.78k flops)\n",
      "  model_1/batch_normalization_47/FusedBatchNormV3 (203.78k/203.78k flops)\n",
      "  model_1/batch_normalization_39/FusedBatchNormV3 (203.78k/203.78k flops)\n",
      "  model_1/batch_normalization_48/FusedBatchNormV3 (203.78k/203.78k flops)\n",
      "  model_1/batch_normalization_49/FusedBatchNormV3 (203.78k/203.78k flops)\n",
      "  model_1/batch_normalization_34/FusedBatchNormV3 (201.47k/201.47k flops)\n",
      "  model_1/depthwise_conv2d_17/BiasAdd (200.70k/200.70k flops)\n",
      "  model_1/conv2d_18/BiasAdd (200.70k/200.70k flops)\n",
      "  model_1/conv2d_19/BiasAdd (200.70k/200.70k flops)\n",
      "  model_1/depthwise_conv2d_14/BiasAdd (200.70k/200.70k flops)\n",
      "  model_1/batch_normalization_52/FusedBatchNormV3 (106.50k/106.50k flops)\n",
      "  model_1/batch_normalization_53/FusedBatchNormV3 (106.50k/106.50k flops)\n",
      "  model_1/batch_normalization_51/FusedBatchNormV3 (106.50k/106.50k flops)\n",
      "  model_1/batch_normalization_38/FusedBatchNormV3 (101.89k/101.89k flops)\n",
      "  model_1/conv2d_20/BiasAdd (100.35k/100.35k flops)\n",
      "  model_1/depthwise_conv2d_16/BiasAdd (100.35k/100.35k flops)\n",
      "  model_1/depthwise_conv2d_23/BiasAdd (100.35k/100.35k flops)\n",
      "  model_1/conv2d_25/BiasAdd (100.35k/100.35k flops)\n",
      "  model_1/conv2d_24/BiasAdd (100.35k/100.35k flops)\n",
      "  model_1/depthwise_conv2d_22/BiasAdd (100.35k/100.35k flops)\n",
      "  model_1/depthwise_conv2d_19/BiasAdd (100.35k/100.35k flops)\n",
      "  model_1/conv2d_23/BiasAdd (100.35k/100.35k flops)\n",
      "  model_1/depthwise_conv2d_20/BiasAdd (100.35k/100.35k flops)\n",
      "  model_1/conv2d_22/BiasAdd (100.35k/100.35k flops)\n",
      "  model_1/depthwise_conv2d_21/BiasAdd (100.35k/100.35k flops)\n",
      "  model_1/conv2d_21/BiasAdd (100.35k/100.35k flops)\n",
      "  model_1/batch_normalization_50/FusedBatchNormV3 (53.25k/53.25k flops)\n",
      "  model_1/depthwise_conv2d_18/BiasAdd (50.18k/50.18k flops)\n",
      "  model_1/conv2d_27/BiasAdd (50.18k/50.18k flops)\n",
      "  model_1/depthwise_conv2d_25/BiasAdd (50.18k/50.18k flops)\n",
      "  model_1/conv2d_26/BiasAdd (50.18k/50.18k flops)\n",
      "  model_1/global_average_pooling2d_1/Mean (50.18k/50.18k flops)\n",
      "  model_1/depthwise_conv2d_24/BiasAdd (25.09k/25.09k flops)\n",
      "  model_1/dense_1/MatMul (20.48k/20.48k flops)\n",
      "  model_1/dense_1/Softmax (50/50 flops)\n",
      "  model_1/dense_1/BiasAdd (10/10 flops)\n",
      "\n",
      "======================End of Report==========================\n",
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_3 (InputLayer)         [(None, 256, 256, 1)]     0         \n",
      "_________________________________________________________________\n",
      "conv2d_28 (Conv2D)           (None, 128, 128, 32)      320       \n",
      "_________________________________________________________________\n",
      "batch_normalization_54 (Batc (None, 128, 128, 32)      128       \n",
      "_________________________________________________________________\n",
      "activation_54 (Activation)   (None, 128, 128, 32)      0         \n",
      "_________________________________________________________________\n",
      "depthwise_conv2d_26 (Depthwi (None, 128, 128, 32)      320       \n",
      "_________________________________________________________________\n",
      "batch_normalization_55 (Batc (None, 128, 128, 32)      128       \n",
      "_________________________________________________________________\n",
      "activation_55 (Activation)   (None, 128, 128, 32)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_29 (Conv2D)           (None, 128, 128, 64)      2112      \n",
      "_________________________________________________________________\n",
      "batch_normalization_56 (Batc (None, 128, 128, 64)      256       \n",
      "_________________________________________________________________\n",
      "activation_56 (Activation)   (None, 128, 128, 64)      0         \n",
      "_________________________________________________________________\n",
      "depthwise_conv2d_27 (Depthwi (None, 64, 64, 64)        640       \n",
      "_________________________________________________________________\n",
      "batch_normalization_57 (Batc (None, 64, 64, 64)        256       \n",
      "_________________________________________________________________\n",
      "activation_57 (Activation)   (None, 64, 64, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_30 (Conv2D)           (None, 64, 64, 128)       8320      \n",
      "_________________________________________________________________\n",
      "batch_normalization_58 (Batc (None, 64, 64, 128)       512       \n",
      "_________________________________________________________________\n",
      "activation_58 (Activation)   (None, 64, 64, 128)       0         \n",
      "_________________________________________________________________\n",
      "depthwise_conv2d_28 (Depthwi (None, 64, 64, 128)       1280      \n",
      "_________________________________________________________________\n",
      "batch_normalization_59 (Batc (None, 64, 64, 128)       512       \n",
      "_________________________________________________________________\n",
      "activation_59 (Activation)   (None, 64, 64, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_31 (Conv2D)           (None, 64, 64, 128)       16512     \n",
      "_________________________________________________________________\n",
      "batch_normalization_60 (Batc (None, 64, 64, 128)       512       \n",
      "_________________________________________________________________\n",
      "activation_60 (Activation)   (None, 64, 64, 128)       0         \n",
      "_________________________________________________________________\n",
      "depthwise_conv2d_29 (Depthwi (None, 32, 32, 128)       1280      \n",
      "_________________________________________________________________\n",
      "batch_normalization_61 (Batc (None, 32, 32, 128)       512       \n",
      "_________________________________________________________________\n",
      "activation_61 (Activation)   (None, 32, 32, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_32 (Conv2D)           (None, 32, 32, 256)       33024     \n",
      "_________________________________________________________________\n",
      "batch_normalization_62 (Batc (None, 32, 32, 256)       1024      \n",
      "_________________________________________________________________\n",
      "activation_62 (Activation)   (None, 32, 32, 256)       0         \n",
      "_________________________________________________________________\n",
      "depthwise_conv2d_30 (Depthwi (None, 32, 32, 256)       2560      \n",
      "_________________________________________________________________\n",
      "batch_normalization_63 (Batc (None, 32, 32, 256)       1024      \n",
      "_________________________________________________________________\n",
      "activation_63 (Activation)   (None, 32, 32, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_33 (Conv2D)           (None, 32, 32, 256)       65792     \n",
      "_________________________________________________________________\n",
      "batch_normalization_64 (Batc (None, 32, 32, 256)       1024      \n",
      "_________________________________________________________________\n",
      "activation_64 (Activation)   (None, 32, 32, 256)       0         \n",
      "_________________________________________________________________\n",
      "depthwise_conv2d_31 (Depthwi (None, 16, 16, 256)       2560      \n",
      "_________________________________________________________________\n",
      "batch_normalization_65 (Batc (None, 16, 16, 256)       1024      \n",
      "_________________________________________________________________\n",
      "activation_65 (Activation)   (None, 16, 16, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_34 (Conv2D)           (None, 16, 16, 512)       131584    \n",
      "_________________________________________________________________\n",
      "batch_normalization_66 (Batc (None, 16, 16, 512)       2048      \n",
      "_________________________________________________________________\n",
      "activation_66 (Activation)   (None, 16, 16, 512)       0         \n",
      "_________________________________________________________________\n",
      "depthwise_conv2d_32 (Depthwi (None, 16, 16, 512)       5120      \n",
      "_________________________________________________________________\n",
      "batch_normalization_67 (Batc (None, 16, 16, 512)       2048      \n",
      "_________________________________________________________________\n",
      "activation_67 (Activation)   (None, 16, 16, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_35 (Conv2D)           (None, 16, 16, 512)       262656    \n",
      "_________________________________________________________________\n",
      "batch_normalization_68 (Batc (None, 16, 16, 512)       2048      \n",
      "_________________________________________________________________\n",
      "activation_68 (Activation)   (None, 16, 16, 512)       0         \n",
      "_________________________________________________________________\n",
      "depthwise_conv2d_33 (Depthwi (None, 16, 16, 512)       5120      \n",
      "_________________________________________________________________\n",
      "batch_normalization_69 (Batc (None, 16, 16, 512)       2048      \n",
      "_________________________________________________________________\n",
      "activation_69 (Activation)   (None, 16, 16, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_36 (Conv2D)           (None, 16, 16, 512)       262656    \n",
      "_________________________________________________________________\n",
      "batch_normalization_70 (Batc (None, 16, 16, 512)       2048      \n",
      "_________________________________________________________________\n",
      "activation_70 (Activation)   (None, 16, 16, 512)       0         \n",
      "_________________________________________________________________\n",
      "depthwise_conv2d_34 (Depthwi (None, 16, 16, 512)       5120      \n",
      "_________________________________________________________________\n",
      "batch_normalization_71 (Batc (None, 16, 16, 512)       2048      \n",
      "_________________________________________________________________\n",
      "activation_71 (Activation)   (None, 16, 16, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_37 (Conv2D)           (None, 16, 16, 512)       262656    \n",
      "_________________________________________________________________\n",
      "batch_normalization_72 (Batc (None, 16, 16, 512)       2048      \n",
      "_________________________________________________________________\n",
      "activation_72 (Activation)   (None, 16, 16, 512)       0         \n",
      "_________________________________________________________________\n",
      "depthwise_conv2d_35 (Depthwi (None, 16, 16, 512)       5120      \n",
      "_________________________________________________________________\n",
      "batch_normalization_73 (Batc (None, 16, 16, 512)       2048      \n",
      "_________________________________________________________________\n",
      "activation_73 (Activation)   (None, 16, 16, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_38 (Conv2D)           (None, 16, 16, 512)       262656    \n",
      "_________________________________________________________________\n",
      "batch_normalization_74 (Batc (None, 16, 16, 512)       2048      \n",
      "_________________________________________________________________\n",
      "activation_74 (Activation)   (None, 16, 16, 512)       0         \n",
      "_________________________________________________________________\n",
      "depthwise_conv2d_36 (Depthwi (None, 16, 16, 512)       5120      \n",
      "_________________________________________________________________\n",
      "batch_normalization_75 (Batc (None, 16, 16, 512)       2048      \n",
      "_________________________________________________________________\n",
      "activation_75 (Activation)   (None, 16, 16, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_39 (Conv2D)           (None, 16, 16, 512)       262656    \n",
      "_________________________________________________________________\n",
      "batch_normalization_76 (Batc (None, 16, 16, 512)       2048      \n",
      "_________________________________________________________________\n",
      "activation_76 (Activation)   (None, 16, 16, 512)       0         \n",
      "_________________________________________________________________\n",
      "depthwise_conv2d_37 (Depthwi (None, 8, 8, 512)         5120      \n",
      "_________________________________________________________________\n",
      "batch_normalization_77 (Batc (None, 8, 8, 512)         2048      \n",
      "_________________________________________________________________\n",
      "activation_77 (Activation)   (None, 8, 8, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_40 (Conv2D)           (None, 8, 8, 1024)        525312    \n",
      "_________________________________________________________________\n",
      "batch_normalization_78 (Batc (None, 8, 8, 1024)        4096      \n",
      "_________________________________________________________________\n",
      "activation_78 (Activation)   (None, 8, 8, 1024)        0         \n",
      "_________________________________________________________________\n",
      "depthwise_conv2d_38 (Depthwi (None, 8, 8, 1024)        10240     \n",
      "_________________________________________________________________\n",
      "batch_normalization_79 (Batc (None, 8, 8, 1024)        4096      \n",
      "_________________________________________________________________\n",
      "activation_79 (Activation)   (None, 8, 8, 1024)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_41 (Conv2D)           (None, 8, 8, 1024)        1049600   \n",
      "_________________________________________________________________\n",
      "batch_normalization_80 (Batc (None, 8, 8, 1024)        4096      \n",
      "_________________________________________________________________\n",
      "activation_80 (Activation)   (None, 8, 8, 1024)        0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_2 ( (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                10250     \n",
      "=================================================================\n",
      "Total params: 3,249,482\n",
      "Trainable params: 3,227,594\n",
      "Non-trainable params: 21,888\n",
      "_________________________________________________________________\n",
      "79.040556\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-02 06:40:54.370488: I tensorflow/core/grappler/devices.cc:66] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0\n",
      "2022-04-02 06:40:54.370603: I tensorflow/core/grappler/clusters/single_machine.cc:357] Starting new session\n",
      "2022-04-02 06:40:54.374670: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:1137] Optimization results for grappler item: graph_to_optimize\n",
      "  function_optimizer: function_optimizer did nothing. time = 0.004ms.\n",
      "  function_optimizer: function_optimizer did nothing. time = 0.001ms.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=========================Options=============================\n",
      "-max_depth                  10000\n",
      "-min_bytes                  0\n",
      "-min_peak_bytes             0\n",
      "-min_residual_bytes         0\n",
      "-min_output_bytes           0\n",
      "-min_micros                 0\n",
      "-min_accelerator_micros     0\n",
      "-min_cpu_micros             0\n",
      "-min_params                 0\n",
      "-min_float_ops              1\n",
      "-min_occurrence             0\n",
      "-step                       -1\n",
      "-order_by                   float_ops\n",
      "-account_type_regexes       .*\n",
      "-start_name_regexes         .*\n",
      "-trim_name_regexes          \n",
      "-show_name_regexes          .*\n",
      "-hide_name_regexes          \n",
      "-account_displayed_op_only  true\n",
      "-select                     float_ops\n",
      "-output                     stdout:\n",
      "\n",
      "==================Model Analysis Report======================\n",
      "\n",
      "Doc:\n",
      "scope: The nodes in the model graph are organized by their names, which is hierarchical like filesystem.\n",
      "flops: Number of float operations. Note: Please read the implementation for the math behind it.\n",
      "\n",
      "Profile:\n",
      "node name | # float_ops\n",
      "_TFProfRoot (--/1.48b flops)\n",
      "  model_2/conv2d_41/Conv2D (134.22m/134.22m flops)\n",
      "  model_2/conv2d_39/Conv2D (134.22m/134.22m flops)\n",
      "  model_2/conv2d_31/Conv2D (134.22m/134.22m flops)\n",
      "  model_2/conv2d_38/Conv2D (134.22m/134.22m flops)\n",
      "  model_2/conv2d_33/Conv2D (134.22m/134.22m flops)\n",
      "  model_2/conv2d_37/Conv2D (134.22m/134.22m flops)\n",
      "  model_2/conv2d_35/Conv2D (134.22m/134.22m flops)\n",
      "  model_2/conv2d_36/Conv2D (134.22m/134.22m flops)\n",
      "  model_2/conv2d_29/Conv2D (67.11m/67.11m flops)\n",
      "  model_2/conv2d_40/Conv2D (67.11m/67.11m flops)\n",
      "  model_2/conv2d_34/Conv2D (67.11m/67.11m flops)\n",
      "  model_2/conv2d_32/Conv2D (67.11m/67.11m flops)\n",
      "  model_2/conv2d_30/Conv2D (67.11m/67.11m flops)\n",
      "  model_2/conv2d_28/Conv2D (9.44m/9.44m flops)\n",
      "  model_2/depthwise_conv2d_28/depthwise (9.44m/9.44m flops)\n",
      "  model_2/depthwise_conv2d_26/depthwise (9.44m/9.44m flops)\n",
      "  model_2/depthwise_conv2d_27/depthwise (4.72m/4.72m flops)\n",
      "  model_2/depthwise_conv2d_30/depthwise (4.72m/4.72m flops)\n",
      "  model_2/depthwise_conv2d_29/depthwise (2.36m/2.36m flops)\n",
      "  model_2/depthwise_conv2d_32/depthwise (2.36m/2.36m flops)\n",
      "  model_2/depthwise_conv2d_33/depthwise (2.36m/2.36m flops)\n",
      "  model_2/depthwise_conv2d_34/depthwise (2.36m/2.36m flops)\n",
      "  model_2/depthwise_conv2d_35/depthwise (2.36m/2.36m flops)\n",
      "  model_2/depthwise_conv2d_36/depthwise (2.36m/2.36m flops)\n",
      "  model_2/batch_normalization_56/FusedBatchNormV3 (2.10m/2.10m flops)\n",
      "  model_2/depthwise_conv2d_31/depthwise (1.18m/1.18m flops)\n",
      "  model_2/depthwise_conv2d_38/depthwise (1.18m/1.18m flops)\n",
      "  model_2/batch_normalization_60/FusedBatchNormV3 (1.05m/1.05m flops)\n",
      "  model_2/batch_normalization_59/FusedBatchNormV3 (1.05m/1.05m flops)\n",
      "  model_2/batch_normalization_58/FusedBatchNormV3 (1.05m/1.05m flops)\n",
      "  model_2/batch_normalization_55/FusedBatchNormV3 (1.05m/1.05m flops)\n",
      "  model_2/batch_normalization_54/FusedBatchNormV3 (1.05m/1.05m flops)\n",
      "  model_2/conv2d_29/BiasAdd (1.05m/1.05m flops)\n",
      "  model_2/depthwise_conv2d_37/depthwise (589.82k/589.82k flops)\n",
      "  model_2/batch_normalization_62/FusedBatchNormV3 (525.82k/525.82k flops)\n",
      "  model_2/batch_normalization_63/FusedBatchNormV3 (525.82k/525.82k flops)\n",
      "  model_2/batch_normalization_64/FusedBatchNormV3 (525.82k/525.82k flops)\n",
      "  model_2/batch_normalization_57/FusedBatchNormV3 (524.67k/524.67k flops)\n",
      "  model_2/depthwise_conv2d_26/BiasAdd (524.29k/524.29k flops)\n",
      "  model_2/depthwise_conv2d_28/BiasAdd (524.29k/524.29k flops)\n",
      "  model_2/conv2d_30/BiasAdd (524.29k/524.29k flops)\n",
      "  model_2/conv2d_28/BiasAdd (524.29k/524.29k flops)\n",
      "  model_2/conv2d_31/BiasAdd (524.29k/524.29k flops)\n",
      "  model_2/batch_normalization_69/FusedBatchNormV3 (265.22k/265.22k flops)\n",
      "  model_2/batch_normalization_70/FusedBatchNormV3 (265.22k/265.22k flops)\n",
      "  model_2/batch_normalization_68/FusedBatchNormV3 (265.22k/265.22k flops)\n",
      "  model_2/batch_normalization_67/FusedBatchNormV3 (265.22k/265.22k flops)\n",
      "  model_2/batch_normalization_71/FusedBatchNormV3 (265.22k/265.22k flops)\n",
      "  model_2/batch_normalization_72/FusedBatchNormV3 (265.22k/265.22k flops)\n",
      "  model_2/batch_normalization_73/FusedBatchNormV3 (265.22k/265.22k flops)\n",
      "  model_2/batch_normalization_74/FusedBatchNormV3 (265.22k/265.22k flops)\n",
      "  model_2/batch_normalization_66/FusedBatchNormV3 (265.22k/265.22k flops)\n",
      "  model_2/batch_normalization_75/FusedBatchNormV3 (265.22k/265.22k flops)\n",
      "  model_2/batch_normalization_76/FusedBatchNormV3 (265.22k/265.22k flops)\n",
      "  model_2/batch_normalization_61/FusedBatchNormV3 (262.91k/262.91k flops)\n",
      "  model_2/depthwise_conv2d_30/BiasAdd (262.14k/262.14k flops)\n",
      "  model_2/conv2d_32/BiasAdd (262.14k/262.14k flops)\n",
      "  model_2/conv2d_33/BiasAdd (262.14k/262.14k flops)\n",
      "  model_2/depthwise_conv2d_27/BiasAdd (262.14k/262.14k flops)\n",
      "  model_2/batch_normalization_79/FusedBatchNormV3 (137.22k/137.22k flops)\n",
      "  model_2/batch_normalization_80/FusedBatchNormV3 (137.22k/137.22k flops)\n",
      "  model_2/batch_normalization_78/FusedBatchNormV3 (137.22k/137.22k flops)\n",
      "  model_2/batch_normalization_65/FusedBatchNormV3 (132.61k/132.61k flops)\n",
      "  model_2/conv2d_34/BiasAdd (131.07k/131.07k flops)\n",
      "  model_2/depthwise_conv2d_29/BiasAdd (131.07k/131.07k flops)\n",
      "  model_2/depthwise_conv2d_36/BiasAdd (131.07k/131.07k flops)\n",
      "  model_2/conv2d_39/BiasAdd (131.07k/131.07k flops)\n",
      "  model_2/conv2d_38/BiasAdd (131.07k/131.07k flops)\n",
      "  model_2/depthwise_conv2d_35/BiasAdd (131.07k/131.07k flops)\n",
      "  model_2/depthwise_conv2d_32/BiasAdd (131.07k/131.07k flops)\n",
      "  model_2/conv2d_37/BiasAdd (131.07k/131.07k flops)\n",
      "  model_2/depthwise_conv2d_33/BiasAdd (131.07k/131.07k flops)\n",
      "  model_2/conv2d_36/BiasAdd (131.07k/131.07k flops)\n",
      "  model_2/depthwise_conv2d_34/BiasAdd (131.07k/131.07k flops)\n",
      "  model_2/conv2d_35/BiasAdd (131.07k/131.07k flops)\n",
      "  model_2/batch_normalization_77/FusedBatchNormV3 (68.61k/68.61k flops)\n",
      "  model_2/depthwise_conv2d_31/BiasAdd (65.54k/65.54k flops)\n",
      "  model_2/conv2d_41/BiasAdd (65.54k/65.54k flops)\n",
      "  model_2/depthwise_conv2d_38/BiasAdd (65.54k/65.54k flops)\n",
      "  model_2/conv2d_40/BiasAdd (65.54k/65.54k flops)\n",
      "  model_2/global_average_pooling2d_2/Mean (65.54k/65.54k flops)\n",
      "  model_2/depthwise_conv2d_37/BiasAdd (32.77k/32.77k flops)\n",
      "  model_2/dense_2/MatMul (20.48k/20.48k flops)\n",
      "  model_2/dense_2/Softmax (50/50 flops)\n",
      "  model_2/dense_2/BiasAdd (10/10 flops)\n",
      "\n",
      "======================End of Report==========================\n",
      "Model: \"model_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         [(None, 288, 288, 1)]     0         \n",
      "_________________________________________________________________\n",
      "conv2d_42 (Conv2D)           (None, 144, 144, 32)      320       \n",
      "_________________________________________________________________\n",
      "batch_normalization_81 (Batc (None, 144, 144, 32)      128       \n",
      "_________________________________________________________________\n",
      "activation_81 (Activation)   (None, 144, 144, 32)      0         \n",
      "_________________________________________________________________\n",
      "depthwise_conv2d_39 (Depthwi (None, 144, 144, 32)      320       \n",
      "_________________________________________________________________\n",
      "batch_normalization_82 (Batc (None, 144, 144, 32)      128       \n",
      "_________________________________________________________________\n",
      "activation_82 (Activation)   (None, 144, 144, 32)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_43 (Conv2D)           (None, 144, 144, 64)      2112      \n",
      "_________________________________________________________________\n",
      "batch_normalization_83 (Batc (None, 144, 144, 64)      256       \n",
      "_________________________________________________________________\n",
      "activation_83 (Activation)   (None, 144, 144, 64)      0         \n",
      "_________________________________________________________________\n",
      "depthwise_conv2d_40 (Depthwi (None, 72, 72, 64)        640       \n",
      "_________________________________________________________________\n",
      "batch_normalization_84 (Batc (None, 72, 72, 64)        256       \n",
      "_________________________________________________________________\n",
      "activation_84 (Activation)   (None, 72, 72, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_44 (Conv2D)           (None, 72, 72, 128)       8320      \n",
      "_________________________________________________________________\n",
      "batch_normalization_85 (Batc (None, 72, 72, 128)       512       \n",
      "_________________________________________________________________\n",
      "activation_85 (Activation)   (None, 72, 72, 128)       0         \n",
      "_________________________________________________________________\n",
      "depthwise_conv2d_41 (Depthwi (None, 72, 72, 128)       1280      \n",
      "_________________________________________________________________\n",
      "batch_normalization_86 (Batc (None, 72, 72, 128)       512       \n",
      "_________________________________________________________________\n",
      "activation_86 (Activation)   (None, 72, 72, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_45 (Conv2D)           (None, 72, 72, 128)       16512     \n",
      "_________________________________________________________________\n",
      "batch_normalization_87 (Batc (None, 72, 72, 128)       512       \n",
      "_________________________________________________________________\n",
      "activation_87 (Activation)   (None, 72, 72, 128)       0         \n",
      "_________________________________________________________________\n",
      "depthwise_conv2d_42 (Depthwi (None, 36, 36, 128)       1280      \n",
      "_________________________________________________________________\n",
      "batch_normalization_88 (Batc (None, 36, 36, 128)       512       \n",
      "_________________________________________________________________\n",
      "activation_88 (Activation)   (None, 36, 36, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_46 (Conv2D)           (None, 36, 36, 256)       33024     \n",
      "_________________________________________________________________\n",
      "batch_normalization_89 (Batc (None, 36, 36, 256)       1024      \n",
      "_________________________________________________________________\n",
      "activation_89 (Activation)   (None, 36, 36, 256)       0         \n",
      "_________________________________________________________________\n",
      "depthwise_conv2d_43 (Depthwi (None, 36, 36, 256)       2560      \n",
      "_________________________________________________________________\n",
      "batch_normalization_90 (Batc (None, 36, 36, 256)       1024      \n",
      "_________________________________________________________________\n",
      "activation_90 (Activation)   (None, 36, 36, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_47 (Conv2D)           (None, 36, 36, 256)       65792     \n",
      "_________________________________________________________________\n",
      "batch_normalization_91 (Batc (None, 36, 36, 256)       1024      \n",
      "_________________________________________________________________\n",
      "activation_91 (Activation)   (None, 36, 36, 256)       0         \n",
      "_________________________________________________________________\n",
      "depthwise_conv2d_44 (Depthwi (None, 18, 18, 256)       2560      \n",
      "_________________________________________________________________\n",
      "batch_normalization_92 (Batc (None, 18, 18, 256)       1024      \n",
      "_________________________________________________________________\n",
      "activation_92 (Activation)   (None, 18, 18, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_48 (Conv2D)           (None, 18, 18, 512)       131584    \n",
      "_________________________________________________________________\n",
      "batch_normalization_93 (Batc (None, 18, 18, 512)       2048      \n",
      "_________________________________________________________________\n",
      "activation_93 (Activation)   (None, 18, 18, 512)       0         \n",
      "_________________________________________________________________\n",
      "depthwise_conv2d_45 (Depthwi (None, 18, 18, 512)       5120      \n",
      "_________________________________________________________________\n",
      "batch_normalization_94 (Batc (None, 18, 18, 512)       2048      \n",
      "_________________________________________________________________\n",
      "activation_94 (Activation)   (None, 18, 18, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_49 (Conv2D)           (None, 18, 18, 512)       262656    \n",
      "_________________________________________________________________\n",
      "batch_normalization_95 (Batc (None, 18, 18, 512)       2048      \n",
      "_________________________________________________________________\n",
      "activation_95 (Activation)   (None, 18, 18, 512)       0         \n",
      "_________________________________________________________________\n",
      "depthwise_conv2d_46 (Depthwi (None, 18, 18, 512)       5120      \n",
      "_________________________________________________________________\n",
      "batch_normalization_96 (Batc (None, 18, 18, 512)       2048      \n",
      "_________________________________________________________________\n",
      "activation_96 (Activation)   (None, 18, 18, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_50 (Conv2D)           (None, 18, 18, 512)       262656    \n",
      "_________________________________________________________________\n",
      "batch_normalization_97 (Batc (None, 18, 18, 512)       2048      \n",
      "_________________________________________________________________\n",
      "activation_97 (Activation)   (None, 18, 18, 512)       0         \n",
      "_________________________________________________________________\n",
      "depthwise_conv2d_47 (Depthwi (None, 18, 18, 512)       5120      \n",
      "_________________________________________________________________\n",
      "batch_normalization_98 (Batc (None, 18, 18, 512)       2048      \n",
      "_________________________________________________________________\n",
      "activation_98 (Activation)   (None, 18, 18, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_51 (Conv2D)           (None, 18, 18, 512)       262656    \n",
      "_________________________________________________________________\n",
      "batch_normalization_99 (Batc (None, 18, 18, 512)       2048      \n",
      "_________________________________________________________________\n",
      "activation_99 (Activation)   (None, 18, 18, 512)       0         \n",
      "_________________________________________________________________\n",
      "depthwise_conv2d_48 (Depthwi (None, 18, 18, 512)       5120      \n",
      "_________________________________________________________________\n",
      "batch_normalization_100 (Bat (None, 18, 18, 512)       2048      \n",
      "_________________________________________________________________\n",
      "activation_100 (Activation)  (None, 18, 18, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_52 (Conv2D)           (None, 18, 18, 512)       262656    \n",
      "_________________________________________________________________\n",
      "batch_normalization_101 (Bat (None, 18, 18, 512)       2048      \n",
      "_________________________________________________________________\n",
      "activation_101 (Activation)  (None, 18, 18, 512)       0         \n",
      "_________________________________________________________________\n",
      "depthwise_conv2d_49 (Depthwi (None, 18, 18, 512)       5120      \n",
      "_________________________________________________________________\n",
      "batch_normalization_102 (Bat (None, 18, 18, 512)       2048      \n",
      "_________________________________________________________________\n",
      "activation_102 (Activation)  (None, 18, 18, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_53 (Conv2D)           (None, 18, 18, 512)       262656    \n",
      "_________________________________________________________________\n",
      "batch_normalization_103 (Bat (None, 18, 18, 512)       2048      \n",
      "_________________________________________________________________\n",
      "activation_103 (Activation)  (None, 18, 18, 512)       0         \n",
      "_________________________________________________________________\n",
      "depthwise_conv2d_50 (Depthwi (None, 9, 9, 512)         5120      \n",
      "_________________________________________________________________\n",
      "batch_normalization_104 (Bat (None, 9, 9, 512)         2048      \n",
      "_________________________________________________________________\n",
      "activation_104 (Activation)  (None, 9, 9, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_54 (Conv2D)           (None, 9, 9, 1024)        525312    \n",
      "_________________________________________________________________\n",
      "batch_normalization_105 (Bat (None, 9, 9, 1024)        4096      \n",
      "_________________________________________________________________\n",
      "activation_105 (Activation)  (None, 9, 9, 1024)        0         \n",
      "_________________________________________________________________\n",
      "depthwise_conv2d_51 (Depthwi (None, 9, 9, 1024)        10240     \n",
      "_________________________________________________________________\n",
      "batch_normalization_106 (Bat (None, 9, 9, 1024)        4096      \n",
      "_________________________________________________________________\n",
      "activation_106 (Activation)  (None, 9, 9, 1024)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_55 (Conv2D)           (None, 9, 9, 1024)        1049600   \n",
      "_________________________________________________________________\n",
      "batch_normalization_107 (Bat (None, 9, 9, 1024)        4096      \n",
      "_________________________________________________________________\n",
      "activation_107 (Activation)  (None, 9, 9, 1024)        0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_3 ( (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                10250     \n",
      "=================================================================\n",
      "Total params: 3,249,482\n",
      "Trainable params: 3,227,594\n",
      "Non-trainable params: 21,888\n",
      "_________________________________________________________________\n",
      "100.034604\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-02 06:40:55.297805: I tensorflow/core/grappler/devices.cc:66] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0\n",
      "2022-04-02 06:40:55.297871: I tensorflow/core/grappler/clusters/single_machine.cc:357] Starting new session\n",
      "2022-04-02 06:40:55.302084: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:1137] Optimization results for grappler item: graph_to_optimize\n",
      "  function_optimizer: function_optimizer did nothing. time = 0.006ms.\n",
      "  function_optimizer: function_optimizer did nothing. time = 0.001ms.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=========================Options=============================\n",
      "-max_depth                  10000\n",
      "-min_bytes                  0\n",
      "-min_peak_bytes             0\n",
      "-min_residual_bytes         0\n",
      "-min_output_bytes           0\n",
      "-min_micros                 0\n",
      "-min_accelerator_micros     0\n",
      "-min_cpu_micros             0\n",
      "-min_params                 0\n",
      "-min_float_ops              1\n",
      "-min_occurrence             0\n",
      "-step                       -1\n",
      "-order_by                   float_ops\n",
      "-account_type_regexes       .*\n",
      "-start_name_regexes         .*\n",
      "-trim_name_regexes          \n",
      "-show_name_regexes          .*\n",
      "-hide_name_regexes          \n",
      "-account_displayed_op_only  true\n",
      "-select                     float_ops\n",
      "-output                     stdout:\n",
      "\n",
      "==================Model Analysis Report======================\n",
      "\n",
      "Doc:\n",
      "scope: The nodes in the model graph are organized by their names, which is hierarchical like filesystem.\n",
      "flops: Number of float operations. Note: Please read the implementation for the math behind it.\n",
      "\n",
      "Profile:\n",
      "node name | # float_ops\n",
      "_TFProfRoot (--/1.88b flops)\n",
      "  model_3/conv2d_53/Conv2D (169.87m/169.87m flops)\n",
      "  model_3/conv2d_55/Conv2D (169.87m/169.87m flops)\n",
      "  model_3/conv2d_45/Conv2D (169.87m/169.87m flops)\n",
      "  model_3/conv2d_47/Conv2D (169.87m/169.87m flops)\n",
      "  model_3/conv2d_52/Conv2D (169.87m/169.87m flops)\n",
      "  model_3/conv2d_51/Conv2D (169.87m/169.87m flops)\n",
      "  model_3/conv2d_49/Conv2D (169.87m/169.87m flops)\n",
      "  model_3/conv2d_50/Conv2D (169.87m/169.87m flops)\n",
      "  model_3/conv2d_48/Conv2D (84.93m/84.93m flops)\n",
      "  model_3/conv2d_43/Conv2D (84.93m/84.93m flops)\n",
      "  model_3/conv2d_44/Conv2D (84.93m/84.93m flops)\n",
      "  model_3/conv2d_54/Conv2D (84.93m/84.93m flops)\n",
      "  model_3/conv2d_46/Conv2D (84.93m/84.93m flops)\n",
      "  model_3/depthwise_conv2d_41/depthwise (11.94m/11.94m flops)\n",
      "  model_3/conv2d_42/Conv2D (11.94m/11.94m flops)\n",
      "  model_3/depthwise_conv2d_39/depthwise (11.94m/11.94m flops)\n",
      "  model_3/depthwise_conv2d_43/depthwise (5.97m/5.97m flops)\n",
      "  model_3/depthwise_conv2d_40/depthwise (5.97m/5.97m flops)\n",
      "  model_3/depthwise_conv2d_49/depthwise (2.99m/2.99m flops)\n",
      "  model_3/depthwise_conv2d_48/depthwise (2.99m/2.99m flops)\n",
      "  model_3/depthwise_conv2d_46/depthwise (2.99m/2.99m flops)\n",
      "  model_3/depthwise_conv2d_47/depthwise (2.99m/2.99m flops)\n",
      "  model_3/depthwise_conv2d_42/depthwise (2.99m/2.99m flops)\n",
      "  model_3/depthwise_conv2d_45/depthwise (2.99m/2.99m flops)\n",
      "  model_3/batch_normalization_83/FusedBatchNormV3 (2.65m/2.65m flops)\n",
      "  model_3/depthwise_conv2d_51/depthwise (1.49m/1.49m flops)\n",
      "  model_3/depthwise_conv2d_44/depthwise (1.49m/1.49m flops)\n",
      "  model_3/batch_normalization_87/FusedBatchNormV3 (1.33m/1.33m flops)\n",
      "  model_3/batch_normalization_86/FusedBatchNormV3 (1.33m/1.33m flops)\n",
      "  model_3/batch_normalization_85/FusedBatchNormV3 (1.33m/1.33m flops)\n",
      "  model_3/batch_normalization_81/FusedBatchNormV3 (1.33m/1.33m flops)\n",
      "  model_3/batch_normalization_82/FusedBatchNormV3 (1.33m/1.33m flops)\n",
      "  model_3/conv2d_43/BiasAdd (1.33m/1.33m flops)\n",
      "  model_3/depthwise_conv2d_50/depthwise (746.50k/746.50k flops)\n",
      "  model_3/batch_normalization_91/FusedBatchNormV3 (665.09k/665.09k flops)\n",
      "  model_3/batch_normalization_90/FusedBatchNormV3 (665.09k/665.09k flops)\n",
      "  model_3/batch_normalization_89/FusedBatchNormV3 (665.09k/665.09k flops)\n",
      "  model_3/batch_normalization_84/FusedBatchNormV3 (663.94k/663.94k flops)\n",
      "  model_3/conv2d_42/BiasAdd (663.55k/663.55k flops)\n",
      "  model_3/conv2d_45/BiasAdd (663.55k/663.55k flops)\n",
      "  model_3/conv2d_44/BiasAdd (663.55k/663.55k flops)\n",
      "  model_3/depthwise_conv2d_41/BiasAdd (663.55k/663.55k flops)\n",
      "  model_3/depthwise_conv2d_39/BiasAdd (663.55k/663.55k flops)\n",
      "  model_3/batch_normalization_101/FusedBatchNormV3 (334.85k/334.85k flops)\n",
      "  model_3/batch_normalization_100/FusedBatchNormV3 (334.85k/334.85k flops)\n",
      "  model_3/batch_normalization_102/FusedBatchNormV3 (334.85k/334.85k flops)\n",
      "  model_3/batch_normalization_103/FusedBatchNormV3 (334.85k/334.85k flops)\n",
      "  model_3/batch_normalization_93/FusedBatchNormV3 (334.85k/334.85k flops)\n",
      "  model_3/batch_normalization_94/FusedBatchNormV3 (334.85k/334.85k flops)\n",
      "  model_3/batch_normalization_95/FusedBatchNormV3 (334.85k/334.85k flops)\n",
      "  model_3/batch_normalization_96/FusedBatchNormV3 (334.85k/334.85k flops)\n",
      "  model_3/batch_normalization_97/FusedBatchNormV3 (334.85k/334.85k flops)\n",
      "  model_3/batch_normalization_98/FusedBatchNormV3 (334.85k/334.85k flops)\n",
      "  model_3/batch_normalization_99/FusedBatchNormV3 (334.85k/334.85k flops)\n",
      "  model_3/batch_normalization_88/FusedBatchNormV3 (332.54k/332.54k flops)\n",
      "  model_3/conv2d_46/BiasAdd (331.78k/331.78k flops)\n",
      "  model_3/depthwise_conv2d_40/BiasAdd (331.78k/331.78k flops)\n",
      "  model_3/conv2d_47/BiasAdd (331.78k/331.78k flops)\n",
      "  model_3/depthwise_conv2d_43/BiasAdd (331.78k/331.78k flops)\n",
      "  model_3/batch_normalization_106/FusedBatchNormV3 (172.03k/172.03k flops)\n",
      "  model_3/batch_normalization_107/FusedBatchNormV3 (172.03k/172.03k flops)\n",
      "  model_3/batch_normalization_105/FusedBatchNormV3 (172.03k/172.03k flops)\n",
      "  model_3/batch_normalization_92/FusedBatchNormV3 (167.42k/167.42k flops)\n",
      "  model_3/depthwise_conv2d_46/BiasAdd (165.89k/165.89k flops)\n",
      "  model_3/depthwise_conv2d_47/BiasAdd (165.89k/165.89k flops)\n",
      "  model_3/depthwise_conv2d_48/BiasAdd (165.89k/165.89k flops)\n",
      "  model_3/depthwise_conv2d_45/BiasAdd (165.89k/165.89k flops)\n",
      "  model_3/depthwise_conv2d_49/BiasAdd (165.89k/165.89k flops)\n",
      "  model_3/conv2d_51/BiasAdd (165.89k/165.89k flops)\n",
      "  model_3/depthwise_conv2d_42/BiasAdd (165.89k/165.89k flops)\n",
      "  model_3/conv2d_53/BiasAdd (165.89k/165.89k flops)\n",
      "  model_3/conv2d_48/BiasAdd (165.89k/165.89k flops)\n",
      "  model_3/conv2d_52/BiasAdd (165.89k/165.89k flops)\n",
      "  model_3/conv2d_49/BiasAdd (165.89k/165.89k flops)\n",
      "  model_3/conv2d_50/BiasAdd (165.89k/165.89k flops)\n",
      "  model_3/batch_normalization_104/FusedBatchNormV3 (86.02k/86.02k flops)\n",
      "  model_3/depthwise_conv2d_44/BiasAdd (82.94k/82.94k flops)\n",
      "  model_3/conv2d_55/BiasAdd (82.94k/82.94k flops)\n",
      "  model_3/conv2d_54/BiasAdd (82.94k/82.94k flops)\n",
      "  model_3/depthwise_conv2d_51/BiasAdd (82.94k/82.94k flops)\n",
      "  model_3/global_average_pooling2d_3/Mean (82.94k/82.94k flops)\n",
      "  model_3/depthwise_conv2d_50/BiasAdd (41.47k/41.47k flops)\n",
      "  model_3/dense_3/MatMul (20.48k/20.48k flops)\n",
      "  model_3/dense_3/Softmax (50/50 flops)\n",
      "  model_3/dense_3/BiasAdd (10/10 flops)\n",
      "\n",
      "======================End of Report==========================\n",
      "Model: \"model_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_5 (InputLayer)         [(None, 320, 320, 1)]     0         \n",
      "_________________________________________________________________\n",
      "conv2d_56 (Conv2D)           (None, 160, 160, 32)      320       \n",
      "_________________________________________________________________\n",
      "batch_normalization_108 (Bat (None, 160, 160, 32)      128       \n",
      "_________________________________________________________________\n",
      "activation_108 (Activation)  (None, 160, 160, 32)      0         \n",
      "_________________________________________________________________\n",
      "depthwise_conv2d_52 (Depthwi (None, 160, 160, 32)      320       \n",
      "_________________________________________________________________\n",
      "batch_normalization_109 (Bat (None, 160, 160, 32)      128       \n",
      "_________________________________________________________________\n",
      "activation_109 (Activation)  (None, 160, 160, 32)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_57 (Conv2D)           (None, 160, 160, 64)      2112      \n",
      "_________________________________________________________________\n",
      "batch_normalization_110 (Bat (None, 160, 160, 64)      256       \n",
      "_________________________________________________________________\n",
      "activation_110 (Activation)  (None, 160, 160, 64)      0         \n",
      "_________________________________________________________________\n",
      "depthwise_conv2d_53 (Depthwi (None, 80, 80, 64)        640       \n",
      "_________________________________________________________________\n",
      "batch_normalization_111 (Bat (None, 80, 80, 64)        256       \n",
      "_________________________________________________________________\n",
      "activation_111 (Activation)  (None, 80, 80, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_58 (Conv2D)           (None, 80, 80, 128)       8320      \n",
      "_________________________________________________________________\n",
      "batch_normalization_112 (Bat (None, 80, 80, 128)       512       \n",
      "_________________________________________________________________\n",
      "activation_112 (Activation)  (None, 80, 80, 128)       0         \n",
      "_________________________________________________________________\n",
      "depthwise_conv2d_54 (Depthwi (None, 80, 80, 128)       1280      \n",
      "_________________________________________________________________\n",
      "batch_normalization_113 (Bat (None, 80, 80, 128)       512       \n",
      "_________________________________________________________________\n",
      "activation_113 (Activation)  (None, 80, 80, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_59 (Conv2D)           (None, 80, 80, 128)       16512     \n",
      "_________________________________________________________________\n",
      "batch_normalization_114 (Bat (None, 80, 80, 128)       512       \n",
      "_________________________________________________________________\n",
      "activation_114 (Activation)  (None, 80, 80, 128)       0         \n",
      "_________________________________________________________________\n",
      "depthwise_conv2d_55 (Depthwi (None, 40, 40, 128)       1280      \n",
      "_________________________________________________________________\n",
      "batch_normalization_115 (Bat (None, 40, 40, 128)       512       \n",
      "_________________________________________________________________\n",
      "activation_115 (Activation)  (None, 40, 40, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_60 (Conv2D)           (None, 40, 40, 256)       33024     \n",
      "_________________________________________________________________\n",
      "batch_normalization_116 (Bat (None, 40, 40, 256)       1024      \n",
      "_________________________________________________________________\n",
      "activation_116 (Activation)  (None, 40, 40, 256)       0         \n",
      "_________________________________________________________________\n",
      "depthwise_conv2d_56 (Depthwi (None, 40, 40, 256)       2560      \n",
      "_________________________________________________________________\n",
      "batch_normalization_117 (Bat (None, 40, 40, 256)       1024      \n",
      "_________________________________________________________________\n",
      "activation_117 (Activation)  (None, 40, 40, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_61 (Conv2D)           (None, 40, 40, 256)       65792     \n",
      "_________________________________________________________________\n",
      "batch_normalization_118 (Bat (None, 40, 40, 256)       1024      \n",
      "_________________________________________________________________\n",
      "activation_118 (Activation)  (None, 40, 40, 256)       0         \n",
      "_________________________________________________________________\n",
      "depthwise_conv2d_57 (Depthwi (None, 20, 20, 256)       2560      \n",
      "_________________________________________________________________\n",
      "batch_normalization_119 (Bat (None, 20, 20, 256)       1024      \n",
      "_________________________________________________________________\n",
      "activation_119 (Activation)  (None, 20, 20, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_62 (Conv2D)           (None, 20, 20, 512)       131584    \n",
      "_________________________________________________________________\n",
      "batch_normalization_120 (Bat (None, 20, 20, 512)       2048      \n",
      "_________________________________________________________________\n",
      "activation_120 (Activation)  (None, 20, 20, 512)       0         \n",
      "_________________________________________________________________\n",
      "depthwise_conv2d_58 (Depthwi (None, 20, 20, 512)       5120      \n",
      "_________________________________________________________________\n",
      "batch_normalization_121 (Bat (None, 20, 20, 512)       2048      \n",
      "_________________________________________________________________\n",
      "activation_121 (Activation)  (None, 20, 20, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_63 (Conv2D)           (None, 20, 20, 512)       262656    \n",
      "_________________________________________________________________\n",
      "batch_normalization_122 (Bat (None, 20, 20, 512)       2048      \n",
      "_________________________________________________________________\n",
      "activation_122 (Activation)  (None, 20, 20, 512)       0         \n",
      "_________________________________________________________________\n",
      "depthwise_conv2d_59 (Depthwi (None, 20, 20, 512)       5120      \n",
      "_________________________________________________________________\n",
      "batch_normalization_123 (Bat (None, 20, 20, 512)       2048      \n",
      "_________________________________________________________________\n",
      "activation_123 (Activation)  (None, 20, 20, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_64 (Conv2D)           (None, 20, 20, 512)       262656    \n",
      "_________________________________________________________________\n",
      "batch_normalization_124 (Bat (None, 20, 20, 512)       2048      \n",
      "_________________________________________________________________\n",
      "activation_124 (Activation)  (None, 20, 20, 512)       0         \n",
      "_________________________________________________________________\n",
      "depthwise_conv2d_60 (Depthwi (None, 20, 20, 512)       5120      \n",
      "_________________________________________________________________\n",
      "batch_normalization_125 (Bat (None, 20, 20, 512)       2048      \n",
      "_________________________________________________________________\n",
      "activation_125 (Activation)  (None, 20, 20, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_65 (Conv2D)           (None, 20, 20, 512)       262656    \n",
      "_________________________________________________________________\n",
      "batch_normalization_126 (Bat (None, 20, 20, 512)       2048      \n",
      "_________________________________________________________________\n",
      "activation_126 (Activation)  (None, 20, 20, 512)       0         \n",
      "_________________________________________________________________\n",
      "depthwise_conv2d_61 (Depthwi (None, 20, 20, 512)       5120      \n",
      "_________________________________________________________________\n",
      "batch_normalization_127 (Bat (None, 20, 20, 512)       2048      \n",
      "_________________________________________________________________\n",
      "activation_127 (Activation)  (None, 20, 20, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_66 (Conv2D)           (None, 20, 20, 512)       262656    \n",
      "_________________________________________________________________\n",
      "batch_normalization_128 (Bat (None, 20, 20, 512)       2048      \n",
      "_________________________________________________________________\n",
      "activation_128 (Activation)  (None, 20, 20, 512)       0         \n",
      "_________________________________________________________________\n",
      "depthwise_conv2d_62 (Depthwi (None, 20, 20, 512)       5120      \n",
      "_________________________________________________________________\n",
      "batch_normalization_129 (Bat (None, 20, 20, 512)       2048      \n",
      "_________________________________________________________________\n",
      "activation_129 (Activation)  (None, 20, 20, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_67 (Conv2D)           (None, 20, 20, 512)       262656    \n",
      "_________________________________________________________________\n",
      "batch_normalization_130 (Bat (None, 20, 20, 512)       2048      \n",
      "_________________________________________________________________\n",
      "activation_130 (Activation)  (None, 20, 20, 512)       0         \n",
      "_________________________________________________________________\n",
      "depthwise_conv2d_63 (Depthwi (None, 10, 10, 512)       5120      \n",
      "_________________________________________________________________\n",
      "batch_normalization_131 (Bat (None, 10, 10, 512)       2048      \n",
      "_________________________________________________________________\n",
      "activation_131 (Activation)  (None, 10, 10, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_68 (Conv2D)           (None, 10, 10, 1024)      525312    \n",
      "_________________________________________________________________\n",
      "batch_normalization_132 (Bat (None, 10, 10, 1024)      4096      \n",
      "_________________________________________________________________\n",
      "activation_132 (Activation)  (None, 10, 10, 1024)      0         \n",
      "_________________________________________________________________\n",
      "depthwise_conv2d_64 (Depthwi (None, 10, 10, 1024)      10240     \n",
      "_________________________________________________________________\n",
      "batch_normalization_133 (Bat (None, 10, 10, 1024)      4096      \n",
      "_________________________________________________________________\n",
      "activation_133 (Activation)  (None, 10, 10, 1024)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_69 (Conv2D)           (None, 10, 10, 1024)      1049600   \n",
      "_________________________________________________________________\n",
      "batch_normalization_134 (Bat (None, 10, 10, 1024)      4096      \n",
      "_________________________________________________________________\n",
      "activation_134 (Activation)  (None, 10, 10, 1024)      0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_4 ( (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 10)                10250     \n",
      "=================================================================\n",
      "Total params: 3,249,482\n",
      "Trainable params: 3,227,594\n",
      "Non-trainable params: 21,888\n",
      "_________________________________________________________________\n",
      "123.49854\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-02 06:40:56.325500: I tensorflow/core/grappler/devices.cc:66] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0\n",
      "2022-04-02 06:40:56.325588: I tensorflow/core/grappler/clusters/single_machine.cc:357] Starting new session\n",
      "2022-04-02 06:40:56.329748: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:1137] Optimization results for grappler item: graph_to_optimize\n",
      "  function_optimizer: function_optimizer did nothing. time = 0.004ms.\n",
      "  function_optimizer: function_optimizer did nothing. time = 0.001ms.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=========================Options=============================\n",
      "-max_depth                  10000\n",
      "-min_bytes                  0\n",
      "-min_peak_bytes             0\n",
      "-min_residual_bytes         0\n",
      "-min_output_bytes           0\n",
      "-min_micros                 0\n",
      "-min_accelerator_micros     0\n",
      "-min_cpu_micros             0\n",
      "-min_params                 0\n",
      "-min_float_ops              1\n",
      "-min_occurrence             0\n",
      "-step                       -1\n",
      "-order_by                   float_ops\n",
      "-account_type_regexes       .*\n",
      "-start_name_regexes         .*\n",
      "-trim_name_regexes          \n",
      "-show_name_regexes          .*\n",
      "-hide_name_regexes          \n",
      "-account_displayed_op_only  true\n",
      "-select                     float_ops\n",
      "-output                     stdout:\n",
      "\n",
      "==================Model Analysis Report======================\n",
      "\n",
      "Doc:\n",
      "scope: The nodes in the model graph are organized by their names, which is hierarchical like filesystem.\n",
      "flops: Number of float operations. Note: Please read the implementation for the math behind it.\n",
      "\n",
      "Profile:\n",
      "node name | # float_ops\n",
      "_TFProfRoot (--/2.32b flops)\n",
      "  model_4/conv2d_69/Conv2D (209.72m/209.72m flops)\n",
      "  model_4/conv2d_67/Conv2D (209.72m/209.72m flops)\n",
      "  model_4/conv2d_59/Conv2D (209.72m/209.72m flops)\n",
      "  model_4/conv2d_66/Conv2D (209.72m/209.72m flops)\n",
      "  model_4/conv2d_61/Conv2D (209.72m/209.72m flops)\n",
      "  model_4/conv2d_65/Conv2D (209.72m/209.72m flops)\n",
      "  model_4/conv2d_63/Conv2D (209.72m/209.72m flops)\n",
      "  model_4/conv2d_64/Conv2D (209.72m/209.72m flops)\n",
      "  model_4/conv2d_57/Conv2D (104.86m/104.86m flops)\n",
      "  model_4/conv2d_68/Conv2D (104.86m/104.86m flops)\n",
      "  model_4/conv2d_62/Conv2D (104.86m/104.86m flops)\n",
      "  model_4/conv2d_60/Conv2D (104.86m/104.86m flops)\n",
      "  model_4/conv2d_58/Conv2D (104.86m/104.86m flops)\n",
      "  model_4/conv2d_56/Conv2D (14.75m/14.75m flops)\n",
      "  model_4/depthwise_conv2d_54/depthwise (14.75m/14.75m flops)\n",
      "  model_4/depthwise_conv2d_52/depthwise (14.75m/14.75m flops)\n",
      "  model_4/depthwise_conv2d_53/depthwise (7.37m/7.37m flops)\n",
      "  model_4/depthwise_conv2d_56/depthwise (7.37m/7.37m flops)\n",
      "  model_4/depthwise_conv2d_55/depthwise (3.69m/3.69m flops)\n",
      "  model_4/depthwise_conv2d_58/depthwise (3.69m/3.69m flops)\n",
      "  model_4/depthwise_conv2d_59/depthwise (3.69m/3.69m flops)\n",
      "  model_4/depthwise_conv2d_60/depthwise (3.69m/3.69m flops)\n",
      "  model_4/depthwise_conv2d_61/depthwise (3.69m/3.69m flops)\n",
      "  model_4/depthwise_conv2d_62/depthwise (3.69m/3.69m flops)\n",
      "  model_4/batch_normalization_110/FusedBatchNormV3 (3.28m/3.28m flops)\n",
      "  model_4/depthwise_conv2d_57/depthwise (1.84m/1.84m flops)\n",
      "  model_4/depthwise_conv2d_64/depthwise (1.84m/1.84m flops)\n",
      "  model_4/batch_normalization_114/FusedBatchNormV3 (1.64m/1.64m flops)\n",
      "  model_4/batch_normalization_113/FusedBatchNormV3 (1.64m/1.64m flops)\n",
      "  model_4/batch_normalization_112/FusedBatchNormV3 (1.64m/1.64m flops)\n",
      "  model_4/batch_normalization_109/FusedBatchNormV3 (1.64m/1.64m flops)\n",
      "  model_4/batch_normalization_108/FusedBatchNormV3 (1.64m/1.64m flops)\n",
      "  model_4/conv2d_57/BiasAdd (1.64m/1.64m flops)\n",
      "  model_4/depthwise_conv2d_63/depthwise (921.60k/921.60k flops)\n",
      "  model_4/batch_normalization_116/FusedBatchNormV3 (820.74k/820.74k flops)\n",
      "  model_4/batch_normalization_117/FusedBatchNormV3 (820.74k/820.74k flops)\n",
      "  model_4/batch_normalization_118/FusedBatchNormV3 (820.74k/820.74k flops)\n",
      "  model_4/batch_normalization_111/FusedBatchNormV3 (819.58k/819.58k flops)\n",
      "  model_4/depthwise_conv2d_52/BiasAdd (819.20k/819.20k flops)\n",
      "  model_4/depthwise_conv2d_54/BiasAdd (819.20k/819.20k flops)\n",
      "  model_4/conv2d_58/BiasAdd (819.20k/819.20k flops)\n",
      "  model_4/conv2d_56/BiasAdd (819.20k/819.20k flops)\n",
      "  model_4/conv2d_59/BiasAdd (819.20k/819.20k flops)\n",
      "  model_4/batch_normalization_123/FusedBatchNormV3 (412.67k/412.67k flops)\n",
      "  model_4/batch_normalization_124/FusedBatchNormV3 (412.67k/412.67k flops)\n",
      "  model_4/batch_normalization_122/FusedBatchNormV3 (412.67k/412.67k flops)\n",
      "  model_4/batch_normalization_121/FusedBatchNormV3 (412.67k/412.67k flops)\n",
      "  model_4/batch_normalization_125/FusedBatchNormV3 (412.67k/412.67k flops)\n",
      "  model_4/batch_normalization_126/FusedBatchNormV3 (412.67k/412.67k flops)\n",
      "  model_4/batch_normalization_127/FusedBatchNormV3 (412.67k/412.67k flops)\n",
      "  model_4/batch_normalization_128/FusedBatchNormV3 (412.67k/412.67k flops)\n",
      "  model_4/batch_normalization_120/FusedBatchNormV3 (412.67k/412.67k flops)\n",
      "  model_4/batch_normalization_129/FusedBatchNormV3 (412.67k/412.67k flops)\n",
      "  model_4/batch_normalization_130/FusedBatchNormV3 (412.67k/412.67k flops)\n",
      "  model_4/batch_normalization_115/FusedBatchNormV3 (410.37k/410.37k flops)\n",
      "  model_4/depthwise_conv2d_56/BiasAdd (409.60k/409.60k flops)\n",
      "  model_4/conv2d_60/BiasAdd (409.60k/409.60k flops)\n",
      "  model_4/conv2d_61/BiasAdd (409.60k/409.60k flops)\n",
      "  model_4/depthwise_conv2d_53/BiasAdd (409.60k/409.60k flops)\n",
      "  model_4/batch_normalization_133/FusedBatchNormV3 (210.94k/210.94k flops)\n",
      "  model_4/batch_normalization_134/FusedBatchNormV3 (210.94k/210.94k flops)\n",
      "  model_4/batch_normalization_132/FusedBatchNormV3 (210.94k/210.94k flops)\n",
      "  model_4/batch_normalization_119/FusedBatchNormV3 (206.34k/206.34k flops)\n",
      "  model_4/conv2d_62/BiasAdd (204.80k/204.80k flops)\n",
      "  model_4/depthwise_conv2d_55/BiasAdd (204.80k/204.80k flops)\n",
      "  model_4/depthwise_conv2d_62/BiasAdd (204.80k/204.80k flops)\n",
      "  model_4/conv2d_67/BiasAdd (204.80k/204.80k flops)\n",
      "  model_4/conv2d_66/BiasAdd (204.80k/204.80k flops)\n",
      "  model_4/depthwise_conv2d_61/BiasAdd (204.80k/204.80k flops)\n",
      "  model_4/depthwise_conv2d_58/BiasAdd (204.80k/204.80k flops)\n",
      "  model_4/conv2d_65/BiasAdd (204.80k/204.80k flops)\n",
      "  model_4/depthwise_conv2d_59/BiasAdd (204.80k/204.80k flops)\n",
      "  model_4/conv2d_64/BiasAdd (204.80k/204.80k flops)\n",
      "  model_4/depthwise_conv2d_60/BiasAdd (204.80k/204.80k flops)\n",
      "  model_4/conv2d_63/BiasAdd (204.80k/204.80k flops)\n",
      "  model_4/batch_normalization_131/FusedBatchNormV3 (105.47k/105.47k flops)\n",
      "  model_4/depthwise_conv2d_57/BiasAdd (102.40k/102.40k flops)\n",
      "  model_4/conv2d_69/BiasAdd (102.40k/102.40k flops)\n",
      "  model_4/depthwise_conv2d_64/BiasAdd (102.40k/102.40k flops)\n",
      "  model_4/conv2d_68/BiasAdd (102.40k/102.40k flops)\n",
      "  model_4/global_average_pooling2d_4/Mean (102.40k/102.40k flops)\n",
      "  model_4/depthwise_conv2d_63/BiasAdd (51.20k/51.20k flops)\n",
      "  model_4/dense_4/MatMul (20.48k/20.48k flops)\n",
      "  model_4/dense_4/Softmax (50/50 flops)\n",
      "  model_4/dense_4/BiasAdd (10/10 flops)\n",
      "\n",
      "======================End of Report==========================\n",
      "Model: \"model_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_6 (InputLayer)         [(None, 352, 352, 1)]     0         \n",
      "_________________________________________________________________\n",
      "conv2d_70 (Conv2D)           (None, 176, 176, 32)      320       \n",
      "_________________________________________________________________\n",
      "batch_normalization_135 (Bat (None, 176, 176, 32)      128       \n",
      "_________________________________________________________________\n",
      "activation_135 (Activation)  (None, 176, 176, 32)      0         \n",
      "_________________________________________________________________\n",
      "depthwise_conv2d_65 (Depthwi (None, 176, 176, 32)      320       \n",
      "_________________________________________________________________\n",
      "batch_normalization_136 (Bat (None, 176, 176, 32)      128       \n",
      "_________________________________________________________________\n",
      "activation_136 (Activation)  (None, 176, 176, 32)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_71 (Conv2D)           (None, 176, 176, 64)      2112      \n",
      "_________________________________________________________________\n",
      "batch_normalization_137 (Bat (None, 176, 176, 64)      256       \n",
      "_________________________________________________________________\n",
      "activation_137 (Activation)  (None, 176, 176, 64)      0         \n",
      "_________________________________________________________________\n",
      "depthwise_conv2d_66 (Depthwi (None, 88, 88, 64)        640       \n",
      "_________________________________________________________________\n",
      "batch_normalization_138 (Bat (None, 88, 88, 64)        256       \n",
      "_________________________________________________________________\n",
      "activation_138 (Activation)  (None, 88, 88, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_72 (Conv2D)           (None, 88, 88, 128)       8320      \n",
      "_________________________________________________________________\n",
      "batch_normalization_139 (Bat (None, 88, 88, 128)       512       \n",
      "_________________________________________________________________\n",
      "activation_139 (Activation)  (None, 88, 88, 128)       0         \n",
      "_________________________________________________________________\n",
      "depthwise_conv2d_67 (Depthwi (None, 88, 88, 128)       1280      \n",
      "_________________________________________________________________\n",
      "batch_normalization_140 (Bat (None, 88, 88, 128)       512       \n",
      "_________________________________________________________________\n",
      "activation_140 (Activation)  (None, 88, 88, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_73 (Conv2D)           (None, 88, 88, 128)       16512     \n",
      "_________________________________________________________________\n",
      "batch_normalization_141 (Bat (None, 88, 88, 128)       512       \n",
      "_________________________________________________________________\n",
      "activation_141 (Activation)  (None, 88, 88, 128)       0         \n",
      "_________________________________________________________________\n",
      "depthwise_conv2d_68 (Depthwi (None, 44, 44, 128)       1280      \n",
      "_________________________________________________________________\n",
      "batch_normalization_142 (Bat (None, 44, 44, 128)       512       \n",
      "_________________________________________________________________\n",
      "activation_142 (Activation)  (None, 44, 44, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_74 (Conv2D)           (None, 44, 44, 256)       33024     \n",
      "_________________________________________________________________\n",
      "batch_normalization_143 (Bat (None, 44, 44, 256)       1024      \n",
      "_________________________________________________________________\n",
      "activation_143 (Activation)  (None, 44, 44, 256)       0         \n",
      "_________________________________________________________________\n",
      "depthwise_conv2d_69 (Depthwi (None, 44, 44, 256)       2560      \n",
      "_________________________________________________________________\n",
      "batch_normalization_144 (Bat (None, 44, 44, 256)       1024      \n",
      "_________________________________________________________________\n",
      "activation_144 (Activation)  (None, 44, 44, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_75 (Conv2D)           (None, 44, 44, 256)       65792     \n",
      "_________________________________________________________________\n",
      "batch_normalization_145 (Bat (None, 44, 44, 256)       1024      \n",
      "_________________________________________________________________\n",
      "activation_145 (Activation)  (None, 44, 44, 256)       0         \n",
      "_________________________________________________________________\n",
      "depthwise_conv2d_70 (Depthwi (None, 22, 22, 256)       2560      \n",
      "_________________________________________________________________\n",
      "batch_normalization_146 (Bat (None, 22, 22, 256)       1024      \n",
      "_________________________________________________________________\n",
      "activation_146 (Activation)  (None, 22, 22, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_76 (Conv2D)           (None, 22, 22, 512)       131584    \n",
      "_________________________________________________________________\n",
      "batch_normalization_147 (Bat (None, 22, 22, 512)       2048      \n",
      "_________________________________________________________________\n",
      "activation_147 (Activation)  (None, 22, 22, 512)       0         \n",
      "_________________________________________________________________\n",
      "depthwise_conv2d_71 (Depthwi (None, 22, 22, 512)       5120      \n",
      "_________________________________________________________________\n",
      "batch_normalization_148 (Bat (None, 22, 22, 512)       2048      \n",
      "_________________________________________________________________\n",
      "activation_148 (Activation)  (None, 22, 22, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_77 (Conv2D)           (None, 22, 22, 512)       262656    \n",
      "_________________________________________________________________\n",
      "batch_normalization_149 (Bat (None, 22, 22, 512)       2048      \n",
      "_________________________________________________________________\n",
      "activation_149 (Activation)  (None, 22, 22, 512)       0         \n",
      "_________________________________________________________________\n",
      "depthwise_conv2d_72 (Depthwi (None, 22, 22, 512)       5120      \n",
      "_________________________________________________________________\n",
      "batch_normalization_150 (Bat (None, 22, 22, 512)       2048      \n",
      "_________________________________________________________________\n",
      "activation_150 (Activation)  (None, 22, 22, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_78 (Conv2D)           (None, 22, 22, 512)       262656    \n",
      "_________________________________________________________________\n",
      "batch_normalization_151 (Bat (None, 22, 22, 512)       2048      \n",
      "_________________________________________________________________\n",
      "activation_151 (Activation)  (None, 22, 22, 512)       0         \n",
      "_________________________________________________________________\n",
      "depthwise_conv2d_73 (Depthwi (None, 22, 22, 512)       5120      \n",
      "_________________________________________________________________\n",
      "batch_normalization_152 (Bat (None, 22, 22, 512)       2048      \n",
      "_________________________________________________________________\n",
      "activation_152 (Activation)  (None, 22, 22, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_79 (Conv2D)           (None, 22, 22, 512)       262656    \n",
      "_________________________________________________________________\n",
      "batch_normalization_153 (Bat (None, 22, 22, 512)       2048      \n",
      "_________________________________________________________________\n",
      "activation_153 (Activation)  (None, 22, 22, 512)       0         \n",
      "_________________________________________________________________\n",
      "depthwise_conv2d_74 (Depthwi (None, 22, 22, 512)       5120      \n",
      "_________________________________________________________________\n",
      "batch_normalization_154 (Bat (None, 22, 22, 512)       2048      \n",
      "_________________________________________________________________\n",
      "activation_154 (Activation)  (None, 22, 22, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_80 (Conv2D)           (None, 22, 22, 512)       262656    \n",
      "_________________________________________________________________\n",
      "batch_normalization_155 (Bat (None, 22, 22, 512)       2048      \n",
      "_________________________________________________________________\n",
      "activation_155 (Activation)  (None, 22, 22, 512)       0         \n",
      "_________________________________________________________________\n",
      "depthwise_conv2d_75 (Depthwi (None, 22, 22, 512)       5120      \n",
      "_________________________________________________________________\n",
      "batch_normalization_156 (Bat (None, 22, 22, 512)       2048      \n",
      "_________________________________________________________________\n",
      "activation_156 (Activation)  (None, 22, 22, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_81 (Conv2D)           (None, 22, 22, 512)       262656    \n",
      "_________________________________________________________________\n",
      "batch_normalization_157 (Bat (None, 22, 22, 512)       2048      \n",
      "_________________________________________________________________\n",
      "activation_157 (Activation)  (None, 22, 22, 512)       0         \n",
      "_________________________________________________________________\n",
      "depthwise_conv2d_76 (Depthwi (None, 11, 11, 512)       5120      \n",
      "_________________________________________________________________\n",
      "batch_normalization_158 (Bat (None, 11, 11, 512)       2048      \n",
      "_________________________________________________________________\n",
      "activation_158 (Activation)  (None, 11, 11, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_82 (Conv2D)           (None, 11, 11, 1024)      525312    \n",
      "_________________________________________________________________\n",
      "batch_normalization_159 (Bat (None, 11, 11, 1024)      4096      \n",
      "_________________________________________________________________\n",
      "activation_159 (Activation)  (None, 11, 11, 1024)      0         \n",
      "_________________________________________________________________\n",
      "depthwise_conv2d_77 (Depthwi (None, 11, 11, 1024)      10240     \n",
      "_________________________________________________________________\n",
      "batch_normalization_160 (Bat (None, 11, 11, 1024)      4096      \n",
      "_________________________________________________________________\n",
      "activation_160 (Activation)  (None, 11, 11, 1024)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_83 (Conv2D)           (None, 11, 11, 1024)      1049600   \n",
      "_________________________________________________________________\n",
      "batch_normalization_161 (Bat (None, 11, 11, 1024)      4096      \n",
      "_________________________________________________________________\n",
      "activation_161 (Activation)  (None, 11, 11, 1024)      0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_5 ( (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 10)                10250     \n",
      "=================================================================\n",
      "Total params: 3,249,482\n",
      "Trainable params: 3,227,594\n",
      "Non-trainable params: 21,888\n",
      "_________________________________________________________________\n",
      "149.432364\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-02 06:40:57.259368: I tensorflow/core/grappler/devices.cc:66] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0\n",
      "2022-04-02 06:40:57.259493: I tensorflow/core/grappler/clusters/single_machine.cc:357] Starting new session\n",
      "2022-04-02 06:40:57.263736: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:1137] Optimization results for grappler item: graph_to_optimize\n",
      "  function_optimizer: function_optimizer did nothing. time = 0.004ms.\n",
      "  function_optimizer: function_optimizer did nothing. time = 0.001ms.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=========================Options=============================\n",
      "-max_depth                  10000\n",
      "-min_bytes                  0\n",
      "-min_peak_bytes             0\n",
      "-min_residual_bytes         0\n",
      "-min_output_bytes           0\n",
      "-min_micros                 0\n",
      "-min_accelerator_micros     0\n",
      "-min_cpu_micros             0\n",
      "-min_params                 0\n",
      "-min_float_ops              1\n",
      "-min_occurrence             0\n",
      "-step                       -1\n",
      "-order_by                   float_ops\n",
      "-account_type_regexes       .*\n",
      "-start_name_regexes         .*\n",
      "-trim_name_regexes          \n",
      "-show_name_regexes          .*\n",
      "-hide_name_regexes          \n",
      "-account_displayed_op_only  true\n",
      "-select                     float_ops\n",
      "-output                     stdout:\n",
      "\n",
      "==================Model Analysis Report======================\n",
      "\n",
      "Doc:\n",
      "scope: The nodes in the model graph are organized by their names, which is hierarchical like filesystem.\n",
      "flops: Number of float operations. Note: Please read the implementation for the math behind it.\n",
      "\n",
      "Profile:\n",
      "node name | # float_ops\n",
      "_TFProfRoot (--/2.81b flops)\n",
      "  model_5/conv2d_83/Conv2D (253.76m/253.76m flops)\n",
      "  model_5/conv2d_81/Conv2D (253.76m/253.76m flops)\n",
      "  model_5/conv2d_73/Conv2D (253.76m/253.76m flops)\n",
      "  model_5/conv2d_80/Conv2D (253.76m/253.76m flops)\n",
      "  model_5/conv2d_75/Conv2D (253.76m/253.76m flops)\n",
      "  model_5/conv2d_79/Conv2D (253.76m/253.76m flops)\n",
      "  model_5/conv2d_77/Conv2D (253.76m/253.76m flops)\n",
      "  model_5/conv2d_78/Conv2D (253.76m/253.76m flops)\n",
      "  model_5/conv2d_71/Conv2D (126.88m/126.88m flops)\n",
      "  model_5/conv2d_82/Conv2D (126.88m/126.88m flops)\n",
      "  model_5/conv2d_76/Conv2D (126.88m/126.88m flops)\n",
      "  model_5/conv2d_74/Conv2D (126.88m/126.88m flops)\n",
      "  model_5/conv2d_72/Conv2D (126.88m/126.88m flops)\n",
      "  model_5/conv2d_70/Conv2D (17.84m/17.84m flops)\n",
      "  model_5/depthwise_conv2d_67/depthwise (17.84m/17.84m flops)\n",
      "  model_5/depthwise_conv2d_65/depthwise (17.84m/17.84m flops)\n",
      "  model_5/depthwise_conv2d_66/depthwise (8.92m/8.92m flops)\n",
      "  model_5/depthwise_conv2d_69/depthwise (8.92m/8.92m flops)\n",
      "  model_5/depthwise_conv2d_68/depthwise (4.46m/4.46m flops)\n",
      "  model_5/depthwise_conv2d_71/depthwise (4.46m/4.46m flops)\n",
      "  model_5/depthwise_conv2d_72/depthwise (4.46m/4.46m flops)\n",
      "  model_5/depthwise_conv2d_73/depthwise (4.46m/4.46m flops)\n",
      "  model_5/depthwise_conv2d_74/depthwise (4.46m/4.46m flops)\n",
      "  model_5/depthwise_conv2d_75/depthwise (4.46m/4.46m flops)\n",
      "  model_5/batch_normalization_137/FusedBatchNormV3 (3.97m/3.97m flops)\n",
      "  model_5/depthwise_conv2d_70/depthwise (2.23m/2.23m flops)\n",
      "  model_5/depthwise_conv2d_77/depthwise (2.23m/2.23m flops)\n",
      "  model_5/batch_normalization_141/FusedBatchNormV3 (1.98m/1.98m flops)\n",
      "  model_5/batch_normalization_140/FusedBatchNormV3 (1.98m/1.98m flops)\n",
      "  model_5/batch_normalization_139/FusedBatchNormV3 (1.98m/1.98m flops)\n",
      "  model_5/batch_normalization_136/FusedBatchNormV3 (1.98m/1.98m flops)\n",
      "  model_5/batch_normalization_135/FusedBatchNormV3 (1.98m/1.98m flops)\n",
      "  model_5/conv2d_71/BiasAdd (1.98m/1.98m flops)\n",
      "  model_5/depthwise_conv2d_76/depthwise (1.12m/1.12m flops)\n",
      "  model_5/batch_normalization_143/FusedBatchNormV3 (992.77k/992.77k flops)\n",
      "  model_5/batch_normalization_144/FusedBatchNormV3 (992.77k/992.77k flops)\n",
      "  model_5/batch_normalization_145/FusedBatchNormV3 (992.77k/992.77k flops)\n",
      "  model_5/batch_normalization_138/FusedBatchNormV3 (991.62k/991.62k flops)\n",
      "  model_5/depthwise_conv2d_65/BiasAdd (991.23k/991.23k flops)\n",
      "  model_5/depthwise_conv2d_67/BiasAdd (991.23k/991.23k flops)\n",
      "  model_5/conv2d_72/BiasAdd (991.23k/991.23k flops)\n",
      "  model_5/conv2d_70/BiasAdd (991.23k/991.23k flops)\n",
      "  model_5/conv2d_73/BiasAdd (991.23k/991.23k flops)\n",
      "  model_5/batch_normalization_150/FusedBatchNormV3 (498.69k/498.69k flops)\n",
      "  model_5/batch_normalization_151/FusedBatchNormV3 (498.69k/498.69k flops)\n",
      "  model_5/batch_normalization_149/FusedBatchNormV3 (498.69k/498.69k flops)\n",
      "  model_5/batch_normalization_148/FusedBatchNormV3 (498.69k/498.69k flops)\n",
      "  model_5/batch_normalization_152/FusedBatchNormV3 (498.69k/498.69k flops)\n",
      "  model_5/batch_normalization_153/FusedBatchNormV3 (498.69k/498.69k flops)\n",
      "  model_5/batch_normalization_154/FusedBatchNormV3 (498.69k/498.69k flops)\n",
      "  model_5/batch_normalization_155/FusedBatchNormV3 (498.69k/498.69k flops)\n",
      "  model_5/batch_normalization_147/FusedBatchNormV3 (498.69k/498.69k flops)\n",
      "  model_5/batch_normalization_156/FusedBatchNormV3 (498.69k/498.69k flops)\n",
      "  model_5/batch_normalization_157/FusedBatchNormV3 (498.69k/498.69k flops)\n",
      "  model_5/batch_normalization_142/FusedBatchNormV3 (496.38k/496.38k flops)\n",
      "  model_5/depthwise_conv2d_69/BiasAdd (495.62k/495.62k flops)\n",
      "  model_5/conv2d_74/BiasAdd (495.62k/495.62k flops)\n",
      "  model_5/conv2d_75/BiasAdd (495.62k/495.62k flops)\n",
      "  model_5/depthwise_conv2d_66/BiasAdd (495.62k/495.62k flops)\n",
      "  model_5/batch_normalization_160/FusedBatchNormV3 (253.95k/253.95k flops)\n",
      "  model_5/batch_normalization_161/FusedBatchNormV3 (253.95k/253.95k flops)\n",
      "  model_5/batch_normalization_159/FusedBatchNormV3 (253.95k/253.95k flops)\n",
      "  model_5/batch_normalization_146/FusedBatchNormV3 (249.34k/249.34k flops)\n",
      "  model_5/conv2d_76/BiasAdd (247.81k/247.81k flops)\n",
      "  model_5/depthwise_conv2d_68/BiasAdd (247.81k/247.81k flops)\n",
      "  model_5/depthwise_conv2d_75/BiasAdd (247.81k/247.81k flops)\n",
      "  model_5/conv2d_81/BiasAdd (247.81k/247.81k flops)\n",
      "  model_5/conv2d_80/BiasAdd (247.81k/247.81k flops)\n",
      "  model_5/depthwise_conv2d_74/BiasAdd (247.81k/247.81k flops)\n",
      "  model_5/depthwise_conv2d_71/BiasAdd (247.81k/247.81k flops)\n",
      "  model_5/conv2d_79/BiasAdd (247.81k/247.81k flops)\n",
      "  model_5/depthwise_conv2d_72/BiasAdd (247.81k/247.81k flops)\n",
      "  model_5/conv2d_78/BiasAdd (247.81k/247.81k flops)\n",
      "  model_5/depthwise_conv2d_73/BiasAdd (247.81k/247.81k flops)\n",
      "  model_5/conv2d_77/BiasAdd (247.81k/247.81k flops)\n",
      "  model_5/batch_normalization_158/FusedBatchNormV3 (126.98k/126.98k flops)\n",
      "  model_5/depthwise_conv2d_70/BiasAdd (123.90k/123.90k flops)\n",
      "  model_5/conv2d_83/BiasAdd (123.90k/123.90k flops)\n",
      "  model_5/depthwise_conv2d_77/BiasAdd (123.90k/123.90k flops)\n",
      "  model_5/conv2d_82/BiasAdd (123.90k/123.90k flops)\n",
      "  model_5/global_average_pooling2d_5/Mean (123.90k/123.90k flops)\n",
      "  model_5/depthwise_conv2d_76/BiasAdd (61.95k/61.95k flops)\n",
      "  model_5/dense_5/MatMul (20.48k/20.48k flops)\n",
      "  model_5/dense_5/Softmax (50/50 flops)\n",
      "  model_5/dense_5/BiasAdd (10/10 flops)\n",
      "\n",
      "======================End of Report==========================\n",
      "Model: \"model_6\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_7 (InputLayer)         [(None, 384, 384, 1)]     0         \n",
      "_________________________________________________________________\n",
      "conv2d_84 (Conv2D)           (None, 192, 192, 32)      320       \n",
      "_________________________________________________________________\n",
      "batch_normalization_162 (Bat (None, 192, 192, 32)      128       \n",
      "_________________________________________________________________\n",
      "activation_162 (Activation)  (None, 192, 192, 32)      0         \n",
      "_________________________________________________________________\n",
      "depthwise_conv2d_78 (Depthwi (None, 192, 192, 32)      320       \n",
      "_________________________________________________________________\n",
      "batch_normalization_163 (Bat (None, 192, 192, 32)      128       \n",
      "_________________________________________________________________\n",
      "activation_163 (Activation)  (None, 192, 192, 32)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_85 (Conv2D)           (None, 192, 192, 64)      2112      \n",
      "_________________________________________________________________\n",
      "batch_normalization_164 (Bat (None, 192, 192, 64)      256       \n",
      "_________________________________________________________________\n",
      "activation_164 (Activation)  (None, 192, 192, 64)      0         \n",
      "_________________________________________________________________\n",
      "depthwise_conv2d_79 (Depthwi (None, 96, 96, 64)        640       \n",
      "_________________________________________________________________\n",
      "batch_normalization_165 (Bat (None, 96, 96, 64)        256       \n",
      "_________________________________________________________________\n",
      "activation_165 (Activation)  (None, 96, 96, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_86 (Conv2D)           (None, 96, 96, 128)       8320      \n",
      "_________________________________________________________________\n",
      "batch_normalization_166 (Bat (None, 96, 96, 128)       512       \n",
      "_________________________________________________________________\n",
      "activation_166 (Activation)  (None, 96, 96, 128)       0         \n",
      "_________________________________________________________________\n",
      "depthwise_conv2d_80 (Depthwi (None, 96, 96, 128)       1280      \n",
      "_________________________________________________________________\n",
      "batch_normalization_167 (Bat (None, 96, 96, 128)       512       \n",
      "_________________________________________________________________\n",
      "activation_167 (Activation)  (None, 96, 96, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_87 (Conv2D)           (None, 96, 96, 128)       16512     \n",
      "_________________________________________________________________\n",
      "batch_normalization_168 (Bat (None, 96, 96, 128)       512       \n",
      "_________________________________________________________________\n",
      "activation_168 (Activation)  (None, 96, 96, 128)       0         \n",
      "_________________________________________________________________\n",
      "depthwise_conv2d_81 (Depthwi (None, 48, 48, 128)       1280      \n",
      "_________________________________________________________________\n",
      "batch_normalization_169 (Bat (None, 48, 48, 128)       512       \n",
      "_________________________________________________________________\n",
      "activation_169 (Activation)  (None, 48, 48, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_88 (Conv2D)           (None, 48, 48, 256)       33024     \n",
      "_________________________________________________________________\n",
      "batch_normalization_170 (Bat (None, 48, 48, 256)       1024      \n",
      "_________________________________________________________________\n",
      "activation_170 (Activation)  (None, 48, 48, 256)       0         \n",
      "_________________________________________________________________\n",
      "depthwise_conv2d_82 (Depthwi (None, 48, 48, 256)       2560      \n",
      "_________________________________________________________________\n",
      "batch_normalization_171 (Bat (None, 48, 48, 256)       1024      \n",
      "_________________________________________________________________\n",
      "activation_171 (Activation)  (None, 48, 48, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_89 (Conv2D)           (None, 48, 48, 256)       65792     \n",
      "_________________________________________________________________\n",
      "batch_normalization_172 (Bat (None, 48, 48, 256)       1024      \n",
      "_________________________________________________________________\n",
      "activation_172 (Activation)  (None, 48, 48, 256)       0         \n",
      "_________________________________________________________________\n",
      "depthwise_conv2d_83 (Depthwi (None, 24, 24, 256)       2560      \n",
      "_________________________________________________________________\n",
      "batch_normalization_173 (Bat (None, 24, 24, 256)       1024      \n",
      "_________________________________________________________________\n",
      "activation_173 (Activation)  (None, 24, 24, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_90 (Conv2D)           (None, 24, 24, 512)       131584    \n",
      "_________________________________________________________________\n",
      "batch_normalization_174 (Bat (None, 24, 24, 512)       2048      \n",
      "_________________________________________________________________\n",
      "activation_174 (Activation)  (None, 24, 24, 512)       0         \n",
      "_________________________________________________________________\n",
      "depthwise_conv2d_84 (Depthwi (None, 24, 24, 512)       5120      \n",
      "_________________________________________________________________\n",
      "batch_normalization_175 (Bat (None, 24, 24, 512)       2048      \n",
      "_________________________________________________________________\n",
      "activation_175 (Activation)  (None, 24, 24, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_91 (Conv2D)           (None, 24, 24, 512)       262656    \n",
      "_________________________________________________________________\n",
      "batch_normalization_176 (Bat (None, 24, 24, 512)       2048      \n",
      "_________________________________________________________________\n",
      "activation_176 (Activation)  (None, 24, 24, 512)       0         \n",
      "_________________________________________________________________\n",
      "depthwise_conv2d_85 (Depthwi (None, 24, 24, 512)       5120      \n",
      "_________________________________________________________________\n",
      "batch_normalization_177 (Bat (None, 24, 24, 512)       2048      \n",
      "_________________________________________________________________\n",
      "activation_177 (Activation)  (None, 24, 24, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_92 (Conv2D)           (None, 24, 24, 512)       262656    \n",
      "_________________________________________________________________\n",
      "batch_normalization_178 (Bat (None, 24, 24, 512)       2048      \n",
      "_________________________________________________________________\n",
      "activation_178 (Activation)  (None, 24, 24, 512)       0         \n",
      "_________________________________________________________________\n",
      "depthwise_conv2d_86 (Depthwi (None, 24, 24, 512)       5120      \n",
      "_________________________________________________________________\n",
      "batch_normalization_179 (Bat (None, 24, 24, 512)       2048      \n",
      "_________________________________________________________________\n",
      "activation_179 (Activation)  (None, 24, 24, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_93 (Conv2D)           (None, 24, 24, 512)       262656    \n",
      "_________________________________________________________________\n",
      "batch_normalization_180 (Bat (None, 24, 24, 512)       2048      \n",
      "_________________________________________________________________\n",
      "activation_180 (Activation)  (None, 24, 24, 512)       0         \n",
      "_________________________________________________________________\n",
      "depthwise_conv2d_87 (Depthwi (None, 24, 24, 512)       5120      \n",
      "_________________________________________________________________\n",
      "batch_normalization_181 (Bat (None, 24, 24, 512)       2048      \n",
      "_________________________________________________________________\n",
      "activation_181 (Activation)  (None, 24, 24, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_94 (Conv2D)           (None, 24, 24, 512)       262656    \n",
      "_________________________________________________________________\n",
      "batch_normalization_182 (Bat (None, 24, 24, 512)       2048      \n",
      "_________________________________________________________________\n",
      "activation_182 (Activation)  (None, 24, 24, 512)       0         \n",
      "_________________________________________________________________\n",
      "depthwise_conv2d_88 (Depthwi (None, 24, 24, 512)       5120      \n",
      "_________________________________________________________________\n",
      "batch_normalization_183 (Bat (None, 24, 24, 512)       2048      \n",
      "_________________________________________________________________\n",
      "activation_183 (Activation)  (None, 24, 24, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_95 (Conv2D)           (None, 24, 24, 512)       262656    \n",
      "_________________________________________________________________\n",
      "batch_normalization_184 (Bat (None, 24, 24, 512)       2048      \n",
      "_________________________________________________________________\n",
      "activation_184 (Activation)  (None, 24, 24, 512)       0         \n",
      "_________________________________________________________________\n",
      "depthwise_conv2d_89 (Depthwi (None, 12, 12, 512)       5120      \n",
      "_________________________________________________________________\n",
      "batch_normalization_185 (Bat (None, 12, 12, 512)       2048      \n",
      "_________________________________________________________________\n",
      "activation_185 (Activation)  (None, 12, 12, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_96 (Conv2D)           (None, 12, 12, 1024)      525312    \n",
      "_________________________________________________________________\n",
      "batch_normalization_186 (Bat (None, 12, 12, 1024)      4096      \n",
      "_________________________________________________________________\n",
      "activation_186 (Activation)  (None, 12, 12, 1024)      0         \n",
      "_________________________________________________________________\n",
      "depthwise_conv2d_90 (Depthwi (None, 12, 12, 1024)      10240     \n",
      "_________________________________________________________________\n",
      "batch_normalization_187 (Bat (None, 12, 12, 1024)      4096      \n",
      "_________________________________________________________________\n",
      "activation_187 (Activation)  (None, 12, 12, 1024)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_97 (Conv2D)           (None, 12, 12, 1024)      1049600   \n",
      "_________________________________________________________________\n",
      "batch_normalization_188 (Bat (None, 12, 12, 1024)      4096      \n",
      "_________________________________________________________________\n",
      "activation_188 (Activation)  (None, 12, 12, 1024)      0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_6 ( (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 10)                10250     \n",
      "=================================================================\n",
      "Total params: 3,249,482\n",
      "Trainable params: 3,227,594\n",
      "Non-trainable params: 21,888\n",
      "_________________________________________________________________\n",
      "177.836076\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-02 06:40:58.293792: I tensorflow/core/grappler/devices.cc:66] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0\n",
      "2022-04-02 06:40:58.293864: I tensorflow/core/grappler/clusters/single_machine.cc:357] Starting new session\n",
      "2022-04-02 06:40:58.298111: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:1137] Optimization results for grappler item: graph_to_optimize\n",
      "  function_optimizer: function_optimizer did nothing. time = 0.005ms.\n",
      "  function_optimizer: function_optimizer did nothing. time = 0.001ms.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=========================Options=============================\n",
      "-max_depth                  10000\n",
      "-min_bytes                  0\n",
      "-min_peak_bytes             0\n",
      "-min_residual_bytes         0\n",
      "-min_output_bytes           0\n",
      "-min_micros                 0\n",
      "-min_accelerator_micros     0\n",
      "-min_cpu_micros             0\n",
      "-min_params                 0\n",
      "-min_float_ops              1\n",
      "-min_occurrence             0\n",
      "-step                       -1\n",
      "-order_by                   float_ops\n",
      "-account_type_regexes       .*\n",
      "-start_name_regexes         .*\n",
      "-trim_name_regexes          \n",
      "-show_name_regexes          .*\n",
      "-hide_name_regexes          \n",
      "-account_displayed_op_only  true\n",
      "-select                     float_ops\n",
      "-output                     stdout:\n",
      "\n",
      "==================Model Analysis Report======================\n",
      "\n",
      "Doc:\n",
      "scope: The nodes in the model graph are organized by their names, which is hierarchical like filesystem.\n",
      "flops: Number of float operations. Note: Please read the implementation for the math behind it.\n",
      "\n",
      "Profile:\n",
      "node name | # float_ops\n",
      "_TFProfRoot (--/3.34b flops)\n",
      "  model_6/conv2d_97/Conv2D (301.99m/301.99m flops)\n",
      "  model_6/conv2d_95/Conv2D (301.99m/301.99m flops)\n",
      "  model_6/conv2d_87/Conv2D (301.99m/301.99m flops)\n",
      "  model_6/conv2d_94/Conv2D (301.99m/301.99m flops)\n",
      "  model_6/conv2d_89/Conv2D (301.99m/301.99m flops)\n",
      "  model_6/conv2d_93/Conv2D (301.99m/301.99m flops)\n",
      "  model_6/conv2d_91/Conv2D (301.99m/301.99m flops)\n",
      "  model_6/conv2d_92/Conv2D (301.99m/301.99m flops)\n",
      "  model_6/conv2d_85/Conv2D (150.99m/150.99m flops)\n",
      "  model_6/conv2d_96/Conv2D (150.99m/150.99m flops)\n",
      "  model_6/conv2d_90/Conv2D (150.99m/150.99m flops)\n",
      "  model_6/conv2d_88/Conv2D (150.99m/150.99m flops)\n",
      "  model_6/conv2d_86/Conv2D (150.99m/150.99m flops)\n",
      "  model_6/conv2d_84/Conv2D (21.23m/21.23m flops)\n",
      "  model_6/depthwise_conv2d_80/depthwise (21.23m/21.23m flops)\n",
      "  model_6/depthwise_conv2d_78/depthwise (21.23m/21.23m flops)\n",
      "  model_6/depthwise_conv2d_79/depthwise (10.62m/10.62m flops)\n",
      "  model_6/depthwise_conv2d_82/depthwise (10.62m/10.62m flops)\n",
      "  model_6/depthwise_conv2d_81/depthwise (5.31m/5.31m flops)\n",
      "  model_6/depthwise_conv2d_84/depthwise (5.31m/5.31m flops)\n",
      "  model_6/depthwise_conv2d_85/depthwise (5.31m/5.31m flops)\n",
      "  model_6/depthwise_conv2d_86/depthwise (5.31m/5.31m flops)\n",
      "  model_6/depthwise_conv2d_87/depthwise (5.31m/5.31m flops)\n",
      "  model_6/depthwise_conv2d_88/depthwise (5.31m/5.31m flops)\n",
      "  model_6/batch_normalization_164/FusedBatchNormV3 (4.72m/4.72m flops)\n",
      "  model_6/depthwise_conv2d_83/depthwise (2.65m/2.65m flops)\n",
      "  model_6/depthwise_conv2d_90/depthwise (2.65m/2.65m flops)\n",
      "  model_6/batch_normalization_168/FusedBatchNormV3 (2.36m/2.36m flops)\n",
      "  model_6/batch_normalization_167/FusedBatchNormV3 (2.36m/2.36m flops)\n",
      "  model_6/batch_normalization_166/FusedBatchNormV3 (2.36m/2.36m flops)\n",
      "  model_6/batch_normalization_163/FusedBatchNormV3 (2.36m/2.36m flops)\n",
      "  model_6/batch_normalization_162/FusedBatchNormV3 (2.36m/2.36m flops)\n",
      "  model_6/conv2d_85/BiasAdd (2.36m/2.36m flops)\n",
      "  model_6/depthwise_conv2d_89/depthwise (1.33m/1.33m flops)\n",
      "  model_6/batch_normalization_170/FusedBatchNormV3 (1.18m/1.18m flops)\n",
      "  model_6/batch_normalization_171/FusedBatchNormV3 (1.18m/1.18m flops)\n",
      "  model_6/batch_normalization_172/FusedBatchNormV3 (1.18m/1.18m flops)\n",
      "  model_6/batch_normalization_165/FusedBatchNormV3 (1.18m/1.18m flops)\n",
      "  model_6/depthwise_conv2d_78/BiasAdd (1.18m/1.18m flops)\n",
      "  model_6/depthwise_conv2d_80/BiasAdd (1.18m/1.18m flops)\n",
      "  model_6/conv2d_86/BiasAdd (1.18m/1.18m flops)\n",
      "  model_6/conv2d_84/BiasAdd (1.18m/1.18m flops)\n",
      "  model_6/conv2d_87/BiasAdd (1.18m/1.18m flops)\n",
      "  model_6/batch_normalization_177/FusedBatchNormV3 (592.90k/592.90k flops)\n",
      "  model_6/batch_normalization_178/FusedBatchNormV3 (592.90k/592.90k flops)\n",
      "  model_6/batch_normalization_176/FusedBatchNormV3 (592.90k/592.90k flops)\n",
      "  model_6/batch_normalization_175/FusedBatchNormV3 (592.90k/592.90k flops)\n",
      "  model_6/batch_normalization_179/FusedBatchNormV3 (592.90k/592.90k flops)\n",
      "  model_6/batch_normalization_180/FusedBatchNormV3 (592.90k/592.90k flops)\n",
      "  model_6/batch_normalization_181/FusedBatchNormV3 (592.90k/592.90k flops)\n",
      "  model_6/batch_normalization_182/FusedBatchNormV3 (592.90k/592.90k flops)\n",
      "  model_6/batch_normalization_174/FusedBatchNormV3 (592.90k/592.90k flops)\n",
      "  model_6/batch_normalization_183/FusedBatchNormV3 (592.90k/592.90k flops)\n",
      "  model_6/batch_normalization_184/FusedBatchNormV3 (592.90k/592.90k flops)\n",
      "  model_6/batch_normalization_169/FusedBatchNormV3 (590.59k/590.59k flops)\n",
      "  model_6/depthwise_conv2d_82/BiasAdd (589.82k/589.82k flops)\n",
      "  model_6/conv2d_88/BiasAdd (589.82k/589.82k flops)\n",
      "  model_6/conv2d_89/BiasAdd (589.82k/589.82k flops)\n",
      "  model_6/depthwise_conv2d_79/BiasAdd (589.82k/589.82k flops)\n",
      "  model_6/batch_normalization_187/FusedBatchNormV3 (301.06k/301.06k flops)\n",
      "  model_6/batch_normalization_188/FusedBatchNormV3 (301.06k/301.06k flops)\n",
      "  model_6/batch_normalization_186/FusedBatchNormV3 (301.06k/301.06k flops)\n",
      "  model_6/batch_normalization_173/FusedBatchNormV3 (296.45k/296.45k flops)\n",
      "  model_6/conv2d_90/BiasAdd (294.91k/294.91k flops)\n",
      "  model_6/depthwise_conv2d_81/BiasAdd (294.91k/294.91k flops)\n",
      "  model_6/depthwise_conv2d_88/BiasAdd (294.91k/294.91k flops)\n",
      "  model_6/conv2d_95/BiasAdd (294.91k/294.91k flops)\n",
      "  model_6/conv2d_94/BiasAdd (294.91k/294.91k flops)\n",
      "  model_6/depthwise_conv2d_87/BiasAdd (294.91k/294.91k flops)\n",
      "  model_6/depthwise_conv2d_84/BiasAdd (294.91k/294.91k flops)\n",
      "  model_6/conv2d_93/BiasAdd (294.91k/294.91k flops)\n",
      "  model_6/depthwise_conv2d_85/BiasAdd (294.91k/294.91k flops)\n",
      "  model_6/conv2d_92/BiasAdd (294.91k/294.91k flops)\n",
      "  model_6/depthwise_conv2d_86/BiasAdd (294.91k/294.91k flops)\n",
      "  model_6/conv2d_91/BiasAdd (294.91k/294.91k flops)\n",
      "  model_6/batch_normalization_185/FusedBatchNormV3 (150.53k/150.53k flops)\n",
      "  model_6/depthwise_conv2d_83/BiasAdd (147.46k/147.46k flops)\n",
      "  model_6/conv2d_97/BiasAdd (147.46k/147.46k flops)\n",
      "  model_6/depthwise_conv2d_90/BiasAdd (147.46k/147.46k flops)\n",
      "  model_6/conv2d_96/BiasAdd (147.46k/147.46k flops)\n",
      "  model_6/global_average_pooling2d_6/Mean (147.46k/147.46k flops)\n",
      "  model_6/depthwise_conv2d_89/BiasAdd (73.73k/73.73k flops)\n",
      "  model_6/dense_6/MatMul (20.48k/20.48k flops)\n",
      "  model_6/dense_6/Softmax (50/50 flops)\n",
      "  model_6/dense_6/BiasAdd (10/10 flops)\n",
      "\n",
      "======================End of Report==========================\n",
      "Model: \"model_7\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_8 (InputLayer)         [(None, 416, 416, 1)]     0         \n",
      "_________________________________________________________________\n",
      "conv2d_98 (Conv2D)           (None, 208, 208, 32)      320       \n",
      "_________________________________________________________________\n",
      "batch_normalization_189 (Bat (None, 208, 208, 32)      128       \n",
      "_________________________________________________________________\n",
      "activation_189 (Activation)  (None, 208, 208, 32)      0         \n",
      "_________________________________________________________________\n",
      "depthwise_conv2d_91 (Depthwi (None, 208, 208, 32)      320       \n",
      "_________________________________________________________________\n",
      "batch_normalization_190 (Bat (None, 208, 208, 32)      128       \n",
      "_________________________________________________________________\n",
      "activation_190 (Activation)  (None, 208, 208, 32)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_99 (Conv2D)           (None, 208, 208, 64)      2112      \n",
      "_________________________________________________________________\n",
      "batch_normalization_191 (Bat (None, 208, 208, 64)      256       \n",
      "_________________________________________________________________\n",
      "activation_191 (Activation)  (None, 208, 208, 64)      0         \n",
      "_________________________________________________________________\n",
      "depthwise_conv2d_92 (Depthwi (None, 104, 104, 64)      640       \n",
      "_________________________________________________________________\n",
      "batch_normalization_192 (Bat (None, 104, 104, 64)      256       \n",
      "_________________________________________________________________\n",
      "activation_192 (Activation)  (None, 104, 104, 64)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_100 (Conv2D)          (None, 104, 104, 128)     8320      \n",
      "_________________________________________________________________\n",
      "batch_normalization_193 (Bat (None, 104, 104, 128)     512       \n",
      "_________________________________________________________________\n",
      "activation_193 (Activation)  (None, 104, 104, 128)     0         \n",
      "_________________________________________________________________\n",
      "depthwise_conv2d_93 (Depthwi (None, 104, 104, 128)     1280      \n",
      "_________________________________________________________________\n",
      "batch_normalization_194 (Bat (None, 104, 104, 128)     512       \n",
      "_________________________________________________________________\n",
      "activation_194 (Activation)  (None, 104, 104, 128)     0         \n",
      "_________________________________________________________________\n",
      "conv2d_101 (Conv2D)          (None, 104, 104, 128)     16512     \n",
      "_________________________________________________________________\n",
      "batch_normalization_195 (Bat (None, 104, 104, 128)     512       \n",
      "_________________________________________________________________\n",
      "activation_195 (Activation)  (None, 104, 104, 128)     0         \n",
      "_________________________________________________________________\n",
      "depthwise_conv2d_94 (Depthwi (None, 52, 52, 128)       1280      \n",
      "_________________________________________________________________\n",
      "batch_normalization_196 (Bat (None, 52, 52, 128)       512       \n",
      "_________________________________________________________________\n",
      "activation_196 (Activation)  (None, 52, 52, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_102 (Conv2D)          (None, 52, 52, 256)       33024     \n",
      "_________________________________________________________________\n",
      "batch_normalization_197 (Bat (None, 52, 52, 256)       1024      \n",
      "_________________________________________________________________\n",
      "activation_197 (Activation)  (None, 52, 52, 256)       0         \n",
      "_________________________________________________________________\n",
      "depthwise_conv2d_95 (Depthwi (None, 52, 52, 256)       2560      \n",
      "_________________________________________________________________\n",
      "batch_normalization_198 (Bat (None, 52, 52, 256)       1024      \n",
      "_________________________________________________________________\n",
      "activation_198 (Activation)  (None, 52, 52, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_103 (Conv2D)          (None, 52, 52, 256)       65792     \n",
      "_________________________________________________________________\n",
      "batch_normalization_199 (Bat (None, 52, 52, 256)       1024      \n",
      "_________________________________________________________________\n",
      "activation_199 (Activation)  (None, 52, 52, 256)       0         \n",
      "_________________________________________________________________\n",
      "depthwise_conv2d_96 (Depthwi (None, 26, 26, 256)       2560      \n",
      "_________________________________________________________________\n",
      "batch_normalization_200 (Bat (None, 26, 26, 256)       1024      \n",
      "_________________________________________________________________\n",
      "activation_200 (Activation)  (None, 26, 26, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_104 (Conv2D)          (None, 26, 26, 512)       131584    \n",
      "_________________________________________________________________\n",
      "batch_normalization_201 (Bat (None, 26, 26, 512)       2048      \n",
      "_________________________________________________________________\n",
      "activation_201 (Activation)  (None, 26, 26, 512)       0         \n",
      "_________________________________________________________________\n",
      "depthwise_conv2d_97 (Depthwi (None, 26, 26, 512)       5120      \n",
      "_________________________________________________________________\n",
      "batch_normalization_202 (Bat (None, 26, 26, 512)       2048      \n",
      "_________________________________________________________________\n",
      "activation_202 (Activation)  (None, 26, 26, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_105 (Conv2D)          (None, 26, 26, 512)       262656    \n",
      "_________________________________________________________________\n",
      "batch_normalization_203 (Bat (None, 26, 26, 512)       2048      \n",
      "_________________________________________________________________\n",
      "activation_203 (Activation)  (None, 26, 26, 512)       0         \n",
      "_________________________________________________________________\n",
      "depthwise_conv2d_98 (Depthwi (None, 26, 26, 512)       5120      \n",
      "_________________________________________________________________\n",
      "batch_normalization_204 (Bat (None, 26, 26, 512)       2048      \n",
      "_________________________________________________________________\n",
      "activation_204 (Activation)  (None, 26, 26, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_106 (Conv2D)          (None, 26, 26, 512)       262656    \n",
      "_________________________________________________________________\n",
      "batch_normalization_205 (Bat (None, 26, 26, 512)       2048      \n",
      "_________________________________________________________________\n",
      "activation_205 (Activation)  (None, 26, 26, 512)       0         \n",
      "_________________________________________________________________\n",
      "depthwise_conv2d_99 (Depthwi (None, 26, 26, 512)       5120      \n",
      "_________________________________________________________________\n",
      "batch_normalization_206 (Bat (None, 26, 26, 512)       2048      \n",
      "_________________________________________________________________\n",
      "activation_206 (Activation)  (None, 26, 26, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_107 (Conv2D)          (None, 26, 26, 512)       262656    \n",
      "_________________________________________________________________\n",
      "batch_normalization_207 (Bat (None, 26, 26, 512)       2048      \n",
      "_________________________________________________________________\n",
      "activation_207 (Activation)  (None, 26, 26, 512)       0         \n",
      "_________________________________________________________________\n",
      "depthwise_conv2d_100 (Depthw (None, 26, 26, 512)       5120      \n",
      "_________________________________________________________________\n",
      "batch_normalization_208 (Bat (None, 26, 26, 512)       2048      \n",
      "_________________________________________________________________\n",
      "activation_208 (Activation)  (None, 26, 26, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_108 (Conv2D)          (None, 26, 26, 512)       262656    \n",
      "_________________________________________________________________\n",
      "batch_normalization_209 (Bat (None, 26, 26, 512)       2048      \n",
      "_________________________________________________________________\n",
      "activation_209 (Activation)  (None, 26, 26, 512)       0         \n",
      "_________________________________________________________________\n",
      "depthwise_conv2d_101 (Depthw (None, 26, 26, 512)       5120      \n",
      "_________________________________________________________________\n",
      "batch_normalization_210 (Bat (None, 26, 26, 512)       2048      \n",
      "_________________________________________________________________\n",
      "activation_210 (Activation)  (None, 26, 26, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_109 (Conv2D)          (None, 26, 26, 512)       262656    \n",
      "_________________________________________________________________\n",
      "batch_normalization_211 (Bat (None, 26, 26, 512)       2048      \n",
      "_________________________________________________________________\n",
      "activation_211 (Activation)  (None, 26, 26, 512)       0         \n",
      "_________________________________________________________________\n",
      "depthwise_conv2d_102 (Depthw (None, 13, 13, 512)       5120      \n",
      "_________________________________________________________________\n",
      "batch_normalization_212 (Bat (None, 13, 13, 512)       2048      \n",
      "_________________________________________________________________\n",
      "activation_212 (Activation)  (None, 13, 13, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_110 (Conv2D)          (None, 13, 13, 1024)      525312    \n",
      "_________________________________________________________________\n",
      "batch_normalization_213 (Bat (None, 13, 13, 1024)      4096      \n",
      "_________________________________________________________________\n",
      "activation_213 (Activation)  (None, 13, 13, 1024)      0         \n",
      "_________________________________________________________________\n",
      "depthwise_conv2d_103 (Depthw (None, 13, 13, 1024)      10240     \n",
      "_________________________________________________________________\n",
      "batch_normalization_214 (Bat (None, 13, 13, 1024)      4096      \n",
      "_________________________________________________________________\n",
      "activation_214 (Activation)  (None, 13, 13, 1024)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_111 (Conv2D)          (None, 13, 13, 1024)      1049600   \n",
      "_________________________________________________________________\n",
      "batch_normalization_215 (Bat (None, 13, 13, 1024)      4096      \n",
      "_________________________________________________________________\n",
      "activation_215 (Activation)  (None, 13, 13, 1024)      0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_7 ( (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 10)                10250     \n",
      "=================================================================\n",
      "Total params: 3,249,482\n",
      "Trainable params: 3,227,594\n",
      "Non-trainable params: 21,888\n",
      "_________________________________________________________________\n",
      "208.709676\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-02 06:40:59.169378: I tensorflow/core/grappler/devices.cc:66] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0\n",
      "2022-04-02 06:40:59.169491: I tensorflow/core/grappler/clusters/single_machine.cc:357] Starting new session\n",
      "2022-04-02 06:40:59.173727: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:1137] Optimization results for grappler item: graph_to_optimize\n",
      "  function_optimizer: function_optimizer did nothing. time = 0.005ms.\n",
      "  function_optimizer: function_optimizer did nothing. time = 0.001ms.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=========================Options=============================\n",
      "-max_depth                  10000\n",
      "-min_bytes                  0\n",
      "-min_peak_bytes             0\n",
      "-min_residual_bytes         0\n",
      "-min_output_bytes           0\n",
      "-min_micros                 0\n",
      "-min_accelerator_micros     0\n",
      "-min_cpu_micros             0\n",
      "-min_params                 0\n",
      "-min_float_ops              1\n",
      "-min_occurrence             0\n",
      "-step                       -1\n",
      "-order_by                   float_ops\n",
      "-account_type_regexes       .*\n",
      "-start_name_regexes         .*\n",
      "-trim_name_regexes          \n",
      "-show_name_regexes          .*\n",
      "-hide_name_regexes          \n",
      "-account_displayed_op_only  true\n",
      "-select                     float_ops\n",
      "-output                     stdout:\n",
      "\n",
      "==================Model Analysis Report======================\n",
      "\n",
      "Doc:\n",
      "scope: The nodes in the model graph are organized by their names, which is hierarchical like filesystem.\n",
      "flops: Number of float operations. Note: Please read the implementation for the math behind it.\n",
      "\n",
      "Profile:\n",
      "node name | # float_ops\n",
      "_TFProfRoot (--/3.92b flops)\n",
      "  model_7/conv2d_101/Conv2D (354.42m/354.42m flops)\n",
      "  model_7/conv2d_103/Conv2D (354.42m/354.42m flops)\n",
      "  model_7/conv2d_105/Conv2D (354.42m/354.42m flops)\n",
      "  model_7/conv2d_106/Conv2D (354.42m/354.42m flops)\n",
      "  model_7/conv2d_107/Conv2D (354.42m/354.42m flops)\n",
      "  model_7/conv2d_108/Conv2D (354.42m/354.42m flops)\n",
      "  model_7/conv2d_111/Conv2D (354.42m/354.42m flops)\n",
      "  model_7/conv2d_109/Conv2D (354.42m/354.42m flops)\n",
      "  model_7/conv2d_102/Conv2D (177.21m/177.21m flops)\n",
      "  model_7/conv2d_100/Conv2D (177.21m/177.21m flops)\n",
      "  model_7/conv2d_104/Conv2D (177.21m/177.21m flops)\n",
      "  model_7/conv2d_99/Conv2D (177.21m/177.21m flops)\n",
      "  model_7/conv2d_110/Conv2D (177.21m/177.21m flops)\n",
      "  model_7/conv2d_98/Conv2D (24.92m/24.92m flops)\n",
      "  model_7/depthwise_conv2d_91/depthwise (24.92m/24.92m flops)\n",
      "  model_7/depthwise_conv2d_93/depthwise (24.92m/24.92m flops)\n",
      "  model_7/depthwise_conv2d_92/depthwise (12.46m/12.46m flops)\n",
      "  model_7/depthwise_conv2d_95/depthwise (12.46m/12.46m flops)\n",
      "  model_7/depthwise_conv2d_101/depthwise (6.23m/6.23m flops)\n",
      "  model_7/depthwise_conv2d_100/depthwise (6.23m/6.23m flops)\n",
      "  model_7/depthwise_conv2d_94/depthwise (6.23m/6.23m flops)\n",
      "  model_7/depthwise_conv2d_97/depthwise (6.23m/6.23m flops)\n",
      "  model_7/depthwise_conv2d_98/depthwise (6.23m/6.23m flops)\n",
      "  model_7/depthwise_conv2d_99/depthwise (6.23m/6.23m flops)\n",
      "  model_7/batch_normalization_191/FusedBatchNormV3 (5.54m/5.54m flops)\n",
      "  model_7/depthwise_conv2d_103/depthwise (3.12m/3.12m flops)\n",
      "  model_7/depthwise_conv2d_96/depthwise (3.12m/3.12m flops)\n",
      "  model_7/batch_normalization_195/FusedBatchNormV3 (2.77m/2.77m flops)\n",
      "  model_7/batch_normalization_194/FusedBatchNormV3 (2.77m/2.77m flops)\n",
      "  model_7/batch_normalization_193/FusedBatchNormV3 (2.77m/2.77m flops)\n",
      "  model_7/batch_normalization_190/FusedBatchNormV3 (2.77m/2.77m flops)\n",
      "  model_7/batch_normalization_189/FusedBatchNormV3 (2.77m/2.77m flops)\n",
      "  model_7/conv2d_99/BiasAdd (2.77m/2.77m flops)\n",
      "  model_7/depthwise_conv2d_102/depthwise (1.56m/1.56m flops)\n",
      "  model_7/batch_normalization_198/FusedBatchNormV3 (1.39m/1.39m flops)\n",
      "  model_7/batch_normalization_197/FusedBatchNormV3 (1.39m/1.39m flops)\n",
      "  model_7/batch_normalization_199/FusedBatchNormV3 (1.39m/1.39m flops)\n",
      "  model_7/batch_normalization_192/FusedBatchNormV3 (1.38m/1.38m flops)\n",
      "  model_7/conv2d_101/BiasAdd (1.38m/1.38m flops)\n",
      "  model_7/conv2d_98/BiasAdd (1.38m/1.38m flops)\n",
      "  model_7/depthwise_conv2d_93/BiasAdd (1.38m/1.38m flops)\n",
      "  model_7/conv2d_100/BiasAdd (1.38m/1.38m flops)\n",
      "  model_7/depthwise_conv2d_91/BiasAdd (1.38m/1.38m flops)\n",
      "  model_7/batch_normalization_204/FusedBatchNormV3 (695.30k/695.30k flops)\n",
      "  model_7/batch_normalization_205/FusedBatchNormV3 (695.30k/695.30k flops)\n",
      "  model_7/batch_normalization_201/FusedBatchNormV3 (695.30k/695.30k flops)\n",
      "  model_7/batch_normalization_206/FusedBatchNormV3 (695.30k/695.30k flops)\n",
      "  model_7/batch_normalization_203/FusedBatchNormV3 (695.30k/695.30k flops)\n",
      "  model_7/batch_normalization_207/FusedBatchNormV3 (695.30k/695.30k flops)\n",
      "  model_7/batch_normalization_202/FusedBatchNormV3 (695.30k/695.30k flops)\n",
      "  model_7/batch_normalization_208/FusedBatchNormV3 (695.30k/695.30k flops)\n",
      "  model_7/batch_normalization_209/FusedBatchNormV3 (695.30k/695.30k flops)\n",
      "  model_7/batch_normalization_210/FusedBatchNormV3 (695.30k/695.30k flops)\n",
      "  model_7/batch_normalization_211/FusedBatchNormV3 (695.30k/695.30k flops)\n",
      "  model_7/batch_normalization_196/FusedBatchNormV3 (692.99k/692.99k flops)\n",
      "  model_7/depthwise_conv2d_95/BiasAdd (692.22k/692.22k flops)\n",
      "  model_7/conv2d_103/BiasAdd (692.22k/692.22k flops)\n",
      "  model_7/depthwise_conv2d_92/BiasAdd (692.22k/692.22k flops)\n",
      "  model_7/conv2d_102/BiasAdd (692.22k/692.22k flops)\n",
      "  model_7/batch_normalization_213/FusedBatchNormV3 (352.26k/352.26k flops)\n",
      "  model_7/batch_normalization_214/FusedBatchNormV3 (352.26k/352.26k flops)\n",
      "  model_7/batch_normalization_215/FusedBatchNormV3 (352.26k/352.26k flops)\n",
      "  model_7/batch_normalization_200/FusedBatchNormV3 (347.65k/347.65k flops)\n",
      "  model_7/depthwise_conv2d_98/BiasAdd (346.11k/346.11k flops)\n",
      "  model_7/depthwise_conv2d_99/BiasAdd (346.11k/346.11k flops)\n",
      "  model_7/depthwise_conv2d_94/BiasAdd (346.11k/346.11k flops)\n",
      "  model_7/depthwise_conv2d_97/BiasAdd (346.11k/346.11k flops)\n",
      "  model_7/depthwise_conv2d_100/BiasAdd (346.11k/346.11k flops)\n",
      "  model_7/depthwise_conv2d_101/BiasAdd (346.11k/346.11k flops)\n",
      "  model_7/conv2d_104/BiasAdd (346.11k/346.11k flops)\n",
      "  model_7/conv2d_105/BiasAdd (346.11k/346.11k flops)\n",
      "  model_7/conv2d_106/BiasAdd (346.11k/346.11k flops)\n",
      "  model_7/conv2d_107/BiasAdd (346.11k/346.11k flops)\n",
      "  model_7/conv2d_108/BiasAdd (346.11k/346.11k flops)\n",
      "  model_7/conv2d_109/BiasAdd (346.11k/346.11k flops)\n",
      "  model_7/batch_normalization_212/FusedBatchNormV3 (176.13k/176.13k flops)\n",
      "  model_7/depthwise_conv2d_96/BiasAdd (173.06k/173.06k flops)\n",
      "  model_7/global_average_pooling2d_7/Mean (173.06k/173.06k flops)\n",
      "  model_7/depthwise_conv2d_103/BiasAdd (173.06k/173.06k flops)\n",
      "  model_7/conv2d_110/BiasAdd (173.06k/173.06k flops)\n",
      "  model_7/conv2d_111/BiasAdd (173.06k/173.06k flops)\n",
      "  model_7/depthwise_conv2d_102/BiasAdd (86.53k/86.53k flops)\n",
      "  model_7/dense_7/MatMul (20.48k/20.48k flops)\n",
      "  model_7/dense_7/Softmax (50/50 flops)\n",
      "  model_7/dense_7/BiasAdd (10/10 flops)\n",
      "\n",
      "======================End of Report==========================\n",
      "Model: \"model_8\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_9 (InputLayer)         [(None, 448, 448, 1)]     0         \n",
      "_________________________________________________________________\n",
      "conv2d_112 (Conv2D)          (None, 224, 224, 32)      320       \n",
      "_________________________________________________________________\n",
      "batch_normalization_216 (Bat (None, 224, 224, 32)      128       \n",
      "_________________________________________________________________\n",
      "activation_216 (Activation)  (None, 224, 224, 32)      0         \n",
      "_________________________________________________________________\n",
      "depthwise_conv2d_104 (Depthw (None, 224, 224, 32)      320       \n",
      "_________________________________________________________________\n",
      "batch_normalization_217 (Bat (None, 224, 224, 32)      128       \n",
      "_________________________________________________________________\n",
      "activation_217 (Activation)  (None, 224, 224, 32)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_113 (Conv2D)          (None, 224, 224, 64)      2112      \n",
      "_________________________________________________________________\n",
      "batch_normalization_218 (Bat (None, 224, 224, 64)      256       \n",
      "_________________________________________________________________\n",
      "activation_218 (Activation)  (None, 224, 224, 64)      0         \n",
      "_________________________________________________________________\n",
      "depthwise_conv2d_105 (Depthw (None, 112, 112, 64)      640       \n",
      "_________________________________________________________________\n",
      "batch_normalization_219 (Bat (None, 112, 112, 64)      256       \n",
      "_________________________________________________________________\n",
      "activation_219 (Activation)  (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_114 (Conv2D)          (None, 112, 112, 128)     8320      \n",
      "_________________________________________________________________\n",
      "batch_normalization_220 (Bat (None, 112, 112, 128)     512       \n",
      "_________________________________________________________________\n",
      "activation_220 (Activation)  (None, 112, 112, 128)     0         \n",
      "_________________________________________________________________\n",
      "depthwise_conv2d_106 (Depthw (None, 112, 112, 128)     1280      \n",
      "_________________________________________________________________\n",
      "batch_normalization_221 (Bat (None, 112, 112, 128)     512       \n",
      "_________________________________________________________________\n",
      "activation_221 (Activation)  (None, 112, 112, 128)     0         \n",
      "_________________________________________________________________\n",
      "conv2d_115 (Conv2D)          (None, 112, 112, 128)     16512     \n",
      "_________________________________________________________________\n",
      "batch_normalization_222 (Bat (None, 112, 112, 128)     512       \n",
      "_________________________________________________________________\n",
      "activation_222 (Activation)  (None, 112, 112, 128)     0         \n",
      "_________________________________________________________________\n",
      "depthwise_conv2d_107 (Depthw (None, 56, 56, 128)       1280      \n",
      "_________________________________________________________________\n",
      "batch_normalization_223 (Bat (None, 56, 56, 128)       512       \n",
      "_________________________________________________________________\n",
      "activation_223 (Activation)  (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_116 (Conv2D)          (None, 56, 56, 256)       33024     \n",
      "_________________________________________________________________\n",
      "batch_normalization_224 (Bat (None, 56, 56, 256)       1024      \n",
      "_________________________________________________________________\n",
      "activation_224 (Activation)  (None, 56, 56, 256)       0         \n",
      "_________________________________________________________________\n",
      "depthwise_conv2d_108 (Depthw (None, 56, 56, 256)       2560      \n",
      "_________________________________________________________________\n",
      "batch_normalization_225 (Bat (None, 56, 56, 256)       1024      \n",
      "_________________________________________________________________\n",
      "activation_225 (Activation)  (None, 56, 56, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_117 (Conv2D)          (None, 56, 56, 256)       65792     \n",
      "_________________________________________________________________\n",
      "batch_normalization_226 (Bat (None, 56, 56, 256)       1024      \n",
      "_________________________________________________________________\n",
      "activation_226 (Activation)  (None, 56, 56, 256)       0         \n",
      "_________________________________________________________________\n",
      "depthwise_conv2d_109 (Depthw (None, 28, 28, 256)       2560      \n",
      "_________________________________________________________________\n",
      "batch_normalization_227 (Bat (None, 28, 28, 256)       1024      \n",
      "_________________________________________________________________\n",
      "activation_227 (Activation)  (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_118 (Conv2D)          (None, 28, 28, 512)       131584    \n",
      "_________________________________________________________________\n",
      "batch_normalization_228 (Bat (None, 28, 28, 512)       2048      \n",
      "_________________________________________________________________\n",
      "activation_228 (Activation)  (None, 28, 28, 512)       0         \n",
      "_________________________________________________________________\n",
      "depthwise_conv2d_110 (Depthw (None, 28, 28, 512)       5120      \n",
      "_________________________________________________________________\n",
      "batch_normalization_229 (Bat (None, 28, 28, 512)       2048      \n",
      "_________________________________________________________________\n",
      "activation_229 (Activation)  (None, 28, 28, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_119 (Conv2D)          (None, 28, 28, 512)       262656    \n",
      "_________________________________________________________________\n",
      "batch_normalization_230 (Bat (None, 28, 28, 512)       2048      \n",
      "_________________________________________________________________\n",
      "activation_230 (Activation)  (None, 28, 28, 512)       0         \n",
      "_________________________________________________________________\n",
      "depthwise_conv2d_111 (Depthw (None, 28, 28, 512)       5120      \n",
      "_________________________________________________________________\n",
      "batch_normalization_231 (Bat (None, 28, 28, 512)       2048      \n",
      "_________________________________________________________________\n",
      "activation_231 (Activation)  (None, 28, 28, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_120 (Conv2D)          (None, 28, 28, 512)       262656    \n",
      "_________________________________________________________________\n",
      "batch_normalization_232 (Bat (None, 28, 28, 512)       2048      \n",
      "_________________________________________________________________\n",
      "activation_232 (Activation)  (None, 28, 28, 512)       0         \n",
      "_________________________________________________________________\n",
      "depthwise_conv2d_112 (Depthw (None, 28, 28, 512)       5120      \n",
      "_________________________________________________________________\n",
      "batch_normalization_233 (Bat (None, 28, 28, 512)       2048      \n",
      "_________________________________________________________________\n",
      "activation_233 (Activation)  (None, 28, 28, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_121 (Conv2D)          (None, 28, 28, 512)       262656    \n",
      "_________________________________________________________________\n",
      "batch_normalization_234 (Bat (None, 28, 28, 512)       2048      \n",
      "_________________________________________________________________\n",
      "activation_234 (Activation)  (None, 28, 28, 512)       0         \n",
      "_________________________________________________________________\n",
      "depthwise_conv2d_113 (Depthw (None, 28, 28, 512)       5120      \n",
      "_________________________________________________________________\n",
      "batch_normalization_235 (Bat (None, 28, 28, 512)       2048      \n",
      "_________________________________________________________________\n",
      "activation_235 (Activation)  (None, 28, 28, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_122 (Conv2D)          (None, 28, 28, 512)       262656    \n",
      "_________________________________________________________________\n",
      "batch_normalization_236 (Bat (None, 28, 28, 512)       2048      \n",
      "_________________________________________________________________\n",
      "activation_236 (Activation)  (None, 28, 28, 512)       0         \n",
      "_________________________________________________________________\n",
      "depthwise_conv2d_114 (Depthw (None, 28, 28, 512)       5120      \n",
      "_________________________________________________________________\n",
      "batch_normalization_237 (Bat (None, 28, 28, 512)       2048      \n",
      "_________________________________________________________________\n",
      "activation_237 (Activation)  (None, 28, 28, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_123 (Conv2D)          (None, 28, 28, 512)       262656    \n",
      "_________________________________________________________________\n",
      "batch_normalization_238 (Bat (None, 28, 28, 512)       2048      \n",
      "_________________________________________________________________\n",
      "activation_238 (Activation)  (None, 28, 28, 512)       0         \n",
      "_________________________________________________________________\n",
      "depthwise_conv2d_115 (Depthw (None, 14, 14, 512)       5120      \n",
      "_________________________________________________________________\n",
      "batch_normalization_239 (Bat (None, 14, 14, 512)       2048      \n",
      "_________________________________________________________________\n",
      "activation_239 (Activation)  (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_124 (Conv2D)          (None, 14, 14, 1024)      525312    \n",
      "_________________________________________________________________\n",
      "batch_normalization_240 (Bat (None, 14, 14, 1024)      4096      \n",
      "_________________________________________________________________\n",
      "activation_240 (Activation)  (None, 14, 14, 1024)      0         \n",
      "_________________________________________________________________\n",
      "depthwise_conv2d_116 (Depthw (None, 14, 14, 1024)      10240     \n",
      "_________________________________________________________________\n",
      "batch_normalization_241 (Bat (None, 14, 14, 1024)      4096      \n",
      "_________________________________________________________________\n",
      "activation_241 (Activation)  (None, 14, 14, 1024)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_125 (Conv2D)          (None, 14, 14, 1024)      1049600   \n",
      "_________________________________________________________________\n",
      "batch_normalization_242 (Bat (None, 14, 14, 1024)      4096      \n",
      "_________________________________________________________________\n",
      "activation_242 (Activation)  (None, 14, 14, 1024)      0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_8 ( (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 10)                10250     \n",
      "=================================================================\n",
      "Total params: 3,249,482\n",
      "Trainable params: 3,227,594\n",
      "Non-trainable params: 21,888\n",
      "_________________________________________________________________\n",
      "242.053164\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-02 06:41:00.137273: I tensorflow/core/grappler/devices.cc:66] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0\n",
      "2022-04-02 06:41:00.137341: I tensorflow/core/grappler/clusters/single_machine.cc:357] Starting new session\n",
      "2022-04-02 06:41:00.141681: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:1137] Optimization results for grappler item: graph_to_optimize\n",
      "  function_optimizer: function_optimizer did nothing. time = 0.005ms.\n",
      "  function_optimizer: function_optimizer did nothing. time = 0.001ms.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=========================Options=============================\n",
      "-max_depth                  10000\n",
      "-min_bytes                  0\n",
      "-min_peak_bytes             0\n",
      "-min_residual_bytes         0\n",
      "-min_output_bytes           0\n",
      "-min_micros                 0\n",
      "-min_accelerator_micros     0\n",
      "-min_cpu_micros             0\n",
      "-min_params                 0\n",
      "-min_float_ops              1\n",
      "-min_occurrence             0\n",
      "-step                       -1\n",
      "-order_by                   float_ops\n",
      "-account_type_regexes       .*\n",
      "-start_name_regexes         .*\n",
      "-trim_name_regexes          \n",
      "-show_name_regexes          .*\n",
      "-hide_name_regexes          \n",
      "-account_displayed_op_only  true\n",
      "-select                     float_ops\n",
      "-output                     stdout:\n",
      "\n",
      "==================Model Analysis Report======================\n",
      "\n",
      "Doc:\n",
      "scope: The nodes in the model graph are organized by their names, which is hierarchical like filesystem.\n",
      "flops: Number of float operations. Note: Please read the implementation for the math behind it.\n",
      "\n",
      "Profile:\n",
      "node name | # float_ops\n",
      "_TFProfRoot (--/4.54b flops)\n",
      "  model_8/conv2d_125/Conv2D (411.04m/411.04m flops)\n",
      "  model_8/conv2d_123/Conv2D (411.04m/411.04m flops)\n",
      "  model_8/conv2d_115/Conv2D (411.04m/411.04m flops)\n",
      "  model_8/conv2d_122/Conv2D (411.04m/411.04m flops)\n",
      "  model_8/conv2d_117/Conv2D (411.04m/411.04m flops)\n",
      "  model_8/conv2d_121/Conv2D (411.04m/411.04m flops)\n",
      "  model_8/conv2d_119/Conv2D (411.04m/411.04m flops)\n",
      "  model_8/conv2d_120/Conv2D (411.04m/411.04m flops)\n",
      "  model_8/conv2d_113/Conv2D (205.52m/205.52m flops)\n",
      "  model_8/conv2d_124/Conv2D (205.52m/205.52m flops)\n",
      "  model_8/conv2d_118/Conv2D (205.52m/205.52m flops)\n",
      "  model_8/conv2d_116/Conv2D (205.52m/205.52m flops)\n",
      "  model_8/conv2d_114/Conv2D (205.52m/205.52m flops)\n",
      "  model_8/conv2d_112/Conv2D (28.90m/28.90m flops)\n",
      "  model_8/depthwise_conv2d_106/depthwise (28.90m/28.90m flops)\n",
      "  model_8/depthwise_conv2d_104/depthwise (28.90m/28.90m flops)\n",
      "  model_8/depthwise_conv2d_105/depthwise (14.45m/14.45m flops)\n",
      "  model_8/depthwise_conv2d_108/depthwise (14.45m/14.45m flops)\n",
      "  model_8/depthwise_conv2d_107/depthwise (7.23m/7.23m flops)\n",
      "  model_8/depthwise_conv2d_110/depthwise (7.23m/7.23m flops)\n",
      "  model_8/depthwise_conv2d_111/depthwise (7.23m/7.23m flops)\n",
      "  model_8/depthwise_conv2d_112/depthwise (7.23m/7.23m flops)\n",
      "  model_8/depthwise_conv2d_113/depthwise (7.23m/7.23m flops)\n",
      "  model_8/depthwise_conv2d_114/depthwise (7.23m/7.23m flops)\n",
      "  model_8/batch_normalization_218/FusedBatchNormV3 (6.42m/6.42m flops)\n",
      "  model_8/depthwise_conv2d_109/depthwise (3.61m/3.61m flops)\n",
      "  model_8/depthwise_conv2d_116/depthwise (3.61m/3.61m flops)\n",
      "  model_8/batch_normalization_222/FusedBatchNormV3 (3.21m/3.21m flops)\n",
      "  model_8/batch_normalization_221/FusedBatchNormV3 (3.21m/3.21m flops)\n",
      "  model_8/batch_normalization_220/FusedBatchNormV3 (3.21m/3.21m flops)\n",
      "  model_8/batch_normalization_217/FusedBatchNormV3 (3.21m/3.21m flops)\n",
      "  model_8/batch_normalization_216/FusedBatchNormV3 (3.21m/3.21m flops)\n",
      "  model_8/conv2d_113/BiasAdd (3.21m/3.21m flops)\n",
      "  model_8/depthwise_conv2d_115/depthwise (1.81m/1.81m flops)\n",
      "  model_8/batch_normalization_224/FusedBatchNormV3 (1.61m/1.61m flops)\n",
      "  model_8/batch_normalization_225/FusedBatchNormV3 (1.61m/1.61m flops)\n",
      "  model_8/batch_normalization_226/FusedBatchNormV3 (1.61m/1.61m flops)\n",
      "  model_8/batch_normalization_219/FusedBatchNormV3 (1.61m/1.61m flops)\n",
      "  model_8/depthwise_conv2d_104/BiasAdd (1.61m/1.61m flops)\n",
      "  model_8/depthwise_conv2d_106/BiasAdd (1.61m/1.61m flops)\n",
      "  model_8/conv2d_114/BiasAdd (1.61m/1.61m flops)\n",
      "  model_8/conv2d_112/BiasAdd (1.61m/1.61m flops)\n",
      "  model_8/conv2d_115/BiasAdd (1.61m/1.61m flops)\n",
      "  model_8/batch_normalization_231/FusedBatchNormV3 (805.89k/805.89k flops)\n",
      "  model_8/batch_normalization_232/FusedBatchNormV3 (805.89k/805.89k flops)\n",
      "  model_8/batch_normalization_230/FusedBatchNormV3 (805.89k/805.89k flops)\n",
      "  model_8/batch_normalization_229/FusedBatchNormV3 (805.89k/805.89k flops)\n",
      "  model_8/batch_normalization_233/FusedBatchNormV3 (805.89k/805.89k flops)\n",
      "  model_8/batch_normalization_234/FusedBatchNormV3 (805.89k/805.89k flops)\n",
      "  model_8/batch_normalization_235/FusedBatchNormV3 (805.89k/805.89k flops)\n",
      "  model_8/batch_normalization_236/FusedBatchNormV3 (805.89k/805.89k flops)\n",
      "  model_8/batch_normalization_228/FusedBatchNormV3 (805.89k/805.89k flops)\n",
      "  model_8/batch_normalization_237/FusedBatchNormV3 (805.89k/805.89k flops)\n",
      "  model_8/batch_normalization_238/FusedBatchNormV3 (805.89k/805.89k flops)\n",
      "  model_8/batch_normalization_223/FusedBatchNormV3 (803.58k/803.58k flops)\n",
      "  model_8/depthwise_conv2d_108/BiasAdd (802.82k/802.82k flops)\n",
      "  model_8/conv2d_116/BiasAdd (802.82k/802.82k flops)\n",
      "  model_8/conv2d_117/BiasAdd (802.82k/802.82k flops)\n",
      "  model_8/depthwise_conv2d_105/BiasAdd (802.82k/802.82k flops)\n",
      "  model_8/batch_normalization_241/FusedBatchNormV3 (407.55k/407.55k flops)\n",
      "  model_8/batch_normalization_242/FusedBatchNormV3 (407.55k/407.55k flops)\n",
      "  model_8/batch_normalization_240/FusedBatchNormV3 (407.55k/407.55k flops)\n",
      "  model_8/batch_normalization_227/FusedBatchNormV3 (402.94k/402.94k flops)\n",
      "  model_8/conv2d_118/BiasAdd (401.41k/401.41k flops)\n",
      "  model_8/depthwise_conv2d_107/BiasAdd (401.41k/401.41k flops)\n",
      "  model_8/depthwise_conv2d_114/BiasAdd (401.41k/401.41k flops)\n",
      "  model_8/conv2d_123/BiasAdd (401.41k/401.41k flops)\n",
      "  model_8/conv2d_122/BiasAdd (401.41k/401.41k flops)\n",
      "  model_8/depthwise_conv2d_113/BiasAdd (401.41k/401.41k flops)\n",
      "  model_8/depthwise_conv2d_110/BiasAdd (401.41k/401.41k flops)\n",
      "  model_8/conv2d_121/BiasAdd (401.41k/401.41k flops)\n",
      "  model_8/depthwise_conv2d_111/BiasAdd (401.41k/401.41k flops)\n",
      "  model_8/conv2d_120/BiasAdd (401.41k/401.41k flops)\n",
      "  model_8/depthwise_conv2d_112/BiasAdd (401.41k/401.41k flops)\n",
      "  model_8/conv2d_119/BiasAdd (401.41k/401.41k flops)\n",
      "  model_8/batch_normalization_239/FusedBatchNormV3 (203.78k/203.78k flops)\n",
      "  model_8/depthwise_conv2d_109/BiasAdd (200.70k/200.70k flops)\n",
      "  model_8/conv2d_125/BiasAdd (200.70k/200.70k flops)\n",
      "  model_8/depthwise_conv2d_116/BiasAdd (200.70k/200.70k flops)\n",
      "  model_8/conv2d_124/BiasAdd (200.70k/200.70k flops)\n",
      "  model_8/global_average_pooling2d_8/Mean (200.70k/200.70k flops)\n",
      "  model_8/depthwise_conv2d_115/BiasAdd (100.35k/100.35k flops)\n",
      "  model_8/dense_8/MatMul (20.48k/20.48k flops)\n",
      "  model_8/dense_8/Softmax (50/50 flops)\n",
      "  model_8/dense_8/BiasAdd (10/10 flops)\n",
      "\n",
      "======================End of Report==========================\n",
      "Model: \"model_9\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_10 (InputLayer)        [(None, 480, 480, 1)]     0         \n",
      "_________________________________________________________________\n",
      "conv2d_126 (Conv2D)          (None, 240, 240, 32)      320       \n",
      "_________________________________________________________________\n",
      "batch_normalization_243 (Bat (None, 240, 240, 32)      128       \n",
      "_________________________________________________________________\n",
      "activation_243 (Activation)  (None, 240, 240, 32)      0         \n",
      "_________________________________________________________________\n",
      "depthwise_conv2d_117 (Depthw (None, 240, 240, 32)      320       \n",
      "_________________________________________________________________\n",
      "batch_normalization_244 (Bat (None, 240, 240, 32)      128       \n",
      "_________________________________________________________________\n",
      "activation_244 (Activation)  (None, 240, 240, 32)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_127 (Conv2D)          (None, 240, 240, 64)      2112      \n",
      "_________________________________________________________________\n",
      "batch_normalization_245 (Bat (None, 240, 240, 64)      256       \n",
      "_________________________________________________________________\n",
      "activation_245 (Activation)  (None, 240, 240, 64)      0         \n",
      "_________________________________________________________________\n",
      "depthwise_conv2d_118 (Depthw (None, 120, 120, 64)      640       \n",
      "_________________________________________________________________\n",
      "batch_normalization_246 (Bat (None, 120, 120, 64)      256       \n",
      "_________________________________________________________________\n",
      "activation_246 (Activation)  (None, 120, 120, 64)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_128 (Conv2D)          (None, 120, 120, 128)     8320      \n",
      "_________________________________________________________________\n",
      "batch_normalization_247 (Bat (None, 120, 120, 128)     512       \n",
      "_________________________________________________________________\n",
      "activation_247 (Activation)  (None, 120, 120, 128)     0         \n",
      "_________________________________________________________________\n",
      "depthwise_conv2d_119 (Depthw (None, 120, 120, 128)     1280      \n",
      "_________________________________________________________________\n",
      "batch_normalization_248 (Bat (None, 120, 120, 128)     512       \n",
      "_________________________________________________________________\n",
      "activation_248 (Activation)  (None, 120, 120, 128)     0         \n",
      "_________________________________________________________________\n",
      "conv2d_129 (Conv2D)          (None, 120, 120, 128)     16512     \n",
      "_________________________________________________________________\n",
      "batch_normalization_249 (Bat (None, 120, 120, 128)     512       \n",
      "_________________________________________________________________\n",
      "activation_249 (Activation)  (None, 120, 120, 128)     0         \n",
      "_________________________________________________________________\n",
      "depthwise_conv2d_120 (Depthw (None, 60, 60, 128)       1280      \n",
      "_________________________________________________________________\n",
      "batch_normalization_250 (Bat (None, 60, 60, 128)       512       \n",
      "_________________________________________________________________\n",
      "activation_250 (Activation)  (None, 60, 60, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_130 (Conv2D)          (None, 60, 60, 256)       33024     \n",
      "_________________________________________________________________\n",
      "batch_normalization_251 (Bat (None, 60, 60, 256)       1024      \n",
      "_________________________________________________________________\n",
      "activation_251 (Activation)  (None, 60, 60, 256)       0         \n",
      "_________________________________________________________________\n",
      "depthwise_conv2d_121 (Depthw (None, 60, 60, 256)       2560      \n",
      "_________________________________________________________________\n",
      "batch_normalization_252 (Bat (None, 60, 60, 256)       1024      \n",
      "_________________________________________________________________\n",
      "activation_252 (Activation)  (None, 60, 60, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_131 (Conv2D)          (None, 60, 60, 256)       65792     \n",
      "_________________________________________________________________\n",
      "batch_normalization_253 (Bat (None, 60, 60, 256)       1024      \n",
      "_________________________________________________________________\n",
      "activation_253 (Activation)  (None, 60, 60, 256)       0         \n",
      "_________________________________________________________________\n",
      "depthwise_conv2d_122 (Depthw (None, 30, 30, 256)       2560      \n",
      "_________________________________________________________________\n",
      "batch_normalization_254 (Bat (None, 30, 30, 256)       1024      \n",
      "_________________________________________________________________\n",
      "activation_254 (Activation)  (None, 30, 30, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_132 (Conv2D)          (None, 30, 30, 512)       131584    \n",
      "_________________________________________________________________\n",
      "batch_normalization_255 (Bat (None, 30, 30, 512)       2048      \n",
      "_________________________________________________________________\n",
      "activation_255 (Activation)  (None, 30, 30, 512)       0         \n",
      "_________________________________________________________________\n",
      "depthwise_conv2d_123 (Depthw (None, 30, 30, 512)       5120      \n",
      "_________________________________________________________________\n",
      "batch_normalization_256 (Bat (None, 30, 30, 512)       2048      \n",
      "_________________________________________________________________\n",
      "activation_256 (Activation)  (None, 30, 30, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_133 (Conv2D)          (None, 30, 30, 512)       262656    \n",
      "_________________________________________________________________\n",
      "batch_normalization_257 (Bat (None, 30, 30, 512)       2048      \n",
      "_________________________________________________________________\n",
      "activation_257 (Activation)  (None, 30, 30, 512)       0         \n",
      "_________________________________________________________________\n",
      "depthwise_conv2d_124 (Depthw (None, 30, 30, 512)       5120      \n",
      "_________________________________________________________________\n",
      "batch_normalization_258 (Bat (None, 30, 30, 512)       2048      \n",
      "_________________________________________________________________\n",
      "activation_258 (Activation)  (None, 30, 30, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_134 (Conv2D)          (None, 30, 30, 512)       262656    \n",
      "_________________________________________________________________\n",
      "batch_normalization_259 (Bat (None, 30, 30, 512)       2048      \n",
      "_________________________________________________________________\n",
      "activation_259 (Activation)  (None, 30, 30, 512)       0         \n",
      "_________________________________________________________________\n",
      "depthwise_conv2d_125 (Depthw (None, 30, 30, 512)       5120      \n",
      "_________________________________________________________________\n",
      "batch_normalization_260 (Bat (None, 30, 30, 512)       2048      \n",
      "_________________________________________________________________\n",
      "activation_260 (Activation)  (None, 30, 30, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_135 (Conv2D)          (None, 30, 30, 512)       262656    \n",
      "_________________________________________________________________\n",
      "batch_normalization_261 (Bat (None, 30, 30, 512)       2048      \n",
      "_________________________________________________________________\n",
      "activation_261 (Activation)  (None, 30, 30, 512)       0         \n",
      "_________________________________________________________________\n",
      "depthwise_conv2d_126 (Depthw (None, 30, 30, 512)       5120      \n",
      "_________________________________________________________________\n",
      "batch_normalization_262 (Bat (None, 30, 30, 512)       2048      \n",
      "_________________________________________________________________\n",
      "activation_262 (Activation)  (None, 30, 30, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_136 (Conv2D)          (None, 30, 30, 512)       262656    \n",
      "_________________________________________________________________\n",
      "batch_normalization_263 (Bat (None, 30, 30, 512)       2048      \n",
      "_________________________________________________________________\n",
      "activation_263 (Activation)  (None, 30, 30, 512)       0         \n",
      "_________________________________________________________________\n",
      "depthwise_conv2d_127 (Depthw (None, 30, 30, 512)       5120      \n",
      "_________________________________________________________________\n",
      "batch_normalization_264 (Bat (None, 30, 30, 512)       2048      \n",
      "_________________________________________________________________\n",
      "activation_264 (Activation)  (None, 30, 30, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_137 (Conv2D)          (None, 30, 30, 512)       262656    \n",
      "_________________________________________________________________\n",
      "batch_normalization_265 (Bat (None, 30, 30, 512)       2048      \n",
      "_________________________________________________________________\n",
      "activation_265 (Activation)  (None, 30, 30, 512)       0         \n",
      "_________________________________________________________________\n",
      "depthwise_conv2d_128 (Depthw (None, 15, 15, 512)       5120      \n",
      "_________________________________________________________________\n",
      "batch_normalization_266 (Bat (None, 15, 15, 512)       2048      \n",
      "_________________________________________________________________\n",
      "activation_266 (Activation)  (None, 15, 15, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_138 (Conv2D)          (None, 15, 15, 1024)      525312    \n",
      "_________________________________________________________________\n",
      "batch_normalization_267 (Bat (None, 15, 15, 1024)      4096      \n",
      "_________________________________________________________________\n",
      "activation_267 (Activation)  (None, 15, 15, 1024)      0         \n",
      "_________________________________________________________________\n",
      "depthwise_conv2d_129 (Depthw (None, 15, 15, 1024)      10240     \n",
      "_________________________________________________________________\n",
      "batch_normalization_268 (Bat (None, 15, 15, 1024)      4096      \n",
      "_________________________________________________________________\n",
      "activation_268 (Activation)  (None, 15, 15, 1024)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_139 (Conv2D)          (None, 15, 15, 1024)      1049600   \n",
      "_________________________________________________________________\n",
      "batch_normalization_269 (Bat (None, 15, 15, 1024)      4096      \n",
      "_________________________________________________________________\n",
      "activation_269 (Activation)  (None, 15, 15, 1024)      0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_9 ( (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 10)                10250     \n",
      "=================================================================\n",
      "Total params: 3,249,482\n",
      "Trainable params: 3,227,594\n",
      "Non-trainable params: 21,888\n",
      "_________________________________________________________________\n",
      "277.86654\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-02 06:41:01.010946: I tensorflow/core/grappler/devices.cc:66] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0\n",
      "2022-04-02 06:41:01.011062: I tensorflow/core/grappler/clusters/single_machine.cc:357] Starting new session\n",
      "2022-04-02 06:41:01.015334: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:1137] Optimization results for grappler item: graph_to_optimize\n",
      "  function_optimizer: function_optimizer did nothing. time = 0.004ms.\n",
      "  function_optimizer: function_optimizer did nothing. time = 0ms.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=========================Options=============================\n",
      "-max_depth                  10000\n",
      "-min_bytes                  0\n",
      "-min_peak_bytes             0\n",
      "-min_residual_bytes         0\n",
      "-min_output_bytes           0\n",
      "-min_micros                 0\n",
      "-min_accelerator_micros     0\n",
      "-min_cpu_micros             0\n",
      "-min_params                 0\n",
      "-min_float_ops              1\n",
      "-min_occurrence             0\n",
      "-step                       -1\n",
      "-order_by                   float_ops\n",
      "-account_type_regexes       .*\n",
      "-start_name_regexes         .*\n",
      "-trim_name_regexes          \n",
      "-show_name_regexes          .*\n",
      "-hide_name_regexes          \n",
      "-account_displayed_op_only  true\n",
      "-select                     float_ops\n",
      "-output                     stdout:\n",
      "\n",
      "==================Model Analysis Report======================\n",
      "\n",
      "Doc:\n",
      "scope: The nodes in the model graph are organized by their names, which is hierarchical like filesystem.\n",
      "flops: Number of float operations. Note: Please read the implementation for the math behind it.\n",
      "\n",
      "Profile:\n",
      "node name | # float_ops\n",
      "_TFProfRoot (--/5.22b flops)\n",
      "  model_9/conv2d_139/Conv2D (471.86m/471.86m flops)\n",
      "  model_9/conv2d_137/Conv2D (471.86m/471.86m flops)\n",
      "  model_9/conv2d_129/Conv2D (471.86m/471.86m flops)\n",
      "  model_9/conv2d_136/Conv2D (471.86m/471.86m flops)\n",
      "  model_9/conv2d_131/Conv2D (471.86m/471.86m flops)\n",
      "  model_9/conv2d_135/Conv2D (471.86m/471.86m flops)\n",
      "  model_9/conv2d_133/Conv2D (471.86m/471.86m flops)\n",
      "  model_9/conv2d_134/Conv2D (471.86m/471.86m flops)\n",
      "  model_9/conv2d_127/Conv2D (235.93m/235.93m flops)\n",
      "  model_9/conv2d_138/Conv2D (235.93m/235.93m flops)\n",
      "  model_9/conv2d_132/Conv2D (235.93m/235.93m flops)\n",
      "  model_9/conv2d_130/Conv2D (235.93m/235.93m flops)\n",
      "  model_9/conv2d_128/Conv2D (235.93m/235.93m flops)\n",
      "  model_9/conv2d_126/Conv2D (33.18m/33.18m flops)\n",
      "  model_9/depthwise_conv2d_119/depthwise (33.18m/33.18m flops)\n",
      "  model_9/depthwise_conv2d_117/depthwise (33.18m/33.18m flops)\n",
      "  model_9/depthwise_conv2d_118/depthwise (16.59m/16.59m flops)\n",
      "  model_9/depthwise_conv2d_121/depthwise (16.59m/16.59m flops)\n",
      "  model_9/depthwise_conv2d_120/depthwise (8.29m/8.29m flops)\n",
      "  model_9/depthwise_conv2d_123/depthwise (8.29m/8.29m flops)\n",
      "  model_9/depthwise_conv2d_124/depthwise (8.29m/8.29m flops)\n",
      "  model_9/depthwise_conv2d_125/depthwise (8.29m/8.29m flops)\n",
      "  model_9/depthwise_conv2d_126/depthwise (8.29m/8.29m flops)\n",
      "  model_9/depthwise_conv2d_127/depthwise (8.29m/8.29m flops)\n",
      "  model_9/batch_normalization_245/FusedBatchNormV3 (7.37m/7.37m flops)\n",
      "  model_9/depthwise_conv2d_122/depthwise (4.15m/4.15m flops)\n",
      "  model_9/depthwise_conv2d_129/depthwise (4.15m/4.15m flops)\n",
      "  model_9/batch_normalization_249/FusedBatchNormV3 (3.69m/3.69m flops)\n",
      "  model_9/batch_normalization_248/FusedBatchNormV3 (3.69m/3.69m flops)\n",
      "  model_9/batch_normalization_247/FusedBatchNormV3 (3.69m/3.69m flops)\n",
      "  model_9/batch_normalization_244/FusedBatchNormV3 (3.69m/3.69m flops)\n",
      "  model_9/batch_normalization_243/FusedBatchNormV3 (3.69m/3.69m flops)\n",
      "  model_9/conv2d_127/BiasAdd (3.69m/3.69m flops)\n",
      "  model_9/depthwise_conv2d_128/depthwise (2.07m/2.07m flops)\n",
      "  model_9/batch_normalization_251/FusedBatchNormV3 (1.84m/1.84m flops)\n",
      "  model_9/batch_normalization_252/FusedBatchNormV3 (1.84m/1.84m flops)\n",
      "  model_9/batch_normalization_253/FusedBatchNormV3 (1.84m/1.84m flops)\n",
      "  model_9/batch_normalization_246/FusedBatchNormV3 (1.84m/1.84m flops)\n",
      "  model_9/depthwise_conv2d_117/BiasAdd (1.84m/1.84m flops)\n",
      "  model_9/depthwise_conv2d_119/BiasAdd (1.84m/1.84m flops)\n",
      "  model_9/conv2d_128/BiasAdd (1.84m/1.84m flops)\n",
      "  model_9/conv2d_126/BiasAdd (1.84m/1.84m flops)\n",
      "  model_9/conv2d_129/BiasAdd (1.84m/1.84m flops)\n",
      "  model_9/batch_normalization_258/FusedBatchNormV3 (924.67k/924.67k flops)\n",
      "  model_9/batch_normalization_259/FusedBatchNormV3 (924.67k/924.67k flops)\n",
      "  model_9/batch_normalization_257/FusedBatchNormV3 (924.67k/924.67k flops)\n",
      "  model_9/batch_normalization_256/FusedBatchNormV3 (924.67k/924.67k flops)\n",
      "  model_9/batch_normalization_260/FusedBatchNormV3 (924.67k/924.67k flops)\n",
      "  model_9/batch_normalization_261/FusedBatchNormV3 (924.67k/924.67k flops)\n",
      "  model_9/batch_normalization_262/FusedBatchNormV3 (924.67k/924.67k flops)\n",
      "  model_9/batch_normalization_263/FusedBatchNormV3 (924.67k/924.67k flops)\n",
      "  model_9/batch_normalization_255/FusedBatchNormV3 (924.67k/924.67k flops)\n",
      "  model_9/batch_normalization_264/FusedBatchNormV3 (924.67k/924.67k flops)\n",
      "  model_9/batch_normalization_265/FusedBatchNormV3 (924.67k/924.67k flops)\n",
      "  model_9/batch_normalization_250/FusedBatchNormV3 (922.37k/922.37k flops)\n",
      "  model_9/depthwise_conv2d_121/BiasAdd (921.60k/921.60k flops)\n",
      "  model_9/conv2d_130/BiasAdd (921.60k/921.60k flops)\n",
      "  model_9/conv2d_131/BiasAdd (921.60k/921.60k flops)\n",
      "  model_9/depthwise_conv2d_118/BiasAdd (921.60k/921.60k flops)\n",
      "  model_9/batch_normalization_268/FusedBatchNormV3 (466.94k/466.94k flops)\n",
      "  model_9/batch_normalization_269/FusedBatchNormV3 (466.94k/466.94k flops)\n",
      "  model_9/batch_normalization_267/FusedBatchNormV3 (466.94k/466.94k flops)\n",
      "  model_9/batch_normalization_254/FusedBatchNormV3 (462.34k/462.34k flops)\n",
      "  model_9/conv2d_132/BiasAdd (460.80k/460.80k flops)\n",
      "  model_9/depthwise_conv2d_120/BiasAdd (460.80k/460.80k flops)\n",
      "  model_9/depthwise_conv2d_127/BiasAdd (460.80k/460.80k flops)\n",
      "  model_9/conv2d_137/BiasAdd (460.80k/460.80k flops)\n",
      "  model_9/conv2d_136/BiasAdd (460.80k/460.80k flops)\n",
      "  model_9/depthwise_conv2d_126/BiasAdd (460.80k/460.80k flops)\n",
      "  model_9/depthwise_conv2d_123/BiasAdd (460.80k/460.80k flops)\n",
      "  model_9/conv2d_135/BiasAdd (460.80k/460.80k flops)\n",
      "  model_9/depthwise_conv2d_124/BiasAdd (460.80k/460.80k flops)\n",
      "  model_9/conv2d_134/BiasAdd (460.80k/460.80k flops)\n",
      "  model_9/depthwise_conv2d_125/BiasAdd (460.80k/460.80k flops)\n",
      "  model_9/conv2d_133/BiasAdd (460.80k/460.80k flops)\n",
      "  model_9/batch_normalization_266/FusedBatchNormV3 (233.47k/233.47k flops)\n",
      "  model_9/depthwise_conv2d_122/BiasAdd (230.40k/230.40k flops)\n",
      "  model_9/conv2d_139/BiasAdd (230.40k/230.40k flops)\n",
      "  model_9/depthwise_conv2d_129/BiasAdd (230.40k/230.40k flops)\n",
      "  model_9/conv2d_138/BiasAdd (230.40k/230.40k flops)\n",
      "  model_9/global_average_pooling2d_9/Mean (230.40k/230.40k flops)\n",
      "  model_9/depthwise_conv2d_128/BiasAdd (115.20k/115.20k flops)\n",
      "  model_9/dense_9/MatMul (20.48k/20.48k flops)\n",
      "  model_9/dense_9/Softmax (50/50 flops)\n",
      "  model_9/dense_9/BiasAdd (10/10 flops)\n",
      "\n",
      "======================End of Report==========================\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "import numpy as np\n",
    "import os\n",
    "import csv\n",
    "from keras import backend as K\n",
    "from keras.layers import Input, Conv2D,GlobalAveragePooling2D, Dense, BatchNormalization, Activation\n",
    "from keras.models import Model\n",
    "from keras.layers import DepthwiseConv2D\n",
    "\n",
    "from keras import optimizers,regularizers\n",
    "from keras.initializers import he_normal\n",
    "\n",
    "from keras_flops import get_flops\n",
    "\n",
    "\n",
    "with open(\"para_count_MobileNet.csv\",\"w\") as csvfile:\n",
    "         writer = csv.writer(csvfile)\n",
    "         writer.writerows([[\"model_num\", \"input_horizontal\", \"input_vertical\", \"FLOPs\", \"Total_params\", \"Memory\"],])\n",
    "def depthwise_separable(x,params):\n",
    "    # f1/f2 filter size, s1 stride of conv\n",
    "    (s1,f2) = params\n",
    "    x = DepthwiseConv2D((3,3),strides=(s1[0],s1[0]), padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = Conv2D(int(f2[0]), (1,1), strides=(1,1), padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    return x\n",
    "\n",
    "\n",
    "def MobileNet(img_input,shallow=False, classes=10):\n",
    "    \"\"\"Instantiates the MobileNet.Network has two hyper-parameters\n",
    "        which are the width of network (controlled by alpha)\n",
    "        and input size.\n",
    "        # Arguments\n",
    "            alpha: optional parameter of the network to change the \n",
    "                width of model.\n",
    "            shallow: optional parameter for making network smaller.\n",
    "            classes: optional number of classes to classify images\n",
    "                into.\n",
    "    \"\"\"\n",
    "    x = Conv2D(int(32), (3,3), strides=(2,2), padding='same')(img_input)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "    x = depthwise_separable(x,params=[(1,),(64,)])\n",
    "    x = depthwise_separable(x,params=[(2,),(128,)])\n",
    "    x = depthwise_separable(x,params=[(1,),(128,)])\n",
    "    x = depthwise_separable(x,params=[(2,),(256,)])\n",
    "    x = depthwise_separable(x,params=[(1,),(256,)])\n",
    "    x = depthwise_separable(x,params=[(2,),(512,)])\n",
    "    \n",
    "    if not shallow:\n",
    "        for _ in range(5):\n",
    "            x = depthwise_separable(x,params=[(1,),(512,)])\n",
    "            \n",
    "    x = depthwise_separable(x,params=[(2,),(1024,)])\n",
    "    x = depthwise_separable(x,params=[(1,),(1024,)])\n",
    "\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    out = Dense(classes, activation='softmax')(x)\n",
    "    return out\n",
    "model_num = 1\n",
    "shape_range =range(192,512,32)\n",
    "for shape_x in shape_range:\n",
    "    shape_y = shape_x\n",
    "    img_input=Input(shape=(shape_x,shape_y,1))\n",
    "    output = MobileNet(img_input)\n",
    "    model=Model(img_input,output)\n",
    "    model.summary()\n",
    "    \n",
    "    # how to compute the memory allocated by the activations of a model\n",
    "    batch = 1\n",
    "    shapes_count = int(np.sum([np.prod(np.array([s if isinstance(s, int) \n",
    "    else 1 for s in l.output_shape])) \n",
    "    for l in model.layers]))\n",
    "    memory = (shapes_count * 4 * batch)/10**6\n",
    "    print(memory)\n",
    "    \n",
    "    Total_params = round(model.count_params()/10 ** 6,2)\n",
    "    FLOPs = round(get_flops(model, batch_size=1)/10 ** 9,2)\n",
    "    with open(\"para_count_MobileNet.csv\",\"a+\") as csvfile:\n",
    "        writer = csv.writer(csvfile)\n",
    "        writer.writerows([[model_num, shape_x, shape_y, \"FLOPs\", Total_params, memory],])\n",
    "\n",
    "        model_num = model_num + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "372f5b16",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
