{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4bbb3bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pynq_dpu import DpuOverlay\n",
    "from time import time\n",
    "import numpy as np\n",
    "from six.moves import urllib\n",
    "import csv\n",
    "import os\n",
    "from itertools import product\n",
    "\n",
    "\n",
    "model_num = 0\n",
    "with open(\"model_result_UNet.csv\",\"w\") as csvfile: \n",
    "    writer = csv.writer(csvfile)\n",
    "    writer.writerow([\"index\",\"input_horizontal\",\"input_vertical\",\"step\",\"Execution time\",\"Throughout\"])\n",
    "\n",
    "path = \"./xmodel_UNet\" #文件夹目录\n",
    "files= os.listdir(path) #得到文件夹下的所有文件名称\n",
    "\n",
    "\n",
    "input_shape_range =range(96,512,32)\n",
    "step_range =range(1,11,1)            \n",
    "for shape_x,step in product(input_shape_range,step_range):\n",
    "    shape_y = shape_x\n",
    "    file = \"UNet_{input_x}_{input_y}_{step}.xmodel\".format(input_x=shape_x,input_y=shape_y,step=step)\n",
    "    if file in files: #遍历文件夹\n",
    "        model_name = str(file)\n",
    "        if not os.path.isdir(file): #判断是否是文件夹，不是文件夹才打开\n",
    "            #Prepare the overlay\n",
    "            overlay = DpuOverlay(\"dpu.bit\")\n",
    "            overlay.load_model(\"./xmodel_UNet/{}\".format(file))\n",
    "\n",
    "            opener = urllib.request.build_opener()\n",
    "            opener.addheaders = [('User-agent', 'Mozilla/5.0')]\n",
    "            urllib.request.install_opener(opener)\n",
    "\n",
    "            #load test data\n",
    "\n",
    "            test_data = np.random.randint(0,255,size=[250,shape_x,shape_y,1])\n",
    "            test_label = np.random.randint(0,255,size=[250,shape_x,shape_y,1])\n",
    "            test_data = test_data.astype('float32')\n",
    "            test_data /= 255.0\n",
    "            \n",
    "            print(\"Total number of test images: {}\".format(test_data.shape[0]))\n",
    "            print(\"  Dimension of each picture: {}x{}\".format(test_data.shape[1],\n",
    "                                                              test_data.shape[2]))\n",
    "\n",
    "            #use VART \n",
    "            dpu = overlay.runner\n",
    "\n",
    "            inputTensors = dpu.get_input_tensors()\n",
    "            outputTensors = dpu.get_output_tensors()\n",
    "\n",
    "            shapeIn = tuple(inputTensors[0].dims)\n",
    "            shapeOut = tuple(outputTensors[0].dims)\n",
    "            outputSize = int(outputTensors[0].get_data_size() / shapeIn[0])\n",
    "\n",
    "            softmax = np.empty(outputSize)\n",
    "\n",
    "            output_data = [np.empty(shapeOut, dtype=np.float32, order=\"C\")]\n",
    "            input_data = [np.empty(shapeIn, dtype=np.float32, order=\"C\")]\n",
    "            image = input_data[0]\n",
    "\n",
    "            def calculate_softmax(data):\n",
    "                result = np.exp(data)\n",
    "                return result\n",
    "\n",
    "\n",
    "            #Run DPU to make predictions\n",
    "\n",
    "            total = test_data.shape[0]\n",
    "            predictions = np.empty_like(test_label)\n",
    "            print(\"Classifying {} digit pictures ...\".format(total))\n",
    "\n",
    "            start = time()\n",
    "            for i in range(total):\n",
    "                image[0,...] = test_data[i]\n",
    "                job_id = dpu.execute_async(input_data, output_data)\n",
    "                dpu.wait(job_id)\n",
    "                temp = [j.reshape(1, outputSize) for j in output_data]\n",
    "                softmax = calculate_softmax(temp[0][0])\n",
    "                predictions[i] = softmax.argmax()\n",
    "\n",
    "            stop = time()\n",
    "            correct = np.sum(predictions==test_label)\n",
    "            execution_time = (stop-start)*4\n",
    "            print(\"Overall accuracy: {}\".format(correct/total))\n",
    "            print(\"  Execution time/per picture: {:.4f}ms\".format(execution_time))\n",
    "            print(\"      Throughput: {:.4f}FPS\".format(total/execution_time))\n",
    "\n",
    "#             lo_Conv2D_kernel = model_name.find(\"Conv2D_kernel\")\n",
    "#             lo_Conv2D_size = model_name.find(\"Conv2D_size\")\n",
    "#             lo_MaxPooling_size = model_name.find(\"MaxPooling_size\")\n",
    "#             lo_Dense_size = model_name.find(\"Dense_size\")\n",
    "#             lo_end = model_name.find(\".xmodel\")\n",
    "            with open(\"model_result_UNet.csv\",\"a+\") as csvfile: \n",
    "                writer = csv.writer(csvfile)\n",
    "                writer.writerows([[model_num,shape_x,shape_y,step,execution_time,total/execution_time],])\n",
    "                model_num += 1\n",
    "\n",
    "\n",
    "            #clean up \n",
    "            del overlay\n",
    "            del dpu"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
