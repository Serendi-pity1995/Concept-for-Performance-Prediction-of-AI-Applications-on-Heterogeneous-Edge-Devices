{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cd3a7989",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"fcn_segment\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input (InputLayer)              [(None, 1024, 1024,  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv_1 (Conv2D)                 (None, 1024, 1024, 2 260         input[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "max_pool_1 (MaxPooling2D)       (None, 512, 512, 26) 0           conv_1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv_2 (Conv2D)                 (None, 512, 512, 42) 9870        max_pool_1[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "max_pool_2 (MaxPooling2D)       (None, 256, 256, 42) 0           conv_2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv_3 (Conv2D)                 (None, 256, 256, 66) 25014       max_pool_2[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "max_pool_3 (MaxPooling2D)       (None, 128, 128, 66) 0           conv_3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv_4 (Conv2D)                 (None, 128, 128, 168 99960       max_pool_3[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "max_pool_4 (MaxPooling2D)       (None, 64, 64, 168)  0           conv_4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv_5 (Conv2D)                 (None, 64, 64, 442)  668746      max_pool_4[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "max_pool_5 (MaxPooling2D)       (None, 32, 32, 442)  0           conv_5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "upsamping_6 (Conv2DTranspose)   (None, 64, 64, 168)  668472      max_pool_5[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_27 (Add)                    (None, 64, 64, 168)  0           max_pool_4[0][0]                 \n",
      "                                                                 upsamping_6[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "upsamping_7 (UpSampling2D)      (None, 1024, 1024, 1 0           add_27[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv_7 (Conv2D)                 (None, 1024, 1024, 1 1513        upsamping_7[0][0]                \n",
      "==================================================================================================\n",
      "Total params: 1,473,835\n",
      "Trainable params: 1,473,835\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "[VAI INFO] Update custom_layer_type: []\n",
      "[VAI INFO] Update activation_bit: 8\n",
      "[VAI INFO] Update weight_bit: 8\n",
      "[VAI INFO] Start CrossLayerEqualization...\n",
      "10/10 [==============================] - 1s 115ms/step\n",
      "[VAI INFO] CrossLayerEqualization Done.\n",
      "[VAI INFO] Start Quantize Calibration...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-30 08:02:12.779428: W tensorflow/core/framework/cpu_allocator_impl.cc:80] Allocation of 4932501504 exceeds 10% of free system memory.\n",
      "2022-04-30 08:02:13.471125: W tensorflow/core/framework/cpu_allocator_impl.cc:80] Allocation of 4932501504 exceeds 10% of free system memory.\n",
      "2022-04-30 08:02:13.471174: W tensorflow/core/framework/cpu_allocator_impl.cc:80] Allocation of 4932501504 exceeds 10% of free system memory.\n",
      "2022-04-30 08:02:13.471195: W tensorflow/core/framework/cpu_allocator_impl.cc:80] Allocation of 4932501504 exceeds 10% of free system memory.\n",
      "2022-04-30 08:02:13.471231: W tensorflow/core/framework/cpu_allocator_impl.cc:80] Allocation of 4932501504 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 33s 33s/step\n",
      "[VAI INFO] Quantize Calibration Done.\n",
      "[VAI INFO] Start Post-Quantize Adjustment...\n",
      "[VAI INFO] Post-Quantize Adjustment Done.\n",
      "[VAI INFO] Quantization Finished.\n",
      "**************************************************\n",
      "* VITIS_AI Compilation - Xilinx Inc.\n",
      "**************************************************\n",
      "[INFO] Namespace(batchsize=1, inputs_shape=None, layout='NHWC', model_files=['./quantized.h5'], model_type='tensorflow2', named_inputs_shape=None, out_filename='/tmp/deploy_org.xmodel', proto=None)\n",
      "[INFO] tensorflow2 model: /workspace/DPU-PYNQ/host/quantized.h5\n",
      "[INFO] keras version: 2.6.0\n",
      "[INFO] Tensorflow Keras model type: functional\n",
      "[INFO] parse raw model     :100%|█| 22/22 [00:00<00:00, 23702.72it/s]           \n",
      "[INFO] infer shape (NHWC)  :100%|█| 37/37 [00:00<00:00, 72.45it/s]              \n",
      "[INFO] perform level-0 opt :100%|█| 2/2 [00:00<00:00, 469.95it/s]               \n",
      "[INFO] perform level-1 opt :100%|█| 2/2 [00:00<00:00, 1699.13it/s]              \n",
      "[INFO] infer shape (NHWC)  :100%|█| 39/39 [00:00<00:00, 75.15it/s]              \n",
      "[INFO] generate xmodel     :100%|█| 39/39 [00:00<00:00, 3311.69it/s]            \n",
      "[INFO] dump xmodel: /tmp/deploy_org.xmodel\n",
      "[UNILOG][INFO] Compile mode: dpu\n",
      "[UNILOG][INFO] Debug mode: function\n",
      "[UNILOG][INFO] Target architecture: DPUCZDX8G_ISA0_B2304_MAX_BG2\n",
      "[UNILOG][INFO] Graph name: fcn_segment, with op num: 67\n",
      "[UNILOG][INFO] Begin to compile...\n",
      "\u001b[0;33m[UNILOG][WARNING] xir::Op{name = quant_conv_7_sigmoid_sigmoid(MergeMultoHsigmoid), type = hard-sigmoid-fix} has been assigned to CPU: [This target does not support single hard-sigmoid.].\n",
      "\u001b[m^C\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './xmodel_FCN/deploy.xmodel' -> './xmodel_FCN/FCN_1024_1024_1.xmodel'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_1636/1978282588.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     87\u001b[0m         \u001b[0mquantized_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'quantized.h5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m         \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'vai_c_tensorflow2                          --model ./quantized.h5                          --arch ./arch.json                          --output_dir ./xmodel_FCN                          --net_name deploy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m         \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrename\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"./xmodel_FCN/deploy.xmodel\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"./xmodel_FCN/FCN_{input_x}_{input_y}_{step}.xmodel\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_x\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshape_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_y\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshape_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     90\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './xmodel_FCN/deploy.xmodel' -> './xmodel_FCN/FCN_1024_1024_1.xmodel'"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "import keras \n",
    "from keras.layers import Input, Conv2D,GlobalAveragePooling2D, Dense, BatchNormalization, Activation, MaxPooling2D\n",
    "from keras.models import Model\n",
    "from keras.layers import DepthwiseConv2D\n",
    "\n",
    "from tensorflow_model_optimization.quantization.keras import vitis_quantize\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "shape_range =range(1024,2048,168)\n",
    "for shape_x in shape_range:\n",
    "    shape_y = shape_x\n",
    "    project_name = \"fcn_segment\"\n",
    "\n",
    "    channels = 1\n",
    "    std_shape = (shape_x, shape_y, channels) # 输入尺寸, std_shape[0]: img_rows, std_shape[1]: img_cols\n",
    "                                     # 这个尺寸按你的图像来, 如果你的图大小不一, 那 img_rows 和 image_cols\n",
    "                                     # 都要设置成 None, 如果你在用 Generator 加载数据时有扩展边缘, 那 std_shape\n",
    "                                     # 就是扩展后的尺寸\n",
    "\n",
    "    img_input = keras.layers.Input(shape = std_shape, name = \"input\")\n",
    "    \n",
    "    filter1_num = random.randrange(16,32,2)\n",
    "    conv_1 = keras.layers.Conv2D(filter1_num, kernel_size = (3, 3), activation = \"relu\",\n",
    "                                 padding = \"same\", name = \"conv_1\")(img_input)\n",
    "    max_pool_1 = keras.layers.MaxPool2D(pool_size = (2, 2), strides = (2, 2),\n",
    "                                        name = \"max_pool_1\")(conv_1)\n",
    "\n",
    "    filter2_num = random.randrange(filter1_num,64,2)\n",
    "    conv_2 = keras.layers.Conv2D(filter2_num, kernel_size = (3, 3), activation = \"relu\",\n",
    "                                 padding = \"same\", name = \"conv_2\")(max_pool_1)\n",
    "    max_pool_2 = keras.layers.MaxPool2D(pool_size = (2, 2), strides = (2, 2),\n",
    "                                        name = \"max_pool_2\")(conv_2)\n",
    "\n",
    "    filter3_num = random.randrange(filter2_num,128,2)\n",
    "    conv_3 = keras.layers.Conv2D(filter3_num, kernel_size = (3, 3), activation = \"relu\",\n",
    "                                 padding = \"same\", name = \"conv_3\")(max_pool_2)\n",
    "    max_pool_3 = keras.layers.MaxPool2D(pool_size = (2, 2), strides = (2, 2),\n",
    "                                        name = \"max_pool_3\")(conv_3)\n",
    "\n",
    "    filter4_num = random.randrange(filter3_num,256,2)\n",
    "    conv_4 = keras.layers.Conv2D(filter4_num , kernel_size = (3, 3), activation = \"relu\",\n",
    "                                 padding = \"same\", name = \"conv_4\")(max_pool_3)\n",
    "    max_pool_4 = keras.layers.MaxPool2D(pool_size = (2, 2), strides = (2, 2),\n",
    "                                        name = \"max_pool_4\")(conv_4)\n",
    "\n",
    "    filter5_num = random.randrange(filter4_num,512,2)\n",
    "    conv_5 = keras.layers.Conv2D(filter5_num, kernel_size = (3, 3), activation = \"relu\",\n",
    "                                 padding = \"same\", name = \"conv_5\")(max_pool_4)\n",
    "    max_pool_5 = keras.layers.MaxPool2D(pool_size = (2, 2), strides = (2, 2),\n",
    "                                        name = \"max_pool_5\")(conv_5)\n",
    "    # max_pool_5 转置卷积上采样 2 倍至 max_pool_4 一样大\n",
    "    up6 = keras.layers.Conv2DTranspose(filter4_num , kernel_size = (3, 3),\n",
    "                                       strides = (2, 2),\n",
    "                                       padding = \"same\",\n",
    "                                       kernel_initializer = \"he_normal\",\n",
    "                                       name = \"upsamping_6\")(max_pool_5)\n",
    "\n",
    "    _16s = keras.layers.add([max_pool_4, up6])\n",
    "\n",
    "    # _16s 上采样 16 倍后与输入尺寸相同\n",
    "    up7 = keras.layers.UpSampling2D(size = (16, 16), interpolation = \"nearest\",\n",
    "                                    name = \"upsamping_7\")(_16s)\n",
    "\n",
    "    # 这里 kernel 也是 3 * 3, 也可以同 FCN-32s 那样修改的\n",
    "    conv_7 = keras.layers.Conv2D(1, kernel_size = (3, 3), activation = \"sigmoid\",\n",
    "                                 padding = \"same\", name = \"conv_7\")(up7)\n",
    "    X_train=np.random.randint(0,255,size=[60,shape_x,shape_y,1])\n",
    "    Y_train=np.random.randint(0,10,size=[60,])\n",
    "    X_test=np.random.randint(0,255,size=[60,shape_x,shape_y,1])\n",
    "    Y_test=np.random.randint(0,10,size=[60,])\n",
    "    X_train = X_train.astype('float32')\n",
    "    X_test = X_test.astype('float32')\n",
    "    X_train /= 255.0\n",
    "    X_test /= 255.0\n",
    "    for step in range(1,6):\n",
    "        model = keras.Model(img_input, conv_7, name = project_name)\n",
    "        model.summary()\n",
    "        model.save('./FCN_h5/FCN_{input_x}_{input_y}_{step}.h5'.format(input_x=shape_x,input_y=shape_y,step=step))\n",
    "        quantizer = vitis_quantize.VitisQuantizer(model)\n",
    "        quantized_model = quantizer.quantize_model(calib_dataset = X_test[1:8], weight_bit=8, activation_bit=8)\n",
    "        quantized_model.save('quantized.h5')\n",
    "        !vai_c_tensorflow2 \\\n",
    "                        --model ./quantized.h5 \\\n",
    "                        --arch ./arch.json \\\n",
    "                        --output_dir ./xmodel_FCN \\\n",
    "                        --net_name deploy\n",
    "        os.rename(\"./xmodel_FCN/deploy.xmodel\",\"./xmodel_FCN/FCN_{input_x}_{input_y}_{step}.xmodel\".format(input_x=shape_x, input_y=shape_y, step=step))\n",
    " \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2d4345d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
