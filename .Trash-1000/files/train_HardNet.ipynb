{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a570623",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from .layers import pyramid_pooling, bottleneck\n",
    "\n",
    "\n",
    "def pyramid_pooling(input_tensor, sub_region_sizes):\n",
    "    \"\"\"This class implements the Pyramid Pooling Module\n",
    "    WARNING: This function uses eager execution, so it only works with\n",
    "        Tensorflow 2.0 backend.\n",
    "    Args:\n",
    "        input_tensor: Tensor with shape: (batch, rows, cols, channels)\n",
    "        sub_region_sizes: A list containing the size of each region for the\n",
    "            sub-region average pooling. The default value is [1, 2, 3, 6]\n",
    "    Returns:\n",
    "        output_tensor: Tensor with shape: (batch, rows, cols, channels * 2)\n",
    "    \"\"\"\n",
    "    _, input_height, input_width, input_channels = input_tensor.shape\n",
    "    feature_maps = [input_tensor]\n",
    "    for i in sub_region_sizes:\n",
    "        curr_feature_map = keras.layers.AveragePooling2D(\n",
    "            pool_size=(input_height // i, input_width // i),\n",
    "            strides=(input_height // i, input_width // i))(input_tensor)\n",
    "        curr_feature_map = keras.layers.Conv2D(\n",
    "            filters=int(input_channels) // len(sub_region_sizes),\n",
    "            kernel_size=3,\n",
    "            padding='same')(curr_feature_map)\n",
    "        curr_feature_map = keras.layers.Lambda(\n",
    "            lambda x: tf.image.resize(\n",
    "                x, (input_height, input_width)))(curr_feature_map)\n",
    "        feature_maps.append(curr_feature_map)\n",
    "\n",
    "    output_tensor = keras.layers.Concatenate(axis=-1)(feature_maps)\n",
    "\n",
    "    output_tensor = keras.layers.Conv2D(\n",
    "        filters=128, kernel_size=3, strides=1, padding=\"same\")(\n",
    "        output_tensor)\n",
    "    output_tensor = keras.layers.BatchNormalization()(output_tensor)\n",
    "    output_tensor = keras.layers.Activation(\"relu\")(output_tensor)\n",
    "    return output_tensor\n",
    "\n",
    "\n",
    "def bottleneck(input_tensor, filters, strides, expansion_factor):\n",
    "    \"\"\"Implementing Bottleneck.\n",
    "    This class implements the bottleneck module for Fast-SCNN.\n",
    "    Layer structure:\n",
    "        ----------------------------------------------------------------\n",
    "        |  Input shape   |  Block  |  Kernel | Stride |  Output shape  |\n",
    "        |                |         |   size  |        |                |\n",
    "        |----------------|---------|---------|--------|----------------|\n",
    "        |   h * w * c    |  Conv2D |    1    |    1   |   h * w * tc   |\n",
    "        |----------------|---------|---------|--------|----------------|\n",
    "        |   h * w * tc   |  DWConv |    3    |    s   | h/s * w/s * tc |\n",
    "        |----------------|---------|---------|--------|----------------|\n",
    "        | h/s * w/s * tc |  Conv2D |    1    |    1   | h/s * w/s * c` |\n",
    "        |--------------------------------------------------------------|\n",
    "        Designations:\n",
    "            h: input height\n",
    "            w: input width\n",
    "            c: number of input channels\n",
    "            t: expansion factor\n",
    "            c`: number of output channels\n",
    "            DWConv: depthwise convolution\n",
    "    Args:\n",
    "        input_tensor: Tensor with shape: (batch, rows, cols, channels)\n",
    "        filters: Output filters\n",
    "        strides: Stride used in depthwise convolution layer\n",
    "        expansion_factor: hyperparameter\n",
    "    Returns:\n",
    "        output_tensor: Tensor with shape: (batch, rows // stride,\n",
    "            cols // stride, new_channels)\n",
    "    \"\"\"\n",
    "    _, input_height, input_width, input_channels = input_tensor.shape\n",
    "    tensor = keras.layers.Conv2D(\n",
    "        filters=input_channels * expansion_factor,\n",
    "        kernel_size=1,\n",
    "        strides=1,\n",
    "        padding=\"same\",\n",
    "        activation=\"relu\")(input_tensor)\n",
    "    tensor = keras.layers.BatchNormalization()(tensor)\n",
    "    tensor = keras.layers.Activation('relu')(tensor)\n",
    "\n",
    "    tensor = keras.layers.DepthwiseConv2D(kernel_size=3,\n",
    "                                          strides=strides,\n",
    "                                          padding=\"same\")(tensor)\n",
    "    tensor = keras.layers.BatchNormalization()(tensor)\n",
    "    tensor = keras.layers.Activation('relu')(tensor)\n",
    "\n",
    "    tensor = keras.layers.Conv2D(filters=filters,\n",
    "                                 kernel_size=1,\n",
    "                                 strides=1,\n",
    "                                 padding=\"same\")(tensor)\n",
    "    tensor = keras.layers.BatchNormalization()(tensor)\n",
    "    output_tensor = keras.layers.Activation('relu')(tensor)\n",
    "    return output_tensor\n",
    "def create_fast_scnn(num_classes, input_shape=[None, None, 3],\n",
    "                     sub_region_sizes=[1, 2, 3, 6], expansion_factor=6):\n",
    "    \"\"\"This function creates a Fast-SCNN neural network model using\n",
    "    the Keras functional API.\n",
    "    Args:\n",
    "        num_classes: Number of classes\n",
    "        input_shape: A list containing information about the size of the image.\n",
    "            List structure: (rows, cols, channels). Dimensions can also be\n",
    "            None if they can be of any size.\n",
    "        expansion_factor: Hyperparameter in the bottleneck layer\n",
    "        sub_region_sizes: A list containing the sizes of subregions for\n",
    "            average pool by region in the pyramidal pool module\n",
    "    Returns:\n",
    "        model: uncompiled Keras model\n",
    "    \"\"\"\n",
    "\n",
    "    # Sub-models for every Fast-SCNN block\n",
    "\n",
    "    input_tensor = keras.layers.Input(input_shape)\n",
    "\n",
    "    learning_to_down_sample = keras.layers.Conv2D(\n",
    "        32, 3, 2, padding=\"same\")(input_tensor)\n",
    "    learning_to_down_sample = keras.layers.BatchNormalization()(\n",
    "        learning_to_down_sample)\n",
    "    learning_to_down_sample = keras.layers.Activation(\"relu\")(\n",
    "        learning_to_down_sample)\n",
    "\n",
    "    learning_to_down_sample = keras.layers.SeparableConv2D(\n",
    "        48, 3, 2, padding=\"same\")(learning_to_down_sample)\n",
    "    learning_to_down_sample = keras.layers.BatchNormalization()(\n",
    "        learning_to_down_sample)\n",
    "    learning_to_down_sample = keras.layers.Activation(\"relu\")(\n",
    "        learning_to_down_sample)\n",
    "\n",
    "    learning_to_down_sample = keras.layers.SeparableConv2D(\n",
    "        64, 3, 2, padding=\"same\")(learning_to_down_sample)\n",
    "    learning_to_down_sample = keras.layers.BatchNormalization()(\n",
    "        learning_to_down_sample)\n",
    "    learning_to_down_sample = keras.layers.Activation(\"relu\")(\n",
    "        learning_to_down_sample)\n",
    "\n",
    "    skip_connection = learning_to_down_sample\n",
    "\n",
    "    # Global feature extractor\n",
    "\n",
    "    global_feature_extractor = bottleneck(learning_to_down_sample,\n",
    "                                          64, 2, expansion_factor)\n",
    "    global_feature_extractor = bottleneck(global_feature_extractor,\n",
    "                                          64, 1, expansion_factor)\n",
    "    global_feature_extractor = bottleneck(global_feature_extractor,\n",
    "                                          64, 1, expansion_factor)\n",
    "\n",
    "    global_feature_extractor = bottleneck(global_feature_extractor,\n",
    "                                          96, 2, expansion_factor)\n",
    "    global_feature_extractor = bottleneck(global_feature_extractor,\n",
    "                                          96, 1, expansion_factor)\n",
    "    global_feature_extractor = bottleneck(global_feature_extractor,\n",
    "                                          96, 1, expansion_factor)\n",
    "\n",
    "    global_feature_extractor = bottleneck(global_feature_extractor,\n",
    "                                          128, 1, expansion_factor)\n",
    "    global_feature_extractor = bottleneck(global_feature_extractor,\n",
    "                                          128, 1, expansion_factor)\n",
    "    global_feature_extractor = bottleneck(global_feature_extractor,\n",
    "                                          128, 1, expansion_factor)\n",
    "    global_feature_extractor = pyramid_pooling(global_feature_extractor,\n",
    "                                               sub_region_sizes)\n",
    "\n",
    "    # Feature fusion\n",
    "\n",
    "    feature_fusion_main_branch = keras.layers.UpSampling2D((4, 4))(\n",
    "        global_feature_extractor)\n",
    "\n",
    "    feature_fusion_main_branch = keras.layers.DepthwiseConv2D(\n",
    "        3, padding=\"same\")(feature_fusion_main_branch)\n",
    "    feature_fusion_main_branch = keras.layers.BatchNormalization()(\n",
    "        feature_fusion_main_branch)\n",
    "    feature_fusion_main_branch = keras.layers.Activation(\"relu\")(\n",
    "        feature_fusion_main_branch)\n",
    "    feature_fusion_main_branch = keras.layers.Conv2D(\n",
    "        128, 1, 1, padding=\"same\")(feature_fusion_main_branch)\n",
    "    feature_fusion_main_branch = keras.layers.BatchNormalization()(\n",
    "        feature_fusion_main_branch)\n",
    "\n",
    "    feature_fusion_skip_connection = keras.layers.Conv2D(\n",
    "        128, 1, 1, padding=\"same\")(skip_connection)\n",
    "    feature_fusion_skip_connection = keras.layers.BatchNormalization()(\n",
    "        feature_fusion_skip_connection)\n",
    "\n",
    "    feature_fusion = feature_fusion_main_branch + feature_fusion_skip_connection\n",
    "\n",
    "    # Classifier\n",
    "\n",
    "    classifier = keras.layers.SeparableConv2D(128, 3, 1, padding=\"same\")(\n",
    "        feature_fusion)\n",
    "    classifier = keras.layers.BatchNormalization()(classifier)\n",
    "    classifier = keras.layers.Activation(\"relu\")(classifier)\n",
    "\n",
    "    classifier = keras.layers.SeparableConv2D(128, 3, 1, padding=\"same\")(\n",
    "        classifier)\n",
    "    classifier = keras.layers.BatchNormalization()(classifier)\n",
    "    classifier = keras.layers.Activation(\"relu\")(classifier)\n",
    "\n",
    "    classifier = keras.layers.Conv2D(num_classes, 3, 1, padding=\"same\")(\n",
    "        classifier)\n",
    "    classifier = keras.layers.BatchNormalization()(classifier)\n",
    "    classifier = keras.layers.Activation(\"relu\")(classifier)\n",
    "\n",
    "    output_tensor = keras.layers.UpSampling2D((8, 8))(classifier)\n",
    "    output_tensor = keras.layers.Softmax()(output_tensor)\n",
    "\n",
    "    model = keras.models.Model(input_tensor, output_tensor)\n",
    "    return model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
