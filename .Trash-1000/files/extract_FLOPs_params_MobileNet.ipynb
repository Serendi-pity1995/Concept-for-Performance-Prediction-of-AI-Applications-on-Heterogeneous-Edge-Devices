{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "56337522",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-02 06:40:50.498355: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/xilinx/xrt/lib:/usr/lib:/usr/lib/x86_64-linux-gnu:/usr/local/lib:/opt/vitis_ai/conda/envs/vitis-ai-tensorflow/lib\n",
      "2022-04-02 06:40:50.498387: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2022-04-02 06:40:51.525501: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/xilinx/xrt/lib:/usr/lib:/usr/lib/x86_64-linux-gnu:/usr/local/lib:/opt/vitis_ai/conda/envs/vitis-ai-tensorflow/lib\n",
      "2022-04-02 06:40:51.525532: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2022-04-02 06:40:51.525547: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:163] no NVIDIA GPU device is present: /dev/nvidia0 does not exist\n",
      "2022-04-02 06:40:51.525743: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 192, 192, 1)]     0         \n",
      "_________________________________________________________________\n",
      "conv2d (Conv2D)              (None, 96, 96, 32)        320       \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 96, 96, 32)        128       \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 96, 96, 32)        0         \n",
      "_________________________________________________________________\n",
      "depthwise_conv2d (DepthwiseC (None, 96, 96, 32)        320       \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 96, 96, 32)        128       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 96, 96, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 96, 96, 64)        2112      \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 96, 96, 64)        256       \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 96, 96, 64)        0         \n",
      "_________________________________________________________________\n",
      "depthwise_conv2d_1 (Depthwis (None, 48, 48, 64)        640       \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 48, 48, 64)        256       \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 48, 48, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 48, 48, 128)       8320      \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 48, 48, 128)       512       \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 48, 48, 128)       0         \n",
      "_________________________________________________________________\n",
      "depthwise_conv2d_2 (Depthwis (None, 48, 48, 128)       1280      \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 48, 48, 128)       512       \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 48, 48, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 48, 48, 128)       16512     \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 48, 48, 128)       512       \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 48, 48, 128)       0         \n",
      "_________________________________________________________________\n",
      "depthwise_conv2d_3 (Depthwis (None, 24, 24, 128)       1280      \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (None, 24, 24, 128)       512       \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 24, 24, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 24, 24, 256)       33024     \n",
      "_________________________________________________________________\n",
      "batch_normalization_8 (Batch (None, 24, 24, 256)       1024      \n",
      "_________________________________________________________________\n",
      "activation_8 (Activation)    (None, 24, 24, 256)       0         \n",
      "_________________________________________________________________\n",
      "depthwise_conv2d_4 (Depthwis (None, 24, 24, 256)       2560      \n",
      "_________________________________________________________________\n",
      "batch_normalization_9 (Batch (None, 24, 24, 256)       1024      \n",
      "_________________________________________________________________\n",
      "activation_9 (Activation)    (None, 24, 24, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 24, 24, 256)       65792     \n",
      "_________________________________________________________________\n",
      "batch_normalization_10 (Batc (None, 24, 24, 256)       1024      \n",
      "_________________________________________________________________\n",
      "activation_10 (Activation)   (None, 24, 24, 256)       0         \n",
      "_________________________________________________________________\n",
      "depthwise_conv2d_5 (Depthwis (None, 12, 12, 256)       2560      \n",
      "_________________________________________________________________\n",
      "batch_normalization_11 (Batc (None, 12, 12, 256)       1024      \n",
      "_________________________________________________________________\n",
      "activation_11 (Activation)   (None, 12, 12, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 12, 12, 512)       131584    \n",
      "_________________________________________________________________\n",
      "batch_normalization_12 (Batc (None, 12, 12, 512)       2048      \n",
      "_________________________________________________________________\n",
      "activation_12 (Activation)   (None, 12, 12, 512)       0         \n",
      "_________________________________________________________________\n",
      "depthwise_conv2d_6 (Depthwis (None, 12, 12, 512)       5120      \n",
      "_________________________________________________________________\n",
      "batch_normalization_13 (Batc (None, 12, 12, 512)       2048      \n",
      "_________________________________________________________________\n",
      "activation_13 (Activation)   (None, 12, 12, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 12, 12, 512)       262656    \n",
      "_________________________________________________________________\n",
      "batch_normalization_14 (Batc (None, 12, 12, 512)       2048      \n",
      "_________________________________________________________________\n",
      "activation_14 (Activation)   (None, 12, 12, 512)       0         \n",
      "_________________________________________________________________\n",
      "depthwise_conv2d_7 (Depthwis (None, 12, 12, 512)       5120      \n",
      "_________________________________________________________________\n",
      "batch_normalization_15 (Batc (None, 12, 12, 512)       2048      \n",
      "_________________________________________________________________\n",
      "activation_15 (Activation)   (None, 12, 12, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 12, 12, 512)       262656    \n",
      "_________________________________________________________________\n",
      "batch_normalization_16 (Batc (None, 12, 12, 512)       2048      \n",
      "_________________________________________________________________\n",
      "activation_16 (Activation)   (None, 12, 12, 512)       0         \n",
      "_________________________________________________________________\n",
      "depthwise_conv2d_8 (Depthwis (None, 12, 12, 512)       5120      \n",
      "_________________________________________________________________\n",
      "batch_normalization_17 (Batc (None, 12, 12, 512)       2048      \n",
      "_________________________________________________________________\n",
      "activation_17 (Activation)   (None, 12, 12, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 12, 12, 512)       262656    \n",
      "_________________________________________________________________\n",
      "batch_normalization_18 (Batc (None, 12, 12, 512)       2048      \n",
      "_________________________________________________________________\n",
      "activation_18 (Activation)   (None, 12, 12, 512)       0         \n",
      "_________________________________________________________________\n",
      "depthwise_conv2d_9 (Depthwis (None, 12, 12, 512)       5120      \n",
      "_________________________________________________________________\n",
      "batch_normalization_19 (Batc (None, 12, 12, 512)       2048      \n",
      "_________________________________________________________________\n",
      "activation_19 (Activation)   (None, 12, 12, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_10 (Conv2D)           (None, 12, 12, 512)       262656    \n",
      "_________________________________________________________________\n",
      "batch_normalization_20 (Batc (None, 12, 12, 512)       2048      \n",
      "_________________________________________________________________\n",
      "activation_20 (Activation)   (None, 12, 12, 512)       0         \n",
      "_________________________________________________________________\n",
      "depthwise_conv2d_10 (Depthwi (None, 12, 12, 512)       5120      \n",
      "_________________________________________________________________\n",
      "batch_normalization_21 (Batc (None, 12, 12, 512)       2048      \n",
      "_________________________________________________________________\n",
      "activation_21 (Activation)   (None, 12, 12, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_11 (Conv2D)           (None, 12, 12, 512)       262656    \n",
      "_________________________________________________________________\n",
      "batch_normalization_22 (Batc (None, 12, 12, 512)       2048      \n",
      "_________________________________________________________________\n",
      "activation_22 (Activation)   (None, 12, 12, 512)       0         \n",
      "_________________________________________________________________\n",
      "depthwise_conv2d_11 (Depthwi (None, 6, 6, 512)         5120      \n",
      "_________________________________________________________________\n",
      "batch_normalization_23 (Batc (None, 6, 6, 512)         2048      \n",
      "_________________________________________________________________\n",
      "activation_23 (Activation)   (None, 6, 6, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_12 (Conv2D)           (None, 6, 6, 1024)        525312    \n",
      "_________________________________________________________________\n",
      "batch_normalization_24 (Batc (None, 6, 6, 1024)        4096      \n",
      "_________________________________________________________________\n",
      "activation_24 (Activation)   (None, 6, 6, 1024)        0         \n",
      "_________________________________________________________________\n",
      "depthwise_conv2d_12 (Depthwi (None, 6, 6, 1024)        10240     \n",
      "_________________________________________________________________\n",
      "batch_normalization_25 (Batc (None, 6, 6, 1024)        4096      \n",
      "_________________________________________________________________\n",
      "activation_25 (Activation)   (None, 6, 6, 1024)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_13 (Conv2D)           (None, 6, 6, 1024)        1049600   \n",
      "_________________________________________________________________\n",
      "batch_normalization_26 (Batc (None, 6, 6, 1024)        4096      \n",
      "_________________________________________________________________\n",
      "activation_26 (Activation)   (None, 6, 6, 1024)        0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d (Gl (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 10)                10250     \n",
      "=================================================================\n",
      "Total params: 3,249,482\n",
      "Trainable params: 3,227,594\n",
      "Non-trainable params: 21,888\n",
      "_________________________________________________________________\n",
      "44.462124\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-02 06:40:52.436740: I tensorflow/core/grappler/devices.cc:66] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0\n",
      "2022-04-02 06:40:52.436885: I tensorflow/core/grappler/clusters/single_machine.cc:357] Starting new session\n",
      "2022-04-02 06:40:52.457871: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:1137] Optimization results for grappler item: graph_to_optimize\n",
      "  function_optimizer: function_optimizer did nothing. time = 0.008ms.\n",
      "  function_optimizer: function_optimizer did nothing. time = 0.001ms.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /opt/vitis_ai/conda/envs/vitis-ai-tensorflow2/lib/python3.7/site-packages/tensorflow/python/ops/nn_ops.py:5063: tensor_shape_from_node_def_name (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.compat.v1.graph_util.tensor_shape_from_node_def_name`\n",
      "\n",
      "=========================Options=============================\n",
      "-max_depth                  10000\n",
      "-min_bytes                  0\n",
      "-min_peak_bytes             0\n",
      "-min_residual_bytes         0\n",
      "-min_output_bytes           0\n",
      "-min_micros                 0\n",
      "-min_accelerator_micros     0\n",
      "-min_cpu_micros             0\n",
      "-min_params                 0\n",
      "-min_float_ops              1\n",
      "-min_occurrence             0\n",
      "-step                       -1\n",
      "-order_by                   float_ops\n",
      "-account_type_regexes       .*\n",
      "-start_name_regexes         .*\n",
      "-trim_name_regexes          \n",
      "-show_name_regexes          .*\n",
      "-hide_name_regexes          \n",
      "-account_displayed_op_only  true\n",
      "-select                     float_ops\n",
      "-output                     stdout:\n",
      "\n",
      "==================Model Analysis Report======================\n",
      "\n",
      "Doc:\n",
      "scope: The nodes in the model graph are organized by their names, which is hierarchical like filesystem.\n",
      "flops: Number of float operations. Note: Please read the implementation for the math behind it.\n",
      "\n",
      "Profile:\n",
      "node name | # float_ops\n",
      "_TFProfRoot (--/834.82m flops)\n",
      "  model/conv2d_10/Conv2D (75.50m/75.50m flops)\n",
      "  model/conv2d_11/Conv2D (75.50m/75.50m flops)\n",
      "  model/conv2d_13/Conv2D (75.50m/75.50m flops)\n",
      "  model/conv2d_3/Conv2D (75.50m/75.50m flops)\n",
      "  model/conv2d_5/Conv2D (75.50m/75.50m flops)\n",
      "  model/conv2d_7/Conv2D (75.50m/75.50m flops)\n",
      "  model/conv2d_8/Conv2D (75.50m/75.50m flops)\n",
      "  model/conv2d_9/Conv2D (75.50m/75.50m flops)\n",
      "  model/conv2d_1/Conv2D (37.75m/37.75m flops)\n",
      "  model/conv2d_12/Conv2D (37.75m/37.75m flops)\n",
      "  model/conv2d_2/Conv2D (37.75m/37.75m flops)\n",
      "  model/conv2d_4/Conv2D (37.75m/37.75m flops)\n",
      "  model/conv2d_6/Conv2D (37.75m/37.75m flops)\n",
      "  model/depthwise_conv2d_2/depthwise (5.31m/5.31m flops)\n",
      "  model/depthwise_conv2d/depthwise (5.31m/5.31m flops)\n",
      "  model/conv2d/Conv2D (5.31m/5.31m flops)\n",
      "  model/depthwise_conv2d_1/depthwise (2.65m/2.65m flops)\n",
      "  model/depthwise_conv2d_4/depthwise (2.65m/2.65m flops)\n",
      "  model/depthwise_conv2d_10/depthwise (1.33m/1.33m flops)\n",
      "  model/depthwise_conv2d_3/depthwise (1.33m/1.33m flops)\n",
      "  model/depthwise_conv2d_9/depthwise (1.33m/1.33m flops)\n",
      "  model/depthwise_conv2d_6/depthwise (1.33m/1.33m flops)\n",
      "  model/depthwise_conv2d_7/depthwise (1.33m/1.33m flops)\n",
      "  model/depthwise_conv2d_8/depthwise (1.33m/1.33m flops)\n",
      "  model/batch_normalization_2/FusedBatchNormV3 (1.18m/1.18m flops)\n",
      "  model/depthwise_conv2d_12/depthwise (663.55k/663.55k flops)\n",
      "  model/depthwise_conv2d_5/depthwise (663.55k/663.55k flops)\n",
      "  model/batch_normalization_5/FusedBatchNormV3 (590.59k/590.59k flops)\n",
      "  model/batch_normalization_6/FusedBatchNormV3 (590.59k/590.59k flops)\n",
      "  model/batch_normalization_4/FusedBatchNormV3 (590.59k/590.59k flops)\n",
      "  model/batch_normalization_1/FusedBatchNormV3 (590.02k/590.02k flops)\n",
      "  model/batch_normalization/FusedBatchNormV3 (590.02k/590.02k flops)\n",
      "  model/conv2d_1/BiasAdd (589.82k/589.82k flops)\n",
      "  model/depthwise_conv2d_11/depthwise (331.78k/331.78k flops)\n",
      "  model/batch_normalization_10/FusedBatchNormV3 (296.45k/296.45k flops)\n",
      "  model/batch_normalization_9/FusedBatchNormV3 (296.45k/296.45k flops)\n",
      "  model/batch_normalization_8/FusedBatchNormV3 (296.45k/296.45k flops)\n",
      "  model/batch_normalization_3/FusedBatchNormV3 (295.30k/295.30k flops)\n",
      "  model/depthwise_conv2d/BiasAdd (294.91k/294.91k flops)\n",
      "  model/depthwise_conv2d_2/BiasAdd (294.91k/294.91k flops)\n",
      "  model/conv2d_3/BiasAdd (294.91k/294.91k flops)\n",
      "  model/conv2d_2/BiasAdd (294.91k/294.91k flops)\n",
      "  model/conv2d/BiasAdd (294.91k/294.91k flops)\n",
      "  model/batch_normalization_18/FusedBatchNormV3 (150.53k/150.53k flops)\n",
      "  model/batch_normalization_12/FusedBatchNormV3 (150.53k/150.53k flops)\n",
      "  model/batch_normalization_13/FusedBatchNormV3 (150.53k/150.53k flops)\n",
      "  model/batch_normalization_14/FusedBatchNormV3 (150.53k/150.53k flops)\n",
      "  model/batch_normalization_15/FusedBatchNormV3 (150.53k/150.53k flops)\n",
      "  model/batch_normalization_16/FusedBatchNormV3 (150.53k/150.53k flops)\n",
      "  model/batch_normalization_17/FusedBatchNormV3 (150.53k/150.53k flops)\n",
      "  model/batch_normalization_19/FusedBatchNormV3 (150.53k/150.53k flops)\n",
      "  model/batch_normalization_20/FusedBatchNormV3 (150.53k/150.53k flops)\n",
      "  model/batch_normalization_21/FusedBatchNormV3 (150.53k/150.53k flops)\n",
      "  model/batch_normalization_22/FusedBatchNormV3 (150.53k/150.53k flops)\n",
      "  model/batch_normalization_7/FusedBatchNormV3 (148.22k/148.22k flops)\n",
      "  model/conv2d_4/BiasAdd (147.46k/147.46k flops)\n",
      "  model/conv2d_5/BiasAdd (147.46k/147.46k flops)\n",
      "  model/depthwise_conv2d_4/BiasAdd (147.46k/147.46k flops)\n",
      "  model/depthwise_conv2d_1/BiasAdd (147.46k/147.46k flops)\n",
      "  model/batch_normalization_24/FusedBatchNormV3 (79.87k/79.87k flops)\n",
      "  model/batch_normalization_26/FusedBatchNormV3 (79.87k/79.87k flops)\n",
      "  model/batch_normalization_25/FusedBatchNormV3 (79.87k/79.87k flops)\n",
      "  model/batch_normalization_11/FusedBatchNormV3 (75.26k/75.26k flops)\n",
      "  model/depthwise_conv2d_10/BiasAdd (73.73k/73.73k flops)\n",
      "  model/conv2d_11/BiasAdd (73.73k/73.73k flops)\n",
      "  model/depthwise_conv2d_9/BiasAdd (73.73k/73.73k flops)\n",
      "  model/depthwise_conv2d_8/BiasAdd (73.73k/73.73k flops)\n",
      "  model/conv2d_7/BiasAdd (73.73k/73.73k flops)\n",
      "  model/conv2d_9/BiasAdd (73.73k/73.73k flops)\n",
      "  model/depthwise_conv2d_3/BiasAdd (73.73k/73.73k flops)\n",
      "  model/conv2d_6/BiasAdd (73.73k/73.73k flops)\n",
      "  model/conv2d_8/BiasAdd (73.73k/73.73k flops)\n",
      "  model/conv2d_10/BiasAdd (73.73k/73.73k flops)\n",
      "  model/depthwise_conv2d_7/BiasAdd (73.73k/73.73k flops)\n",
      "  model/depthwise_conv2d_6/BiasAdd (73.73k/73.73k flops)\n",
      "  model/batch_normalization_23/FusedBatchNormV3 (39.94k/39.94k flops)\n",
      "  model/depthwise_conv2d_5/BiasAdd (36.86k/36.86k flops)\n",
      "  model/conv2d_12/BiasAdd (36.86k/36.86k flops)\n",
      "  model/depthwise_conv2d_12/BiasAdd (36.86k/36.86k flops)\n",
      "  model/conv2d_13/BiasAdd (36.86k/36.86k flops)\n",
      "  model/global_average_pooling2d/Mean (36.86k/36.86k flops)\n",
      "  model/dense/MatMul (20.48k/20.48k flops)\n",
      "  model/depthwise_conv2d_11/BiasAdd (18.43k/18.43k flops)\n",
      "  model/dense/Softmax (50/50 flops)\n",
      "  model/dense/BiasAdd (10/10 flops)\n",
      "\n",
      "======================End of Report==========================\n",
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         [(None, 224, 224, 1)]     0         \n",
      "_________________________________________________________________\n",
      "conv2d_14 (Conv2D)           (None, 112, 112, 32)      320       \n",
      "_________________________________________________________________\n",
      "batch_normalization_27 (Batc (None, 112, 112, 32)      128       \n",
      "_________________________________________________________________\n",
      "activation_27 (Activation)   (None, 112, 112, 32)      0         \n",
      "_________________________________________________________________\n",
      "depthwise_conv2d_13 (Depthwi (None, 112, 112, 32)      320       \n",
      "_________________________________________________________________\n",
      "batch_normalization_28 (Batc (None, 112, 112, 32)      128       \n",
      "_________________________________________________________________\n",
      "activation_28 (Activation)   (None, 112, 112, 32)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_15 (Conv2D)           (None, 112, 112, 64)      2112      \n",
      "_________________________________________________________________\n",
      "batch_normalization_29 (Batc (None, 112, 112, 64)      256       \n",
      "_________________________________________________________________\n",
      "activation_29 (Activation)   (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "depthwise_conv2d_14 (Depthwi (None, 56, 56, 64)        640       \n",
      "_________________________________________________________________\n",
      "batch_normalization_30 (Batc (None, 56, 56, 64)        256       \n",
      "_________________________________________________________________\n",
      "activation_30 (Activation)   (None, 56, 56, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_16 (Conv2D)           (None, 56, 56, 128)       8320      \n",
      "_________________________________________________________________\n",
      "batch_normalization_31 (Batc (None, 56, 56, 128)       512       \n",
      "_________________________________________________________________\n",
      "activation_31 (Activation)   (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "depthwise_conv2d_15 (Depthwi (None, 56, 56, 128)       1280      \n",
      "_________________________________________________________________\n",
      "batch_normalization_32 (Batc (None, 56, 56, 128)       512       \n",
      "_________________________________________________________________\n",
      "activation_32 (Activation)   (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_17 (Conv2D)           (None, 56, 56, 128)       16512     \n",
      "_________________________________________________________________\n",
      "batch_normalization_33 (Batc (None, 56, 56, 128)       512       \n",
      "_________________________________________________________________\n",
      "activation_33 (Activation)   (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "depthwise_conv2d_16 (Depthwi (None, 28, 28, 128)       1280      \n",
      "_________________________________________________________________\n",
      "batch_normalization_34 (Batc (None, 28, 28, 128)       512       \n",
      "_________________________________________________________________\n",
      "activation_34 (Activation)   (None, 28, 28, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_18 (Conv2D)           (None, 28, 28, 256)       33024     \n",
      "_________________________________________________________________\n",
      "batch_normalization_35 (Batc (None, 28, 28, 256)       1024      \n",
      "_________________________________________________________________\n",
      "activation_35 (Activation)   (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "depthwise_conv2d_17 (Depthwi (None, 28, 28, 256)       2560      \n",
      "_________________________________________________________________\n",
      "batch_normalization_36 (Batc (None, 28, 28, 256)       1024      \n",
      "_________________________________________________________________\n",
      "activation_36 (Activation)   (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_19 (Conv2D)           (None, 28, 28, 256)       65792     \n",
      "_________________________________________________________________\n",
      "batch_normalization_37 (Batc (None, 28, 28, 256)       1024      \n",
      "_________________________________________________________________\n",
      "activation_37 (Activation)   (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "depthwise_conv2d_18 (Depthwi (None, 14, 14, 256)       2560      \n",
      "_________________________________________________________________\n",
      "batch_normalization_38 (Batc (None, 14, 14, 256)       1024      \n",
      "_________________________________________________________________\n",
      "activation_38 (Activation)   (None, 14, 14, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_20 (Conv2D)           (None, 14, 14, 512)       131584    \n",
      "_________________________________________________________________\n",
      "batch_normalization_39 (Batc (None, 14, 14, 512)       2048      \n",
      "_________________________________________________________________\n",
      "activation_39 (Activation)   (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "depthwise_conv2d_19 (Depthwi (None, 14, 14, 512)       5120      \n",
      "_________________________________________________________________\n",
      "batch_normalization_40 (Batc (None, 14, 14, 512)       2048      \n",
      "_________________________________________________________________\n",
      "activation_40 (Activation)   (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_21 (Conv2D)           (None, 14, 14, 512)       262656    \n",
      "_________________________________________________________________\n",
      "batch_normalization_41 (Batc (None, 14, 14, 512)       2048      \n",
      "_________________________________________________________________\n",
      "activation_41 (Activation)   (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "depthwise_conv2d_20 (Depthwi (None, 14, 14, 512)       5120      \n",
      "_________________________________________________________________\n",
      "batch_normalization_42 (Batc (None, 14, 14, 512)       2048      \n",
      "_________________________________________________________________\n",
      "activation_42 (Activation)   (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_22 (Conv2D)           (None, 14, 14, 512)       262656    \n",
      "_________________________________________________________________\n",
      "batch_normalization_43 (Batc (None, 14, 14, 512)       2048      \n",
      "_________________________________________________________________\n",
      "activation_43 (Activation)   (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "depthwise_conv2d_21 (Depthwi (None, 14, 14, 512)       5120      \n",
      "_________________________________________________________________\n",
      "batch_normalization_44 (Batc (None, 14, 14, 512)       2048      \n",
      "_________________________________________________________________\n",
      "activation_44 (Activation)   (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_23 (Conv2D)           (None, 14, 14, 512)       262656    \n",
      "_________________________________________________________________\n",
      "batch_normalization_45 (Batc (None, 14, 14, 512)       2048      \n",
      "_________________________________________________________________\n",
      "activation_45 (Activation)   (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "depthwise_conv2d_22 (Depthwi (None, 14, 14, 512)       5120      \n",
      "_________________________________________________________________\n",
      "batch_normalization_46 (Batc (None, 14, 14, 512)       2048      \n",
      "_________________________________________________________________\n",
      "activation_46 (Activation)   (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_24 (Conv2D)           (None, 14, 14, 512)       262656    \n",
      "_________________________________________________________________\n",
      "batch_normalization_47 (Batc (None, 14, 14, 512)       2048      \n",
      "_________________________________________________________________\n",
      "activation_47 (Activation)   (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "depthwise_conv2d_23 (Depthwi (None, 14, 14, 512)       5120      \n",
      "_________________________________________________________________\n",
      "batch_normalization_48 (Batc (None, 14, 14, 512)       2048      \n",
      "_________________________________________________________________\n",
      "activation_48 (Activation)   (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_25 (Conv2D)           (None, 14, 14, 512)       262656    \n",
      "_________________________________________________________________\n",
      "batch_normalization_49 (Batc (None, 14, 14, 512)       2048      \n",
      "_________________________________________________________________\n",
      "activation_49 (Activation)   (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "depthwise_conv2d_24 (Depthwi (None, 7, 7, 512)         5120      \n",
      "_________________________________________________________________\n",
      "batch_normalization_50 (Batc (None, 7, 7, 512)         2048      \n",
      "_________________________________________________________________\n",
      "activation_50 (Activation)   (None, 7, 7, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_26 (Conv2D)           (None, 7, 7, 1024)        525312    \n",
      "_________________________________________________________________\n",
      "batch_normalization_51 (Batc (None, 7, 7, 1024)        4096      \n",
      "_________________________________________________________________\n",
      "activation_51 (Activation)   (None, 7, 7, 1024)        0         \n",
      "_________________________________________________________________\n",
      "depthwise_conv2d_25 (Depthwi (None, 7, 7, 1024)        10240     \n",
      "_________________________________________________________________\n",
      "batch_normalization_52 (Batc (None, 7, 7, 1024)        4096      \n",
      "_________________________________________________________________\n",
      "activation_52 (Activation)   (None, 7, 7, 1024)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_27 (Conv2D)           (None, 7, 7, 1024)        1049600   \n",
      "_________________________________________________________________\n",
      "batch_normalization_53 (Batc (None, 7, 7, 1024)        4096      \n",
      "_________________________________________________________________\n",
      "activation_53 (Activation)   (None, 7, 7, 1024)        0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_1 ( (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                10250     \n",
      "=================================================================\n",
      "Total params: 3,249,482\n",
      "Trainable params: 3,227,594\n",
      "Non-trainable params: 21,888\n",
      "_________________________________________________________________\n",
      "60.516396\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-02 06:40:53.412153: I tensorflow/core/grappler/devices.cc:66] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0\n",
      "2022-04-02 06:40:53.412267: I tensorflow/core/grappler/clusters/single_machine.cc:357] Starting new session\n",
      "2022-04-02 06:40:53.416386: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:1137] Optimization results for grappler item: graph_to_optimize\n",
      "  function_optimizer: function_optimizer did nothing. time = 0.005ms.\n",
      "  function_optimizer: function_optimizer did nothing. time = 0.001ms.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=========================Options=============================\n",
      "-max_depth                  10000\n",
      "-min_bytes                  0\n",
      "-min_peak_bytes             0\n",
      "-min_residual_bytes         0\n",
      "-min_output_bytes           0\n",
      "-min_micros                 0\n",
      "-min_accelerator_micros     0\n",
      "-min_cpu_micros             0\n",
      "-min_params                 0\n",
      "-min_float_ops              1\n",
      "-min_occurrence             0\n",
      "-step                       -1\n",
      "-order_by                   float_ops\n",
      "-account_type_regexes       .*\n",
      "-start_name_regexes         .*\n",
      "-trim_name_regexes          \n",
      "-show_name_regexes          .*\n",
      "-hide_name_regexes          \n",
      "-account_displayed_op_only  true\n",
      "-select                     float_ops\n",
      "-output                     stdout:\n",
      "\n",
      "==================Model Analysis Report======================\n",
      "\n",
      "Doc:\n",
      "scope: The nodes in the model graph are organized by their names, which is hierarchical like filesystem.\n",
      "flops: Number of float operations. Note: Please read the implementation for the math behind it.\n",
      "\n",
      "Profile:\n",
      "node name | # float_ops\n",
      "_TFProfRoot (--/1.14b flops)\n",
      "  model_1/conv2d_27/Conv2D (102.76m/102.76m flops)\n",
      "  model_1/conv2d_25/Conv2D (102.76m/102.76m flops)\n",
      "  model_1/conv2d_17/Conv2D (102.76m/102.76m flops)\n",
      "  model_1/conv2d_24/Conv2D (102.76m/102.76m flops)\n",
      "  model_1/conv2d_19/Conv2D (102.76m/102.76m flops)\n",
      "  model_1/conv2d_23/Conv2D (102.76m/102.76m flops)\n",
      "  model_1/conv2d_21/Conv2D (102.76m/102.76m flops)\n",
      "  model_1/conv2d_22/Conv2D (102.76m/102.76m flops)\n",
      "  model_1/conv2d_15/Conv2D (51.38m/51.38m flops)\n",
      "  model_1/conv2d_26/Conv2D (51.38m/51.38m flops)\n",
      "  model_1/conv2d_20/Conv2D (51.38m/51.38m flops)\n",
      "  model_1/conv2d_18/Conv2D (51.38m/51.38m flops)\n",
      "  model_1/conv2d_16/Conv2D (51.38m/51.38m flops)\n",
      "  model_1/conv2d_14/Conv2D (7.23m/7.23m flops)\n",
      "  model_1/depthwise_conv2d_15/depthwise (7.23m/7.23m flops)\n",
      "  model_1/depthwise_conv2d_13/depthwise (7.23m/7.23m flops)\n",
      "  model_1/depthwise_conv2d_14/depthwise (3.61m/3.61m flops)\n",
      "  model_1/depthwise_conv2d_17/depthwise (3.61m/3.61m flops)\n",
      "  model_1/depthwise_conv2d_16/depthwise (1.81m/1.81m flops)\n",
      "  model_1/depthwise_conv2d_19/depthwise (1.81m/1.81m flops)\n",
      "  model_1/depthwise_conv2d_20/depthwise (1.81m/1.81m flops)\n",
      "  model_1/depthwise_conv2d_21/depthwise (1.81m/1.81m flops)\n",
      "  model_1/depthwise_conv2d_22/depthwise (1.81m/1.81m flops)\n",
      "  model_1/depthwise_conv2d_23/depthwise (1.81m/1.81m flops)\n",
      "  model_1/batch_normalization_29/FusedBatchNormV3 (1.61m/1.61m flops)\n",
      "  model_1/depthwise_conv2d_18/depthwise (903.17k/903.17k flops)\n",
      "  model_1/depthwise_conv2d_25/depthwise (903.17k/903.17k flops)\n",
      "  model_1/batch_normalization_33/FusedBatchNormV3 (803.58k/803.58k flops)\n",
      "  model_1/batch_normalization_32/FusedBatchNormV3 (803.58k/803.58k flops)\n",
      "  model_1/batch_normalization_31/FusedBatchNormV3 (803.58k/803.58k flops)\n",
      "  model_1/batch_normalization_28/FusedBatchNormV3 (803.01k/803.01k flops)\n",
      "  model_1/batch_normalization_27/FusedBatchNormV3 (803.01k/803.01k flops)\n",
      "  model_1/conv2d_15/BiasAdd (802.82k/802.82k flops)\n",
      "  model_1/depthwise_conv2d_24/depthwise (451.58k/451.58k flops)\n",
      "  model_1/batch_normalization_35/FusedBatchNormV3 (402.94k/402.94k flops)\n",
      "  model_1/batch_normalization_36/FusedBatchNormV3 (402.94k/402.94k flops)\n",
      "  model_1/batch_normalization_37/FusedBatchNormV3 (402.94k/402.94k flops)\n",
      "  model_1/batch_normalization_30/FusedBatchNormV3 (401.79k/401.79k flops)\n",
      "  model_1/depthwise_conv2d_13/BiasAdd (401.41k/401.41k flops)\n",
      "  model_1/depthwise_conv2d_15/BiasAdd (401.41k/401.41k flops)\n",
      "  model_1/conv2d_16/BiasAdd (401.41k/401.41k flops)\n",
      "  model_1/conv2d_14/BiasAdd (401.41k/401.41k flops)\n",
      "  model_1/conv2d_17/BiasAdd (401.41k/401.41k flops)\n",
      "  model_1/batch_normalization_42/FusedBatchNormV3 (203.78k/203.78k flops)\n",
      "  model_1/batch_normalization_43/FusedBatchNormV3 (203.78k/203.78k flops)\n",
      "  model_1/batch_normalization_41/FusedBatchNormV3 (203.78k/203.78k flops)\n",
      "  model_1/batch_normalization_40/FusedBatchNormV3 (203.78k/203.78k flops)\n",
      "  model_1/batch_normalization_44/FusedBatchNormV3 (203.78k/203.78k flops)\n",
      "  model_1/batch_normalization_45/FusedBatchNormV3 (203.78k/203.78k flops)\n",
      "  model_1/batch_normalization_46/FusedBatchNormV3 (203.78k/203.78k flops)\n",
      "  model_1/batch_normalization_47/FusedBatchNormV3 (203.78k/203.78k flops)\n",
      "  model_1/batch_normalization_39/FusedBatchNormV3 (203.78k/203.78k flops)\n",
      "  model_1/batch_normalization_48/FusedBatchNormV3 (203.78k/203.78k flops)\n",
      "  model_1/batch_normalization_49/FusedBatchNormV3 (203.78k/203.78k flops)\n",
      "  model_1/batch_normalization_34/FusedBatchNormV3 (201.47k/201.47k flops)\n",
      "  model_1/depthwise_conv2d_17/BiasAdd (200.70k/200.70k flops)\n",
      "  model_1/conv2d_18/BiasAdd (200.70k/200.70k flops)\n",
      "  model_1/conv2d_19/BiasAdd (200.70k/200.70k flops)\n",
      "  model_1/depthwise_conv2d_14/BiasAdd (200.70k/200.70k flops)\n",
      "  model_1/batch_normalization_52/FusedBatchNormV3 (106.50k/106.50k flops)\n",
      "  model_1/batch_normalization_53/FusedBatchNormV3 (106.50k/106.50k flops)\n",
      "  model_1/batch_normalization_51/FusedBatchNormV3 (106.50k/106.50k flops)\n",
      "  model_1/batch_normalization_38/FusedBatchNormV3 (101.89k/101.89k flops)\n",
      "  model_1/conv2d_20/BiasAdd (100.35k/100.35k flops)\n",
      "  model_1/depthwise_conv2d_16/BiasAdd (100.35k/100.35k flops)\n",
      "  model_1/depthwise_conv2d_23/BiasAdd (100.35k/100.35k flops)\n",
      "  model_1/conv2d_25/BiasAdd (100.35k/100.35k flops)\n",
      "  model_1/conv2d_24/BiasAdd (100.35k/100.35k flops)\n",
      "  model_1/depthwise_conv2d_22/BiasAdd (100.35k/100.35k flops)\n",
      "  model_1/depthwise_conv2d_19/BiasAdd (100.35k/100.35k flops)\n",
      "  model_1/conv2d_23/BiasAdd (100.35k/100.35k flops)\n",
      "  model_1/depthwise_conv2d_20/BiasAdd (100.35k/100.35k flops)\n",
      "  model_1/conv2d_22/BiasAdd (100.35k/100.35k flops)\n",
      "  model_1/depthwise_conv2d_21/BiasAdd (100.35k/100.35k flops)\n",
      "  model_1/conv2d_21/BiasAdd (100.35k/100.35k flops)\n",
      "  model_1/batch_normalization_50/FusedBatchNormV3 (53.25k/53.25k flops)\n",
      "  model_1/depthwise_conv2d_18/BiasAdd (50.18k/50.18k flops)\n",
      "  model_1/conv2d_27/BiasAdd (50.18k/50.18k flops)\n",
      "  model_1/depthwise_conv2d_25/BiasAdd (50.18k/50.18k flops)\n",
      "  model_1/conv2d_26/BiasAdd (50.18k/50.18k flops)\n",
      "  model_1/global_average_pooling2d_1/Mean (50.18k/50.18k flops)\n",
      "  model_1/depthwise_conv2d_24/BiasAdd (25.09k/25.09k flops)\n",
      "  model_1/dense_1/MatMul (20.48k/20.48k flops)\n",
      "  model_1/dense_1/Softmax (50/50 flops)\n",
      "  model_1/dense_1/BiasAdd (10/10 flops)\n",
      "\n",
      "======================End of Report==========================\n",
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_3 (InputLayer)         [(None, 256, 256, 1)]     0         \n",
      "_________________________________________________________________\n",
      "conv2d_28 (Conv2D)           (None, 128, 128, 32)      320       \n",
      "_________________________________________________________________\n",
      "batch_normalization_54 (Batc (None, 128, 128, 32)      128       \n",
      "_________________________________________________________________\n",
      "activation_54 (Activation)   (None, 128, 128, 32)      0         \n",
      "_________________________________________________________________\n",
      "depthwise_conv2d_26 (Depthwi (None, 128, 128, 32)      320       \n",
      "_________________________________________________________________\n",
      "batch_normalization_55 (Batc (None, 128, 128, 32)      128       \n",
      "_________________________________________________________________\n",
      "activation_55 (Activation)   (None, 128, 128, 32)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_29 (Conv2D)           (None, 128, 128, 64)      2112      \n",
      "_________________________________________________________________\n",
      "batch_normalization_56 (Batc (None, 128, 128, 64)      256       \n",
      "_________________________________________________________________\n",
      "activation_56 (Activation)   (None, 128, 128, 64)      0         \n",
      "_________________________________________________________________\n",
      "depthwise_conv2d_27 (Depthwi (None, 64, 64, 64)        640       \n",
      "_________________________________________________________________\n",
      "batch_normalization_57 (Batc (None, 64, 64, 64)        256       \n",
      "_________________________________________________________________\n",
      "activation_57 (Activation)   (None, 64, 64, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_30 (Conv2D)           (None, 64, 64, 128)       8320      \n",
      "_________________________________________________________________\n",
      "batch_normalization_58 (Batc (None, 64, 64, 128)       512       \n",
      "_________________________________________________________________\n",
      "activation_58 (Activation)   (None, 64, 64, 128)       0         \n",
      "_________________________________________________________________\n",
      "depthwise_conv2d_28 (Depthwi (None, 64, 64, 128)       1280      \n",
      "_________________________________________________________________\n",
      "batch_normalization_59 (Batc (None, 64, 64, 128)       512       \n",
      "_________________________________________________________________\n",
      "activation_59 (Activation)   (None, 64, 64, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_31 (Conv2D)           (None, 64, 64, 128)       16512     \n",
      "_________________________________________________________________\n",
      "batch_normalization_60 (Batc (None, 64, 64, 128)       512       \n",
      "_________________________________________________________________\n",
      "activation_60 (Activation)   (None, 64, 64, 128)       0         \n",
      "_________________________________________________________________\n",
      "depthwise_conv2d_29 (Depthwi (None, 32, 32, 128)       1280      \n",
      "_________________________________________________________________\n",
      "batch_normalization_61 (Batc (None, 32, 32, 128)       512       \n",
      "_________________________________________________________________\n",
      "activation_61 (Activation)   (None, 32, 32, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_32 (Conv2D)           (None, 32, 32, 256)       33024     \n",
      "_________________________________________________________________\n",
      "batch_normalization_62 (Batc (None, 32, 32, 256)       1024      \n",
      "_________________________________________________________________\n",
      "activation_62 (Activation)   (None, 32, 32, 256)       0         \n",
      "_________________________________________________________________\n",
      "depthwise_conv2d_30 (Depthwi (None, 32, 32, 256)       2560      \n",
      "_________________________________________________________________\n",
      "batch_normalization_63 (Batc (None, 32, 32, 256)       1024      \n",
      "_________________________________________________________________\n",
      "activation_63 (Activation)   (None, 32, 32, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_33 (Conv2D)           (None, 32, 32, 256)       65792     \n",
      "_________________________________________________________________\n",
      "batch_normalization_64 (Batc (None, 32, 32, 256)       1024      \n",
      "_________________________________________________________________\n",
      "activation_64 (Activation)   (None, 32, 32, 256)       0         \n",
      "_________________________________________________________________\n",
      "depthwise_conv2d_31 (Depthwi (None, 16, 16, 256)       2560      \n",
      "_________________________________________________________________\n",
      "batch_normalization_65 (Batc (None, 16, 16, 256)       1024      \n",
      "_________________________________________________________________\n",
      "activation_65 (Activation)   (None, 16, 16, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_34 (Conv2D)           (None, 16, 16, 512)       131584    \n",
      "_________________________________________________________________\n",
      "batch_normalization_66 (Batc (None, 16, 16, 512)       2048      \n",
      "_________________________________________________________________\n",
      "activation_66 (Activation)   (None, 16, 16, 512)       0         \n",
      "_________________________________________________________________\n",
      "depthwise_conv2d_32 (Depthwi (None, 16, 16, 512)       5120      \n",
      "_________________________________________________________________\n",
      "batch_normalization_67 (Batc (None, 16, 16, 512)       2048      \n",
      "_________________________________________________________________\n",
      "activation_67 (Activation)   (None, 16, 16, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_35 (Conv2D)           (None, 16, 16, 512)       262656    \n",
      "_________________________________________________________________\n",
      "batch_normalization_68 (Batc (None, 16, 16, 512)       2048      \n",
      "_________________________________________________________________\n",
      "activation_68 (Activation)   (None, 16, 16, 512)       0         \n",
      "_________________________________________________________________\n",
      "depthwise_conv2d_33 (Depthwi (None, 16, 16, 512)       5120      \n",
      "_________________________________________________________________\n",
      "batch_normalization_69 (Batc (None, 16, 16, 512)       2048      \n",
      "_________________________________________________________________\n",
      "activation_69 (Activation)   (None, 16, 16, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_36 (Conv2D)           (None, 16, 16, 512)       262656    \n",
      "_________________________________________________________________\n",
      "batch_normalization_70 (Batc (None, 16, 16, 512)       2048      \n",
      "_________________________________________________________________\n",
      "activation_70 (Activation)   (None, 16, 16, 512)       0         \n",
      "_________________________________________________________________\n",
      "depthwise_conv2d_34 (Depthwi (None, 16, 16, 512)       5120      \n",
      "_________________________________________________________________\n",
      "batch_normalization_71 (Batc (None, 16, 16, 512)       2048      \n",
      "_________________________________________________________________\n",
      "activation_71 (Activation)   (None, 16, 16, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_37 (Conv2D)           (None, 16, 16, 512)       262656    \n",
      "_________________________________________________________________\n",
      "batch_normalization_72 (Batc (None, 16, 16, 512)       2048      \n",
      "_________________________________________________________________\n",
      "activation_72 (Activation)   (None, 16, 16, 512)       0         \n",
      "_________________________________________________________________\n",
      "depthwise_conv2d_35 (Depthwi (None, 16, 16, 512)       5120      \n",
      "_________________________________________________________________\n",
      "batch_normalization_73 (Batc (None, 16, 16, 512)       2048      \n",
      "_________________________________________________________________\n",
      "activation_73 (Activation)   (None, 16, 16, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_38 (Conv2D)           (None, 16, 16, 512)       262656    \n",
      "_________________________________________________________________\n",
      "batch_normalization_74 (Batc (None, 16, 16, 512)       2048      \n",
      "_________________________________________________________________\n",
      "activation_74 (Activation)   (None, 16, 16, 512)       0         \n",
      "_________________________________________________________________\n",
      "depthwise_conv2d_36 (Depthwi (None, 16, 16, 512)       5120      \n",
      "_________________________________________________________________\n",
      "batch_normalization_75 (Batc (None, 16, 16, 512)       2048      \n",
      "_________________________________________________________________\n",
      "activation_75 (Activation)   (None, 16, 16, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_39 (Conv2D)           (None, 16, 16, 512)       262656    \n",
      "_________________________________________________________________\n",
      "batch_normalization_76 (Batc (None, 16, 16, 512)       2048      \n",
      "_________________________________________________________________\n",
      "activation_76 (Activation)   (None, 16, 16, 512)       0         \n",
      "_________________________________________________________________\n",
      "depthwise_conv2d_37 (Depthwi (None, 8, 8, 512)         5120      \n",
      "_________________________________________________________________\n",
      "batch_normalization_77 (Batc (None, 8, 8, 512)         2048      \n",
      "_________________________________________________________________\n",
      "activation_77 (Activation)   (None, 8, 8, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_40 (Conv2D)           (None, 8, 8, 1024)        525312    \n",
      "_________________________________________________________________\n",
      "batch_normalization_78 (Batc (None, 8, 8, 1024)        4096      \n",
      "_________________________________________________________________\n",
      "activation_78 (Activation)   (None, 8, 8, 1024)        0         \n",
      "_________________________________________________________________\n",
      "depthwise_conv2d_38 (Depthwi (None, 8, 8, 1024)        10240     \n",
      "_________________________________________________________________\n",
      "batch_normalization_79 (Batc (None, 8, 8, 1024)        4096      \n",
      "_________________________________________________________________\n",
      "activation_79 (Activation)   (None, 8, 8, 1024)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_41 (Conv2D)           (None, 8, 8, 1024)        1049600   \n",
      "_________________________________________________________________\n",
      "batch_normalization_80 (Batc (None, 8, 8, 1024)        4096      \n",
      "_________________________________________________________________\n",
      "activation_80 (Activation)   (None, 8, 8, 1024)        0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_2 ( (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                10250     \n",
      "=================================================================\n",
      "Total params: 3,249,482\n",
      "Trainable params: 3,227,594\n",
      "Non-trainable params: 21,888\n",
      "_________________________________________________________________\n",
      "79.040556\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-02 06:40:54.370488: I tensorflow/core/grappler/devices.cc:66] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0\n",
      "2022-04-02 06:40:54.370603: I tensorflow/core/grappler/clusters/single_machine.cc:357] Starting new session\n",
      "2022-04-02 06:40:54.374670: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:1137] Optimization results for grappler item: graph_to_optimize\n",
      "  function_optimizer: function_optimizer did nothing. time = 0.004ms.\n",
      "  function_optimizer: function_optimizer did nothing. time = 0.001ms.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=========================Options=============================\n",
      "-max_depth                  10000\n",
      "-min_bytes                  0\n",
      "-min_peak_bytes             0\n",
      "-min_residual_bytes         0\n",
      "-min_output_bytes           0\n",
      "-min_micros                 0\n",
      "-min_accelerator_micros     0\n",
      "-min_cpu_micros             0\n",
      "-min_params                 0\n",
      "-min_float_ops              1\n",
      "-min_occurrence             0\n",
      "-step                       -1\n",
      "-order_by                   float_ops\n",
      "-account_type_regexes       .*\n",
      "-start_name_regexes         .*\n",
      "-trim_name_regexes          \n",
      "-show_name_regexes          .*\n",
      "-hide_name_regexes          \n",
      "-account_displayed_op_only  true\n",
      "-select                     float_ops\n",
      "-output                     stdout:\n",
      "\n",
      "==================Model Analysis Report======================\n",
      "\n",
      "Doc:\n",
      "scope: The nodes in the model graph are organized by their names, which is hierarchical like filesystem.\n",
      "flops: Number of float operations. Note: Please read the implementation for the math behind it.\n",
      "\n",
      "Profile:\n",
      "node name | # float_ops\n",
      "_TFProfRoot (--/1.48b flops)\n",
      "  model_2/conv2d_41/Conv2D (134.22m/134.22m flops)\n",
      "  model_2/conv2d_39/Conv2D (134.22m/134.22m flops)\n",
      "  model_2/conv2d_31/Conv2D (134.22m/134.22m flops)\n",
      "  model_2/conv2d_38/Conv2D (134.22m/134.22m flops)\n",
      "  model_2/conv2d_33/Conv2D (134.22m/134.22m flops)\n",
      "  model_2/conv2d_37/Conv2D (134.22m/134.22m flops)\n",
      "  model_2/conv2d_35/Conv2D (134.22m/134.22m flops)\n",
      "  model_2/conv2d_36/Conv2D (134.22m/134.22m flops)\n",
      "  model_2/conv2d_29/Conv2D (67.11m/67.11m flops)\n",
      "  model_2/conv2d_40/Conv2D (67.11m/67.11m flops)\n",
      "  model_2/conv2d_34/Conv2D (67.11m/67.11m flops)\n",
      "  model_2/conv2d_32/Conv2D (67.11m/67.11m flops)\n",
      "  model_2/conv2d_30/Conv2D (67.11m/67.11m flops)\n",
      "  model_2/conv2d_28/Conv2D (9.44m/9.44m flops)\n",
      "  model_2/depthwise_conv2d_28/depthwise (9.44m/9.44m flops)\n",
      "  model_2/depthwise_conv2d_26/depthwise (9.44m/9.44m flops)\n",
      "  model_2/depthwise_conv2d_27/depthwise (4.72m/4.72m flops)\n",
      "  model_2/depthwise_conv2d_30/depthwise (4.72m/4.72m flops)\n",
      "  model_2/depthwise_conv2d_29/depthwise (2.36m/2.36m flops)\n",
      "  model_2/depthwise_conv2d_32/depthwise (2.36m/2.36m flops)\n",
      "  model_2/depthwise_conv2d_33/depthwise (2.36m/2.36m flops)\n",
      "  model_2/depthwise_conv2d_34/depthwise (2.36m/2.36m flops)\n",
      "  model_2/depthwise_conv2d_35/depthwise (2.36m/2.36m flops)\n",
      "  model_2/depthwise_conv2d_36/depthwise (2.36m/2.36m flops)\n",
      "  model_2/batch_normalization_56/FusedBatchNormV3 (2.10m/2.10m flops)\n",
      "  model_2/depthwise_conv2d_31/depthwise (1.18m/1.18m flops)\n",
      "  model_2/depthwise_conv2d_38/depthwise (1.18m/1.18m flops)\n",
      "  model_2/batch_normalization_60/FusedBatchNormV3 (1.05m/1.05m flops)\n",
      "  model_2/batch_normalization_59/FusedBatchNormV3 (1.05m/1.05m flops)\n",
      "  model_2/batch_normalization_58/FusedBatchNormV3 (1.05m/1.05m flops)\n",
      "  model_2/batch_normalization_55/FusedBatchNormV3 (1.05m/1.05m flops)\n",
      "  model_2/batch_normalization_54/FusedBatchNormV3 (1.05m/1.05m flops)\n",
      "  model_2/conv2d_29/BiasAdd (1.05m/1.05m flops)\n",
      "  model_2/depthwise_conv2d_37/depthwise (589.82k/589.82k flops)\n",
      "  model_2/batch_normalization_62/FusedBatchNormV3 (525.82k/525.82k flops)\n",
      "  model_2/batch_normalization_63/FusedBatchNormV3 (525.82k/525.82k flops)\n",
      "  model_2/batch_normalization_64/FusedBatchNormV3 (525.82k/525.82k flops)\n",
      "  model_2/batch_normalization_57/FusedBatchNormV3 (524.67k/524.67k flops)\n",
      "  model_2/depthwise_conv2d_26/BiasAdd (524.29k/524.29k flops)\n",
      "  model_2/depthwise_conv2d_28/BiasAdd (524.29k/524.29k flops)\n",
      "  model_2/conv2d_30/BiasAdd (524.29k/524.29k flops)\n",
      "  model_2/conv2d_28/BiasAdd (524.29k/524.29k flops)\n",
      "  model_2/conv2d_31/BiasAdd (524.29k/524.29k flops)\n",
      "  model_2/batch_normalization_69/FusedBatchNormV3 (265.22k/265.22k flops)\n",
      "  model_2/batch_normalization_70/FusedBatchNormV3 (265.22k/265.22k flops)\n",
      "  model_2/batch_normalization_68/FusedBatchNormV3 (265.22k/265.22k flops)\n",
      "  model_2/batch_normalization_67/FusedBatchNormV3 (265.22k/265.22k flops)\n",
      "  model_2/batch_normalization_71/FusedBatchNormV3 (265.22k/265.22k flops)\n",
      "  model_2/batch_normalization_72/FusedBatchNormV3 (265.22k/265.22k flops)\n",
      "  model_2/batch_normalization_73/FusedBatchNormV3 (265.22k/265.22k flops)\n",
      "  model_2/batch_normalization_74/FusedBatchNormV3 (265.22k/265.22k flops)\n",
      "  model_2/batch_normalization_66/FusedBatchNormV3 (265.22k/265.22k flops)\n",
      "  model_2/batch_normalization_75/FusedBatchNormV3 (265.22k/265.22k flops)\n",
      "  model_2/batch_normalization_76/FusedBatchNormV3 (265.22k/265.22k flops)\n",
      "  model_2/batch_normalization_61/FusedBatchNormV3 (262.91k/262.91k flops)\n",
      "  model_2/depthwise_conv2d_30/BiasAdd (262.14k/262.14k flops)\n",
      "  model_2/conv2d_32/BiasAdd (262.14k/262.14k flops)\n",
      "  model_2/conv2d_33/BiasAdd (262.14k/262.14k flops)\n",
      "  model_2/depthwise_conv2d_27/BiasAdd (262.14k/262.14k flops)\n",
      "  model_2/batch_normalization_79/FusedBatchNormV3 (137.22k/137.22k flops)\n",
      "  model_2/batch_normalization_80/FusedBatchNormV3 (137.22k/137.22k flops)\n",
      "  model_2/batch_normalization_78/FusedBatchNormV3 (137.22k/137.22k flops)\n",
      "  model_2/batch_normalization_65/FusedBatchNormV3 (132.61k/132.61k flops)\n",
      "  model_2/conv2d_34/BiasAdd (131.07k/131.07k flops)\n",
      "  model_2/depthwise_conv2d_29/BiasAdd (131.07k/131.07k flops)\n",
      "  model_2/depthwise_conv2d_36/BiasAdd (131.07k/131.07k flops)\n",
      "  model_2/conv2d_39/BiasAdd (131.07k/131.07k flops)\n",
      "  model_2/conv2d_38/BiasAdd (131.07k/131.07k flops)\n",
      "  model_2/depthwise_conv2d_35/BiasAdd (131.07k/131.07k flops)\n",
      "  model_2/depthwise_conv2d_32/BiasAdd (131.07k/131.07k flops)\n",
      "  model_2/conv2d_37/BiasAdd (131.07k/131.07k flops)\n",
      "  model_2/depthwise_conv2d_33/BiasAdd (131.07k/131.07k flops)\n",
      "  model_2/conv2d_36/BiasAdd (131.07k/131.07k flops)\n",
      "  model_2/depthwise_conv2d_34/BiasAdd (131.07k/131.07k flops)\n",
      "  model_2/conv2d_35/BiasAdd (131.07k/131.07k flops)\n",
      "  model_2/batch_normalization_77/FusedBatchNormV3 (68.61k/68.61k flops)\n",
      "  model_2/depthwise_conv2d_31/BiasAdd (65.54k/65.54k flops)\n",
      "  model_2/conv2d_41/BiasAdd (65.54k/65.54k flops)\n",
      "  model_2/depthwise_conv2d_38/BiasAdd (65.54k/65.54k flops)\n",
      "  model_2/conv2d_40/BiasAdd (65.54k/65.54k flops)\n",
      "  model_2/global_average_pooling2d_2/Mean (65.54k/65.54k flops)\n",
      "  model_2/depthwise_conv2d_37/BiasAdd (32.77k/32.77k flops)\n",
      "  model_2/dense_2/MatMul (20.48k/20.48k flops)\n",
      "  model_2/dense_2/Softmax (50/50 flops)\n",
      "  model_2/dense_2/BiasAdd (10/10 flops)\n",
      "\n",
      "======================End of Report==========================\n",
      "Model: \"model_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         [(None, 288, 288, 1)]     0         \n",
      "_________________________________________________________________\n",
      "conv2d_42 (Conv2D)           (None, 144, 144, 32)      320       \n",
      "_________________________________________________________________\n",
      "batch_normalization_81 (Batc (None, 144, 144, 32)      128       \n",
      "_________________________________________________________________\n",
      "activation_81 (Activation)   (None, 144, 144, 32)      0         \n",
      "_________________________________________________________________\n",
      "depthwise_conv2d_39 (Depthwi (None, 144, 144, 32)      320       \n",
      "_________________________________________________________________\n",
      "batch_normalization_82 (Batc (None, 144, 144, 32)      128       \n",
      "_________________________________________________________________\n",
      "activation_82 (Activation)   (None, 144, 144, 32)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_43 (Conv2D)           (None, 144, 144, 64)      2112      \n",
      "_________________________________________________________________\n",
      "batch_normalization_83 (Batc (None, 144, 144, 64)      256       \n",
      "_________________________________________________________________\n",
      "activation_83 (Activation)   (None, 144, 144, 64)      0         \n",
      "_________________________________________________________________\n",
      "depthwise_conv2d_40 (Depthwi (None, 72, 72, 64)        640       \n",
      "_________________________________________________________________\n",
      "batch_normalization_84 (Batc (None, 72, 72, 64)        256       \n",
      "_________________________________________________________________\n",
      "activation_84 (Activation)   (None, 72, 72, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_44 (Conv2D)           (None, 72, 72, 128)       8320      \n",
      "_________________________________________________________________\n",
      "batch_normalization_85 (Batc (None, 72, 72, 128)       512       \n",
      "_________________________________________________________________\n",
      "activation_85 (Activation)   (None, 72, 72, 128)       0         \n",
      "_________________________________________________________________\n",
      "depthwise_conv2d_41 (Depthwi (None, 72, 72, 128)       1280      \n",
      "_________________________________________________________________\n",
      "batch_normalization_86 (Batc (None, 72, 72, 128)       512       \n",
      "_________________________________________________________________\n",
      "activation_86 (Activation)   (None, 72, 72, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_45 (Conv2D)           (None, 72, 72, 128)       16512     \n",
      "_________________________________________________________________\n",
      "batch_normalization_87 (Batc (None, 72, 72, 128)       512       \n",
      "_________________________________________________________________\n",
      "activation_87 (Activation)   (None, 72, 72, 128)       0         \n",
      "_________________________________________________________________\n",
      "depthwise_conv2d_42 (Depthwi (None, 36, 36, 128)       1280      \n",
      "_________________________________________________________________\n",
      "batch_normalization_88 (Batc (None, 36, 36, 128)       512       \n",
      "_________________________________________________________________\n",
      "activation_88 (Activation)   (None, 36, 36, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_46 (Conv2D)           (None, 36, 36, 256)       33024     \n",
      "_________________________________________________________________\n",
      "batch_normalization_89 (Batc (None, 36, 36, 256)       1024      \n",
      "_________________________________________________________________\n",
      "activation_89 (Activation)   (None, 36, 36, 256)       0         \n",
      "_________________________________________________________________\n",
      "depthwise_conv2d_43 (Depthwi (None, 36, 36, 256)       2560      \n",
      "_________________________________________________________________\n",
      "batch_normalization_90 (Batc (None, 36, 36, 256)       1024      \n",
      "_________________________________________________________________\n",
      "activation_90 (Activation)   (None, 36, 36, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_47 (Conv2D)           (None, 36, 36, 256)       65792     \n",
      "_________________________________________________________________\n",
      "batch_normalization_91 (Batc (None, 36, 36, 256)       1024      \n",
      "_________________________________________________________________\n",
      "activation_91 (Activation)   (None, 36, 36, 256)       0         \n",
      "_________________________________________________________________\n",
      "depthwise_conv2d_44 (Depthwi (None, 18, 18, 256)       2560      \n",
      "_________________________________________________________________\n",
      "batch_normalization_92 (Batc (None, 18, 18, 256)       1024      \n",
      "_________________________________________________________________\n",
      "activation_92 (Activation)   (None, 18, 18, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_48 (Conv2D)           (None, 18, 18, 512)       131584    \n",
      "_________________________________________________________________\n",
      "batch_normalization_93 (Batc (None, 18, 18, 512)       2048      \n",
      "_________________________________________________________________\n",
      "activation_93 (Activation)   (None, 18, 18, 512)       0         \n",
      "_________________________________________________________________\n",
      "depthwise_conv2d_45 (Depthwi (None, 18, 18, 512)       5120      \n",
      "_________________________________________________________________\n",
      "batch_normalization_94 (Batc (None, 18, 18, 512)       2048      \n",
      "_________________________________________________________________\n",
      "activation_94 (Activation)   (None, 18, 18, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_49 (Conv2D)           (None, 18, 18, 512)       262656    \n",
      "_________________________________________________________________\n",
      "batch_normalization_95 (Batc (None, 18, 18, 512)       2048      \n",
      "_________________________________________________________________\n",
      "activation_95 (Activation)   (None, 18, 18, 512)       0         \n",
      "_________________________________________________________________\n",
      "depthwise_conv2d_46 (Depthwi (None, 18, 18, 512)       5120      \n",
      "_________________________________________________________________\n",
      "batch_normalization_96 (Batc (None, 18, 18, 512)       2048      \n",
      "_________________________________________________________________\n",
      "activation_96 (Activation)   (None, 18, 18, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_50 (Conv2D)           (None, 18, 18, 512)       262656    \n",
      "_________________________________________________________________\n",
      "batch_normalization_97 (Batc (None, 18, 18, 512)       2048      \n",
      "_________________________________________________________________\n",
      "activation_97 (Activation)   (None, 18, 18, 512)       0         \n",
      "_________________________________________________________________\n",
      "depthwise_conv2d_47 (Depthwi (None, 18, 18, 512)       5120      \n",
      "_________________________________________________________________\n",
      "batch_normalization_98 (Batc (None, 18, 18, 512)       2048      \n",
      "_________________________________________________________________\n",
      "activation_98 (Activation)   (None, 18, 18, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_51 (Conv2D)           (None, 18, 18, 512)       262656    \n",
      "_________________________________________________________________\n",
      "batch_normalization_99 (Batc (None, 18, 18, 512)       2048      \n",
      "_________________________________________________________________\n",
      "activation_99 (Activation)   (None, 18, 18, 512)       0         \n",
      "_________________________________________________________________\n",
      "depthwise_conv2d_48 (Depthwi (None, 18, 18, 512)       5120      \n",
      "_________________________________________________________________\n",
      "batch_normalization_100 (Bat (None, 18, 18, 512)       2048      \n",
      "_________________________________________________________________\n",
      "activation_100 (Activation)  (None, 18, 18, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_52 (Conv2D)           (None, 18, 18, 512)       262656    \n",
      "_________________________________________________________________\n",
      "batch_normalization_101 (Bat (None, 18, 18, 512)       2048      \n",
      "_________________________________________________________________\n",
      "activation_101 (Activation)  (None, 18, 18, 512)       0         \n",
      "_________________________________________________________________\n",
      "depthwise_conv2d_49 (Depthwi (None, 18, 18, 512)       5120      \n",
      "_________________________________________________________________\n",
      "batch_normalization_102 (Bat (None, 18, 18, 512)       2048      \n",
      "_________________________________________________________________\n",
      "activation_102 (Activation)  (None, 18, 18, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_53 (Conv2D)           (None, 18, 18, 512)       262656    \n",
      "_________________________________________________________________\n",
      "batch_normalization_103 (Bat (None, 18, 18, 512)       2048      \n",
      "_________________________________________________________________\n",
      "activation_103 (Activation)  (None, 18, 18, 512)       0         \n",
      "_________________________________________________________________\n",
      "depthwise_conv2d_50 (Depthwi (None, 9, 9, 512)         5120      \n",
      "_________________________________________________________________\n",
      "batch_normalization_104 (Bat (None, 9, 9, 512)         2048      \n",
      "_________________________________________________________________\n",
      "activation_104 (Activation)  (None, 9, 9, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_54 (Conv2D)           (None, 9, 9, 1024)        525312    \n",
      "_________________________________________________________________\n",
      "batch_normalization_105 (Bat (None, 9, 9, 1024)        4096      \n",
      "_________________________________________________________________\n",
      "activation_105 (Activation)  (None, 9, 9, 1024)        0         \n",
      "_________________________________________________________________\n",
      "depthwise_conv2d_51 (Depthwi (None, 9, 9, 1024)        10240     \n",
      "_________________________________________________________________\n",
      "batch_normalization_106 (Bat (None, 9, 9, 1024)        4096      \n",
      "_________________________________________________________________\n",
      "activation_106 (Activation)  (None, 9, 9, 1024)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_55 (Conv2D)           (None, 9, 9, 1024)        1049600   \n",
      "_________________________________________________________________\n",
      "batch_normalization_107 (Bat (None, 9, 9, 1024)        4096      \n",
      "_________________________________________________________________\n",
      "activation_107 (Activation)  (None, 9, 9, 1024)        0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_3 ( (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                10250     \n",
      "=================================================================\n",
      "Total params: 3,249,482\n",
      "Trainable params: 3,227,594\n",
      "Non-trainable params: 21,888\n",
      "_________________________________________________________________\n",
      "100.034604\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-02 06:40:55.297805: I tensorflow/core/grappler/devices.cc:66] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0\n",
      "2022-04-02 06:40:55.297871: I tensorflow/core/grappler/clusters/single_machine.cc:357] Starting new session\n",
      "2022-04-02 06:40:55.302084: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:1137] Optimization results for grappler item: graph_to_optimize\n",
      "  function_optimizer: function_optimizer did nothing. time = 0.006ms.\n",
      "  function_optimizer: function_optimizer did nothing. time = 0.001ms.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=========================Options=============================\n",
      "-max_depth                  10000\n",
      "-min_bytes                  0\n",
      "-min_peak_bytes             0\n",
      "-min_residual_bytes         0\n",
      "-min_output_bytes           0\n",
      "-min_micros                 0\n",
      "-min_accelerator_micros     0\n",
      "-min_cpu_micros             0\n",
      "-min_params                 0\n",
      "-min_float_ops              1\n",
      "-min_occurrence             0\n",
      "-step                       -1\n",
      "-order_by                   float_ops\n",
      "-account_type_regexes       .*\n",
      "-start_name_regexes         .*\n",
      "-trim_name_regexes          \n",
      "-show_name_regexes          .*\n",
      "-hide_name_regexes          \n",
      "-account_displayed_op_only  true\n",
      "-select                     float_ops\n",
      "-output                     stdout:\n",
      "\n",
      "==================Model Analysis Report======================\n",
      "\n",
      "Doc:\n",
      "scope: The nodes in the model graph are organized by their names, which is hierarchical like filesystem.\n",
      "flops: Number of float operations. Note: Please read the implementation for the math behind it.\n",
      "\n",
      "Profile:\n",
      "node name | # float_ops\n",
      "_TFProfRoot (--/1.88b flops)\n",
      "  model_3/conv2d_53/Conv2D (169.87m/169.87m flops)\n",
      "  model_3/conv2d_55/Conv2D (169.87m/169.87m flops)\n",
      "  model_3/conv2d_45/Conv2D (169.87m/169.87m flops)\n",
      "  model_3/conv2d_47/Conv2D (169.87m/169.87m flops)\n",
      "  model_3/conv2d_52/Conv2D (169.87m/169.87m flops)\n",
      "  model_3/conv2d_51/Conv2D (169.87m/169.87m flops)\n",
      "  model_3/conv2d_49/Conv2D (169.87m/169.87m flops)\n",
      "  model_3/conv2d_50/Conv2D (169.87m/169.87m flops)\n",
      "  model_3/conv2d_48/Conv2D (84.93m/84.93m flops)\n",
      "  model_3/conv2d_43/Conv2D (84.93m/84.93m flops)\n",
      "  model_3/conv2d_44/Conv2D (84.93m/84.93m flops)\n",
      "  model_3/conv2d_54/Conv2D (84.93m/84.93m flops)\n",
      "  model_3/conv2d_46/Conv2D (84.93m/84.93m flops)\n",
      "  model_3/depthwise_conv2d_41/depthwise (11.94m/11.94m flops)\n",
      "  model_3/conv2d_42/Conv2D (11.94m/11.94m flops)\n",
      "  model_3/depthwise_conv2d_39/depthwise (11.94m/11.94m flops)\n",
      "  model_3/depthwise_conv2d_43/depthwise (5.97m/5.97m flops)\n",
      "  model_3/depthwise_conv2d_40/depthwise (5.97m/5.97m flops)\n",
      "  model_3/depthwise_conv2d_49/depthwise (2.99m/2.99m flops)\n",
      "  model_3/depthwise_conv2d_48/depthwise (2.99m/2.99m flops)\n",
      "  model_3/depthwise_conv2d_46/depthwise (2.99m/2.99m flops)\n",
      "  model_3/depthwise_conv2d_47/depthwise (2.99m/2.99m flops)\n",
      "  model_3/depthwise_conv2d_42/depthwise (2.99m/2.99m flops)\n",
      "  model_3/depthwise_conv2d_45/depthwise (2.99m/2.99m flops)\n",
      "  model_3/batch_normalization_83/FusedBatchNormV3 (2.65m/2.65m flops)\n",
      "  model_3/depthwise_conv2d_51/depthwise (1.49m/1.49m flops)\n",
      "  model_3/depthwise_conv2d_44/depthwise (1.49m/1.49m flops)\n",
      "  model_3/batch_normalization_87/FusedBatchNormV3 (1.33m/1.33m flops)\n",
      "  model_3/batch_normalization_86/FusedBatchNormV3 (1.33m/1.33m flops)\n",
      "  model_3/batch_normalization_85/FusedBatchNormV3 (1.33m/1.33m flops)\n",
      "  model_3/batch_normalization_81/FusedBatchNormV3 (1.33m/1.33m flops)\n",
      "  model_3/batch_normalization_82/FusedBatchNormV3 (1.33m/1.33m flops)\n",
      "  model_3/conv2d_43/BiasAdd (1.33m/1.33m flops)\n",
      "  model_3/depthwise_conv2d_50/depthwise (746.50k/746.50k flops)\n",
      "  model_3/batch_normalization_91/FusedBatchNormV3 (665.09k/665.09k flops)\n",
      "  model_3/batch_normalization_90/FusedBatchNormV3 (665.09k/665.09k flops)\n",
      "  model_3/batch_normalization_89/FusedBatchNormV3 (665.09k/665.09k flops)\n",
      "  model_3/batch_normalization_84/FusedBatchNormV3 (663.94k/663.94k flops)\n",
      "  model_3/conv2d_42/BiasAdd (663.55k/663.55k flops)\n",
      "  model_3/conv2d_45/BiasAdd (663.55k/663.55k flops)\n",
      "  model_3/conv2d_44/BiasAdd (663.55k/663.55k flops)\n",
      "  model_3/depthwise_conv2d_41/BiasAdd (663.55k/663.55k flops)\n",
      "  model_3/depthwise_conv2d_39/BiasAdd (663.55k/663.55k flops)\n",
      "  model_3/batch_normalization_101/FusedBatchNormV3 (334.85k/334.85k flops)\n",
      "  model_3/batch_normalization_100/FusedBatchNormV3 (334.85k/334.85k flops)\n",
      "  model_3/batch_normalization_102/FusedBatchNormV3 (334.85k/334.85k flops)\n",
      "  model_3/batch_normalization_103/FusedBatchNormV3 (334.85k/334.85k flops)\n",
      "  model_3/batch_normalization_93/FusedBatchNormV3 (334.85k/334.85k flops)\n",
      "  model_3/batch_normalization_94/FusedBatchNormV3 (334.85k/334.85k flops)\n",
      "  model_3/batch_normalization_95/FusedBatchNormV3 (334.85k/334.85k flops)\n",
      "  model_3/batch_normalization_96/FusedBatchNormV3 (334.85k/334.85k flops)\n",
      "  model_3/batch_normalization_97/FusedBatchNormV3 (334.85k/334.85k flops)\n",
      "  model_3/batch_normalization_98/FusedBatchNormV3 (334.85k/334.85k flops)\n",
      "  model_3/batch_normalization_99/FusedBatchNormV3 (334.85k/334.85k flops)\n",
      "  model_3/batch_normalization_88/FusedBatchNormV3 (332.54k/332.54k flops)\n",
      "  model_3/conv2d_46/BiasAdd (331.78k/331.78k flops)\n",
      "  model_3/depthwise_conv2d_40/BiasAdd (331.78k/331.78k flops)\n",
      "  model_3/conv2d_47/BiasAdd (331.78k/331.78k flops)\n",
      "  model_3/depthwise_conv2d_43/BiasAdd (331.78k/331.78k flops)\n",
      "  model_3/batch_normalization_106/FusedBatchNormV3 (172.03k/172.03k flops)\n",
      "  model_3/batch_normalization_107/FusedBatchNormV3 (172.03k/172.03k flops)\n",
      "  model_3/batch_normalization_105/FusedBatchNormV3 (172.03k/172.03k flops)\n",
      "  model_3/batch_normalization_92/FusedBatchNormV3 (167.42k/167.42k flops)\n",
      "  model_3/depthwise_conv2d_46/BiasAdd (165.89k/165.89k flops)\n",
      "  model_3/depthwise_conv2d_47/BiasAdd (165.89k/165.89k flops)\n",
      "  model_3/depthwise_conv2d_48/BiasAdd (165.89k/165.89k flops)\n",
      "  model_3/depthwise_conv2d_45/BiasAdd (165.89k/165.89k flops)\n",
      "  model_3/depthwise_conv2d_49/BiasAdd (165.89k/165.89k flops)\n",
      "  model_3/conv2d_51/BiasAdd (165.89k/165.89k flops)\n",
      "  model_3/depthwise_conv2d_42/BiasAdd (165.89k/165.89k flops)\n",
      "  model_3/conv2d_53/BiasAdd (165.89k/165.89k flops)\n",
      "  model_3/conv2d_48/BiasAdd (165.89k/165.89k flops)\n",
      "  model_3/conv2d_52/BiasAdd (165.89k/165.89k flops)\n",
      "  model_3/conv2d_49/BiasAdd (165.89k/165.89k flops)\n",
      "  model_3/conv2d_50/BiasAdd (165.89k/165.89k flops)\n",
      "  model_3/batch_normalization_104/FusedBatchNormV3 (86.02k/86.02k flops)\n",
      "  model_3/depthwise_conv2d_44/BiasAdd (82.94k/82.94k flops)\n",
      "  model_3/conv2d_55/BiasAdd (82.94k/82.94k flops)\n",
      "  model_3/conv2d_54/BiasAdd (82.94k/82.94k flops)\n",
      "  model_3/depthwise_conv2d_51/BiasAdd (82.94k/82.94k flops)\n",
      "  model_3/global_average_pooling2d_3/Mean (82.94k/82.94k flops)\n",
      "  model_3/depthwise_conv2d_50/BiasAdd (41.47k/41.47k flops)\n",
      "  model_3/dense_3/MatMul (20.48k/20.48k flops)\n",
      "  model_3/dense_3/Softmax (50/50 flops)\n",
      "  model_3/dense_3/BiasAdd (10/10 flops)\n",
      "\n",
      "======================End of Report==========================\n",
      "Model: \"model_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_5 (InputLayer)         [(None, 320, 320, 1)]     0         \n",
      "_________________________________________________________________\n",
      "conv2d_56 (Conv2D)           (None, 160, 160, 32)      320       \n",
      "_________________________________________________________________\n",
      "batch_normalization_108 (Bat (None, 160, 160, 32)      128       \n",
      "_________________________________________________________________\n",
      "activation_108 (Activation)  (None, 160, 160, 32)      0         \n",
      "_________________________________________________________________\n",
      "depthwise_conv2d_52 (Depthwi (None, 160, 160, 32)      320       \n",
      "_________________________________________________________________\n",
      "batch_normalization_109 (Bat (None, 160, 160, 32)      128       \n",
      "_________________________________________________________________\n",
      "activation_109 (Activation)  (None, 160, 160, 32)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_57 (Conv2D)           (None, 160, 160, 64)      2112      \n",
      "_________________________________________________________________\n",
      "batch_normalization_110 (Bat (None, 160, 160, 64)      256       \n",
      "_________________________________________________________________\n",
      "activation_110 (Activation)  (None, 160, 160, 64)      0         \n",
      "_________________________________________________________________\n",
      "depthwise_conv2d_53 (Depthwi (None, 80, 80, 64)        640       \n",
      "_________________________________________________________________\n",
      "batch_normalization_111 (Bat (None, 80, 80, 64)        256       \n",
      "_________________________________________________________________\n",
      "activation_111 (Activation)  (None, 80, 80, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_58 (Conv2D)           (None, 80, 80, 128)       8320      \n",
      "_________________________________________________________________\n",
      "batch_normalization_112 (Bat (None, 80, 80, 128)       512       \n",
      "_________________________________________________________________\n",
      "activation_112 (Activation)  (None, 80, 80, 128)       0         \n",
      "_________________________________________________________________\n",
      "depthwise_conv2d_54 (Depthwi (None, 80, 80, 128)       1280      \n",
      "_________________________________________________________________\n",
      "batch_normalization_113 (Bat (None, 80, 80, 128)       512       \n",
      "_________________________________________________________________\n",
      "activation_113 (Activation)  (None, 80, 80, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_59 (Conv2D)           (None, 80, 80, 128)       16512     \n",
      "_________________________________________________________________\n",
      "batch_normalization_114 (Bat (None, 80, 80, 128)       512       \n",
      "_________________________________________________________________\n",
      "activation_114 (Activation)  (None, 80, 80, 128)       0         \n",
      "_________________________________________________________________\n",
      "depthwise_conv2d_55 (Depthwi (None, 40, 40, 128)       1280      \n",
      "_________________________________________________________________\n",
      "batch_normalization_115 (Bat (None, 40, 40, 128)       512       \n",
      "_________________________________________________________________\n",
      "activation_115 (Activation)  (None, 40, 40, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_60 (Conv2D)           (None, 40, 40, 256)       33024     \n",
      "_________________________________________________________________\n",
      "batch_normalization_116 (Bat (None, 40, 40, 256)       1024      \n",
      "_________________________________________________________________\n",
      "activation_116 (Activation)  (None, 40, 40, 256)       0         \n",
      "_________________________________________________________________\n",
      "depthwise_conv2d_56 (Depthwi (None, 40, 40, 256)       2560      \n",
      "_________________________________________________________________\n",
      "batch_normalization_117 (Bat (None, 40, 40, 256)       1024      \n",
      "_________________________________________________________________\n",
      "activation_117 (Activation)  (None, 40, 40, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_61 (Conv2D)           (None, 40, 40, 256)       65792     \n",
      "_________________________________________________________________\n",
      "batch_normalization_118 (Bat (None, 40, 40, 256)       1024      \n",
      "_________________________________________________________________\n",
      "activation_118 (Activation)  (None, 40, 40, 256)       0         \n",
      "_________________________________________________________________\n",
      "depthwise_conv2d_57 (Depthwi (None, 20, 20, 256)       2560      \n",
      "_________________________________________________________________\n",
      "batch_normalization_119 (Bat (None, 20, 20, 256)       1024      \n",
      "_________________________________________________________________\n",
      "activation_119 (Activation)  (None, 20, 20, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_62 (Conv2D)           (None, 20, 20, 512)       131584    \n",
      "_________________________________________________________________\n",
      "batch_normalization_120 (Bat (None, 20, 20, 512)       2048      \n",
      "_________________________________________________________________\n",
      "activation_120 (Activation)  (None, 20, 20, 512)       0         \n",
      "_________________________________________________________________\n",
      "depthwise_conv2d_58 (Depthwi (None, 20, 20, 512)       5120      \n",
      "_________________________________________________________________\n",
      "batch_normalization_121 (Bat (None, 20, 20, 512)       2048      \n",
      "_________________________________________________________________\n",
      "activation_121 (Activation)  (None, 20, 20, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_63 (Conv2D)           (None, 20, 20, 512)       262656    \n",
      "_________________________________________________________________\n",
      "batch_normalization_122 (Bat (None, 20, 20, 512)       2048      \n",
      "_________________________________________________________________\n",
      "activation_122 (Activation)  (None, 20, 20, 512)       0         \n",
      "_________________________________________________________________\n",
      "depthwise_conv2d_59 (Depthwi (None, 20, 20, 512)       5120      \n",
      "_________________________________________________________________\n",
      "batch_normalization_123 (Bat (None, 20, 20, 512)       2048      \n",
      "_________________________________________________________________\n",
      "activation_123 (Activation)  (None, 20, 20, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_64 (Conv2D)           (None, 20, 20, 512)       262656    \n",
      "_________________________________________________________________\n",
      "batch_normalization_124 (Bat (None, 20, 20, 512)       2048      \n",
      "_________________________________________________________________\n",
      "activation_124 (Activation)  (None, 20, 20, 512)       0         \n",
      "_________________________________________________________________\n",
      "depthwise_conv2d_60 (Depthwi (None, 20, 20, 512)       5120      \n",
      "_________________________________________________________________\n",
      "batch_normalization_125 (Bat (None, 20, 20, 512)       2048      \n",
      "_________________________________________________________________\n",
      "activation_125 (Activation)  (None, 20, 20, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_65 (Conv2D)           (None, 20, 20, 512)       262656    \n",
      "_________________________________________________________________\n",
      "batch_normalization_126 (Bat (None, 20, 20, 512)       2048      \n",
      "_________________________________________________________________\n",
      "activation_126 (Activation)  (None, 20, 20, 512)       0         \n",
      "_________________________________________________________________\n",
      "depthwise_conv2d_61 (Depthwi (None, 20, 20, 512)       5120      \n",
      "_________________________________________________________________\n",
      "batch_normalization_127 (Bat (None, 20, 20, 512)       2048      \n",
      "_________________________________________________________________\n",
      "activation_127 (Activation)  (None, 20, 20, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_66 (Conv2D)           (None, 20, 20, 512)       262656    \n",
      "_________________________________________________________________\n",
      "batch_normalization_128 (Bat (None, 20, 20, 512)       2048      \n",
      "_________________________________________________________________\n",
      "activation_128 (Activation)  (None, 20, 20, 512)       0         \n",
      "_________________________________________________________________\n",
      "depthwise_conv2d_62 (Depthwi (None, 20, 20, 512)       5120      \n",
      "_________________________________________________________________\n",
      "batch_normalization_129 (Bat (None, 20, 20, 512)       2048      \n",
      "_________________________________________________________________\n",
      "activation_129 (Activation)  (None, 20, 20, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_67 (Conv2D)           (None, 20, 20, 512)       262656    \n",
      "_________________________________________________________________\n",
      "batch_normalization_130 (Bat (None, 20, 20, 512)       2048      \n",
      "_________________________________________________________________\n",
      "activation_130 (Activation)  (None, 20, 20, 512)       0         \n",
      "_________________________________________________________________\n",
      "depthwise_conv2d_63 (Depthwi (None, 10, 10, 512)       5120      \n",
      "_________________________________________________________________\n",
      "batch_normalization_131 (Bat (None, 10, 10, 512)       2048      \n",
      "_________________________________________________________________\n",
      "activation_131 (Activation)  (None, 10, 10, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_68 (Conv2D)           (None, 10, 10, 1024)      525312    \n",
      "_________________________________________________________________\n",
      "batch_normalization_132 (Bat (None, 10, 10, 1024)      4096      \n",
      "_________________________________________________________________\n",
      "activation_132 (Activation)  (None, 10, 10, 1024)      0         \n",
      "_________________________________________________________________\n",
      "depthwise_conv2d_64 (Depthwi (None, 10, 10, 1024)      10240     \n",
      "_________________________________________________________________\n",
      "batch_normalization_133 (Bat (None, 10, 10, 1024)      4096      \n",
      "_________________________________________________________________\n",
      "activation_133 (Activation)  (None, 10, 10, 1024)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_69 (Conv2D)           (None, 10, 10, 1024)      1049600   \n",
      "_________________________________________________________________\n",
      "batch_normalization_134 (Bat (None, 10, 10, 1024)      4096      \n",
      "_________________________________________________________________\n",
      "activation_134 (Activation)  (None, 10, 10, 1024)      0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_4 ( (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 10)                10250     \n",
      "=================================================================\n",
      "Total params: 3,249,482\n",
      "Trainable params: 3,227,594\n",
      "Non-trainable params: 21,888\n",
      "_________________________________________________________________\n",
      "123.49854\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-02 06:40:56.325500: I tensorflow/core/grappler/devices.cc:66] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0\n",
      "2022-04-02 06:40:56.325588: I tensorflow/core/grappler/clusters/single_machine.cc:357] Starting new session\n",
      "2022-04-02 06:40:56.329748: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:1137] Optimization results for grappler item: graph_to_optimize\n",
      "  function_optimizer: function_optimizer did nothing. time = 0.004ms.\n",
      "  function_optimizer: function_optimizer did nothing. time = 0.001ms.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=========================Options=============================\n",
      "-max_depth                  10000\n",
      "-min_bytes                  0\n",
      "-min_peak_bytes             0\n",
      "-min_residual_bytes         0\n",
      "-min_output_bytes           0\n",
      "-min_micros                 0\n",
      "-min_accelerator_micros     0\n",
      "-min_cpu_micros             0\n",
      "-min_params                 0\n",
      "-min_float_ops              1\n",
      "-min_occurrence             0\n",
      "-step                       -1\n",
      "-order_by                   float_ops\n",
      "-account_type_regexes       .*\n",
      "-start_name_regexes         .*\n",
      "-trim_name_regexes          \n",
      "-show_name_regexes          .*\n",
      "-hide_name_regexes          \n",
      "-account_displayed_op_only  true\n",
      "-select                     float_ops\n",
      "-output                     stdout:\n",
      "\n",
      "==================Model Analysis Report======================\n",
      "\n",
      "Doc:\n",
      "scope: The nodes in the model graph are organized by their names, which is hierarchical like filesystem.\n",
      "flops: Number of float operations. Note: Please read the implementation for the math behind it.\n",
      "\n",
      "Profile:\n",
      "node name | # float_ops\n",
      "_TFProfRoot (--/2.32b flops)\n",
      "  model_4/conv2d_69/Conv2D (209.72m/209.72m flops)\n",
      "  model_4/conv2d_67/Conv2D (209.72m/209.72m flops)\n",
      "  model_4/conv2d_59/Conv2D (209.72m/209.72m flops)\n",
      "  model_4/conv2d_66/Conv2D (209.72m/209.72m flops)\n",
      "  model_4/conv2d_61/Conv2D (209.72m/209.72m flops)\n",
      "  model_4/conv2d_65/Conv2D (209.72m/209.72m flops)\n",
      "  model_4/conv2d_63/Conv2D (209.72m/209.72m flops)\n",
      "  model_4/conv2d_64/Conv2D (209.72m/209.72m flops)\n",
      "  model_4/conv2d_57/Conv2D (104.86m/104.86m flops)\n",
      "  model_4/conv2d_68/Conv2D (104.86m/104.86m flops)\n",
      "  model_4/conv2d_62/Conv2D (104.86m/104.86m flops)\n",
      "  model_4/conv2d_60/Conv2D (104.86m/104.86m flops)\n",
      "  model_4/conv2d_58/Conv2D (104.86m/104.86m flops)\n",
      "  model_4/conv2d_56/Conv2D (14.75m/14.75m flops)\n",
      "  model_4/depthwise_conv2d_54/depthwise (14.75m/14.75m flops)\n",
      "  model_4/depthwise_conv2d_52/depthwise (14.75m/14.75m flops)\n",
      "  model_4/depthwise_conv2d_53/depthwise (7.37m/7.37m flops)\n",
      "  model_4/depthwise_conv2d_56/depthwise (7.37m/7.37m flops)\n",
      "  model_4/depthwise_conv2d_55/depthwise (3.69m/3.69m flops)\n",
      "  model_4/depthwise_conv2d_58/depthwise (3.69m/3.69m flops)\n",
      "  model_4/depthwise_conv2d_59/depthwise (3.69m/3.69m flops)\n",
      "  model_4/depthwise_conv2d_60/depthwise (3.69m/3.69m flops)\n",
      "  model_4/depthwise_conv2d_61/depthwise (3.69m/3.69m flops)\n",
      "  model_4/depthwise_conv2d_62/depthwise (3.69m/3.69m flops)\n",
      "  model_4/batch_normalization_110/FusedBatchNormV3 (3.28m/3.28m flops)\n",
      "  model_4/depthwise_conv2d_57/depthwise (1.84m/1.84m flops)\n",
      "  model_4/depthwise_conv2d_64/depthwise (1.84m/1.84m flops)\n",
      "  model_4/batch_normalization_114/FusedBatchNormV3 (1.64m/1.64m flops)\n",
      "  model_4/batch_normalization_113/FusedBatchNormV3 (1.64m/1.64m flops)\n",
      "  model_4/batch_normalization_112/FusedBatchNormV3 (1.64m/1.64m flops)\n",
      "  model_4/batch_normalization_109/FusedBatchNormV3 (1.64m/1.64m flops)\n",
      "  model_4/batch_normalization_108/FusedBatchNormV3 (1.64m/1.64m flops)\n",
      "  model_4/conv2d_57/BiasAdd (1.64m/1.64m flops)\n",
      "  model_4/depthwise_conv2d_63/depthwise (921.60k/921.60k flops)\n",
      "  model_4/batch_normalization_116/FusedBatchNormV3 (820.74k/820.74k flops)\n",
      "  model_4/batch_normalization_117/FusedBatchNormV3 (820.74k/820.74k flops)\n",
      "  model_4/batch_normalization_118/FusedBatchNormV3 (820.74k/820.74k flops)\n",
      "  model_4/batch_normalization_111/FusedBatchNormV3 (819.58k/819.58k flops)\n",
      "  model_4/depthwise_conv2d_52/BiasAdd (819.20k/819.20k flops)\n",
      "  model_4/depthwise_conv2d_54/BiasAdd (819.20k/819.20k flops)\n",
      "  model_4/conv2d_58/BiasAdd (819.20k/819.20k flops)\n",
      "  model_4/conv2d_56/BiasAdd (819.20k/819.20k flops)\n",
      "  model_4/conv2d_59/BiasAdd (819.20k/819.20k flops)\n",
      "  model_4/batch_normalization_123/FusedBatchNormV3 (412.67k/412.67k flops)\n",
      "  model_4/batch_normalization_124/FusedBatchNormV3 (412.67k/412.67k flops)\n",
      "  model_4/batch_normalization_122/FusedBatchNormV3 (412.67k/412.67k flops)\n",
      "  model_4/batch_normalization_121/FusedBatchNormV3 (412.67k/412.67k flops)\n",
      "  model_4/batch_normalization_125/FusedBatchNormV3 (412.67k/412.67k flops)\n",
      "  model_4/batch_normalization_126/FusedBatchNormV3 (412.67k/412.67k flops)\n",
      "  model_4/batch_normalization_127/FusedBatchNormV3 (412.67k/412.67k flops)\n",
      "  model_4/batch_normalization_128/FusedBatchNormV3 (412.67k/412.67k flops)\n",
      "  model_4/batch_normalization_120/FusedBatchNormV3 (412.67k/412.67k flops)\n",
      "  model_4/batch_normalization_129/FusedBatchNormV3 (412.67k/412.67k flops)\n",
      "  model_4/batch_normalization_130/FusedBatchNormV3 (412.67k/412.67k flops)\n",
      "  model_4/batch_normalization_115/FusedBatchNormV3 (410.37k/410.37k flops)\n",
      "  model_4/depthwise_conv2d_56/BiasAdd (409.60k/409.60k flops)\n",
      "  model_4/conv2d_60/BiasAdd (409.60k/409.60k flops)\n",
      "  model_4/conv2d_61/BiasAdd (409.60k/409.60k flops)\n",
      "  model_4/depthwise_conv2d_53/BiasAdd (409.60k/409.60k flops)\n",
      "  model_4/batch_normalization_133/FusedBatchNormV3 (210.94k/210.94k flops)\n",
      "  model_4/batch_normalization_134/FusedBatchNormV3 (210.94k/210.94k flops)\n",
      "  model_4/batch_normalization_132/FusedBatchNormV3 (210.94k/210.94k flops)\n",
      "  model_4/batch_normalization_119/FusedBatchNormV3 (206.34k/206.34k flops)\n",
      "  model_4/conv2d_62/BiasAdd (204.80k/204.80k flops)\n",
      "  model_4/depthwise_conv2d_55/BiasAdd (204.80k/204.80k flops)\n",
      "  model_4/depthwise_conv2d_62/BiasAdd (204.80k/204.80k flops)\n",
      "  model_4/conv2d_67/BiasAdd (204.80k/204.80k flops)\n",
      "  model_4/conv2d_66/BiasAdd (204.80k/204.80k flops)\n",
      "  model_4/depthwise_conv2d_61/BiasAdd (204.80k/204.80k flops)\n",
      "  model_4/depthwise_conv2d_58/BiasAdd (204.80k/204.80k flops)\n",
      "  model_4/conv2d_65/BiasAdd (204.80k/204.80k flops)\n",
      "  model_4/depthwise_conv2d_59/BiasAdd (204.80k/204.80k flops)\n",
      "  model_4/conv2d_64/BiasAdd (204.80k/204.80k flops)\n",
      "  model_4/depthwise_conv2d_60/BiasAdd (204.80k/204.80k flops)\n",
      "  model_4/conv2d_63/BiasAdd (204.80k/204.80k flops)\n",
      "  model_4/batch_normalization_131/FusedBatchNormV3 (105.47k/105.47k flops)\n",
      "  model_4/depthwise_conv2d_57/BiasAdd (102.40k/102.40k flops)\n",
      "  model_4/conv2d_69/BiasAdd (102.40k/102.40k flops)\n",
      "  model_4/depthwise_conv2d_64/BiasAdd (102.40k/102.40k flops)\n",
      "  model_4/conv2d_68/BiasAdd (102.40k/102.40k flops)\n",
      "  model_4/global_average_pooling2d_4/Mean (102.40k/102.40k flops)\n",
      "  model_4/depthwise_conv2d_63/BiasAdd (51.20k/51.20k flops)\n",
      "  model_4/dense_4/MatMul (20.48k/20.48k flops)\n",
      "  model_4/dense_4/Softmax (50/50 flops)\n",
      "  model_4/dense_4/BiasAdd (10/10 flops)\n",
      "\n",
      "======================End of Report==========================\n",
      "Model: \"model_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_6 (InputLayer)         [(None, 352, 352, 1)]     0         \n",
      "_________________________________________________________________\n",
      "conv2d_70 (Conv2D)           (None, 176, 176, 32)      320       \n",
      "_________________________________________________________________\n",
      "batch_normalization_135 (Bat (None, 176, 176, 32)      128       \n",
      "_________________________________________________________________\n",
      "activation_135 (Activation)  (None, 176, 176, 32)      0         \n",
      "_________________________________________________________________\n",
      "depthwise_conv2d_65 (Depthwi (None, 176, 176, 32)      320       \n",
      "_________________________________________________________________\n",
      "batch_normalization_136 (Bat (None, 176, 176, 32)      128       \n",
      "_________________________________________________________________\n",
      "activation_136 (Activation)  (None, 176, 176, 32)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_71 (Conv2D)           (None, 176, 176, 64)      2112      \n",
      "_________________________________________________________________\n",
      "batch_normalization_137 (Bat (None, 176, 176, 64)      256       \n",
      "_________________________________________________________________\n",
      "activation_137 (Activation)  (None, 176, 176, 64)      0         \n",
      "_________________________________________________________________\n",
      "depthwise_conv2d_66 (Depthwi (None, 88, 88, 64)        640       \n",
      "_________________________________________________________________\n",
      "batch_normalization_138 (Bat (None, 88, 88, 64)        256       \n",
      "_________________________________________________________________\n",
      "activation_138 (Activation)  (None, 88, 88, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_72 (Conv2D)           (None, 88, 88, 128)       8320      \n",
      "_________________________________________________________________\n",
      "batch_normalization_139 (Bat (None, 88, 88, 128)       512       \n",
      "_________________________________________________________________\n",
      "activation_139 (Activation)  (None, 88, 88, 128)       0         \n",
      "_________________________________________________________________\n",
      "depthwise_conv2d_67 (Depthwi (None, 88, 88, 128)       1280      \n",
      "_________________________________________________________________\n",
      "batch_normalization_140 (Bat (None, 88, 88, 128)       512       \n",
      "_________________________________________________________________\n",
      "activation_140 (Activation)  (None, 88, 88, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_73 (Conv2D)           (None, 88, 88, 128)       16512     \n",
      "_________________________________________________________________\n",
      "batch_normalization_141 (Bat (None, 88, 88, 128)       512       \n",
      "_________________________________________________________________\n",
      "activation_141 (Activation)  (None, 88, 88, 128)       0         \n",
      "_________________________________________________________________\n",
      "depthwise_conv2d_68 (Depthwi (None, 44, 44, 128)       1280      \n",
      "_________________________________________________________________\n",
      "batch_normalization_142 (Bat (None, 44, 44, 128)       512       \n",
      "_________________________________________________________________\n",
      "activation_142 (Activation)  (None, 44, 44, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_74 (Conv2D)           (None, 44, 44, 256)       33024     \n",
      "_________________________________________________________________\n",
      "batch_normalization_143 (Bat (None, 44, 44, 256)       1024      \n",
      "_________________________________________________________________\n",
      "activation_143 (Activation)  (None, 44, 44, 256)       0         \n",
      "_________________________________________________________________\n",
      "depthwise_conv2d_69 (Depthwi (None, 44, 44, 256)       2560      \n",
      "_________________________________________________________________\n",
      "batch_normalization_144 (Bat (None, 44, 44, 256)       1024      \n",
      "_________________________________________________________________\n",
      "activation_144 (Activation)  (None, 44, 44, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_75 (Conv2D)           (None, 44, 44, 256)       65792     \n",
      "_________________________________________________________________\n",
      "batch_normalization_145 (Bat (None, 44, 44, 256)       1024      \n",
      "_________________________________________________________________\n",
      "activation_145 (Activation)  (None, 44, 44, 256)       0         \n",
      "_________________________________________________________________\n",
      "depthwise_conv2d_70 (Depthwi (None, 22, 22, 256)       2560      \n",
      "_________________________________________________________________\n",
      "batch_normalization_146 (Bat (None, 22, 22, 256)       1024      \n",
      "_________________________________________________________________\n",
      "activation_146 (Activation)  (None, 22, 22, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_76 (Conv2D)           (None, 22, 22, 512)       131584    \n",
      "_________________________________________________________________\n",
      "batch_normalization_147 (Bat (None, 22, 22, 512)       2048      \n",
      "_________________________________________________________________\n",
      "activation_147 (Activation)  (None, 22, 22, 512)       0         \n",
      "_________________________________________________________________\n",
      "depthwise_conv2d_71 (Depthwi (None, 22, 22, 512)       5120      \n",
      "_________________________________________________________________\n",
      "batch_normalization_148 (Bat (None, 22, 22, 512)       2048      \n",
      "_________________________________________________________________\n",
      "activation_148 (Activation)  (None, 22, 22, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_77 (Conv2D)           (None, 22, 22, 512)       262656    \n",
      "_________________________________________________________________\n",
      "batch_normalization_149 (Bat (None, 22, 22, 512)       2048      \n",
      "_________________________________________________________________\n",
      "activation_149 (Activation)  (None, 22, 22, 512)       0         \n",
      "_________________________________________________________________\n",
      "depthwise_conv2d_72 (Depthwi (None, 22, 22, 512)       5120      \n",
      "_________________________________________________________________\n",
      "batch_normalization_150 (Bat (None, 22, 22, 512)       2048      \n",
      "_________________________________________________________________\n",
      "activation_150 (Activation)  (None, 22, 22, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_78 (Conv2D)           (None, 22, 22, 512)       262656    \n",
      "_________________________________________________________________\n",
      "batch_normalization_151 (Bat (None, 22, 22, 512)       2048      \n",
      "_________________________________________________________________\n",
      "activation_151 (Activation)  (None, 22, 22, 512)       0         \n",
      "_________________________________________________________________\n",
      "depthwise_conv2d_73 (Depthwi (None, 22, 22, 512)       5120      \n",
      "_________________________________________________________________\n",
      "batch_normalization_152 (Bat (None, 22, 22, 512)       2048      \n",
      "_________________________________________________________________\n",
      "activation_152 (Activation)  (None, 22, 22, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_79 (Conv2D)           (None, 22, 22, 512)       262656    \n",
      "_________________________________________________________________\n",
      "batch_normalization_153 (Bat (None, 22, 22, 512)       2048      \n",
      "_________________________________________________________________\n",
      "activation_153 (Activation)  (None, 22, 22, 512)       0         \n",
      "_________________________________________________________________\n",
      "depthwise_conv2d_74 (Depthwi (None, 22, 22, 512)       5120      \n",
      "_________________________________________________________________\n",
      "batch_normalization_154 (Bat (None, 22, 22, 512)       2048      \n",
      "_________________________________________________________________\n",
      "activation_154 (Activation)  (None, 22, 22, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_80 (Conv2D)           (None, 22, 22, 512)       262656    \n",
      "_________________________________________________________________\n",
      "batch_normalization_155 (Bat (None, 22, 22, 512)       2048      \n",
      "_________________________________________________________________\n",
      "activation_155 (Activation)  (None, 22, 22, 512)       0         \n",
      "_________________________________________________________________\n",
      "depthwise_conv2d_75 (Depthwi (None, 22, 22, 512)       5120      \n",
      "_________________________________________________________________\n",
      "batch_normalization_156 (Bat (None, 22, 22, 512)       2048      \n",
      "_________________________________________________________________\n",
      "activation_156 (Activation)  (None, 22, 22, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_81 (Conv2D)           (None, 22, 22, 512)       262656    \n",
      "_________________________________________________________________\n",
      "batch_normalization_157 (Bat (None, 22, 22, 512)       2048      \n",
      "_________________________________________________________________\n",
      "activation_157 (Activation)  (None, 22, 22, 512)       0         \n",
      "_________________________________________________________________\n",
      "depthwise_conv2d_76 (Depthwi (None, 11, 11, 512)       5120      \n",
      "_________________________________________________________________\n",
      "batch_normalization_158 (Bat (None, 11, 11, 512)       2048      \n",
      "_________________________________________________________________\n",
      "activation_158 (Activation)  (None, 11, 11, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_82 (Conv2D)           (None, 11, 11, 1024)      525312    \n",
      "_________________________________________________________________\n",
      "batch_normalization_159 (Bat (None, 11, 11, 1024)      4096      \n",
      "_________________________________________________________________\n",
      "activation_159 (Activation)  (None, 11, 11, 1024)      0         \n",
      "_________________________________________________________________\n",
      "depthwise_conv2d_77 (Depthwi (None, 11, 11, 1024)      10240     \n",
      "_________________________________________________________________\n",
      "batch_normalization_160 (Bat (None, 11, 11, 1024)      4096      \n",
      "_________________________________________________________________\n",
      "activation_160 (Activation)  (None, 11, 11, 1024)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_83 (Conv2D)           (None, 11, 11, 1024)      1049600   \n",
      "_________________________________________________________________\n",
      "batch_normalization_161 (Bat (None, 11, 11, 1024)      4096      \n",
      "_________________________________________________________________\n",
      "activation_161 (Activation)  (None, 11, 11, 1024)      0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_5 ( (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 10)                10250     \n",
      "=================================================================\n",
      "Total params: 3,249,482\n",
      "Trainable params: 3,227,594\n",
      "Non-trainable params: 21,888\n",
      "_________________________________________________________________\n",
      "149.432364\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-02 06:40:57.259368: I tensorflow/core/grappler/devices.cc:66] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0\n",
      "2022-04-02 06:40:57.259493: I tensorflow/core/grappler/clusters/single_machine.cc:357] Starting new session\n",
      "2022-04-02 06:40:57.263736: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:1137] Optimization results for grappler item: graph_to_optimize\n",
      "  function_optimizer: function_optimizer did nothing. time = 0.004ms.\n",
      "  function_optimizer: function_optimizer did nothing. time = 0.001ms.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=========================Options=============================\n",
      "-max_depth                  10000\n",
      "-min_bytes                  0\n",
      "-min_peak_bytes             0\n",
      "-min_residual_bytes         0\n",
      "-min_output_bytes           0\n",
      "-min_micros                 0\n",
      "-min_accelerator_micros     0\n",
      "-min_cpu_micros             0\n",
      "-min_params                 0\n",
      "-min_float_ops              1\n",
      "-min_occurrence             0\n",
      "-step                       -1\n",
      "-order_by                   float_ops\n",
      "-account_type_regexes       .*\n",
      "-start_name_regexes         .*\n",
      "-trim_name_regexes          \n",
      "-show_name_regexes          .*\n",
      "-hide_name_regexes          \n",
      "-account_displayed_op_only  true\n",
      "-select                     float_ops\n",
      "-output                     stdout:\n",
      "\n",
      "==================Model Analysis Report======================\n",
      "\n",
      "Doc:\n",
      "scope: The nodes in the model graph are organized by their names, which is hierarchical like filesystem.\n",
      "flops: Number of float operations. Note: Please read the implementation for the math behind it.\n",
      "\n",
      "Profile:\n",
      "node name | # float_ops\n",
      "_TFProfRoot (--/2.81b flops)\n",
      "  model_5/conv2d_83/Conv2D (253.76m/253.76m flops)\n",
      "  model_5/conv2d_81/Conv2D (253.76m/253.76m flops)\n",
      "  model_5/conv2d_73/Conv2D (253.76m/253.76m flops)\n",
      "  model_5/conv2d_80/Conv2D (253.76m/253.76m flops)\n",
      "  model_5/conv2d_75/Conv2D (253.76m/253.76m flops)\n",
      "  model_5/conv2d_79/Conv2D (253.76m/253.76m flops)\n",
      "  model_5/conv2d_77/Conv2D (253.76m/253.76m flops)\n",
      "  model_5/conv2d_78/Conv2D (253.76m/253.76m flops)\n",
      "  model_5/conv2d_71/Conv2D (126.88m/126.88m flops)\n",
      "  model_5/conv2d_82/Conv2D (126.88m/126.88m flops)\n",
      "  model_5/conv2d_76/Conv2D (126.88m/126.88m flops)\n",
      "  model_5/conv2d_74/Conv2D (126.88m/126.88m flops)\n",
      "  model_5/conv2d_72/Conv2D (126.88m/126.88m flops)\n",
      "  model_5/conv2d_70/Conv2D (17.84m/17.84m flops)\n",
      "  model_5/depthwise_conv2d_67/depthwise (17.84m/17.84m flops)\n",
      "  model_5/depthwise_conv2d_65/depthwise (17.84m/17.84m flops)\n",
      "  model_5/depthwise_conv2d_66/depthwise (8.92m/8.92m flops)\n",
      "  model_5/depthwise_conv2d_69/depthwise (8.92m/8.92m flops)\n",
      "  model_5/depthwise_conv2d_68/depthwise (4.46m/4.46m flops)\n",
      "  model_5/depthwise_conv2d_71/depthwise (4.46m/4.46m flops)\n",
      "  model_5/depthwise_conv2d_72/depthwise (4.46m/4.46m flops)\n",
      "  model_5/depthwise_conv2d_73/depthwise (4.46m/4.46m flops)\n",
      "  model_5/depthwise_conv2d_74/depthwise (4.46m/4.46m flops)\n",
      "  model_5/depthwise_conv2d_75/depthwise (4.46m/4.46m flops)\n",
      "  model_5/batch_normalization_137/FusedBatchNormV3 (3.97m/3.97m flops)\n",
      "  model_5/depthwise_conv2d_70/depthwise (2.23m/2.23m flops)\n",
      "  model_5/depthwise_conv2d_77/depthwise (2.23m/2.23m flops)\n",
      "  model_5/batch_normalization_141/FusedBatchNormV3 (1.98m/1.98m flops)\n",
      "  model_5/batch_normalization_140/FusedBatchNormV3 (1.98m/1.98m flops)\n",
      "  model_5/batch_normalization_139/FusedBatchNormV3 (1.98m/1.98m flops)\n",
      "  model_5/batch_normalization_136/FusedBatchNormV3 (1.98m/1.98m flops)\n",
      "  model_5/batch_normalization_135/FusedBatchNormV3 (1.98m/1.98m flops)\n",
      "  model_5/conv2d_71/BiasAdd (1.98m/1.98m flops)\n",
      "  model_5/depthwise_conv2d_76/depthwise (1.12m/1.12m flops)\n",
      "  model_5/batch_normalization_143/FusedBatchNormV3 (992.77k/992.77k flops)\n",
      "  model_5/batch_normalization_144/FusedBatchNormV3 (992.77k/992.77k flops)\n",
      "  model_5/batch_normalization_145/FusedBatchNormV3 (992.77k/992.77k flops)\n",
      "  model_5/batch_normalization_138/FusedBatchNormV3 (991.62k/991.62k flops)\n",
      "  model_5/depthwise_conv2d_65/BiasAdd (991.23k/991.23k flops)\n",
      "  model_5/depthwise_conv2d_67/BiasAdd (991.23k/991.23k flops)\n",
      "  model_5/conv2d_72/BiasAdd (991.23k/991.23k flops)\n",
      "  model_5/conv2d_70/BiasAdd (991.23k/991.23k flops)\n",
      "  model_5/conv2d_73/BiasAdd (991.23k/991.23k flops)\n",
      "  model_5/batch_normalization_150/FusedBatchNormV3 (498.69k/498.69k flops)\n",
      "  model_5/batch_normalization_151/FusedBatchNormV3 (498.69k/498.69k flops)\n",
      "  model_5/batch_normalization_149/FusedBatchNormV3 (498.69k/498.69k flops)\n",
      "  model_5/batch_normalization_148/FusedBatchNormV3 (498.69k/498.69k flops)\n",
      "  model_5/batch_normalization_152/FusedBatchNormV3 (498.69k/498.69k flops)\n",
      "  model_5/batch_normalization_153/FusedBatchNormV3 (498.69k/498.69k flops)\n",
      "  model_5/batch_normalization_154/FusedBatchNormV3 (498.69k/498.69k flops)\n",
      "  model_5/batch_normalization_155/FusedBatchNormV3 (498.69k/498.69k flops)\n",
      "  model_5/batch_normalization_147/FusedBatchNormV3 (498.69k/498.69k flops)\n",
      "  model_5/batch_normalization_156/FusedBatchNormV3 (498.69k/498.69k flops)\n",
      "  model_5/batch_normalization_157/FusedBatchNormV3 (498.69k/498.69k flops)\n",
      "  model_5/batch_normalization_142/FusedBatchNormV3 (496.38k/496.38k flops)\n",
      "  model_5/depthwise_conv2d_69/BiasAdd (495.62k/495.62k flops)\n",
      "  model_5/conv2d_74/BiasAdd (495.62k/495.62k flops)\n",
      "  model_5/conv2d_75/BiasAdd (495.62k/495.62k flops)\n",
      "  model_5/depthwise_conv2d_66/BiasAdd (495.62k/495.62k flops)\n",
      "  model_5/batch_normalization_160/FusedBatchNormV3 (253.95k/253.95k flops)\n",
      "  model_5/batch_normalization_161/FusedBatchNormV3 (253.95k/253.95k flops)\n",
      "  model_5/batch_normalization_159/FusedBatchNormV3 (253.95k/253.95k flops)\n",
      "  model_5/batch_normalization_146/FusedBatchNormV3 (249.34k/249.34k flops)\n",
      "  model_5/conv2d_76/BiasAdd (247.81k/247.81k flops)\n",
      "  model_5/depthwise_conv2d_68/BiasAdd (247.81k/247.81k flops)\n",
      "  model_5/depthwise_conv2d_75/BiasAdd (247.81k/247.81k flops)\n",
      "  model_5/conv2d_81/BiasAdd (247.81k/247.81k flops)\n",
      "  model_5/conv2d_80/BiasAdd (247.81k/247.81k flops)\n",
      "  model_5/depthwise_conv2d_74/BiasAdd (247.81k/247.81k flops)\n",
      "  model_5/depthwise_conv2d_71/BiasAdd (247.81k/247.81k flops)\n",
      "  model_5/conv2d_79/BiasAdd (247.81k/247.81k flops)\n",
      "  model_5/depthwise_conv2d_72/BiasAdd (247.81k/247.81k flops)\n",
      "  model_5/conv2d_78/BiasAdd (247.81k/247.81k flops)\n",
      "  model_5/depthwise_conv2d_73/BiasAdd (247.81k/247.81k flops)\n",
      "  model_5/conv2d_77/BiasAdd (247.81k/247.81k flops)\n",
      "  model_5/batch_normalization_158/FusedBatchNormV3 (126.98k/126.98k flops)\n",
      "  model_5/depthwise_conv2d_70/BiasAdd (123.90k/123.90k flops)\n",
      "  model_5/conv2d_83/BiasAdd (123.90k/123.90k flops)\n",
      "  model_5/depthwise_conv2d_77/BiasAdd (123.90k/123.90k flops)\n",
      "  model_5/conv2d_82/BiasAdd (123.90k/123.90k flops)\n",
      "  model_5/global_average_pooling2d_5/Mean (123.90k/123.90k flops)\n",
      "  model_5/depthwise_conv2d_76/BiasAdd (61.95k/61.95k flops)\n",
      "  model_5/dense_5/MatMul (20.48k/20.48k flops)\n",
      "  model_5/dense_5/Softmax (50/50 flops)\n",
      "  model_5/dense_5/BiasAdd (10/10 flops)\n",
      "\n",
      "======================End of Report==========================\n",
      "Model: \"model_6\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_7 (InputLayer)         [(None, 384, 384, 1)]     0         \n",
      "_________________________________________________________________\n",
      "conv2d_84 (Conv2D)           (None, 192, 192, 32)      320       \n",
      "_________________________________________________________________\n",
      "batch_normalization_162 (Bat (None, 192, 192, 32)      128       \n",
      "_________________________________________________________________\n",
      "activation_162 (Activation)  (None, 192, 192, 32)      0         \n",
      "_________________________________________________________________\n",
      "depthwise_conv2d_78 (Depthwi (None, 192, 192, 32)      320       \n",
      "_________________________________________________________________\n",
      "batch_normalization_163 (Bat (None, 192, 192, 32)      128       \n",
      "_________________________________________________________________\n",
      "activation_163 (Activation)  (None, 192, 192, 32)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_85 (Conv2D)           (None, 192, 192, 64)      2112      \n",
      "_________________________________________________________________\n",
      "batch_normalization_164 (Bat (None, 192, 192, 64)      256       \n",
      "_________________________________________________________________\n",
      "activation_164 (Activation)  (None, 192, 192, 64)      0         \n",
      "_________________________________________________________________\n",
      "depthwise_conv2d_79 (Depthwi (None, 96, 96, 64)        640       \n",
      "_________________________________________________________________\n",
      "batch_normalization_165 (Bat (None, 96, 96, 64)        256       \n",
      "_________________________________________________________________\n",
      "activation_165 (Activation)  (None, 96, 96, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_86 (Conv2D)           (None, 96, 96, 128)       8320      \n",
      "_________________________________________________________________\n",
      "batch_normalization_166 (Bat (None, 96, 96, 128)       512       \n",
      "_________________________________________________________________\n",
      "activation_166 (Activation)  (None, 96, 96, 128)       0         \n",
      "_________________________________________________________________\n",
      "depthwise_conv2d_80 (Depthwi (None, 96, 96, 128)       1280      \n",
      "_________________________________________________________________\n",
      "batch_normalization_167 (Bat (None, 96, 96, 128)       512       \n",
      "_________________________________________________________________\n",
      "activation_167 (Activation)  (None, 96, 96, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_87 (Conv2D)           (None, 96, 96, 128)       16512     \n",
      "_________________________________________________________________\n",
      "batch_normalization_168 (Bat (None, 96, 96, 128)       512       \n",
      "_________________________________________________________________\n",
      "activation_168 (Activation)  (None, 96, 96, 128)       0         \n",
      "_________________________________________________________________\n",
      "depthwise_conv2d_81 (Depthwi (None, 48, 48, 128)       1280      \n",
      "_________________________________________________________________\n",
      "batch_normalization_169 (Bat (None, 48, 48, 128)       512       \n",
      "_________________________________________________________________\n",
      "activation_169 (Activation)  (None, 48, 48, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_88 (Conv2D)           (None, 48, 48, 256)       33024     \n",
      "_________________________________________________________________\n",
      "batch_normalization_170 (Bat (None, 48, 48, 256)       1024      \n",
      "_________________________________________________________________\n",
      "activation_170 (Activation)  (None, 48, 48, 256)       0         \n",
      "_________________________________________________________________\n",
      "depthwise_conv2d_82 (Depthwi (None, 48, 48, 256)       2560      \n",
      "_________________________________________________________________\n",
      "batch_normalization_171 (Bat (None, 48, 48, 256)       1024      \n",
      "_________________________________________________________________\n",
      "activation_171 (Activation)  (None, 48, 48, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_89 (Conv2D)           (None, 48, 48, 256)       65792     \n",
      "_________________________________________________________________\n",
      "batch_normalization_172 (Bat (None, 48, 48, 256)       1024      \n",
      "_________________________________________________________________\n",
      "activation_172 (Activation)  (None, 48, 48, 256)       0         \n",
      "_________________________________________________________________\n",
      "depthwise_conv2d_83 (Depthwi (None, 24, 24, 256)       2560      \n",
      "_________________________________________________________________\n",
      "batch_normalization_173 (Bat (None, 24, 24, 256)       1024      \n",
      "_________________________________________________________________\n",
      "activation_173 (Activation)  (None, 24, 24, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_90 (Conv2D)           (None, 24, 24, 512)       131584    \n",
      "_________________________________________________________________\n",
      "batch_normalization_174 (Bat (None, 24, 24, 512)       2048      \n",
      "_________________________________________________________________\n",
      "activation_174 (Activation)  (None, 24, 24, 512)       0         \n",
      "_________________________________________________________________\n",
      "depthwise_conv2d_84 (Depthwi (None, 24, 24, 512)       5120      \n",
      "_________________________________________________________________\n",
      "batch_normalization_175 (Bat (None, 24, 24, 512)       2048      \n",
      "_________________________________________________________________\n",
      "activation_175 (Activation)  (None, 24, 24, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_91 (Conv2D)           (None, 24, 24, 512)       262656    \n",
      "_________________________________________________________________\n",
      "batch_normalization_176 (Bat (None, 24, 24, 512)       2048      \n",
      "_________________________________________________________________\n",
      "activation_176 (Activation)  (None, 24, 24, 512)       0         \n",
      "_________________________________________________________________\n",
      "depthwise_conv2d_85 (Depthwi (None, 24, 24, 512)       5120      \n",
      "_________________________________________________________________\n",
      "batch_normalization_177 (Bat (None, 24, 24, 512)       2048      \n",
      "_________________________________________________________________\n",
      "activation_177 (Activation)  (None, 24, 24, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_92 (Conv2D)           (None, 24, 24, 512)       262656    \n",
      "_________________________________________________________________\n",
      "batch_normalization_178 (Bat (None, 24, 24, 512)       2048      \n",
      "_________________________________________________________________\n",
      "activation_178 (Activation)  (None, 24, 24, 512)       0         \n",
      "_________________________________________________________________\n",
      "depthwise_conv2d_86 (Depthwi (None, 24, 24, 512)       5120      \n",
      "_________________________________________________________________\n",
      "batch_normalization_179 (Bat (None, 24, 24, 512)       2048      \n",
      "_________________________________________________________________\n",
      "activation_179 (Activation)  (None, 24, 24, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_93 (Conv2D)           (None, 24, 24, 512)       262656    \n",
      "_________________________________________________________________\n",
      "batch_normalization_180 (Bat (None, 24, 24, 512)       2048      \n",
      "_________________________________________________________________\n",
      "activation_180 (Activation)  (None, 24, 24, 512)       0         \n",
      "_________________________________________________________________\n",
      "depthwise_conv2d_87 (Depthwi (None, 24, 24, 512)       5120      \n",
      "_________________________________________________________________\n",
      "batch_normalization_181 (Bat (None, 24, 24, 512)       2048      \n",
      "_________________________________________________________________\n",
      "activation_181 (Activation)  (None, 24, 24, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_94 (Conv2D)           (None, 24, 24, 512)       262656    \n",
      "_________________________________________________________________\n",
      "batch_normalization_182 (Bat (None, 24, 24, 512)       2048      \n",
      "_________________________________________________________________\n",
      "activation_182 (Activation)  (None, 24, 24, 512)       0         \n",
      "_________________________________________________________________\n",
      "depthwise_conv2d_88 (Depthwi (None, 24, 24, 512)       5120      \n",
      "_________________________________________________________________\n",
      "batch_normalization_183 (Bat (None, 24, 24, 512)       2048      \n",
      "_________________________________________________________________\n",
      "activation_183 (Activation)  (None, 24, 24, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_95 (Conv2D)           (None, 24, 24, 512)       262656    \n",
      "_________________________________________________________________\n",
      "batch_normalization_184 (Bat (None, 24, 24, 512)       2048      \n",
      "_________________________________________________________________\n",
      "activation_184 (Activation)  (None, 24, 24, 512)       0         \n",
      "_________________________________________________________________\n",
      "depthwise_conv2d_89 (Depthwi (None, 12, 12, 512)       5120      \n",
      "_________________________________________________________________\n",
      "batch_normalization_185 (Bat (None, 12, 12, 512)       2048      \n",
      "_________________________________________________________________\n",
      "activation_185 (Activation)  (None, 12, 12, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_96 (Conv2D)           (None, 12, 12, 1024)      525312    \n",
      "_________________________________________________________________\n",
      "batch_normalization_186 (Bat (None, 12, 12, 1024)      4096      \n",
      "_________________________________________________________________\n",
      "activation_186 (Activation)  (None, 12, 12, 1024)      0         \n",
      "_________________________________________________________________\n",
      "depthwise_conv2d_90 (Depthwi (None, 12, 12, 1024)      10240     \n",
      "_________________________________________________________________\n",
      "batch_normalization_187 (Bat (None, 12, 12, 1024)      4096      \n",
      "_________________________________________________________________\n",
      "activation_187 (Activation)  (None, 12, 12, 1024)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_97 (Conv2D)           (None, 12, 12, 1024)      1049600   \n",
      "_________________________________________________________________\n",
      "batch_normalization_188 (Bat (None, 12, 12, 1024)      4096      \n",
      "_________________________________________________________________\n",
      "activation_188 (Activation)  (None, 12, 12, 1024)      0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_6 ( (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 10)                10250     \n",
      "=================================================================\n",
      "Total params: 3,249,482\n",
      "Trainable params: 3,227,594\n",
      "Non-trainable params: 21,888\n",
      "_________________________________________________________________\n",
      "177.836076\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-02 06:40:58.293792: I tensorflow/core/grappler/devices.cc:66] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0\n",
      "2022-04-02 06:40:58.293864: I tensorflow/core/grappler/clusters/single_machine.cc:357] Starting new session\n",
      "2022-04-02 06:40:58.298111: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:1137] Optimization results for grappler item: graph_to_optimize\n",
      "  function_optimizer: function_optimizer did nothing. time = 0.005ms.\n",
      "  function_optimizer: function_optimizer did nothing. time = 0.001ms.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=========================Options=============================\n",
      "-max_depth                  10000\n",
      "-min_bytes                  0\n",
      "-min_peak_bytes             0\n",
      "-min_residual_bytes         0\n",
      "-min_output_bytes           0\n",
      "-min_micros                 0\n",
      "-min_accelerator_micros     0\n",
      "-min_cpu_micros             0\n",
      "-min_params                 0\n",
      "-min_float_ops              1\n",
      "-min_occurrence             0\n",
      "-step                       -1\n",
      "-order_by                   float_ops\n",
      "-account_type_regexes       .*\n",
      "-start_name_regexes         .*\n",
      "-trim_name_regexes          \n",
      "-show_name_regexes          .*\n",
      "-hide_name_regexes          \n",
      "-account_displayed_op_only  true\n",
      "-select                     float_ops\n",
      "-output                     stdout:\n",
      "\n",
      "==================Model Analysis Report======================\n",
      "\n",
      "Doc:\n",
      "scope: The nodes in the model graph are organized by their names, which is hierarchical like filesystem.\n",
      "flops: Number of float operations. Note: Please read the implementation for the math behind it.\n",
      "\n",
      "Profile:\n",
      "node name | # float_ops\n",
      "_TFProfRoot (--/3.34b flops)\n",
      "  model_6/conv2d_97/Conv2D (301.99m/301.99m flops)\n",
      "  model_6/conv2d_95/Conv2D (301.99m/301.99m flops)\n",
      "  model_6/conv2d_87/Conv2D (301.99m/301.99m flops)\n",
      "  model_6/conv2d_94/Conv2D (301.99m/301.99m flops)\n",
      "  model_6/conv2d_89/Conv2D (301.99m/301.99m flops)\n",
      "  model_6/conv2d_93/Conv2D (301.99m/301.99m flops)\n",
      "  model_6/conv2d_91/Conv2D (301.99m/301.99m flops)\n",
      "  model_6/conv2d_92/Conv2D (301.99m/301.99m flops)\n",
      "  model_6/conv2d_85/Conv2D (150.99m/150.99m flops)\n",
      "  model_6/conv2d_96/Conv2D (150.99m/150.99m flops)\n",
      "  model_6/conv2d_90/Conv2D (150.99m/150.99m flops)\n",
      "  model_6/conv2d_88/Conv2D (150.99m/150.99m flops)\n",
      "  model_6/conv2d_86/Conv2D (150.99m/150.99m flops)\n",
      "  model_6/conv2d_84/Conv2D (21.23m/21.23m flops)\n",
      "  model_6/depthwise_conv2d_80/depthwise (21.23m/21.23m flops)\n",
      "  model_6/depthwise_conv2d_78/depthwise (21.23m/21.23m flops)\n",
      "  model_6/depthwise_conv2d_79/depthwise (10.62m/10.62m flops)\n",
      "  model_6/depthwise_conv2d_82/depthwise (10.62m/10.62m flops)\n",
      "  model_6/depthwise_conv2d_81/depthwise (5.31m/5.31m flops)\n",
      "  model_6/depthwise_conv2d_84/depthwise (5.31m/5.31m flops)\n",
      "  model_6/depthwise_conv2d_85/depthwise (5.31m/5.31m flops)\n",
      "  model_6/depthwise_conv2d_86/depthwise (5.31m/5.31m flops)\n",
      "  model_6/depthwise_conv2d_87/depthwise (5.31m/5.31m flops)\n",
      "  model_6/depthwise_conv2d_88/depthwise (5.31m/5.31m flops)\n",
      "  model_6/batch_normalization_164/FusedBatchNormV3 (4.72m/4.72m flops)\n",
      "  model_6/depthwise_conv2d_83/depthwise (2.65m/2.65m flops)\n",
      "  model_6/depthwise_conv2d_90/depthwise (2.65m/2.65m flops)\n",
      "  model_6/batch_normalization_168/FusedBatchNormV3 (2.36m/2.36m flops)\n",
      "  model_6/batch_normalization_167/FusedBatchNormV3 (2.36m/2.36m flops)\n",
      "  model_6/batch_normalization_166/FusedBatchNormV3 (2.36m/2.36m flops)\n",
      "  model_6/batch_normalization_163/FusedBatchNormV3 (2.36m/2.36m flops)\n",
      "  model_6/batch_normalization_162/FusedBatchNormV3 (2.36m/2.36m flops)\n",
      "  model_6/conv2d_85/BiasAdd (2.36m/2.36m flops)\n",
      "  model_6/depthwise_conv2d_89/depthwise (1.33m/1.33m flops)\n",
      "  model_6/batch_normalization_170/FusedBatchNormV3 (1.18m/1.18m flops)\n",
      "  model_6/batch_normalization_171/FusedBatchNormV3 (1.18m/1.18m flops)\n",
      "  model_6/batch_normalization_172/FusedBatchNormV3 (1.18m/1.18m flops)\n",
      "  model_6/batch_normalization_165/FusedBatchNormV3 (1.18m/1.18m flops)\n",
      "  model_6/depthwise_conv2d_78/BiasAdd (1.18m/1.18m flops)\n",
      "  model_6/depthwise_conv2d_80/BiasAdd (1.18m/1.18m flops)\n",
      "  model_6/conv2d_86/BiasAdd (1.18m/1.18m flops)\n",
      "  model_6/conv2d_84/BiasAdd (1.18m/1.18m flops)\n",
      "  model_6/conv2d_87/BiasAdd (1.18m/1.18m flops)\n",
      "  model_6/batch_normalization_177/FusedBatchNormV3 (592.90k/592.90k flops)\n",
      "  model_6/batch_normalization_178/FusedBatchNormV3 (592.90k/592.90k flops)\n",
      "  model_6/batch_normalization_176/FusedBatchNormV3 (592.90k/592.90k flops)\n",
      "  model_6/batch_normalization_175/FusedBatchNormV3 (592.90k/592.90k flops)\n",
      "  model_6/batch_normalization_179/FusedBatchNormV3 (592.90k/592.90k flops)\n",
      "  model_6/batch_normalization_180/FusedBatchNormV3 (592.90k/592.90k flops)\n",
      "  model_6/batch_normalization_181/FusedBatchNormV3 (592.90k/592.90k flops)\n",
      "  model_6/batch_normalization_182/FusedBatchNormV3 (592.90k/592.90k flops)\n",
      "  model_6/batch_normalization_174/FusedBatchNormV3 (592.90k/592.90k flops)\n",
      "  model_6/batch_normalization_183/FusedBatchNormV3 (592.90k/592.90k flops)\n",
      "  model_6/batch_normalization_184/FusedBatchNormV3 (592.90k/592.90k flops)\n",
      "  model_6/batch_normalization_169/FusedBatchNormV3 (590.59k/590.59k flops)\n",
      "  model_6/depthwise_conv2d_82/BiasAdd (589.82k/589.82k flops)\n",
      "  model_6/conv2d_88/BiasAdd (589.82k/589.82k flops)\n",
      "  model_6/conv2d_89/BiasAdd (589.82k/589.82k flops)\n",
      "  model_6/depthwise_conv2d_79/BiasAdd (589.82k/589.82k flops)\n",
      "  model_6/batch_normalization_187/FusedBatchNormV3 (301.06k/301.06k flops)\n",
      "  model_6/batch_normalization_188/FusedBatchNormV3 (301.06k/301.06k flops)\n",
      "  model_6/batch_normalization_186/FusedBatchNormV3 (301.06k/301.06k flops)\n",
      "  model_6/batch_normalization_173/FusedBatchNormV3 (296.45k/296.45k flops)\n",
      "  model_6/conv2d_90/BiasAdd (294.91k/294.91k flops)\n",
      "  model_6/depthwise_conv2d_81/BiasAdd (294.91k/294.91k flops)\n",
      "  model_6/depthwise_conv2d_88/BiasAdd (294.91k/294.91k flops)\n",
      "  model_6/conv2d_95/BiasAdd (294.91k/294.91k flops)\n",
      "  model_6/conv2d_94/BiasAdd (294.91k/294.91k flops)\n",
      "  model_6/depthwise_conv2d_87/BiasAdd (294.91k/294.91k flops)\n",
      "  model_6/depthwise_conv2d_84/BiasAdd (294.91k/294.91k flops)\n",
      "  model_6/conv2d_93/BiasAdd (294.91k/294.91k flops)\n",
      "  model_6/depthwise_conv2d_85/BiasAdd (294.91k/294.91k flops)\n",
      "  model_6/conv2d_92/BiasAdd (294.91k/294.91k flops)\n",
      "  model_6/depthwise_conv2d_86/BiasAdd (294.91k/294.91k flops)\n",
      "  model_6/conv2d_91/BiasAdd (294.91k/294.91k flops)\n",
      "  model_6/batch_normalization_185/FusedBatchNormV3 (150.53k/150.53k flops)\n",
      "  model_6/depthwise_conv2d_83/BiasAdd (147.46k/147.46k flops)\n",
      "  model_6/conv2d_97/BiasAdd (147.46k/147.46k flops)\n",
      "  model_6/depthwise_conv2d_90/BiasAdd (147.46k/147.46k flops)\n",
      "  model_6/conv2d_96/BiasAdd (147.46k/147.46k flops)\n",
      "  model_6/global_average_pooling2d_6/Mean (147.46k/147.46k flops)\n",
      "  model_6/depthwise_conv2d_89/BiasAdd (73.73k/73.73k flops)\n",
      "  model_6/dense_6/MatMul (20.48k/20.48k flops)\n",
      "  model_6/dense_6/Softmax (50/50 flops)\n",
      "  model_6/dense_6/BiasAdd (10/10 flops)\n",
      "\n",
      "======================End of Report==========================\n",
      "Model: \"model_7\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_8 (InputLayer)         [(None, 416, 416, 1)]     0         \n",
      "_________________________________________________________________\n",
      "conv2d_98 (Conv2D)           (None, 208, 208, 32)      320       \n",
      "_________________________________________________________________\n",
      "batch_normalization_189 (Bat (None, 208, 208, 32)      128       \n",
      "_________________________________________________________________\n",
      "activation_189 (Activation)  (None, 208, 208, 32)      0         \n",
      "_________________________________________________________________\n",
      "depthwise_conv2d_91 (Depthwi (None, 208, 208, 32)      320       \n",
      "_________________________________________________________________\n",
      "batch_normalization_190 (Bat (None, 208, 208, 32)      128       \n",
      "_________________________________________________________________\n",
      "activation_190 (Activation)  (None, 208, 208, 32)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_99 (Conv2D)           (None, 208, 208, 64)      2112      \n",
      "_________________________________________________________________\n",
      "batch_normalization_191 (Bat (None, 208, 208, 64)      256       \n",
      "_________________________________________________________________\n",
      "activation_191 (Activation)  (None, 208, 208, 64)      0         \n",
      "_________________________________________________________________\n",
      "depthwise_conv2d_92 (Depthwi (None, 104, 104, 64)      640       \n",
      "_________________________________________________________________\n",
      "batch_normalization_192 (Bat (None, 104, 104, 64)      256       \n",
      "_________________________________________________________________\n",
      "activation_192 (Activation)  (None, 104, 104, 64)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_100 (Conv2D)          (None, 104, 104, 128)     8320      \n",
      "_________________________________________________________________\n",
      "batch_normalization_193 (Bat (None, 104, 104, 128)     512       \n",
      "_________________________________________________________________\n",
      "activation_193 (Activation)  (None, 104, 104, 128)     0         \n",
      "_________________________________________________________________\n",
      "depthwise_conv2d_93 (Depthwi (None, 104, 104, 128)     1280      \n",
      "_________________________________________________________________\n",
      "batch_normalization_194 (Bat (None, 104, 104, 128)     512       \n",
      "_________________________________________________________________\n",
      "activation_194 (Activation)  (None, 104, 104, 128)     0         \n",
      "_________________________________________________________________\n",
      "conv2d_101 (Conv2D)          (None, 104, 104, 128)     16512     \n",
      "_________________________________________________________________\n",
      "batch_normalization_195 (Bat (None, 104, 104, 128)     512       \n",
      "_________________________________________________________________\n",
      "activation_195 (Activation)  (None, 104, 104, 128)     0         \n",
      "_________________________________________________________________\n",
      "depthwise_conv2d_94 (Depthwi (None, 52, 52, 128)       1280      \n",
      "_________________________________________________________________\n",
      "batch_normalization_196 (Bat (None, 52, 52, 128)       512       \n",
      "_________________________________________________________________\n",
      "activation_196 (Activation)  (None, 52, 52, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_102 (Conv2D)          (None, 52, 52, 256)       33024     \n",
      "_________________________________________________________________\n",
      "batch_normalization_197 (Bat (None, 52, 52, 256)       1024      \n",
      "_________________________________________________________________\n",
      "activation_197 (Activation)  (None, 52, 52, 256)       0         \n",
      "_________________________________________________________________\n",
      "depthwise_conv2d_95 (Depthwi (None, 52, 52, 256)       2560      \n",
      "_________________________________________________________________\n",
      "batch_normalization_198 (Bat (None, 52, 52, 256)       1024      \n",
      "_________________________________________________________________\n",
      "activation_198 (Activation)  (None, 52, 52, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_103 (Conv2D)          (None, 52, 52, 256)       65792     \n",
      "_________________________________________________________________\n",
      "batch_normalization_199 (Bat (None, 52, 52, 256)       1024      \n",
      "_________________________________________________________________\n",
      "activation_199 (Activation)  (None, 52, 52, 256)       0         \n",
      "_________________________________________________________________\n",
      "depthwise_conv2d_96 (Depthwi (None, 26, 26, 256)       2560      \n",
      "_________________________________________________________________\n",
      "batch_normalization_200 (Bat (None, 26, 26, 256)       1024      \n",
      "_________________________________________________________________\n",
      "activation_200 (Activation)  (None, 26, 26, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_104 (Conv2D)          (None, 26, 26, 512)       131584    \n",
      "_________________________________________________________________\n",
      "batch_normalization_201 (Bat (None, 26, 26, 512)       2048      \n",
      "_________________________________________________________________\n",
      "activation_201 (Activation)  (None, 26, 26, 512)       0         \n",
      "_________________________________________________________________\n",
      "depthwise_conv2d_97 (Depthwi (None, 26, 26, 512)       5120      \n",
      "_________________________________________________________________\n",
      "batch_normalization_202 (Bat (None, 26, 26, 512)       2048      \n",
      "_________________________________________________________________\n",
      "activation_202 (Activation)  (None, 26, 26, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_105 (Conv2D)          (None, 26, 26, 512)       262656    \n",
      "_________________________________________________________________\n",
      "batch_normalization_203 (Bat (None, 26, 26, 512)       2048      \n",
      "_________________________________________________________________\n",
      "activation_203 (Activation)  (None, 26, 26, 512)       0         \n",
      "_________________________________________________________________\n",
      "depthwise_conv2d_98 (Depthwi (None, 26, 26, 512)       5120      \n",
      "_________________________________________________________________\n",
      "batch_normalization_204 (Bat (None, 26, 26, 512)       2048      \n",
      "_________________________________________________________________\n",
      "activation_204 (Activation)  (None, 26, 26, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_106 (Conv2D)          (None, 26, 26, 512)       262656    \n",
      "_________________________________________________________________\n",
      "batch_normalization_205 (Bat (None, 26, 26, 512)       2048      \n",
      "_________________________________________________________________\n",
      "activation_205 (Activation)  (None, 26, 26, 512)       0         \n",
      "_________________________________________________________________\n",
      "depthwise_conv2d_99 (Depthwi (None, 26, 26, 512)       5120      \n",
      "_________________________________________________________________\n",
      "batch_normalization_206 (Bat (None, 26, 26, 512)       2048      \n",
      "_________________________________________________________________\n",
      "activation_206 (Activation)  (None, 26, 26, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_107 (Conv2D)          (None, 26, 26, 512)       262656    \n",
      "_________________________________________________________________\n",
      "batch_normalization_207 (Bat (None, 26, 26, 512)       2048      \n",
      "_________________________________________________________________\n",
      "activation_207 (Activation)  (None, 26, 26, 512)       0         \n",
      "_________________________________________________________________\n",
      "depthwise_conv2d_100 (Depthw (None, 26, 26, 512)       5120      \n",
      "_________________________________________________________________\n",
      "batch_normalization_208 (Bat (None, 26, 26, 512)       2048      \n",
      "_________________________________________________________________\n",
      "activation_208 (Activation)  (None, 26, 26, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_108 (Conv2D)          (None, 26, 26, 512)       262656    \n",
      "_________________________________________________________________\n",
      "batch_normalization_209 (Bat (None, 26, 26, 512)       2048      \n",
      "_________________________________________________________________\n",
      "activation_209 (Activation)  (None, 26, 26, 512)       0         \n",
      "_________________________________________________________________\n",
      "depthwise_conv2d_101 (Depthw (None, 26, 26, 512)       5120      \n",
      "_________________________________________________________________\n",
      "batch_normalization_210 (Bat (None, 26, 26, 512)       2048      \n",
      "_________________________________________________________________\n",
      "activation_210 (Activation)  (None, 26, 26, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_109 (Conv2D)          (None, 26, 26, 512)       262656    \n",
      "_________________________________________________________________\n",
      "batch_normalization_211 (Bat (None, 26, 26, 512)       2048      \n",
      "_________________________________________________________________\n",
      "activation_211 (Activation)  (None, 26, 26, 512)       0         \n",
      "_________________________________________________________________\n",
      "depthwise_conv2d_102 (Depthw (None, 13, 13, 512)       5120      \n",
      "_________________________________________________________________\n",
      "batch_normalization_212 (Bat (None, 13, 13, 512)       2048      \n",
      "_________________________________________________________________\n",
      "activation_212 (Activation)  (None, 13, 13, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_110 (Conv2D)          (None, 13, 13, 1024)      525312    \n",
      "_________________________________________________________________\n",
      "batch_normalization_213 (Bat (None, 13, 13, 1024)      4096      \n",
      "_________________________________________________________________\n",
      "activation_213 (Activation)  (None, 13, 13, 1024)      0         \n",
      "_________________________________________________________________\n",
      "depthwise_conv2d_103 (Depthw (None, 13, 13, 1024)      10240     \n",
      "_________________________________________________________________\n",
      "batch_normalization_214 (Bat (None, 13, 13, 1024)      4096      \n",
      "_________________________________________________________________\n",
      "activation_214 (Activation)  (None, 13, 13, 1024)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_111 (Conv2D)          (None, 13, 13, 1024)      1049600   \n",
      "_________________________________________________________________\n",
      "batch_normalization_215 (Bat (None, 13, 13, 1024)      4096      \n",
      "_________________________________________________________________\n",
      "activation_215 (Activation)  (None, 13, 13, 1024)      0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_7 ( (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 10)                10250     \n",
      "=================================================================\n",
      "Total params: 3,249,482\n",
      "Trainable params: 3,227,594\n",
      "Non-trainable params: 21,888\n",
      "_________________________________________________________________\n",
      "208.709676\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-02 06:40:59.169378: I tensorflow/core/grappler/devices.cc:66] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0\n",
      "2022-04-02 06:40:59.169491: I tensorflow/core/grappler/clusters/single_machine.cc:357] Starting new session\n",
      "2022-04-02 06:40:59.173727: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:1137] Optimization results for grappler item: graph_to_optimize\n",
      "  function_optimizer: function_optimizer did nothing. time = 0.005ms.\n",
      "  function_optimizer: function_optimizer did nothing. time = 0.001ms.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=========================Options=============================\n",
      "-max_depth                  10000\n",
      "-min_bytes                  0\n",
      "-min_peak_bytes             0\n",
      "-min_residual_bytes         0\n",
      "-min_output_bytes           0\n",
      "-min_micros                 0\n",
      "-min_accelerator_micros     0\n",
      "-min_cpu_micros             0\n",
      "-min_params                 0\n",
      "-min_float_ops              1\n",
      "-min_occurrence             0\n",
      "-step                       -1\n",
      "-order_by                   float_ops\n",
      "-account_type_regexes       .*\n",
      "-start_name_regexes         .*\n",
      "-trim_name_regexes          \n",
      "-show_name_regexes          .*\n",
      "-hide_name_regexes          \n",
      "-account_displayed_op_only  true\n",
      "-select                     float_ops\n",
      "-output                     stdout:\n",
      "\n",
      "==================Model Analysis Report======================\n",
      "\n",
      "Doc:\n",
      "scope: The nodes in the model graph are organized by their names, which is hierarchical like filesystem.\n",
      "flops: Number of float operations. Note: Please read the implementation for the math behind it.\n",
      "\n",
      "Profile:\n",
      "node name | # float_ops\n",
      "_TFProfRoot (--/3.92b flops)\n",
      "  model_7/conv2d_101/Conv2D (354.42m/354.42m flops)\n",
      "  model_7/conv2d_103/Conv2D (354.42m/354.42m flops)\n",
      "  model_7/conv2d_105/Conv2D (354.42m/354.42m flops)\n",
      "  model_7/conv2d_106/Conv2D (354.42m/354.42m flops)\n",
      "  model_7/conv2d_107/Conv2D (354.42m/354.42m flops)\n",
      "  model_7/conv2d_108/Conv2D (354.42m/354.42m flops)\n",
      "  model_7/conv2d_111/Conv2D (354.42m/354.42m flops)\n",
      "  model_7/conv2d_109/Conv2D (354.42m/354.42m flops)\n",
      "  model_7/conv2d_102/Conv2D (177.21m/177.21m flops)\n",
      "  model_7/conv2d_100/Conv2D (177.21m/177.21m flops)\n",
      "  model_7/conv2d_104/Conv2D (177.21m/177.21m flops)\n",
      "  model_7/conv2d_99/Conv2D (177.21m/177.21m flops)\n",
      "  model_7/conv2d_110/Conv2D (177.21m/177.21m flops)\n",
      "  model_7/conv2d_98/Conv2D (24.92m/24.92m flops)\n",
      "  model_7/depthwise_conv2d_91/depthwise (24.92m/24.92m flops)\n",
      "  model_7/depthwise_conv2d_93/depthwise (24.92m/24.92m flops)\n",
      "  model_7/depthwise_conv2d_92/depthwise (12.46m/12.46m flops)\n",
      "  model_7/depthwise_conv2d_95/depthwise (12.46m/12.46m flops)\n",
      "  model_7/depthwise_conv2d_101/depthwise (6.23m/6.23m flops)\n",
      "  model_7/depthwise_conv2d_100/depthwise (6.23m/6.23m flops)\n",
      "  model_7/depthwise_conv2d_94/depthwise (6.23m/6.23m flops)\n",
      "  model_7/depthwise_conv2d_97/depthwise (6.23m/6.23m flops)\n",
      "  model_7/depthwise_conv2d_98/depthwise (6.23m/6.23m flops)\n",
      "  model_7/depthwise_conv2d_99/depthwise (6.23m/6.23m flops)\n",
      "  model_7/batch_normalization_191/FusedBatchNormV3 (5.54m/5.54m flops)\n",
      "  model_7/depthwise_conv2d_103/depthwise (3.12m/3.12m flops)\n",
      "  model_7/depthwise_conv2d_96/depthwise (3.12m/3.12m flops)\n",
      "  model_7/batch_normalization_195/FusedBatchNormV3 (2.77m/2.77m flops)\n",
      "  model_7/batch_normalization_194/FusedBatchNormV3 (2.77m/2.77m flops)\n",
      "  model_7/batch_normalization_193/FusedBatchNormV3 (2.77m/2.77m flops)\n",
      "  model_7/batch_normalization_190/FusedBatchNormV3 (2.77m/2.77m flops)\n",
      "  model_7/batch_normalization_189/FusedBatchNormV3 (2.77m/2.77m flops)\n",
      "  model_7/conv2d_99/BiasAdd (2.77m/2.77m flops)\n",
      "  model_7/depthwise_conv2d_102/depthwise (1.56m/1.56m flops)\n",
      "  model_7/batch_normalization_198/FusedBatchNormV3 (1.39m/1.39m flops)\n",
      "  model_7/batch_normalization_197/FusedBatchNormV3 (1.39m/1.39m flops)\n",
      "  model_7/batch_normalization_199/FusedBatchNormV3 (1.39m/1.39m flops)\n",
      "  model_7/batch_normalization_192/FusedBatchNormV3 (1.38m/1.38m flops)\n",
      "  model_7/conv2d_101/BiasAdd (1.38m/1.38m flops)\n",
      "  model_7/conv2d_98/BiasAdd (1.38m/1.38m flops)\n",
      "  model_7/depthwise_conv2d_93/BiasAdd (1.38m/1.38m flops)\n",
      "  model_7/conv2d_100/BiasAdd (1.38m/1.38m flops)\n",
      "  model_7/depthwise_conv2d_91/BiasAdd (1.38m/1.38m flops)\n",
      "  model_7/batch_normalization_204/FusedBatchNormV3 (695.30k/695.30k flops)\n",
      "  model_7/batch_normalization_205/FusedBatchNormV3 (695.30k/695.30k flops)\n",
      "  model_7/batch_normalization_201/FusedBatchNormV3 (695.30k/695.30k flops)\n",
      "  model_7/batch_normalization_206/FusedBatchNormV3 (695.30k/695.30k flops)\n",
      "  model_7/batch_normalization_203/FusedBatchNormV3 (695.30k/695.30k flops)\n",
      "  model_7/batch_normalization_207/FusedBatchNormV3 (695.30k/695.30k flops)\n",
      "  model_7/batch_normalization_202/FusedBatchNormV3 (695.30k/695.30k flops)\n",
      "  model_7/batch_normalization_208/FusedBatchNormV3 (695.30k/695.30k flops)\n",
      "  model_7/batch_normalization_209/FusedBatchNormV3 (695.30k/695.30k flops)\n",
      "  model_7/batch_normalization_210/FusedBatchNormV3 (695.30k/695.30k flops)\n",
      "  model_7/batch_normalization_211/FusedBatchNormV3 (695.30k/695.30k flops)\n",
      "  model_7/batch_normalization_196/FusedBatchNormV3 (692.99k/692.99k flops)\n",
      "  model_7/depthwise_conv2d_95/BiasAdd (692.22k/692.22k flops)\n",
      "  model_7/conv2d_103/BiasAdd (692.22k/692.22k flops)\n",
      "  model_7/depthwise_conv2d_92/BiasAdd (692.22k/692.22k flops)\n",
      "  model_7/conv2d_102/BiasAdd (692.22k/692.22k flops)\n",
      "  model_7/batch_normalization_213/FusedBatchNormV3 (352.26k/352.26k flops)\n",
      "  model_7/batch_normalization_214/FusedBatchNormV3 (352.26k/352.26k flops)\n",
      "  model_7/batch_normalization_215/FusedBatchNormV3 (352.26k/352.26k flops)\n",
      "  model_7/batch_normalization_200/FusedBatchNormV3 (347.65k/347.65k flops)\n",
      "  model_7/depthwise_conv2d_98/BiasAdd (346.11k/346.11k flops)\n",
      "  model_7/depthwise_conv2d_99/BiasAdd (346.11k/346.11k flops)\n",
      "  model_7/depthwise_conv2d_94/BiasAdd (346.11k/346.11k flops)\n",
      "  model_7/depthwise_conv2d_97/BiasAdd (346.11k/346.11k flops)\n",
      "  model_7/depthwise_conv2d_100/BiasAdd (346.11k/346.11k flops)\n",
      "  model_7/depthwise_conv2d_101/BiasAdd (346.11k/346.11k flops)\n",
      "  model_7/conv2d_104/BiasAdd (346.11k/346.11k flops)\n",
      "  model_7/conv2d_105/BiasAdd (346.11k/346.11k flops)\n",
      "  model_7/conv2d_106/BiasAdd (346.11k/346.11k flops)\n",
      "  model_7/conv2d_107/BiasAdd (346.11k/346.11k flops)\n",
      "  model_7/conv2d_108/BiasAdd (346.11k/346.11k flops)\n",
      "  model_7/conv2d_109/BiasAdd (346.11k/346.11k flops)\n",
      "  model_7/batch_normalization_212/FusedBatchNormV3 (176.13k/176.13k flops)\n",
      "  model_7/depthwise_conv2d_96/BiasAdd (173.06k/173.06k flops)\n",
      "  model_7/global_average_pooling2d_7/Mean (173.06k/173.06k flops)\n",
      "  model_7/depthwise_conv2d_103/BiasAdd (173.06k/173.06k flops)\n",
      "  model_7/conv2d_110/BiasAdd (173.06k/173.06k flops)\n",
      "  model_7/conv2d_111/BiasAdd (173.06k/173.06k flops)\n",
      "  model_7/depthwise_conv2d_102/BiasAdd (86.53k/86.53k flops)\n",
      "  model_7/dense_7/MatMul (20.48k/20.48k flops)\n",
      "  model_7/dense_7/Softmax (50/50 flops)\n",
      "  model_7/dense_7/BiasAdd (10/10 flops)\n",
      "\n",
      "======================End of Report==========================\n",
      "Model: \"model_8\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_9 (InputLayer)         [(None, 448, 448, 1)]     0         \n",
      "_________________________________________________________________\n",
      "conv2d_112 (Conv2D)          (None, 224, 224, 32)      320       \n",
      "_________________________________________________________________\n",
      "batch_normalization_216 (Bat (None, 224, 224, 32)      128       \n",
      "_________________________________________________________________\n",
      "activation_216 (Activation)  (None, 224, 224, 32)      0         \n",
      "_________________________________________________________________\n",
      "depthwise_conv2d_104 (Depthw (None, 224, 224, 32)      320       \n",
      "_________________________________________________________________\n",
      "batch_normalization_217 (Bat (None, 224, 224, 32)      128       \n",
      "_________________________________________________________________\n",
      "activation_217 (Activation)  (None, 224, 224, 32)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_113 (Conv2D)          (None, 224, 224, 64)      2112      \n",
      "_________________________________________________________________\n",
      "batch_normalization_218 (Bat (None, 224, 224, 64)      256       \n",
      "_________________________________________________________________\n",
      "activation_218 (Activation)  (None, 224, 224, 64)      0         \n",
      "_________________________________________________________________\n",
      "depthwise_conv2d_105 (Depthw (None, 112, 112, 64)      640       \n",
      "_________________________________________________________________\n",
      "batch_normalization_219 (Bat (None, 112, 112, 64)      256       \n",
      "_________________________________________________________________\n",
      "activation_219 (Activation)  (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_114 (Conv2D)          (None, 112, 112, 128)     8320      \n",
      "_________________________________________________________________\n",
      "batch_normalization_220 (Bat (None, 112, 112, 128)     512       \n",
      "_________________________________________________________________\n",
      "activation_220 (Activation)  (None, 112, 112, 128)     0         \n",
      "_________________________________________________________________\n",
      "depthwise_conv2d_106 (Depthw (None, 112, 112, 128)     1280      \n",
      "_________________________________________________________________\n",
      "batch_normalization_221 (Bat (None, 112, 112, 128)     512       \n",
      "_________________________________________________________________\n",
      "activation_221 (Activation)  (None, 112, 112, 128)     0         \n",
      "_________________________________________________________________\n",
      "conv2d_115 (Conv2D)          (None, 112, 112, 128)     16512     \n",
      "_________________________________________________________________\n",
      "batch_normalization_222 (Bat (None, 112, 112, 128)     512       \n",
      "_________________________________________________________________\n",
      "activation_222 (Activation)  (None, 112, 112, 128)     0         \n",
      "_________________________________________________________________\n",
      "depthwise_conv2d_107 (Depthw (None, 56, 56, 128)       1280      \n",
      "_________________________________________________________________\n",
      "batch_normalization_223 (Bat (None, 56, 56, 128)       512       \n",
      "_________________________________________________________________\n",
      "activation_223 (Activation)  (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_116 (Conv2D)          (None, 56, 56, 256)       33024     \n",
      "_________________________________________________________________\n",
      "batch_normalization_224 (Bat (None, 56, 56, 256)       1024      \n",
      "_________________________________________________________________\n",
      "activation_224 (Activation)  (None, 56, 56, 256)       0         \n",
      "_________________________________________________________________\n",
      "depthwise_conv2d_108 (Depthw (None, 56, 56, 256)       2560      \n",
      "_________________________________________________________________\n",
      "batch_normalization_225 (Bat (None, 56, 56, 256)       1024      \n",
      "_________________________________________________________________\n",
      "activation_225 (Activation)  (None, 56, 56, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_117 (Conv2D)          (None, 56, 56, 256)       65792     \n",
      "_________________________________________________________________\n",
      "batch_normalization_226 (Bat (None, 56, 56, 256)       1024      \n",
      "_________________________________________________________________\n",
      "activation_226 (Activation)  (None, 56, 56, 256)       0         \n",
      "_________________________________________________________________\n",
      "depthwise_conv2d_109 (Depthw (None, 28, 28, 256)       2560      \n",
      "_________________________________________________________________\n",
      "batch_normalization_227 (Bat (None, 28, 28, 256)       1024      \n",
      "_________________________________________________________________\n",
      "activation_227 (Activation)  (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_118 (Conv2D)          (None, 28, 28, 512)       131584    \n",
      "_________________________________________________________________\n",
      "batch_normalization_228 (Bat (None, 28, 28, 512)       2048      \n",
      "_________________________________________________________________\n",
      "activation_228 (Activation)  (None, 28, 28, 512)       0         \n",
      "_________________________________________________________________\n",
      "depthwise_conv2d_110 (Depthw (None, 28, 28, 512)       5120      \n",
      "_________________________________________________________________\n",
      "batch_normalization_229 (Bat (None, 28, 28, 512)       2048      \n",
      "_________________________________________________________________\n",
      "activation_229 (Activation)  (None, 28, 28, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_119 (Conv2D)          (None, 28, 28, 512)       262656    \n",
      "_________________________________________________________________\n",
      "batch_normalization_230 (Bat (None, 28, 28, 512)       2048      \n",
      "_________________________________________________________________\n",
      "activation_230 (Activation)  (None, 28, 28, 512)       0         \n",
      "_________________________________________________________________\n",
      "depthwise_conv2d_111 (Depthw (None, 28, 28, 512)       5120      \n",
      "_________________________________________________________________\n",
      "batch_normalization_231 (Bat (None, 28, 28, 512)       2048      \n",
      "_________________________________________________________________\n",
      "activation_231 (Activation)  (None, 28, 28, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_120 (Conv2D)          (None, 28, 28, 512)       262656    \n",
      "_________________________________________________________________\n",
      "batch_normalization_232 (Bat (None, 28, 28, 512)       2048      \n",
      "_________________________________________________________________\n",
      "activation_232 (Activation)  (None, 28, 28, 512)       0         \n",
      "_________________________________________________________________\n",
      "depthwise_conv2d_112 (Depthw (None, 28, 28, 512)       5120      \n",
      "_________________________________________________________________\n",
      "batch_normalization_233 (Bat (None, 28, 28, 512)       2048      \n",
      "_________________________________________________________________\n",
      "activation_233 (Activation)  (None, 28, 28, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_121 (Conv2D)          (None, 28, 28, 512)       262656    \n",
      "_________________________________________________________________\n",
      "batch_normalization_234 (Bat (None, 28, 28, 512)       2048      \n",
      "_________________________________________________________________\n",
      "activation_234 (Activation)  (None, 28, 28, 512)       0         \n",
      "_________________________________________________________________\n",
      "depthwise_conv2d_113 (Depthw (None, 28, 28, 512)       5120      \n",
      "_________________________________________________________________\n",
      "batch_normalization_235 (Bat (None, 28, 28, 512)       2048      \n",
      "_________________________________________________________________\n",
      "activation_235 (Activation)  (None, 28, 28, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_122 (Conv2D)          (None, 28, 28, 512)       262656    \n",
      "_________________________________________________________________\n",
      "batch_normalization_236 (Bat (None, 28, 28, 512)       2048      \n",
      "_________________________________________________________________\n",
      "activation_236 (Activation)  (None, 28, 28, 512)       0         \n",
      "_________________________________________________________________\n",
      "depthwise_conv2d_114 (Depthw (None, 28, 28, 512)       5120      \n",
      "_________________________________________________________________\n",
      "batch_normalization_237 (Bat (None, 28, 28, 512)       2048      \n",
      "_________________________________________________________________\n",
      "activation_237 (Activation)  (None, 28, 28, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_123 (Conv2D)          (None, 28, 28, 512)       262656    \n",
      "_________________________________________________________________\n",
      "batch_normalization_238 (Bat (None, 28, 28, 512)       2048      \n",
      "_________________________________________________________________\n",
      "activation_238 (Activation)  (None, 28, 28, 512)       0         \n",
      "_________________________________________________________________\n",
      "depthwise_conv2d_115 (Depthw (None, 14, 14, 512)       5120      \n",
      "_________________________________________________________________\n",
      "batch_normalization_239 (Bat (None, 14, 14, 512)       2048      \n",
      "_________________________________________________________________\n",
      "activation_239 (Activation)  (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_124 (Conv2D)          (None, 14, 14, 1024)      525312    \n",
      "_________________________________________________________________\n",
      "batch_normalization_240 (Bat (None, 14, 14, 1024)      4096      \n",
      "_________________________________________________________________\n",
      "activation_240 (Activation)  (None, 14, 14, 1024)      0         \n",
      "_________________________________________________________________\n",
      "depthwise_conv2d_116 (Depthw (None, 14, 14, 1024)      10240     \n",
      "_________________________________________________________________\n",
      "batch_normalization_241 (Bat (None, 14, 14, 1024)      4096      \n",
      "_________________________________________________________________\n",
      "activation_241 (Activation)  (None, 14, 14, 1024)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_125 (Conv2D)          (None, 14, 14, 1024)      1049600   \n",
      "_________________________________________________________________\n",
      "batch_normalization_242 (Bat (None, 14, 14, 1024)      4096      \n",
      "_________________________________________________________________\n",
      "activation_242 (Activation)  (None, 14, 14, 1024)      0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_8 ( (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 10)                10250     \n",
      "=================================================================\n",
      "Total params: 3,249,482\n",
      "Trainable params: 3,227,594\n",
      "Non-trainable params: 21,888\n",
      "_________________________________________________________________\n",
      "242.053164\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-02 06:41:00.137273: I tensorflow/core/grappler/devices.cc:66] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0\n",
      "2022-04-02 06:41:00.137341: I tensorflow/core/grappler/clusters/single_machine.cc:357] Starting new session\n",
      "2022-04-02 06:41:00.141681: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:1137] Optimization results for grappler item: graph_to_optimize\n",
      "  function_optimizer: function_optimizer did nothing. time = 0.005ms.\n",
      "  function_optimizer: function_optimizer did nothing. time = 0.001ms.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=========================Options=============================\n",
      "-max_depth                  10000\n",
      "-min_bytes                  0\n",
      "-min_peak_bytes             0\n",
      "-min_residual_bytes         0\n",
      "-min_output_bytes           0\n",
      "-min_micros                 0\n",
      "-min_accelerator_micros     0\n",
      "-min_cpu_micros             0\n",
      "-min_params                 0\n",
      "-min_float_ops              1\n",
      "-min_occurrence             0\n",
      "-step                       -1\n",
      "-order_by                   float_ops\n",
      "-account_type_regexes       .*\n",
      "-start_name_regexes         .*\n",
      "-trim_name_regexes          \n",
      "-show_name_regexes          .*\n",
      "-hide_name_regexes          \n",
      "-account_displayed_op_only  true\n",
      "-select                     float_ops\n",
      "-output                     stdout:\n",
      "\n",
      "==================Model Analysis Report======================\n",
      "\n",
      "Doc:\n",
      "scope: The nodes in the model graph are organized by their names, which is hierarchical like filesystem.\n",
      "flops: Number of float operations. Note: Please read the implementation for the math behind it.\n",
      "\n",
      "Profile:\n",
      "node name | # float_ops\n",
      "_TFProfRoot (--/4.54b flops)\n",
      "  model_8/conv2d_125/Conv2D (411.04m/411.04m flops)\n",
      "  model_8/conv2d_123/Conv2D (411.04m/411.04m flops)\n",
      "  model_8/conv2d_115/Conv2D (411.04m/411.04m flops)\n",
      "  model_8/conv2d_122/Conv2D (411.04m/411.04m flops)\n",
      "  model_8/conv2d_117/Conv2D (411.04m/411.04m flops)\n",
      "  model_8/conv2d_121/Conv2D (411.04m/411.04m flops)\n",
      "  model_8/conv2d_119/Conv2D (411.04m/411.04m flops)\n",
      "  model_8/conv2d_120/Conv2D (411.04m/411.04m flops)\n",
      "  model_8/conv2d_113/Conv2D (205.52m/205.52m flops)\n",
      "  model_8/conv2d_124/Conv2D (205.52m/205.52m flops)\n",
      "  model_8/conv2d_118/Conv2D (205.52m/205.52m flops)\n",
      "  model_8/conv2d_116/Conv2D (205.52m/205.52m flops)\n",
      "  model_8/conv2d_114/Conv2D (205.52m/205.52m flops)\n",
      "  model_8/conv2d_112/Conv2D (28.90m/28.90m flops)\n",
      "  model_8/depthwise_conv2d_106/depthwise (28.90m/28.90m flops)\n",
      "  model_8/depthwise_conv2d_104/depthwise (28.90m/28.90m flops)\n",
      "  model_8/depthwise_conv2d_105/depthwise (14.45m/14.45m flops)\n",
      "  model_8/depthwise_conv2d_108/depthwise (14.45m/14.45m flops)\n",
      "  model_8/depthwise_conv2d_107/depthwise (7.23m/7.23m flops)\n",
      "  model_8/depthwise_conv2d_110/depthwise (7.23m/7.23m flops)\n",
      "  model_8/depthwise_conv2d_111/depthwise (7.23m/7.23m flops)\n",
      "  model_8/depthwise_conv2d_112/depthwise (7.23m/7.23m flops)\n",
      "  model_8/depthwise_conv2d_113/depthwise (7.23m/7.23m flops)\n",
      "  model_8/depthwise_conv2d_114/depthwise (7.23m/7.23m flops)\n",
      "  model_8/batch_normalization_218/FusedBatchNormV3 (6.42m/6.42m flops)\n",
      "  model_8/depthwise_conv2d_109/depthwise (3.61m/3.61m flops)\n",
      "  model_8/depthwise_conv2d_116/depthwise (3.61m/3.61m flops)\n",
      "  model_8/batch_normalization_222/FusedBatchNormV3 (3.21m/3.21m flops)\n",
      "  model_8/batch_normalization_221/FusedBatchNormV3 (3.21m/3.21m flops)\n",
      "  model_8/batch_normalization_220/FusedBatchNormV3 (3.21m/3.21m flops)\n",
      "  model_8/batch_normalization_217/FusedBatchNormV3 (3.21m/3.21m flops)\n",
      "  model_8/batch_normalization_216/FusedBatchNormV3 (3.21m/3.21m flops)\n",
      "  model_8/conv2d_113/BiasAdd (3.21m/3.21m flops)\n",
      "  model_8/depthwise_conv2d_115/depthwise (1.81m/1.81m flops)\n",
      "  model_8/batch_normalization_224/FusedBatchNormV3 (1.61m/1.61m flops)\n",
      "  model_8/batch_normalization_225/FusedBatchNormV3 (1.61m/1.61m flops)\n",
      "  model_8/batch_normalization_226/FusedBatchNormV3 (1.61m/1.61m flops)\n",
      "  model_8/batch_normalization_219/FusedBatchNormV3 (1.61m/1.61m flops)\n",
      "  model_8/depthwise_conv2d_104/BiasAdd (1.61m/1.61m flops)\n",
      "  model_8/depthwise_conv2d_106/BiasAdd (1.61m/1.61m flops)\n",
      "  model_8/conv2d_114/BiasAdd (1.61m/1.61m flops)\n",
      "  model_8/conv2d_112/BiasAdd (1.61m/1.61m flops)\n",
      "  model_8/conv2d_115/BiasAdd (1.61m/1.61m flops)\n",
      "  model_8/batch_normalization_231/FusedBatchNormV3 (805.89k/805.89k flops)\n",
      "  model_8/batch_normalization_232/FusedBatchNormV3 (805.89k/805.89k flops)\n",
      "  model_8/batch_normalization_230/FusedBatchNormV3 (805.89k/805.89k flops)\n",
      "  model_8/batch_normalization_229/FusedBatchNormV3 (805.89k/805.89k flops)\n",
      "  model_8/batch_normalization_233/FusedBatchNormV3 (805.89k/805.89k flops)\n",
      "  model_8/batch_normalization_234/FusedBatchNormV3 (805.89k/805.89k flops)\n",
      "  model_8/batch_normalization_235/FusedBatchNormV3 (805.89k/805.89k flops)\n",
      "  model_8/batch_normalization_236/FusedBatchNormV3 (805.89k/805.89k flops)\n",
      "  model_8/batch_normalization_228/FusedBatchNormV3 (805.89k/805.89k flops)\n",
      "  model_8/batch_normalization_237/FusedBatchNormV3 (805.89k/805.89k flops)\n",
      "  model_8/batch_normalization_238/FusedBatchNormV3 (805.89k/805.89k flops)\n",
      "  model_8/batch_normalization_223/FusedBatchNormV3 (803.58k/803.58k flops)\n",
      "  model_8/depthwise_conv2d_108/BiasAdd (802.82k/802.82k flops)\n",
      "  model_8/conv2d_116/BiasAdd (802.82k/802.82k flops)\n",
      "  model_8/conv2d_117/BiasAdd (802.82k/802.82k flops)\n",
      "  model_8/depthwise_conv2d_105/BiasAdd (802.82k/802.82k flops)\n",
      "  model_8/batch_normalization_241/FusedBatchNormV3 (407.55k/407.55k flops)\n",
      "  model_8/batch_normalization_242/FusedBatchNormV3 (407.55k/407.55k flops)\n",
      "  model_8/batch_normalization_240/FusedBatchNormV3 (407.55k/407.55k flops)\n",
      "  model_8/batch_normalization_227/FusedBatchNormV3 (402.94k/402.94k flops)\n",
      "  model_8/conv2d_118/BiasAdd (401.41k/401.41k flops)\n",
      "  model_8/depthwise_conv2d_107/BiasAdd (401.41k/401.41k flops)\n",
      "  model_8/depthwise_conv2d_114/BiasAdd (401.41k/401.41k flops)\n",
      "  model_8/conv2d_123/BiasAdd (401.41k/401.41k flops)\n",
      "  model_8/conv2d_122/BiasAdd (401.41k/401.41k flops)\n",
      "  model_8/depthwise_conv2d_113/BiasAdd (401.41k/401.41k flops)\n",
      "  model_8/depthwise_conv2d_110/BiasAdd (401.41k/401.41k flops)\n",
      "  model_8/conv2d_121/BiasAdd (401.41k/401.41k flops)\n",
      "  model_8/depthwise_conv2d_111/BiasAdd (401.41k/401.41k flops)\n",
      "  model_8/conv2d_120/BiasAdd (401.41k/401.41k flops)\n",
      "  model_8/depthwise_conv2d_112/BiasAdd (401.41k/401.41k flops)\n",
      "  model_8/conv2d_119/BiasAdd (401.41k/401.41k flops)\n",
      "  model_8/batch_normalization_239/FusedBatchNormV3 (203.78k/203.78k flops)\n",
      "  model_8/depthwise_conv2d_109/BiasAdd (200.70k/200.70k flops)\n",
      "  model_8/conv2d_125/BiasAdd (200.70k/200.70k flops)\n",
      "  model_8/depthwise_conv2d_116/BiasAdd (200.70k/200.70k flops)\n",
      "  model_8/conv2d_124/BiasAdd (200.70k/200.70k flops)\n",
      "  model_8/global_average_pooling2d_8/Mean (200.70k/200.70k flops)\n",
      "  model_8/depthwise_conv2d_115/BiasAdd (100.35k/100.35k flops)\n",
      "  model_8/dense_8/MatMul (20.48k/20.48k flops)\n",
      "  model_8/dense_8/Softmax (50/50 flops)\n",
      "  model_8/dense_8/BiasAdd (10/10 flops)\n",
      "\n",
      "======================End of Report==========================\n",
      "Model: \"model_9\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_10 (InputLayer)        [(None, 480, 480, 1)]     0         \n",
      "_________________________________________________________________\n",
      "conv2d_126 (Conv2D)          (None, 240, 240, 32)      320       \n",
      "_________________________________________________________________\n",
      "batch_normalization_243 (Bat (None, 240, 240, 32)      128       \n",
      "_________________________________________________________________\n",
      "activation_243 (Activation)  (None, 240, 240, 32)      0         \n",
      "_________________________________________________________________\n",
      "depthwise_conv2d_117 (Depthw (None, 240, 240, 32)      320       \n",
      "_________________________________________________________________\n",
      "batch_normalization_244 (Bat (None, 240, 240, 32)      128       \n",
      "_________________________________________________________________\n",
      "activation_244 (Activation)  (None, 240, 240, 32)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_127 (Conv2D)          (None, 240, 240, 64)      2112      \n",
      "_________________________________________________________________\n",
      "batch_normalization_245 (Bat (None, 240, 240, 64)      256       \n",
      "_________________________________________________________________\n",
      "activation_245 (Activation)  (None, 240, 240, 64)      0         \n",
      "_________________________________________________________________\n",
      "depthwise_conv2d_118 (Depthw (None, 120, 120, 64)      640       \n",
      "_________________________________________________________________\n",
      "batch_normalization_246 (Bat (None, 120, 120, 64)      256       \n",
      "_________________________________________________________________\n",
      "activation_246 (Activation)  (None, 120, 120, 64)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_128 (Conv2D)          (None, 120, 120, 128)     8320      \n",
      "_________________________________________________________________\n",
      "batch_normalization_247 (Bat (None, 120, 120, 128)     512       \n",
      "_________________________________________________________________\n",
      "activation_247 (Activation)  (None, 120, 120, 128)     0         \n",
      "_________________________________________________________________\n",
      "depthwise_conv2d_119 (Depthw (None, 120, 120, 128)     1280      \n",
      "_________________________________________________________________\n",
      "batch_normalization_248 (Bat (None, 120, 120, 128)     512       \n",
      "_________________________________________________________________\n",
      "activation_248 (Activation)  (None, 120, 120, 128)     0         \n",
      "_________________________________________________________________\n",
      "conv2d_129 (Conv2D)          (None, 120, 120, 128)     16512     \n",
      "_________________________________________________________________\n",
      "batch_normalization_249 (Bat (None, 120, 120, 128)     512       \n",
      "_________________________________________________________________\n",
      "activation_249 (Activation)  (None, 120, 120, 128)     0         \n",
      "_________________________________________________________________\n",
      "depthwise_conv2d_120 (Depthw (None, 60, 60, 128)       1280      \n",
      "_________________________________________________________________\n",
      "batch_normalization_250 (Bat (None, 60, 60, 128)       512       \n",
      "_________________________________________________________________\n",
      "activation_250 (Activation)  (None, 60, 60, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_130 (Conv2D)          (None, 60, 60, 256)       33024     \n",
      "_________________________________________________________________\n",
      "batch_normalization_251 (Bat (None, 60, 60, 256)       1024      \n",
      "_________________________________________________________________\n",
      "activation_251 (Activation)  (None, 60, 60, 256)       0         \n",
      "_________________________________________________________________\n",
      "depthwise_conv2d_121 (Depthw (None, 60, 60, 256)       2560      \n",
      "_________________________________________________________________\n",
      "batch_normalization_252 (Bat (None, 60, 60, 256)       1024      \n",
      "_________________________________________________________________\n",
      "activation_252 (Activation)  (None, 60, 60, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_131 (Conv2D)          (None, 60, 60, 256)       65792     \n",
      "_________________________________________________________________\n",
      "batch_normalization_253 (Bat (None, 60, 60, 256)       1024      \n",
      "_________________________________________________________________\n",
      "activation_253 (Activation)  (None, 60, 60, 256)       0         \n",
      "_________________________________________________________________\n",
      "depthwise_conv2d_122 (Depthw (None, 30, 30, 256)       2560      \n",
      "_________________________________________________________________\n",
      "batch_normalization_254 (Bat (None, 30, 30, 256)       1024      \n",
      "_________________________________________________________________\n",
      "activation_254 (Activation)  (None, 30, 30, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_132 (Conv2D)          (None, 30, 30, 512)       131584    \n",
      "_________________________________________________________________\n",
      "batch_normalization_255 (Bat (None, 30, 30, 512)       2048      \n",
      "_________________________________________________________________\n",
      "activation_255 (Activation)  (None, 30, 30, 512)       0         \n",
      "_________________________________________________________________\n",
      "depthwise_conv2d_123 (Depthw (None, 30, 30, 512)       5120      \n",
      "_________________________________________________________________\n",
      "batch_normalization_256 (Bat (None, 30, 30, 512)       2048      \n",
      "_________________________________________________________________\n",
      "activation_256 (Activation)  (None, 30, 30, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_133 (Conv2D)          (None, 30, 30, 512)       262656    \n",
      "_________________________________________________________________\n",
      "batch_normalization_257 (Bat (None, 30, 30, 512)       2048      \n",
      "_________________________________________________________________\n",
      "activation_257 (Activation)  (None, 30, 30, 512)       0         \n",
      "_________________________________________________________________\n",
      "depthwise_conv2d_124 (Depthw (None, 30, 30, 512)       5120      \n",
      "_________________________________________________________________\n",
      "batch_normalization_258 (Bat (None, 30, 30, 512)       2048      \n",
      "_________________________________________________________________\n",
      "activation_258 (Activation)  (None, 30, 30, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_134 (Conv2D)          (None, 30, 30, 512)       262656    \n",
      "_________________________________________________________________\n",
      "batch_normalization_259 (Bat (None, 30, 30, 512)       2048      \n",
      "_________________________________________________________________\n",
      "activation_259 (Activation)  (None, 30, 30, 512)       0         \n",
      "_________________________________________________________________\n",
      "depthwise_conv2d_125 (Depthw (None, 30, 30, 512)       5120      \n",
      "_________________________________________________________________\n",
      "batch_normalization_260 (Bat (None, 30, 30, 512)       2048      \n",
      "_________________________________________________________________\n",
      "activation_260 (Activation)  (None, 30, 30, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_135 (Conv2D)          (None, 30, 30, 512)       262656    \n",
      "_________________________________________________________________\n",
      "batch_normalization_261 (Bat (None, 30, 30, 512)       2048      \n",
      "_________________________________________________________________\n",
      "activation_261 (Activation)  (None, 30, 30, 512)       0         \n",
      "_________________________________________________________________\n",
      "depthwise_conv2d_126 (Depthw (None, 30, 30, 512)       5120      \n",
      "_________________________________________________________________\n",
      "batch_normalization_262 (Bat (None, 30, 30, 512)       2048      \n",
      "_________________________________________________________________\n",
      "activation_262 (Activation)  (None, 30, 30, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_136 (Conv2D)          (None, 30, 30, 512)       262656    \n",
      "_________________________________________________________________\n",
      "batch_normalization_263 (Bat (None, 30, 30, 512)       2048      \n",
      "_________________________________________________________________\n",
      "activation_263 (Activation)  (None, 30, 30, 512)       0         \n",
      "_________________________________________________________________\n",
      "depthwise_conv2d_127 (Depthw (None, 30, 30, 512)       5120      \n",
      "_________________________________________________________________\n",
      "batch_normalization_264 (Bat (None, 30, 30, 512)       2048      \n",
      "_________________________________________________________________\n",
      "activation_264 (Activation)  (None, 30, 30, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_137 (Conv2D)          (None, 30, 30, 512)       262656    \n",
      "_________________________________________________________________\n",
      "batch_normalization_265 (Bat (None, 30, 30, 512)       2048      \n",
      "_________________________________________________________________\n",
      "activation_265 (Activation)  (None, 30, 30, 512)       0         \n",
      "_________________________________________________________________\n",
      "depthwise_conv2d_128 (Depthw (None, 15, 15, 512)       5120      \n",
      "_________________________________________________________________\n",
      "batch_normalization_266 (Bat (None, 15, 15, 512)       2048      \n",
      "_________________________________________________________________\n",
      "activation_266 (Activation)  (None, 15, 15, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_138 (Conv2D)          (None, 15, 15, 1024)      525312    \n",
      "_________________________________________________________________\n",
      "batch_normalization_267 (Bat (None, 15, 15, 1024)      4096      \n",
      "_________________________________________________________________\n",
      "activation_267 (Activation)  (None, 15, 15, 1024)      0         \n",
      "_________________________________________________________________\n",
      "depthwise_conv2d_129 (Depthw (None, 15, 15, 1024)      10240     \n",
      "_________________________________________________________________\n",
      "batch_normalization_268 (Bat (None, 15, 15, 1024)      4096      \n",
      "_________________________________________________________________\n",
      "activation_268 (Activation)  (None, 15, 15, 1024)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_139 (Conv2D)          (None, 15, 15, 1024)      1049600   \n",
      "_________________________________________________________________\n",
      "batch_normalization_269 (Bat (None, 15, 15, 1024)      4096      \n",
      "_________________________________________________________________\n",
      "activation_269 (Activation)  (None, 15, 15, 1024)      0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_9 ( (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 10)                10250     \n",
      "=================================================================\n",
      "Total params: 3,249,482\n",
      "Trainable params: 3,227,594\n",
      "Non-trainable params: 21,888\n",
      "_________________________________________________________________\n",
      "277.86654\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-02 06:41:01.010946: I tensorflow/core/grappler/devices.cc:66] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0\n",
      "2022-04-02 06:41:01.011062: I tensorflow/core/grappler/clusters/single_machine.cc:357] Starting new session\n",
      "2022-04-02 06:41:01.015334: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:1137] Optimization results for grappler item: graph_to_optimize\n",
      "  function_optimizer: function_optimizer did nothing. time = 0.004ms.\n",
      "  function_optimizer: function_optimizer did nothing. time = 0ms.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=========================Options=============================\n",
      "-max_depth                  10000\n",
      "-min_bytes                  0\n",
      "-min_peak_bytes             0\n",
      "-min_residual_bytes         0\n",
      "-min_output_bytes           0\n",
      "-min_micros                 0\n",
      "-min_accelerator_micros     0\n",
      "-min_cpu_micros             0\n",
      "-min_params                 0\n",
      "-min_float_ops              1\n",
      "-min_occurrence             0\n",
      "-step                       -1\n",
      "-order_by                   float_ops\n",
      "-account_type_regexes       .*\n",
      "-start_name_regexes         .*\n",
      "-trim_name_regexes          \n",
      "-show_name_regexes          .*\n",
      "-hide_name_regexes          \n",
      "-account_displayed_op_only  true\n",
      "-select                     float_ops\n",
      "-output                     stdout:\n",
      "\n",
      "==================Model Analysis Report======================\n",
      "\n",
      "Doc:\n",
      "scope: The nodes in the model graph are organized by their names, which is hierarchical like filesystem.\n",
      "flops: Number of float operations. Note: Please read the implementation for the math behind it.\n",
      "\n",
      "Profile:\n",
      "node name | # float_ops\n",
      "_TFProfRoot (--/5.22b flops)\n",
      "  model_9/conv2d_139/Conv2D (471.86m/471.86m flops)\n",
      "  model_9/conv2d_137/Conv2D (471.86m/471.86m flops)\n",
      "  model_9/conv2d_129/Conv2D (471.86m/471.86m flops)\n",
      "  model_9/conv2d_136/Conv2D (471.86m/471.86m flops)\n",
      "  model_9/conv2d_131/Conv2D (471.86m/471.86m flops)\n",
      "  model_9/conv2d_135/Conv2D (471.86m/471.86m flops)\n",
      "  model_9/conv2d_133/Conv2D (471.86m/471.86m flops)\n",
      "  model_9/conv2d_134/Conv2D (471.86m/471.86m flops)\n",
      "  model_9/conv2d_127/Conv2D (235.93m/235.93m flops)\n",
      "  model_9/conv2d_138/Conv2D (235.93m/235.93m flops)\n",
      "  model_9/conv2d_132/Conv2D (235.93m/235.93m flops)\n",
      "  model_9/conv2d_130/Conv2D (235.93m/235.93m flops)\n",
      "  model_9/conv2d_128/Conv2D (235.93m/235.93m flops)\n",
      "  model_9/conv2d_126/Conv2D (33.18m/33.18m flops)\n",
      "  model_9/depthwise_conv2d_119/depthwise (33.18m/33.18m flops)\n",
      "  model_9/depthwise_conv2d_117/depthwise (33.18m/33.18m flops)\n",
      "  model_9/depthwise_conv2d_118/depthwise (16.59m/16.59m flops)\n",
      "  model_9/depthwise_conv2d_121/depthwise (16.59m/16.59m flops)\n",
      "  model_9/depthwise_conv2d_120/depthwise (8.29m/8.29m flops)\n",
      "  model_9/depthwise_conv2d_123/depthwise (8.29m/8.29m flops)\n",
      "  model_9/depthwise_conv2d_124/depthwise (8.29m/8.29m flops)\n",
      "  model_9/depthwise_conv2d_125/depthwise (8.29m/8.29m flops)\n",
      "  model_9/depthwise_conv2d_126/depthwise (8.29m/8.29m flops)\n",
      "  model_9/depthwise_conv2d_127/depthwise (8.29m/8.29m flops)\n",
      "  model_9/batch_normalization_245/FusedBatchNormV3 (7.37m/7.37m flops)\n",
      "  model_9/depthwise_conv2d_122/depthwise (4.15m/4.15m flops)\n",
      "  model_9/depthwise_conv2d_129/depthwise (4.15m/4.15m flops)\n",
      "  model_9/batch_normalization_249/FusedBatchNormV3 (3.69m/3.69m flops)\n",
      "  model_9/batch_normalization_248/FusedBatchNormV3 (3.69m/3.69m flops)\n",
      "  model_9/batch_normalization_247/FusedBatchNormV3 (3.69m/3.69m flops)\n",
      "  model_9/batch_normalization_244/FusedBatchNormV3 (3.69m/3.69m flops)\n",
      "  model_9/batch_normalization_243/FusedBatchNormV3 (3.69m/3.69m flops)\n",
      "  model_9/conv2d_127/BiasAdd (3.69m/3.69m flops)\n",
      "  model_9/depthwise_conv2d_128/depthwise (2.07m/2.07m flops)\n",
      "  model_9/batch_normalization_251/FusedBatchNormV3 (1.84m/1.84m flops)\n",
      "  model_9/batch_normalization_252/FusedBatchNormV3 (1.84m/1.84m flops)\n",
      "  model_9/batch_normalization_253/FusedBatchNormV3 (1.84m/1.84m flops)\n",
      "  model_9/batch_normalization_246/FusedBatchNormV3 (1.84m/1.84m flops)\n",
      "  model_9/depthwise_conv2d_117/BiasAdd (1.84m/1.84m flops)\n",
      "  model_9/depthwise_conv2d_119/BiasAdd (1.84m/1.84m flops)\n",
      "  model_9/conv2d_128/BiasAdd (1.84m/1.84m flops)\n",
      "  model_9/conv2d_126/BiasAdd (1.84m/1.84m flops)\n",
      "  model_9/conv2d_129/BiasAdd (1.84m/1.84m flops)\n",
      "  model_9/batch_normalization_258/FusedBatchNormV3 (924.67k/924.67k flops)\n",
      "  model_9/batch_normalization_259/FusedBatchNormV3 (924.67k/924.67k flops)\n",
      "  model_9/batch_normalization_257/FusedBatchNormV3 (924.67k/924.67k flops)\n",
      "  model_9/batch_normalization_256/FusedBatchNormV3 (924.67k/924.67k flops)\n",
      "  model_9/batch_normalization_260/FusedBatchNormV3 (924.67k/924.67k flops)\n",
      "  model_9/batch_normalization_261/FusedBatchNormV3 (924.67k/924.67k flops)\n",
      "  model_9/batch_normalization_262/FusedBatchNormV3 (924.67k/924.67k flops)\n",
      "  model_9/batch_normalization_263/FusedBatchNormV3 (924.67k/924.67k flops)\n",
      "  model_9/batch_normalization_255/FusedBatchNormV3 (924.67k/924.67k flops)\n",
      "  model_9/batch_normalization_264/FusedBatchNormV3 (924.67k/924.67k flops)\n",
      "  model_9/batch_normalization_265/FusedBatchNormV3 (924.67k/924.67k flops)\n",
      "  model_9/batch_normalization_250/FusedBatchNormV3 (922.37k/922.37k flops)\n",
      "  model_9/depthwise_conv2d_121/BiasAdd (921.60k/921.60k flops)\n",
      "  model_9/conv2d_130/BiasAdd (921.60k/921.60k flops)\n",
      "  model_9/conv2d_131/BiasAdd (921.60k/921.60k flops)\n",
      "  model_9/depthwise_conv2d_118/BiasAdd (921.60k/921.60k flops)\n",
      "  model_9/batch_normalization_268/FusedBatchNormV3 (466.94k/466.94k flops)\n",
      "  model_9/batch_normalization_269/FusedBatchNormV3 (466.94k/466.94k flops)\n",
      "  model_9/batch_normalization_267/FusedBatchNormV3 (466.94k/466.94k flops)\n",
      "  model_9/batch_normalization_254/FusedBatchNormV3 (462.34k/462.34k flops)\n",
      "  model_9/conv2d_132/BiasAdd (460.80k/460.80k flops)\n",
      "  model_9/depthwise_conv2d_120/BiasAdd (460.80k/460.80k flops)\n",
      "  model_9/depthwise_conv2d_127/BiasAdd (460.80k/460.80k flops)\n",
      "  model_9/conv2d_137/BiasAdd (460.80k/460.80k flops)\n",
      "  model_9/conv2d_136/BiasAdd (460.80k/460.80k flops)\n",
      "  model_9/depthwise_conv2d_126/BiasAdd (460.80k/460.80k flops)\n",
      "  model_9/depthwise_conv2d_123/BiasAdd (460.80k/460.80k flops)\n",
      "  model_9/conv2d_135/BiasAdd (460.80k/460.80k flops)\n",
      "  model_9/depthwise_conv2d_124/BiasAdd (460.80k/460.80k flops)\n",
      "  model_9/conv2d_134/BiasAdd (460.80k/460.80k flops)\n",
      "  model_9/depthwise_conv2d_125/BiasAdd (460.80k/460.80k flops)\n",
      "  model_9/conv2d_133/BiasAdd (460.80k/460.80k flops)\n",
      "  model_9/batch_normalization_266/FusedBatchNormV3 (233.47k/233.47k flops)\n",
      "  model_9/depthwise_conv2d_122/BiasAdd (230.40k/230.40k flops)\n",
      "  model_9/conv2d_139/BiasAdd (230.40k/230.40k flops)\n",
      "  model_9/depthwise_conv2d_129/BiasAdd (230.40k/230.40k flops)\n",
      "  model_9/conv2d_138/BiasAdd (230.40k/230.40k flops)\n",
      "  model_9/global_average_pooling2d_9/Mean (230.40k/230.40k flops)\n",
      "  model_9/depthwise_conv2d_128/BiasAdd (115.20k/115.20k flops)\n",
      "  model_9/dense_9/MatMul (20.48k/20.48k flops)\n",
      "  model_9/dense_9/Softmax (50/50 flops)\n",
      "  model_9/dense_9/BiasAdd (10/10 flops)\n",
      "\n",
      "======================End of Report==========================\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "import numpy as np\n",
    "import os\n",
    "import csv\n",
    "from keras import backend as K\n",
    "from keras.layers import Input, Conv2D,GlobalAveragePooling2D, Dense, BatchNormalization, Activation\n",
    "from keras.models import Model\n",
    "from keras.layers import DepthwiseConv2D\n",
    "\n",
    "from keras import optimizers,regularizers\n",
    "from keras.initializers import he_normal\n",
    "\n",
    "from keras_flops import get_flops\n",
    "\n",
    "\n",
    "with open(\"para_count_MobileNet.csv\",\"w\") as csvfile:\n",
    "         writer = csv.writer(csvfile)\n",
    "         writer.writerows([[\"model_num\", \"input_horizontal\", \"input_vertical\", \"FLOPs\", \"Total_params\", \"Memory\"],])\n",
    "def depthwise_separable(x,params):\n",
    "    # f1/f2 filter size, s1 stride of conv\n",
    "    (s1,f2) = params\n",
    "    x = DepthwiseConv2D((3,3),strides=(s1[0],s1[0]), padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = Conv2D(int(f2[0]), (1,1), strides=(1,1), padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    return x\n",
    "\n",
    "\n",
    "def MobileNet(img_input,shallow=False, classes=10):\n",
    "    \"\"\"Instantiates the MobileNet.Network has two hyper-parameters\n",
    "        which are the width of network (controlled by alpha)\n",
    "        and input size.\n",
    "        # Arguments\n",
    "            alpha: optional parameter of the network to change the \n",
    "                width of model.\n",
    "            shallow: optional parameter for making network smaller.\n",
    "            classes: optional number of classes to classify images\n",
    "                into.\n",
    "    \"\"\"\n",
    "    x = Conv2D(int(32), (3,3), strides=(2,2), padding='same')(img_input)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "    x = depthwise_separable(x,params=[(1,),(64,)])\n",
    "    x = depthwise_separable(x,params=[(2,),(128,)])\n",
    "    x = depthwise_separable(x,params=[(1,),(128,)])\n",
    "    x = depthwise_separable(x,params=[(2,),(256,)])\n",
    "    x = depthwise_separable(x,params=[(1,),(256,)])\n",
    "    x = depthwise_separable(x,params=[(2,),(512,)])\n",
    "    \n",
    "    if not shallow:\n",
    "        for _ in range(5):\n",
    "            x = depthwise_separable(x,params=[(1,),(512,)])\n",
    "            \n",
    "    x = depthwise_separable(x,params=[(2,),(1024,)])\n",
    "    x = depthwise_separable(x,params=[(1,),(1024,)])\n",
    "\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    out = Dense(classes, activation='softmax')(x)\n",
    "    return out\n",
    "model_num = 1\n",
    "shape_range =range(192,512,32)\n",
    "for shape_x in shape_range:\n",
    "    shape_y = shape_x\n",
    "    img_input=Input(shape=(shape_x,shape_y,1))\n",
    "    output = MobileNet(img_input)\n",
    "    model=Model(img_input,output)\n",
    "    model.summary()\n",
    "    \n",
    "    # how to compute the memory allocated by the activations of a model\n",
    "    batch = 1\n",
    "    shapes_count = int(np.sum([np.prod(np.array([s if isinstance(s, int) \n",
    "    else 1 for s in l.output_shape])) \n",
    "    for l in model.layers]))\n",
    "    memory = (shapes_count * 4 * batch)/10**6\n",
    "    print(memory)\n",
    "    \n",
    "    Total_params = round(model.count_params()/10 ** 6,2)\n",
    "    FLOPs = round(get_flops(model, batch_size=1)/10 ** 9,2)\n",
    "    with open(\"para_count_MobileNet.csv\",\"a+\") as csvfile:\n",
    "        writer = csv.writer(csvfile)\n",
    "        writer.writerows([[model_num, shape_x, shape_y, \"FLOPs\", Total_params, memory],])\n",
    "\n",
    "        model_num = model_num + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "372f5b16",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-30 13:39:35.490750: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/xilinx/xrt/lib:/usr/lib:/usr/lib/x86_64-linux-gnu:/usr/local/lib:/opt/vitis_ai/conda/envs/vitis-ai-tensorflow/lib\n",
      "2022-04-30 13:39:35.490782: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2022-04-30 13:39:36.589031: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/xilinx/xrt/lib:/usr/lib:/usr/lib/x86_64-linux-gnu:/usr/local/lib:/opt/vitis_ai/conda/envs/vitis-ai-tensorflow/lib\n",
      "2022-04-30 13:39:36.589061: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2022-04-30 13:39:36.589074: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:163] no NVIDIA GPU device is present: /dev/nvidia0 does not exist\n",
      "2022-04-30 13:39:36.589208: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "1.104212\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-30 13:39:37.491181: I tensorflow/core/grappler/devices.cc:66] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0\n",
      "2022-04-30 13:39:37.491323: I tensorflow/core/grappler/clusters/single_machine.cc:357] Starting new session\n",
      "2022-04-30 13:39:37.512315: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:1137] Optimization results for grappler item: graph_to_optimize\n",
      "  function_optimizer: function_optimizer did nothing. time = 0.007ms.\n",
      "  function_optimizer: function_optimizer did nothing. time = 0.001ms.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /opt/vitis_ai/conda/envs/vitis-ai-tensorflow2/lib/python3.7/site-packages/tensorflow/python/ops/nn_ops.py:5063: tensor_shape_from_node_def_name (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.compat.v1.graph_util.tensor_shape_from_node_def_name`\n",
      "\n",
      "=========================Options=============================\n",
      "-max_depth                  10000\n",
      "-min_bytes                  0\n",
      "-min_peak_bytes             0\n",
      "-min_residual_bytes         0\n",
      "-min_output_bytes           0\n",
      "-min_micros                 0\n",
      "-min_accelerator_micros     0\n",
      "-min_cpu_micros             0\n",
      "-min_params                 0\n",
      "-min_float_ops              1\n",
      "-min_occurrence             0\n",
      "-step                       -1\n",
      "-order_by                   float_ops\n",
      "-account_type_regexes       .*\n",
      "-start_name_regexes         .*\n",
      "-trim_name_regexes          \n",
      "-show_name_regexes          .*\n",
      "-hide_name_regexes          \n",
      "-account_displayed_op_only  true\n",
      "-select                     float_ops\n",
      "-output                     stdout:\n",
      "\n",
      "==================Model Analysis Report======================\n",
      "\n",
      "Doc:\n",
      "scope: The nodes in the model graph are organized by their names, which is hierarchical like filesystem.\n",
      "flops: Number of float operations. Note: Please read the implementation for the math behind it.\n",
      "\n",
      "Profile:\n",
      "node name | # float_ops\n",
      "_TFProfRoot (--/19.79m flops)\n",
      "  model_1/conv2d_22/Conv2D (2.05m/2.05m flops)\n",
      "  model_1/conv2d_23/Conv2D (2.02m/2.02m flops)\n",
      "  model_1/conv2d_25/Conv2D (2.02m/2.02m flops)\n",
      "  model_1/conv2d_21/Conv2D (2.00m/2.00m flops)\n",
      "  model_1/conv2d_24/Conv2D (1.99m/1.99m flops)\n",
      "  model_1/conv2d_17/Conv2D (1.59m/1.59m flops)\n",
      "  model_1/conv2d_19/Conv2D (1.59m/1.59m flops)\n",
      "  model_1/conv2d_27/Conv2D (1.35m/1.35m flops)\n",
      "  model_1/conv2d_20/Conv2D (889.54k/889.54k flops)\n",
      "  model_1/conv2d_18/Conv2D (858.88k/858.88k flops)\n",
      "  model_1/conv2d_15/Conv2D (819.20k/819.20k flops)\n",
      "  model_1/conv2d_26/Conv2D (685.44k/685.44k flops)\n",
      "  model_1/conv2d_16/Conv2D (652.80k/652.80k flops)\n",
      "  model_1/conv2d_14/Conv2D (262.14k/262.14k flops)\n",
      "  model_1/depthwise_conv2d_13/depthwise (147.46k/147.46k flops)\n",
      "  model_1/depthwise_conv2d_15/depthwise (117.50k/117.50k flops)\n",
      "  model_1/depthwise_conv2d_17/depthwise (63.36k/63.36k flops)\n",
      "  model_1/depthwise_conv2d_14/depthwise (57.60k/57.60k flops)\n",
      "  model_1/depthwise_conv2d_20/depthwise (36.58k/36.58k flops)\n",
      "  model_1/depthwise_conv2d_21/depthwise (36.29k/36.29k flops)\n",
      "  model_1/depthwise_conv2d_22/depthwise (36.14k/36.14k flops)\n",
      "  model_1/depthwise_conv2d_23/depthwise (35.71k/35.71k flops)\n",
      "  model_1/depthwise_conv2d_19/depthwise (35.42k/35.42k flops)\n",
      "  model_1/depthwise_conv2d_16/depthwise (35.14k/35.14k flops)\n",
      "  model_1/batch_normalization_29/FusedBatchNormV3 (25.90k/25.90k flops)\n",
      "  model_1/dense_1/MatMul (20.16k/20.16k flops)\n",
      "  model_1/batch_normalization_28/FusedBatchNormV3 (16.58k/16.58k flops)\n",
      "  model_1/batch_normalization_27/FusedBatchNormV3 (16.58k/16.58k flops)\n",
      "  model_1/batch_normalization_33/FusedBatchNormV3 (16.35k/16.35k flops)\n",
      "  model_1/depthwise_conv2d_18/depthwise (16.27k/16.27k flops)\n",
      "  model_1/batch_normalization_31/FusedBatchNormV3 (13.67k/13.67k flops)\n",
      "  model_1/batch_normalization_32/FusedBatchNormV3 (13.67k/13.67k flops)\n",
      "  model_1/conv2d_15/BiasAdd (12.80k/12.80k flops)\n",
      "  model_1/depthwise_conv2d_25/depthwise (12.10k/12.10k flops)\n",
      "  model_1/depthwise_conv2d_24/depthwise (9.18k/9.18k flops)\n",
      "  model_1/batch_normalization_37/FusedBatchNormV3 (8.59k/8.59k flops)\n",
      "  model_1/batch_normalization_36/FusedBatchNormV3 (8.36k/8.36k flops)\n",
      "  model_1/batch_normalization_35/FusedBatchNormV3 (8.36k/8.36k flops)\n",
      "  model_1/depthwise_conv2d_13/BiasAdd (8.19k/8.19k flops)\n",
      "  model_1/conv2d_14/BiasAdd (8.19k/8.19k flops)\n",
      "  model_1/batch_normalization_53/FusedBatchNormV3 (8.06k/8.06k flops)\n",
      "  model_1/conv2d_17/BiasAdd (7.81k/7.81k flops)\n",
      "  model_1/batch_normalization_49/FusedBatchNormV3 (7.14k/7.14k flops)\n",
      "  model_1/batch_normalization_42/FusedBatchNormV3 (7.11k/7.11k flops)\n",
      "  model_1/batch_normalization_41/FusedBatchNormV3 (7.11k/7.11k flops)\n",
      "  model_1/batch_normalization_44/FusedBatchNormV3 (7.06k/7.06k flops)\n",
      "  model_1/batch_normalization_43/FusedBatchNormV3 (7.06k/7.06k flops)\n",
      "  model_1/batch_normalization_45/FusedBatchNormV3 (7.03k/7.03k flops)\n",
      "  model_1/batch_normalization_46/FusedBatchNormV3 (7.03k/7.03k flops)\n",
      "  model_1/batch_normalization_47/FusedBatchNormV3 (6.94k/6.94k flops)\n",
      "  model_1/batch_normalization_48/FusedBatchNormV3 (6.94k/6.94k flops)\n",
      "  model_1/batch_normalization_40/FusedBatchNormV3 (6.89k/6.89k flops)\n",
      "  model_1/batch_normalization_39/FusedBatchNormV3 (6.89k/6.89k flops)\n",
      "  model_1/batch_normalization_30/FusedBatchNormV3 (6.70k/6.70k flops)\n",
      "  model_1/conv2d_16/BiasAdd (6.53k/6.53k flops)\n",
      "  model_1/depthwise_conv2d_15/BiasAdd (6.53k/6.53k flops)\n",
      "  model_1/batch_normalization_52/FusedBatchNormV3 (5.38k/5.38k flops)\n",
      "  model_1/batch_normalization_51/FusedBatchNormV3 (5.38k/5.38k flops)\n",
      "  model_1/batch_normalization_34/FusedBatchNormV3 (4.64k/4.64k flops)\n",
      "  model_1/batch_normalization_50/FusedBatchNormV3 (4.08k/4.08k flops)\n",
      "  model_1/conv2d_19/BiasAdd (3.62k/3.62k flops)\n",
      "  model_1/conv2d_18/BiasAdd (3.52k/3.52k flops)\n",
      "  model_1/depthwise_conv2d_17/BiasAdd (3.52k/3.52k flops)\n",
      "  model_1/depthwise_conv2d_14/BiasAdd (3.20k/3.20k flops)\n",
      "  model_1/batch_normalization_38/FusedBatchNormV3 (3.16k/3.16k flops)\n",
      "  model_1/conv2d_25/BiasAdd (2.04k/2.04k flops)\n",
      "  model_1/depthwise_conv2d_20/BiasAdd (2.03k/2.03k flops)\n",
      "  model_1/conv2d_21/BiasAdd (2.03k/2.03k flops)\n",
      "  model_1/conv2d_22/BiasAdd (2.02k/2.02k flops)\n",
      "  model_1/depthwise_conv2d_21/BiasAdd (2.02k/2.02k flops)\n",
      "  model_1/conv2d_23/BiasAdd (2.01k/2.01k flops)\n",
      "  model_1/depthwise_conv2d_22/BiasAdd (2.01k/2.01k flops)\n",
      "  model_1/depthwise_conv2d_23/BiasAdd (1.98k/1.98k flops)\n",
      "  model_1/conv2d_24/BiasAdd (1.98k/1.98k flops)\n",
      "  model_1/depthwise_conv2d_19/BiasAdd (1.97k/1.97k flops)\n",
      "  model_1/conv2d_20/BiasAdd (1.97k/1.97k flops)\n",
      "  model_1/depthwise_conv2d_16/BiasAdd (1.95k/1.95k flops)\n",
      "  model_1/conv2d_27/BiasAdd (1.01k/1.01k flops)\n",
      "  model_1/global_average_pooling2d_1/Mean (1.01k/1.01k flops)\n",
      "  model_1/depthwise_conv2d_18/BiasAdd (904/904 flops)\n",
      "  model_1/depthwise_conv2d_25/BiasAdd (672/672 flops)\n",
      "  model_1/conv2d_26/BiasAdd (672/672 flops)\n",
      "  model_1/depthwise_conv2d_24/BiasAdd (510/510 flops)\n",
      "  model_1/dense_1/Softmax (50/50 flops)\n",
      "  model_1/dense_1/BiasAdd (10/10 flops)\n",
      "\n",
      "======================End of Report==========================\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "0.96118\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-30 13:39:38.511038: I tensorflow/core/grappler/devices.cc:66] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0\n",
      "2022-04-30 13:39:38.511151: I tensorflow/core/grappler/clusters/single_machine.cc:357] Starting new session\n",
      "2022-04-30 13:39:38.515058: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:1137] Optimization results for grappler item: graph_to_optimize\n",
      "  function_optimizer: function_optimizer did nothing. time = 0.005ms.\n",
      "  function_optimizer: function_optimizer did nothing. time = 0ms.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=========================Options=============================\n",
      "-max_depth                  10000\n",
      "-min_bytes                  0\n",
      "-min_peak_bytes             0\n",
      "-min_residual_bytes         0\n",
      "-min_output_bytes           0\n",
      "-min_micros                 0\n",
      "-min_accelerator_micros     0\n",
      "-min_cpu_micros             0\n",
      "-min_params                 0\n",
      "-min_float_ops              1\n",
      "-min_occurrence             0\n",
      "-step                       -1\n",
      "-order_by                   float_ops\n",
      "-account_type_regexes       .*\n",
      "-start_name_regexes         .*\n",
      "-trim_name_regexes          \n",
      "-show_name_regexes          .*\n",
      "-hide_name_regexes          \n",
      "-account_displayed_op_only  true\n",
      "-select                     float_ops\n",
      "-output                     stdout:\n",
      "\n",
      "==================Model Analysis Report======================\n",
      "\n",
      "Doc:\n",
      "scope: The nodes in the model graph are organized by their names, which is hierarchical like filesystem.\n",
      "flops: Number of float operations. Note: Please read the implementation for the math behind it.\n",
      "\n",
      "Profile:\n",
      "node name | # float_ops\n",
      "_TFProfRoot (--/14.83m flops)\n",
      "  model_2/conv2d_39/Conv2D (1.74m/1.74m flops)\n",
      "  model_2/conv2d_33/Conv2D (1.45m/1.45m flops)\n",
      "  model_2/conv2d_38/Conv2D (1.42m/1.42m flops)\n",
      "  model_2/conv2d_36/Conv2D (1.35m/1.35m flops)\n",
      "  model_2/conv2d_37/Conv2D (1.33m/1.33m flops)\n",
      "  model_2/conv2d_35/Conv2D (1.12m/1.12m flops)\n",
      "  model_2/conv2d_41/Conv2D (1.10m/1.10m flops)\n",
      "  model_2/conv2d_31/Conv2D (1.10m/1.10m flops)\n",
      "  model_2/conv2d_34/Conv2D (706.62k/706.62k flops)\n",
      "  model_2/conv2d_40/Conv2D (670.18k/670.18k flops)\n",
      "  model_2/conv2d_29/Conv2D (655.36k/655.36k flops)\n",
      "  model_2/conv2d_32/Conv2D (595.20k/595.20k flops)\n",
      "  model_2/conv2d_30/Conv2D (440.32k/440.32k flops)\n",
      "  model_2/conv2d_28/Conv2D (262.14k/262.14k flops)\n",
      "  model_2/depthwise_conv2d_26/depthwise (147.46k/147.46k flops)\n",
      "  model_2/depthwise_conv2d_28/depthwise (99.07k/99.07k flops)\n",
      "  model_2/depthwise_conv2d_30/depthwise (53.57k/53.57k flops)\n",
      "  model_2/depthwise_conv2d_27/depthwise (46.08k/46.08k flops)\n",
      "  model_2/depthwise_conv2d_36/depthwise (33.55k/33.55k flops)\n",
      "  model_2/depthwise_conv2d_34/depthwise (31.39k/31.39k flops)\n",
      "  model_2/depthwise_conv2d_29/depthwise (28.80k/28.80k flops)\n",
      "  model_2/depthwise_conv2d_33/depthwise (27.94k/27.94k flops)\n",
      "  model_2/depthwise_conv2d_35/depthwise (27.50k/27.50k flops)\n",
      "  model_2/depthwise_conv2d_32/depthwise (26.06k/26.06k flops)\n",
      "  model_2/batch_normalization_56/FusedBatchNormV3 (20.72k/20.72k flops)\n",
      "  model_2/depthwise_conv2d_31/depthwise (17.57k/17.57k flops)\n",
      "  model_2/batch_normalization_55/FusedBatchNormV3 (16.58k/16.58k flops)\n",
      "  model_2/batch_normalization_54/FusedBatchNormV3 (16.58k/16.58k flops)\n",
      "  model_2/dense_2/MatMul (15.40k/15.40k flops)\n",
      "  model_2/batch_normalization_60/FusedBatchNormV3 (13.40k/13.40k flops)\n",
      "  model_2/depthwise_conv2d_38/depthwise (12.89k/12.89k flops)\n",
      "  model_2/batch_normalization_58/FusedBatchNormV3 (11.52k/11.52k flops)\n",
      "  model_2/batch_normalization_59/FusedBatchNormV3 (11.52k/11.52k flops)\n",
      "  model_2/conv2d_29/BiasAdd (10.24k/10.24k flops)\n",
      "  model_2/batch_normalization_64/FusedBatchNormV3 (9.27k/9.27k flops)\n",
      "  model_2/depthwise_conv2d_37/depthwise (8.42k/8.42k flops)\n",
      "  model_2/conv2d_28/BiasAdd (8.19k/8.19k flops)\n",
      "  model_2/depthwise_conv2d_26/BiasAdd (8.19k/8.19k flops)\n",
      "  model_2/batch_normalization_62/FusedBatchNormV3 (7.07k/7.07k flops)\n",
      "  model_2/batch_normalization_63/FusedBatchNormV3 (7.07k/7.07k flops)\n",
      "  model_2/batch_normalization_76/FusedBatchNormV3 (6.55k/6.55k flops)\n",
      "  model_2/batch_normalization_75/FusedBatchNormV3 (6.52k/6.52k flops)\n",
      "  model_2/batch_normalization_74/FusedBatchNormV3 (6.52k/6.52k flops)\n",
      "  model_2/conv2d_31/BiasAdd (6.40k/6.40k flops)\n",
      "  model_2/batch_normalization_80/FusedBatchNormV3 (6.16k/6.16k flops)\n",
      "  model_2/batch_normalization_71/FusedBatchNormV3 (6.10k/6.10k flops)\n",
      "  model_2/batch_normalization_70/FusedBatchNormV3 (6.10k/6.10k flops)\n",
      "  model_2/batch_normalization_79/FusedBatchNormV3 (5.73k/5.73k flops)\n",
      "  model_2/batch_normalization_78/FusedBatchNormV3 (5.73k/5.73k flops)\n",
      "  model_2/conv2d_30/BiasAdd (5.50k/5.50k flops)\n",
      "  model_2/depthwise_conv2d_28/BiasAdd (5.50k/5.50k flops)\n",
      "  model_2/batch_normalization_69/FusedBatchNormV3 (5.43k/5.43k flops)\n",
      "  model_2/batch_normalization_68/FusedBatchNormV3 (5.43k/5.43k flops)\n",
      "  model_2/batch_normalization_57/FusedBatchNormV3 (5.36k/5.36k flops)\n",
      "  model_2/batch_normalization_73/FusedBatchNormV3 (5.35k/5.35k flops)\n",
      "  model_2/batch_normalization_72/FusedBatchNormV3 (5.35k/5.35k flops)\n",
      "  model_2/batch_normalization_67/FusedBatchNormV3 (5.07k/5.07k flops)\n",
      "  model_2/batch_normalization_66/FusedBatchNormV3 (5.07k/5.07k flops)\n",
      "  model_2/conv2d_33/BiasAdd (3.90k/3.90k flops)\n",
      "  model_2/batch_normalization_61/FusedBatchNormV3 (3.80k/3.80k flops)\n",
      "  model_2/batch_normalization_77/FusedBatchNormV3 (3.74k/3.74k flops)\n",
      "  model_2/batch_normalization_65/FusedBatchNormV3 (3.42k/3.42k flops)\n",
      "  model_2/depthwise_conv2d_30/BiasAdd (2.98k/2.98k flops)\n",
      "  model_2/conv2d_32/BiasAdd (2.98k/2.98k flops)\n",
      "  model_2/depthwise_conv2d_27/BiasAdd (2.56k/2.56k flops)\n",
      "  model_2/conv2d_39/BiasAdd (1.87k/1.87k flops)\n",
      "  model_2/depthwise_conv2d_36/BiasAdd (1.86k/1.86k flops)\n",
      "  model_2/conv2d_38/BiasAdd (1.86k/1.86k flops)\n",
      "  model_2/conv2d_36/BiasAdd (1.74k/1.74k flops)\n",
      "  model_2/depthwise_conv2d_34/BiasAdd (1.74k/1.74k flops)\n",
      "  model_2/depthwise_conv2d_29/BiasAdd (1.60k/1.60k flops)\n",
      "  model_2/conv2d_35/BiasAdd (1.55k/1.55k flops)\n",
      "  model_2/depthwise_conv2d_33/BiasAdd (1.55k/1.55k flops)\n",
      "  model_2/depthwise_conv2d_35/BiasAdd (1.53k/1.53k flops)\n",
      "  model_2/conv2d_37/BiasAdd (1.53k/1.53k flops)\n",
      "  model_2/depthwise_conv2d_32/BiasAdd (1.45k/1.45k flops)\n",
      "  model_2/conv2d_34/BiasAdd (1.45k/1.45k flops)\n",
      "  model_2/depthwise_conv2d_31/BiasAdd (976/976 flops)\n",
      "  model_2/conv2d_41/BiasAdd (770/770 flops)\n",
      "  model_2/global_average_pooling2d_2/Mean (770/770 flops)\n",
      "  model_2/depthwise_conv2d_38/BiasAdd (716/716 flops)\n",
      "  model_2/conv2d_40/BiasAdd (716/716 flops)\n",
      "  model_2/depthwise_conv2d_37/BiasAdd (468/468 flops)\n",
      "  model_2/dense_2/Softmax (50/50 flops)\n",
      "  model_2/dense_2/BiasAdd (10/10 flops)\n",
      "\n",
      "======================End of Report==========================\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "0.941156\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-30 13:39:39.497310: I tensorflow/core/grappler/devices.cc:66] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0\n",
      "2022-04-30 13:39:39.497423: I tensorflow/core/grappler/clusters/single_machine.cc:357] Starting new session\n",
      "2022-04-30 13:39:39.501381: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:1137] Optimization results for grappler item: graph_to_optimize\n",
      "  function_optimizer: function_optimizer did nothing. time = 0.004ms.\n",
      "  function_optimizer: function_optimizer did nothing. time = 0.001ms.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=========================Options=============================\n",
      "-max_depth                  10000\n",
      "-min_bytes                  0\n",
      "-min_peak_bytes             0\n",
      "-min_residual_bytes         0\n",
      "-min_output_bytes           0\n",
      "-min_micros                 0\n",
      "-min_accelerator_micros     0\n",
      "-min_cpu_micros             0\n",
      "-min_params                 0\n",
      "-min_float_ops              1\n",
      "-min_occurrence             0\n",
      "-step                       -1\n",
      "-order_by                   float_ops\n",
      "-account_type_regexes       .*\n",
      "-start_name_regexes         .*\n",
      "-trim_name_regexes          \n",
      "-show_name_regexes          .*\n",
      "-hide_name_regexes          \n",
      "-account_displayed_op_only  true\n",
      "-select                     float_ops\n",
      "-output                     stdout:\n",
      "\n",
      "==================Model Analysis Report======================\n",
      "\n",
      "Doc:\n",
      "scope: The nodes in the model graph are organized by their names, which is hierarchical like filesystem.\n",
      "flops: Number of float operations. Note: Please read the implementation for the math behind it.\n",
      "\n",
      "Profile:\n",
      "node name | # float_ops\n",
      "_TFProfRoot (--/13.41m flops)\n",
      "  model_3/conv2d_45/Conv2D (1.78m/1.78m flops)\n",
      "  model_3/conv2d_51/Conv2D (1.78m/1.78m flops)\n",
      "  model_3/conv2d_52/Conv2D (1.58m/1.58m flops)\n",
      "  model_3/conv2d_53/Conv2D (1.36m/1.36m flops)\n",
      "  model_3/conv2d_55/Conv2D (1.21m/1.21m flops)\n",
      "  model_3/conv2d_50/Conv2D (1.07m/1.07m flops)\n",
      "  model_3/conv2d_47/Conv2D (619.26k/619.26k flops)\n",
      "  model_3/conv2d_54/Conv2D (586.27k/586.27k flops)\n",
      "  model_3/conv2d_43/Conv2D (557.06k/557.06k flops)\n",
      "  model_3/conv2d_44/Conv2D (513.54k/513.54k flops)\n",
      "  model_3/conv2d_49/Conv2D (504.16k/504.16k flops)\n",
      "  model_3/conv2d_46/Conv2D (445.57k/445.57k flops)\n",
      "  model_3/conv2d_48/Conv2D (301.76k/301.76k flops)\n",
      "  model_3/conv2d_42/Conv2D (262.14k/262.14k flops)\n",
      "  model_3/depthwise_conv2d_39/depthwise (147.46k/147.46k flops)\n",
      "  model_3/depthwise_conv2d_41/depthwise (135.94k/135.94k flops)\n",
      "  model_3/depthwise_conv2d_40/depthwise (39.17k/39.17k flops)\n",
      "  model_3/depthwise_conv2d_47/depthwise (34.99k/34.99k flops)\n",
      "  model_3/depthwise_conv2d_43/depthwise (33.98k/33.98k flops)\n",
      "  model_3/depthwise_conv2d_42/depthwise (33.98k/33.98k flops)\n",
      "  model_3/depthwise_conv2d_48/depthwise (32.98k/32.98k flops)\n",
      "  model_3/depthwise_conv2d_49/depthwise (30.96k/30.96k flops)\n",
      "  model_3/depthwise_conv2d_46/depthwise (19.73k/19.73k flops)\n",
      "  model_3/batch_normalization_83/FusedBatchNormV3 (17.61k/17.61k flops)\n",
      "  model_3/batch_normalization_82/FusedBatchNormV3 (16.58k/16.58k flops)\n",
      "  model_3/batch_normalization_81/FusedBatchNormV3 (16.58k/16.58k flops)\n",
      "  model_3/depthwise_conv2d_45/depthwise (16.56k/16.56k flops)\n",
      "  model_3/dense_3/MatMul (16.20k/16.20k flops)\n",
      "  model_3/batch_normalization_87/FusedBatchNormV3 (15.81k/15.81k flops)\n",
      "  model_3/batch_normalization_86/FusedBatchNormV3 (15.81k/15.81k flops)\n",
      "  model_3/batch_normalization_85/FusedBatchNormV3 (15.81k/15.81k flops)\n",
      "  model_3/depthwise_conv2d_51/depthwise (13.39k/13.39k flops)\n",
      "  model_3/depthwise_conv2d_44/depthwise (11.81k/11.81k flops)\n",
      "  model_3/conv2d_43/BiasAdd (8.70k/8.70k flops)\n",
      "  model_3/conv2d_42/BiasAdd (8.19k/8.19k flops)\n",
      "  model_3/depthwise_conv2d_39/BiasAdd (8.19k/8.19k flops)\n",
      "  model_3/conv2d_44/BiasAdd (7.55k/7.55k flops)\n",
      "  model_3/conv2d_45/BiasAdd (7.55k/7.55k flops)\n",
      "  model_3/depthwise_conv2d_41/BiasAdd (7.55k/7.55k flops)\n",
      "  model_3/depthwise_conv2d_50/depthwise (7.09k/7.09k flops)\n",
      "  model_3/batch_normalization_98/FusedBatchNormV3 (6.80k/6.80k flops)\n",
      "  model_3/batch_normalization_97/FusedBatchNormV3 (6.80k/6.80k flops)\n",
      "  model_3/batch_normalization_107/FusedBatchNormV3 (6.48k/6.48k flops)\n",
      "  model_3/batch_normalization_99/FusedBatchNormV3 (6.41k/6.41k flops)\n",
      "  model_3/batch_normalization_100/FusedBatchNormV3 (6.41k/6.41k flops)\n",
      "  model_3/batch_normalization_91/FusedBatchNormV3 (6.23k/6.23k flops)\n",
      "  model_3/batch_normalization_101/FusedBatchNormV3 (6.02k/6.02k flops)\n",
      "  model_3/batch_normalization_102/FusedBatchNormV3 (6.02k/6.02k flops)\n",
      "  model_3/batch_normalization_105/FusedBatchNormV3 (5.95k/5.95k flops)\n",
      "  model_3/batch_normalization_106/FusedBatchNormV3 (5.95k/5.95k flops)\n",
      "  model_3/batch_normalization_103/FusedBatchNormV3 (5.52k/5.52k flops)\n",
      "  model_3/batch_normalization_84/FusedBatchNormV3 (4.56k/4.56k flops)\n",
      "  model_3/batch_normalization_89/FusedBatchNormV3 (4.48k/4.48k flops)\n",
      "  model_3/batch_normalization_88/FusedBatchNormV3 (4.48k/4.48k flops)\n",
      "  model_3/batch_normalization_90/FusedBatchNormV3 (4.48k/4.48k flops)\n",
      "  model_3/batch_normalization_96/FusedBatchNormV3 (3.84k/3.84k flops)\n",
      "  model_3/batch_normalization_95/FusedBatchNormV3 (3.84k/3.84k flops)\n",
      "  model_3/batch_normalization_94/FusedBatchNormV3 (3.22k/3.22k flops)\n",
      "  model_3/batch_normalization_93/FusedBatchNormV3 (3.22k/3.22k flops)\n",
      "  model_3/batch_normalization_104/FusedBatchNormV3 (3.15k/3.15k flops)\n",
      "  model_3/conv2d_47/BiasAdd (2.62k/2.62k flops)\n",
      "  model_3/batch_normalization_92/FusedBatchNormV3 (2.30k/2.30k flops)\n",
      "  model_3/depthwise_conv2d_40/BiasAdd (2.18k/2.18k flops)\n",
      "  model_3/depthwise_conv2d_47/BiasAdd (1.94k/1.94k flops)\n",
      "  model_3/conv2d_50/BiasAdd (1.94k/1.94k flops)\n",
      "  model_3/conv2d_46/BiasAdd (1.89k/1.89k flops)\n",
      "  model_3/depthwise_conv2d_42/BiasAdd (1.89k/1.89k flops)\n",
      "  model_3/depthwise_conv2d_43/BiasAdd (1.89k/1.89k flops)\n",
      "  model_3/depthwise_conv2d_48/BiasAdd (1.83k/1.83k flops)\n",
      "  model_3/conv2d_51/BiasAdd (1.83k/1.83k flops)\n",
      "  model_3/depthwise_conv2d_49/BiasAdd (1.72k/1.72k flops)\n",
      "  model_3/conv2d_52/BiasAdd (1.72k/1.72k flops)\n",
      "  model_3/conv2d_53/BiasAdd (1.58k/1.58k flops)\n",
      "  model_3/depthwise_conv2d_46/BiasAdd (1.10k/1.10k flops)\n",
      "  model_3/conv2d_49/BiasAdd (1.10k/1.10k flops)\n",
      "  model_3/depthwise_conv2d_45/BiasAdd (920/920 flops)\n",
      "  model_3/conv2d_48/BiasAdd (920/920 flops)\n",
      "  model_3/conv2d_55/BiasAdd (810/810 flops)\n",
      "  model_3/global_average_pooling2d_3/Mean (810/810 flops)\n",
      "  model_3/conv2d_54/BiasAdd (744/744 flops)\n",
      "  model_3/depthwise_conv2d_51/BiasAdd (744/744 flops)\n",
      "  model_3/depthwise_conv2d_44/BiasAdd (656/656 flops)\n",
      "  model_3/depthwise_conv2d_50/BiasAdd (394/394 flops)\n",
      "  model_3/dense_3/Softmax (50/50 flops)\n",
      "  model_3/dense_3/BiasAdd (10/10 flops)\n",
      "\n",
      "======================End of Report==========================\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "0.916644\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-30 13:39:40.421928: I tensorflow/core/grappler/devices.cc:66] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0\n",
      "2022-04-30 13:39:40.422049: I tensorflow/core/grappler/clusters/single_machine.cc:357] Starting new session\n",
      "2022-04-30 13:39:40.426020: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:1137] Optimization results for grappler item: graph_to_optimize\n",
      "  function_optimizer: function_optimizer did nothing. time = 0.005ms.\n",
      "  function_optimizer: function_optimizer did nothing. time = 0ms.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=========================Options=============================\n",
      "-max_depth                  10000\n",
      "-min_bytes                  0\n",
      "-min_peak_bytes             0\n",
      "-min_residual_bytes         0\n",
      "-min_output_bytes           0\n",
      "-min_micros                 0\n",
      "-min_accelerator_micros     0\n",
      "-min_cpu_micros             0\n",
      "-min_params                 0\n",
      "-min_float_ops              1\n",
      "-min_occurrence             0\n",
      "-step                       -1\n",
      "-order_by                   float_ops\n",
      "-account_type_regexes       .*\n",
      "-start_name_regexes         .*\n",
      "-trim_name_regexes          \n",
      "-show_name_regexes          .*\n",
      "-hide_name_regexes          \n",
      "-account_displayed_op_only  true\n",
      "-select                     float_ops\n",
      "-output                     stdout:\n",
      "\n",
      "==================Model Analysis Report======================\n",
      "\n",
      "Doc:\n",
      "scope: The nodes in the model graph are organized by their names, which is hierarchical like filesystem.\n",
      "flops: Number of float operations. Note: Please read the implementation for the math behind it.\n",
      "\n",
      "Profile:\n",
      "node name | # float_ops\n",
      "_TFProfRoot (--/14.78m flops)\n",
      "  model_4/conv2d_67/Conv2D (1.82m/1.82m flops)\n",
      "  model_4/conv2d_66/Conv2D (1.59m/1.59m flops)\n",
      "  model_4/conv2d_61/Conv2D (1.53m/1.53m flops)\n",
      "  model_4/conv2d_69/Conv2D (1.39m/1.39m flops)\n",
      "  model_4/conv2d_65/Conv2D (1.37m/1.37m flops)\n",
      "  model_4/conv2d_64/Conv2D (1.34m/1.34m flops)\n",
      "  model_4/conv2d_63/Conv2D (1.21m/1.21m flops)\n",
      "  model_4/conv2d_57/Conv2D (753.66k/753.66k flops)\n",
      "  model_4/conv2d_68/Conv2D (741.87k/741.87k flops)\n",
      "  model_4/conv2d_62/Conv2D (713.66k/713.66k flops)\n",
      "  model_4/conv2d_59/Conv2D (465.92k/465.92k flops)\n",
      "  model_4/conv2d_60/Conv2D (452.48k/452.48k flops)\n",
      "  model_4/conv2d_58/Conv2D (306.18k/306.18k flops)\n",
      "  model_4/conv2d_56/Conv2D (262.14k/262.14k flops)\n",
      "  model_4/depthwise_conv2d_52/depthwise (147.46k/147.46k flops)\n",
      "  model_4/depthwise_conv2d_54/depthwise (59.90k/59.90k flops)\n",
      "  model_4/depthwise_conv2d_56/depthwise (58.18k/58.18k flops)\n",
      "  model_4/depthwise_conv2d_53/depthwise (52.99k/52.99k flops)\n",
      "  model_4/depthwise_conv2d_62/depthwise (35.14k/35.14k flops)\n",
      "  model_4/depthwise_conv2d_60/depthwise (30.24k/30.24k flops)\n",
      "  model_4/depthwise_conv2d_61/depthwise (29.38k/29.38k flops)\n",
      "  model_4/depthwise_conv2d_59/depthwise (28.80k/28.80k flops)\n",
      "  model_4/depthwise_conv2d_58/depthwise (27.22k/27.22k flops)\n",
      "  model_4/batch_normalization_110/FusedBatchNormV3 (23.83k/23.83k flops)\n",
      "  model_4/depthwise_conv2d_55/depthwise (20.16k/20.16k flops)\n",
      "  model_4/dense_4/MatMul (17.48k/17.48k flops)\n",
      "  model_4/depthwise_conv2d_57/depthwise (16.99k/16.99k flops)\n",
      "  model_4/batch_normalization_109/FusedBatchNormV3 (16.58k/16.58k flops)\n",
      "  model_4/batch_normalization_108/FusedBatchNormV3 (16.58k/16.58k flops)\n",
      "  model_4/depthwise_conv2d_64/depthwise (14.33k/14.33k flops)\n",
      "  model_4/conv2d_57/BiasAdd (11.78k/11.78k flops)\n",
      "  model_4/batch_normalization_114/FusedBatchNormV3 (9.38k/9.38k flops)\n",
      "  model_4/batch_normalization_118/FusedBatchNormV3 (8.97k/8.97k flops)\n",
      "  model_4/depthwise_conv2d_63/depthwise (8.39k/8.39k flops)\n",
      "  model_4/conv2d_56/BiasAdd (8.19k/8.19k flops)\n",
      "  model_4/depthwise_conv2d_52/BiasAdd (8.19k/8.19k flops)\n",
      "  model_4/batch_normalization_116/FusedBatchNormV3 (7.68k/7.68k flops)\n",
      "  model_4/batch_normalization_117/FusedBatchNormV3 (7.68k/7.68k flops)\n",
      "  model_4/batch_normalization_134/FusedBatchNormV3 (6.99k/6.99k flops)\n",
      "  model_4/batch_normalization_113/FusedBatchNormV3 (6.97k/6.97k flops)\n",
      "  model_4/batch_normalization_112/FusedBatchNormV3 (6.97k/6.97k flops)\n",
      "  model_4/batch_normalization_129/FusedBatchNormV3 (6.83k/6.83k flops)\n",
      "  model_4/batch_normalization_128/FusedBatchNormV3 (6.83k/6.83k flops)\n",
      "  model_4/batch_normalization_130/FusedBatchNormV3 (6.52k/6.52k flops)\n",
      "  model_4/batch_normalization_132/FusedBatchNormV3 (6.37k/6.37k flops)\n",
      "  model_4/batch_normalization_133/FusedBatchNormV3 (6.37k/6.37k flops)\n",
      "  model_4/batch_normalization_111/FusedBatchNormV3 (6.16k/6.16k flops)\n",
      "  model_4/batch_normalization_125/FusedBatchNormV3 (5.88k/5.88k flops)\n",
      "  model_4/batch_normalization_124/FusedBatchNormV3 (5.88k/5.88k flops)\n",
      "  model_4/batch_normalization_126/FusedBatchNormV3 (5.71k/5.71k flops)\n",
      "  model_4/batch_normalization_127/FusedBatchNormV3 (5.71k/5.71k flops)\n",
      "  model_4/batch_normalization_123/FusedBatchNormV3 (5.60k/5.60k flops)\n",
      "  model_4/batch_normalization_122/FusedBatchNormV3 (5.60k/5.60k flops)\n",
      "  model_4/batch_normalization_120/FusedBatchNormV3 (5.29k/5.29k flops)\n",
      "  model_4/batch_normalization_121/FusedBatchNormV3 (5.29k/5.29k flops)\n",
      "  model_4/conv2d_59/BiasAdd (4.48k/4.48k flops)\n",
      "  model_4/conv2d_61/BiasAdd (3.78k/3.78k flops)\n",
      "  model_4/batch_normalization_131/FusedBatchNormV3 (3.73k/3.73k flops)\n",
      "  model_4/conv2d_58/BiasAdd (3.33k/3.33k flops)\n",
      "  model_4/depthwise_conv2d_54/BiasAdd (3.33k/3.33k flops)\n",
      "  model_4/batch_normalization_119/FusedBatchNormV3 (3.30k/3.30k flops)\n",
      "  model_4/conv2d_60/BiasAdd (3.23k/3.23k flops)\n",
      "  model_4/depthwise_conv2d_56/BiasAdd (3.23k/3.23k flops)\n",
      "  model_4/depthwise_conv2d_53/BiasAdd (2.94k/2.94k flops)\n",
      "  model_4/batch_normalization_115/FusedBatchNormV3 (2.66k/2.66k flops)\n",
      "  model_4/depthwise_conv2d_62/BiasAdd (1.95k/1.95k flops)\n",
      "  model_4/conv2d_66/BiasAdd (1.95k/1.95k flops)\n",
      "  model_4/conv2d_67/BiasAdd (1.86k/1.86k flops)\n",
      "  model_4/conv2d_64/BiasAdd (1.68k/1.68k flops)\n",
      "  model_4/depthwise_conv2d_60/BiasAdd (1.68k/1.68k flops)\n",
      "  model_4/conv2d_65/BiasAdd (1.63k/1.63k flops)\n",
      "  model_4/depthwise_conv2d_61/BiasAdd (1.63k/1.63k flops)\n",
      "  model_4/conv2d_63/BiasAdd (1.60k/1.60k flops)\n",
      "  model_4/depthwise_conv2d_59/BiasAdd (1.60k/1.60k flops)\n",
      "  model_4/depthwise_conv2d_58/BiasAdd (1.51k/1.51k flops)\n",
      "  model_4/conv2d_62/BiasAdd (1.51k/1.51k flops)\n",
      "  model_4/depthwise_conv2d_55/BiasAdd (1.12k/1.12k flops)\n",
      "  model_4/depthwise_conv2d_57/BiasAdd (944/944 flops)\n",
      "  model_4/global_average_pooling2d_4/Mean (874/874 flops)\n",
      "  model_4/conv2d_69/BiasAdd (874/874 flops)\n",
      "  model_4/conv2d_68/BiasAdd (796/796 flops)\n",
      "  model_4/depthwise_conv2d_64/BiasAdd (796/796 flops)\n",
      "  model_4/depthwise_conv2d_63/BiasAdd (466/466 flops)\n",
      "  model_4/dense_4/Softmax (50/50 flops)\n",
      "  model_4/dense_4/BiasAdd (10/10 flops)\n",
      "\n",
      "======================End of Report==========================\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "0.952372\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-30 13:39:41.442413: I tensorflow/core/grappler/devices.cc:66] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0\n",
      "2022-04-30 13:39:41.442527: I tensorflow/core/grappler/clusters/single_machine.cc:357] Starting new session\n",
      "2022-04-30 13:39:41.446610: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:1137] Optimization results for grappler item: graph_to_optimize\n",
      "  function_optimizer: function_optimizer did nothing. time = 0.005ms.\n",
      "  function_optimizer: function_optimizer did nothing. time = 0.001ms.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=========================Options=============================\n",
      "-max_depth                  10000\n",
      "-min_bytes                  0\n",
      "-min_peak_bytes             0\n",
      "-min_residual_bytes         0\n",
      "-min_output_bytes           0\n",
      "-min_micros                 0\n",
      "-min_accelerator_micros     0\n",
      "-min_cpu_micros             0\n",
      "-min_params                 0\n",
      "-min_float_ops              1\n",
      "-min_occurrence             0\n",
      "-step                       -1\n",
      "-order_by                   float_ops\n",
      "-account_type_regexes       .*\n",
      "-start_name_regexes         .*\n",
      "-trim_name_regexes          \n",
      "-show_name_regexes          .*\n",
      "-hide_name_regexes          \n",
      "-account_displayed_op_only  true\n",
      "-select                     float_ops\n",
      "-output                     stdout:\n",
      "\n",
      "==================Model Analysis Report======================\n",
      "\n",
      "Doc:\n",
      "scope: The nodes in the model graph are organized by their names, which is hierarchical like filesystem.\n",
      "flops: Number of float operations. Note: Please read the implementation for the math behind it.\n",
      "\n",
      "Profile:\n",
      "node name | # float_ops\n",
      "_TFProfRoot (--/14.21m flops)\n",
      "  model_5/conv2d_75/Conv2D (1.95m/1.95m flops)\n",
      "  model_5/conv2d_79/Conv2D (1.46m/1.46m flops)\n",
      "  model_5/conv2d_78/Conv2D (1.40m/1.40m flops)\n",
      "  model_5/conv2d_80/Conv2D (1.38m/1.38m flops)\n",
      "  model_5/conv2d_81/Conv2D (1.35m/1.35m flops)\n",
      "  model_5/conv2d_83/Conv2D (992.88k/992.88k flops)\n",
      "  model_5/conv2d_73/Conv2D (875.52k/875.52k flops)\n",
      "  model_5/conv2d_77/Conv2D (840.32k/840.32k flops)\n",
      "  model_5/conv2d_74/Conv2D (702.72k/702.72k flops)\n",
      "  model_5/conv2d_71/Conv2D (688.13k/688.13k flops)\n",
      "  model_5/conv2d_76/Conv2D (520.00k/520.00k flops)\n",
      "  model_5/conv2d_82/Conv2D (516.60k/516.60k flops)\n",
      "  model_5/conv2d_72/Conv2D (408.58k/408.58k flops)\n",
      "  model_5/conv2d_70/Conv2D (262.14k/262.14k flops)\n",
      "  model_5/depthwise_conv2d_65/depthwise (147.46k/147.46k flops)\n",
      "  model_5/depthwise_conv2d_67/depthwise (87.55k/87.55k flops)\n",
      "  model_5/depthwise_conv2d_69/depthwise (70.27k/70.27k flops)\n",
      "  model_5/depthwise_conv2d_66/depthwise (48.38k/48.38k flops)\n",
      "  model_5/depthwise_conv2d_73/depthwise (31.25k/31.25k flops)\n",
      "  model_5/depthwise_conv2d_74/depthwise (30.24k/30.24k flops)\n",
      "  model_5/depthwise_conv2d_75/depthwise (29.66k/29.66k flops)\n",
      "  model_5/depthwise_conv2d_72/depthwise (29.09k/29.09k flops)\n",
      "  model_5/depthwise_conv2d_68/depthwise (25.92k/25.92k flops)\n",
      "  model_5/batch_normalization_137/FusedBatchNormV3 (21.76k/21.76k flops)\n",
      "  model_5/depthwise_conv2d_71/depthwise (18.72k/18.72k flops)\n",
      "  model_5/depthwise_conv2d_70/depthwise (18.00k/18.00k flops)\n",
      "  model_5/batch_normalization_136/FusedBatchNormV3 (16.58k/16.58k flops)\n",
      "  model_5/batch_normalization_135/FusedBatchNormV3 (16.58k/16.58k flops)\n",
      "  model_5/dense_5/MatMul (15.76k/15.76k flops)\n",
      "  model_5/batch_normalization_141/FusedBatchNormV3 (12.06k/12.06k flops)\n",
      "  model_5/depthwise_conv2d_77/depthwise (11.34k/11.34k flops)\n",
      "  model_5/conv2d_71/BiasAdd (10.75k/10.75k flops)\n",
      "  model_5/batch_normalization_139/FusedBatchNormV3 (10.18k/10.18k flops)\n",
      "  model_5/batch_normalization_140/FusedBatchNormV3 (10.18k/10.18k flops)\n",
      "  model_5/batch_normalization_145/FusedBatchNormV3 (9.50k/9.50k flops)\n",
      "  model_5/batch_normalization_143/FusedBatchNormV3 (9.27k/9.27k flops)\n",
      "  model_5/batch_normalization_144/FusedBatchNormV3 (9.27k/9.27k flops)\n",
      "  model_5/conv2d_70/BiasAdd (8.19k/8.19k flops)\n",
      "  model_5/depthwise_conv2d_65/BiasAdd (8.19k/8.19k flops)\n",
      "  model_5/depthwise_conv2d_76/depthwise (7.38k/7.38k flops)\n",
      "  model_5/batch_normalization_161/FusedBatchNormV3 (6.30k/6.30k flops)\n",
      "  model_5/batch_normalization_151/FusedBatchNormV3 (6.08k/6.08k flops)\n",
      "  model_5/batch_normalization_152/FusedBatchNormV3 (6.08k/6.08k flops)\n",
      "  model_5/batch_normalization_154/FusedBatchNormV3 (5.88k/5.88k flops)\n",
      "  model_5/batch_normalization_153/FusedBatchNormV3 (5.88k/5.88k flops)\n",
      "  model_5/batch_normalization_156/FusedBatchNormV3 (5.77k/5.77k flops)\n",
      "  model_5/batch_normalization_155/FusedBatchNormV3 (5.77k/5.77k flops)\n",
      "  model_5/conv2d_73/BiasAdd (5.76k/5.76k flops)\n",
      "  model_5/batch_normalization_157/FusedBatchNormV3 (5.74k/5.74k flops)\n",
      "  model_5/batch_normalization_150/FusedBatchNormV3 (5.66k/5.66k flops)\n",
      "  model_5/batch_normalization_149/FusedBatchNormV3 (5.66k/5.66k flops)\n",
      "  model_5/batch_normalization_138/FusedBatchNormV3 (5.63k/5.63k flops)\n",
      "  model_5/batch_normalization_160/FusedBatchNormV3 (5.04k/5.04k flops)\n",
      "  model_5/batch_normalization_159/FusedBatchNormV3 (5.04k/5.04k flops)\n",
      "  model_5/conv2d_72/BiasAdd (4.86k/4.86k flops)\n",
      "  model_5/depthwise_conv2d_67/BiasAdd (4.86k/4.86k flops)\n",
      "  model_5/conv2d_75/BiasAdd (4.00k/4.00k flops)\n",
      "  model_5/depthwise_conv2d_69/BiasAdd (3.90k/3.90k flops)\n",
      "  model_5/conv2d_74/BiasAdd (3.90k/3.90k flops)\n",
      "  model_5/batch_normalization_148/FusedBatchNormV3 (3.64k/3.64k flops)\n",
      "  model_5/batch_normalization_147/FusedBatchNormV3 (3.64k/3.64k flops)\n",
      "  model_5/batch_normalization_146/FusedBatchNormV3 (3.50k/3.50k flops)\n",
      "  model_5/batch_normalization_142/FusedBatchNormV3 (3.42k/3.42k flops)\n",
      "  model_5/batch_normalization_158/FusedBatchNormV3 (3.28k/3.28k flops)\n",
      "  model_5/depthwise_conv2d_66/BiasAdd (2.69k/2.69k flops)\n",
      "  model_5/depthwise_conv2d_73/BiasAdd (1.74k/1.74k flops)\n",
      "  model_5/conv2d_78/BiasAdd (1.74k/1.74k flops)\n",
      "  model_5/depthwise_conv2d_74/BiasAdd (1.68k/1.68k flops)\n",
      "  model_5/conv2d_79/BiasAdd (1.68k/1.68k flops)\n",
      "  model_5/depthwise_conv2d_75/BiasAdd (1.65k/1.65k flops)\n",
      "  model_5/conv2d_80/BiasAdd (1.65k/1.65k flops)\n",
      "  model_5/conv2d_81/BiasAdd (1.64k/1.64k flops)\n",
      "  model_5/depthwise_conv2d_72/BiasAdd (1.62k/1.62k flops)\n",
      "  model_5/conv2d_77/BiasAdd (1.62k/1.62k flops)\n",
      "  model_5/depthwise_conv2d_68/BiasAdd (1.44k/1.44k flops)\n",
      "  model_5/depthwise_conv2d_71/BiasAdd (1.04k/1.04k flops)\n",
      "  model_5/conv2d_76/BiasAdd (1.04k/1.04k flops)\n",
      "  model_5/depthwise_conv2d_70/BiasAdd (1.00k/1.00k flops)\n",
      "  model_5/conv2d_83/BiasAdd (788/788 flops)\n",
      "  model_5/global_average_pooling2d_5/Mean (788/788 flops)\n",
      "  model_5/conv2d_82/BiasAdd (630/630 flops)\n",
      "  model_5/depthwise_conv2d_77/BiasAdd (630/630 flops)\n",
      "  model_5/depthwise_conv2d_76/BiasAdd (410/410 flops)\n",
      "  model_5/dense_5/Softmax (50/50 flops)\n",
      "  model_5/dense_5/BiasAdd (10/10 flops)\n",
      "\n",
      "======================End of Report==========================\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "0.942316\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-30 13:39:42.353637: I tensorflow/core/grappler/devices.cc:66] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0\n",
      "2022-04-30 13:39:42.353747: I tensorflow/core/grappler/clusters/single_machine.cc:357] Starting new session\n",
      "2022-04-30 13:39:42.357724: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:1137] Optimization results for grappler item: graph_to_optimize\n",
      "  function_optimizer: function_optimizer did nothing. time = 0.005ms.\n",
      "  function_optimizer: function_optimizer did nothing. time = 0ms.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=========================Options=============================\n",
      "-max_depth                  10000\n",
      "-min_bytes                  0\n",
      "-min_peak_bytes             0\n",
      "-min_residual_bytes         0\n",
      "-min_output_bytes           0\n",
      "-min_micros                 0\n",
      "-min_accelerator_micros     0\n",
      "-min_cpu_micros             0\n",
      "-min_params                 0\n",
      "-min_float_ops              1\n",
      "-min_occurrence             0\n",
      "-step                       -1\n",
      "-order_by                   float_ops\n",
      "-account_type_regexes       .*\n",
      "-start_name_regexes         .*\n",
      "-trim_name_regexes          \n",
      "-show_name_regexes          .*\n",
      "-hide_name_regexes          \n",
      "-account_displayed_op_only  true\n",
      "-select                     float_ops\n",
      "-output                     stdout:\n",
      "\n",
      "==================Model Analysis Report======================\n",
      "\n",
      "Doc:\n",
      "scope: The nodes in the model graph are organized by their names, which is hierarchical like filesystem.\n",
      "flops: Number of float operations. Note: Please read the implementation for the math behind it.\n",
      "\n",
      "Profile:\n",
      "node name | # float_ops\n",
      "_TFProfRoot (--/15.66m flops)\n",
      "  model_6/conv2d_93/Conv2D (2.01m/2.01m flops)\n",
      "  model_6/conv2d_92/Conv2D (1.85m/1.85m flops)\n",
      "  model_6/conv2d_94/Conv2D (1.81m/1.81m flops)\n",
      "  model_6/conv2d_95/Conv2D (1.55m/1.55m flops)\n",
      "  model_6/conv2d_91/Conv2D (1.54m/1.54m flops)\n",
      "  model_6/conv2d_89/Conv2D (1.08m/1.08m flops)\n",
      "  model_6/conv2d_97/Conv2D (1.04m/1.04m flops)\n",
      "  model_6/conv2d_87/Conv2D (887.81k/887.81k flops)\n",
      "  model_6/conv2d_90/Conv2D (742.37k/742.37k flops)\n",
      "  model_6/conv2d_85/Conv2D (655.36k/655.36k flops)\n",
      "  model_6/conv2d_96/Conv2D (532.43k/532.43k flops)\n",
      "  model_6/conv2d_88/Conv2D (496.13k/496.13k flops)\n",
      "  model_6/conv2d_86/Conv2D (348.16k/348.16k flops)\n",
      "  model_6/conv2d_84/Conv2D (262.14k/262.14k flops)\n",
      "  model_6/depthwise_conv2d_78/depthwise (147.46k/147.46k flops)\n",
      "  model_6/depthwise_conv2d_80/depthwise (78.34k/78.34k flops)\n",
      "  model_6/depthwise_conv2d_79/depthwise (46.08k/46.08k flops)\n",
      "  model_6/depthwise_conv2d_82/depthwise (43.78k/43.78k flops)\n",
      "  model_6/depthwise_conv2d_86/depthwise (36.29k/36.29k flops)\n",
      "  model_6/depthwise_conv2d_87/depthwise (35.86k/35.86k flops)\n",
      "  model_6/depthwise_conv2d_85/depthwise (33.12k/33.12k flops)\n",
      "  model_6/depthwise_conv2d_88/depthwise (32.69k/32.69k flops)\n",
      "  model_6/depthwise_conv2d_84/depthwise (30.10k/30.10k flops)\n",
      "  model_6/depthwise_conv2d_81/depthwise (29.38k/29.38k flops)\n",
      "  model_6/batch_normalization_164/FusedBatchNormV3 (20.72k/20.72k flops)\n",
      "  model_6/dense_6/MatMul (16.72k/16.72k flops)\n",
      "  model_6/batch_normalization_163/FusedBatchNormV3 (16.58k/16.58k flops)\n",
      "  model_6/batch_normalization_162/FusedBatchNormV3 (16.58k/16.58k flops)\n",
      "  model_6/depthwise_conv2d_83/depthwise (15.98k/15.98k flops)\n",
      "  model_6/batch_normalization_168/FusedBatchNormV3 (13.67k/13.67k flops)\n",
      "  model_6/depthwise_conv2d_90/depthwise (11.20k/11.20k flops)\n",
      "  model_6/conv2d_85/BiasAdd (10.24k/10.24k flops)\n",
      "  model_6/batch_normalization_166/FusedBatchNormV3 (9.11k/9.11k flops)\n",
      "  model_6/batch_normalization_167/FusedBatchNormV3 (9.11k/9.11k flops)\n",
      "  model_6/batch_normalization_172/FusedBatchNormV3 (8.44k/8.44k flops)\n",
      "  model_6/conv2d_84/BiasAdd (8.19k/8.19k flops)\n",
      "  model_6/depthwise_conv2d_78/BiasAdd (8.19k/8.19k flops)\n",
      "  model_6/depthwise_conv2d_89/depthwise (7.70k/7.70k flops)\n",
      "  model_6/batch_normalization_178/FusedBatchNormV3 (7.06k/7.06k flops)\n",
      "  model_6/batch_normalization_179/FusedBatchNormV3 (7.06k/7.06k flops)\n",
      "  model_6/batch_normalization_180/FusedBatchNormV3 (6.97k/6.97k flops)\n",
      "  model_6/batch_normalization_181/FusedBatchNormV3 (6.97k/6.97k flops)\n",
      "  model_6/batch_normalization_188/FusedBatchNormV3 (6.69k/6.69k flops)\n",
      "  model_6/conv2d_87/BiasAdd (6.53k/6.53k flops)\n",
      "  model_6/batch_normalization_176/FusedBatchNormV3 (6.44k/6.44k flops)\n",
      "  model_6/batch_normalization_177/FusedBatchNormV3 (6.44k/6.44k flops)\n",
      "  model_6/batch_normalization_182/FusedBatchNormV3 (6.36k/6.36k flops)\n",
      "  model_6/batch_normalization_183/FusedBatchNormV3 (6.36k/6.36k flops)\n",
      "  model_6/batch_normalization_184/FusedBatchNormV3 (5.99k/5.99k flops)\n",
      "  model_6/batch_normalization_175/FusedBatchNormV3 (5.85k/5.85k flops)\n",
      "  model_6/batch_normalization_174/FusedBatchNormV3 (5.85k/5.85k flops)\n",
      "  model_6/batch_normalization_170/FusedBatchNormV3 (5.78k/5.78k flops)\n",
      "  model_6/batch_normalization_171/FusedBatchNormV3 (5.78k/5.78k flops)\n",
      "  model_6/batch_normalization_165/FusedBatchNormV3 (5.36k/5.36k flops)\n",
      "  model_6/batch_normalization_187/FusedBatchNormV3 (4.98k/4.98k flops)\n",
      "  model_6/batch_normalization_186/FusedBatchNormV3 (4.98k/4.98k flops)\n",
      "  model_6/depthwise_conv2d_80/BiasAdd (4.35k/4.35k flops)\n",
      "  model_6/conv2d_86/BiasAdd (4.35k/4.35k flops)\n",
      "  model_6/batch_normalization_169/FusedBatchNormV3 (3.88k/3.88k flops)\n",
      "  model_6/conv2d_89/BiasAdd (3.55k/3.55k flops)\n",
      "  model_6/batch_normalization_185/FusedBatchNormV3 (3.42k/3.42k flops)\n",
      "  model_6/batch_normalization_173/FusedBatchNormV3 (3.11k/3.11k flops)\n",
      "  model_6/depthwise_conv2d_79/BiasAdd (2.56k/2.56k flops)\n",
      "  model_6/conv2d_88/BiasAdd (2.43k/2.43k flops)\n",
      "  model_6/depthwise_conv2d_82/BiasAdd (2.43k/2.43k flops)\n",
      "  model_6/conv2d_92/BiasAdd (2.02k/2.02k flops)\n",
      "  model_6/depthwise_conv2d_86/BiasAdd (2.02k/2.02k flops)\n",
      "  model_6/depthwise_conv2d_87/BiasAdd (1.99k/1.99k flops)\n",
      "  model_6/conv2d_93/BiasAdd (1.99k/1.99k flops)\n",
      "  model_6/conv2d_91/BiasAdd (1.84k/1.84k flops)\n",
      "  model_6/depthwise_conv2d_85/BiasAdd (1.84k/1.84k flops)\n",
      "  model_6/conv2d_94/BiasAdd (1.82k/1.82k flops)\n",
      "  model_6/depthwise_conv2d_88/BiasAdd (1.82k/1.82k flops)\n",
      "  model_6/conv2d_95/BiasAdd (1.71k/1.71k flops)\n",
      "  model_6/depthwise_conv2d_84/BiasAdd (1.67k/1.67k flops)\n",
      "  model_6/conv2d_90/BiasAdd (1.67k/1.67k flops)\n",
      "  model_6/depthwise_conv2d_81/BiasAdd (1.63k/1.63k flops)\n",
      "  model_6/depthwise_conv2d_83/BiasAdd (888/888 flops)\n",
      "  model_6/conv2d_97/BiasAdd (836/836 flops)\n",
      "  model_6/global_average_pooling2d_6/Mean (836/836 flops)\n",
      "  model_6/conv2d_96/BiasAdd (622/622 flops)\n",
      "  model_6/depthwise_conv2d_90/BiasAdd (622/622 flops)\n",
      "  model_6/depthwise_conv2d_89/BiasAdd (428/428 flops)\n",
      "  model_6/dense_6/Softmax (50/50 flops)\n",
      "  model_6/dense_6/BiasAdd (10/10 flops)\n",
      "\n",
      "======================End of Report==========================\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "1.025028\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-30 13:39:43.384150: I tensorflow/core/grappler/devices.cc:66] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0\n",
      "2022-04-30 13:39:43.384271: I tensorflow/core/grappler/clusters/single_machine.cc:357] Starting new session\n",
      "2022-04-30 13:39:43.388496: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:1137] Optimization results for grappler item: graph_to_optimize\n",
      "  function_optimizer: function_optimizer did nothing. time = 0.005ms.\n",
      "  function_optimizer: function_optimizer did nothing. time = 0.001ms.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=========================Options=============================\n",
      "-max_depth                  10000\n",
      "-min_bytes                  0\n",
      "-min_peak_bytes             0\n",
      "-min_residual_bytes         0\n",
      "-min_output_bytes           0\n",
      "-min_micros                 0\n",
      "-min_accelerator_micros     0\n",
      "-min_cpu_micros             0\n",
      "-min_params                 0\n",
      "-min_float_ops              1\n",
      "-min_occurrence             0\n",
      "-step                       -1\n",
      "-order_by                   float_ops\n",
      "-account_type_regexes       .*\n",
      "-start_name_regexes         .*\n",
      "-trim_name_regexes          \n",
      "-show_name_regexes          .*\n",
      "-hide_name_regexes          \n",
      "-account_displayed_op_only  true\n",
      "-select                     float_ops\n",
      "-output                     stdout:\n",
      "\n",
      "==================Model Analysis Report======================\n",
      "\n",
      "Doc:\n",
      "scope: The nodes in the model graph are organized by their names, which is hierarchical like filesystem.\n",
      "flops: Number of float operations. Note: Please read the implementation for the math behind it.\n",
      "\n",
      "Profile:\n",
      "node name | # float_ops\n",
      "_TFProfRoot (--/15.41m flops)\n",
      "  model_7/conv2d_109/Conv2D (1.71m/1.71m flops)\n",
      "  model_7/conv2d_107/Conv2D (1.53m/1.53m flops)\n",
      "  model_7/conv2d_108/Conv2D (1.51m/1.51m flops)\n",
      "  model_7/conv2d_101/Conv2D (1.46m/1.46m flops)\n",
      "  model_7/conv2d_103/Conv2D (1.43m/1.43m flops)\n",
      "  model_7/conv2d_106/Conv2D (1.41m/1.41m flops)\n",
      "  model_7/conv2d_105/Conv2D (959.62k/959.62k flops)\n",
      "  model_7/conv2d_111/Conv2D (940.86k/940.86k flops)\n",
      "  model_7/conv2d_99/Conv2D (786.43k/786.43k flops)\n",
      "  model_7/conv2d_102/Conv2D (661.76k/661.76k flops)\n",
      "  model_7/conv2d_100/Conv2D (638.98k/638.98k flops)\n",
      "  model_7/conv2d_110/Conv2D (636.54k/636.54k flops)\n",
      "  model_7/conv2d_104/Conv2D (559.78k/559.78k flops)\n",
      "  model_7/conv2d_98/Conv2D (262.14k/262.14k flops)\n",
      "  model_7/depthwise_conv2d_91/depthwise (147.46k/147.46k flops)\n",
      "  model_7/depthwise_conv2d_93/depthwise (119.81k/119.81k flops)\n",
      "  model_7/depthwise_conv2d_92/depthwise (55.30k/55.30k flops)\n",
      "  model_7/depthwise_conv2d_95/depthwise (54.14k/54.14k flops)\n",
      "  model_7/depthwise_conv2d_100/depthwise (31.82k/31.82k flops)\n",
      "  model_7/depthwise_conv2d_94/depthwise (31.68k/31.68k flops)\n",
      "  model_7/depthwise_conv2d_99/depthwise (31.10k/31.10k flops)\n",
      "  model_7/depthwise_conv2d_101/depthwise (30.67k/30.67k flops)\n",
      "  model_7/depthwise_conv2d_98/depthwise (29.38k/29.38k flops)\n",
      "  model_7/batch_normalization_191/FusedBatchNormV3 (24.86k/24.86k flops)\n",
      "  model_7/depthwise_conv2d_97/depthwise (21.17k/21.17k flops)\n",
      "  model_7/depthwise_conv2d_96/depthwise (17.14k/17.14k flops)\n",
      "  model_7/batch_normalization_190/FusedBatchNormV3 (16.58k/16.58k flops)\n",
      "  model_7/batch_normalization_189/FusedBatchNormV3 (16.58k/16.58k flops)\n",
      "  model_7/dense_7/MatMul (14.84k/14.84k flops)\n",
      "  model_7/batch_normalization_195/FusedBatchNormV3 (14.74k/14.74k flops)\n",
      "  model_7/batch_normalization_193/FusedBatchNormV3 (13.94k/13.94k flops)\n",
      "  model_7/batch_normalization_194/FusedBatchNormV3 (13.94k/13.94k flops)\n",
      "  model_7/conv2d_99/BiasAdd (12.29k/12.29k flops)\n",
      "  model_7/depthwise_conv2d_103/depthwise (11.41k/11.41k flops)\n",
      "  model_7/batch_normalization_199/FusedBatchNormV3 (9.04k/9.04k flops)\n",
      "  model_7/depthwise_conv2d_102/depthwise (9.04k/9.04k flops)\n",
      "  model_7/conv2d_98/BiasAdd (8.19k/8.19k flops)\n",
      "  model_7/depthwise_conv2d_91/BiasAdd (8.19k/8.19k flops)\n",
      "  model_7/batch_normalization_198/FusedBatchNormV3 (7.14k/7.14k flops)\n",
      "  model_7/batch_normalization_197/FusedBatchNormV3 (7.14k/7.14k flops)\n",
      "  model_7/conv2d_101/BiasAdd (7.04k/7.04k flops)\n",
      "  model_7/batch_normalization_211/FusedBatchNormV3 (7.03k/7.03k flops)\n",
      "  model_7/depthwise_conv2d_93/BiasAdd (6.66k/6.66k flops)\n",
      "  model_7/conv2d_100/BiasAdd (6.66k/6.66k flops)\n",
      "  model_7/batch_normalization_192/FusedBatchNormV3 (6.43k/6.43k flops)\n",
      "  model_7/batch_normalization_208/FusedBatchNormV3 (6.19k/6.19k flops)\n",
      "  model_7/batch_normalization_207/FusedBatchNormV3 (6.19k/6.19k flops)\n",
      "  model_7/batch_normalization_206/FusedBatchNormV3 (6.05k/6.05k flops)\n",
      "  model_7/batch_normalization_205/FusedBatchNormV3 (6.05k/6.05k flops)\n",
      "  model_7/batch_normalization_209/FusedBatchNormV3 (5.96k/5.96k flops)\n",
      "  model_7/batch_normalization_210/FusedBatchNormV3 (5.96k/5.96k flops)\n",
      "  model_7/batch_normalization_215/FusedBatchNormV3 (5.94k/5.94k flops)\n",
      "  model_7/batch_normalization_204/FusedBatchNormV3 (5.71k/5.71k flops)\n",
      "  model_7/batch_normalization_203/FusedBatchNormV3 (5.71k/5.71k flops)\n",
      "  model_7/batch_normalization_214/FusedBatchNormV3 (5.07k/5.07k flops)\n",
      "  model_7/batch_normalization_213/FusedBatchNormV3 (5.07k/5.07k flops)\n",
      "  model_7/batch_normalization_196/FusedBatchNormV3 (4.18k/4.18k flops)\n",
      "  model_7/batch_normalization_202/FusedBatchNormV3 (4.12k/4.12k flops)\n",
      "  model_7/batch_normalization_201/FusedBatchNormV3 (4.12k/4.12k flops)\n",
      "  model_7/batch_normalization_212/FusedBatchNormV3 (4.02k/4.02k flops)\n",
      "  model_7/conv2d_103/BiasAdd (3.81k/3.81k flops)\n",
      "  model_7/batch_normalization_200/FusedBatchNormV3 (3.33k/3.33k flops)\n",
      "  model_7/depthwise_conv2d_92/BiasAdd (3.07k/3.07k flops)\n",
      "  model_7/conv2d_102/BiasAdd (3.01k/3.01k flops)\n",
      "  model_7/depthwise_conv2d_95/BiasAdd (3.01k/3.01k flops)\n",
      "  model_7/conv2d_109/BiasAdd (2.01k/2.01k flops)\n",
      "  model_7/conv2d_107/BiasAdd (1.77k/1.77k flops)\n",
      "  model_7/depthwise_conv2d_100/BiasAdd (1.77k/1.77k flops)\n",
      "  model_7/depthwise_conv2d_94/BiasAdd (1.76k/1.76k flops)\n",
      "  model_7/depthwise_conv2d_99/BiasAdd (1.73k/1.73k flops)\n",
      "  model_7/conv2d_106/BiasAdd (1.73k/1.73k flops)\n",
      "  model_7/conv2d_108/BiasAdd (1.70k/1.70k flops)\n",
      "  model_7/depthwise_conv2d_101/BiasAdd (1.70k/1.70k flops)\n",
      "  model_7/conv2d_105/BiasAdd (1.63k/1.63k flops)\n",
      "  model_7/depthwise_conv2d_98/BiasAdd (1.63k/1.63k flops)\n",
      "  model_7/conv2d_104/BiasAdd (1.18k/1.18k flops)\n",
      "  model_7/depthwise_conv2d_97/BiasAdd (1.18k/1.18k flops)\n",
      "  model_7/depthwise_conv2d_96/BiasAdd (952/952 flops)\n",
      "  model_7/global_average_pooling2d_7/Mean (742/742 flops)\n",
      "  model_7/conv2d_111/BiasAdd (742/742 flops)\n",
      "  model_7/depthwise_conv2d_103/BiasAdd (634/634 flops)\n",
      "  model_7/conv2d_110/BiasAdd (634/634 flops)\n",
      "  model_7/depthwise_conv2d_102/BiasAdd (502/502 flops)\n",
      "  model_7/dense_7/Softmax (50/50 flops)\n",
      "  model_7/dense_7/BiasAdd (10/10 flops)\n",
      "\n",
      "======================End of Report==========================\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "1.1171\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-30 13:39:44.298533: I tensorflow/core/grappler/devices.cc:66] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0\n",
      "2022-04-30 13:39:44.298647: I tensorflow/core/grappler/clusters/single_machine.cc:357] Starting new session\n",
      "2022-04-30 13:39:44.302624: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:1137] Optimization results for grappler item: graph_to_optimize\n",
      "  function_optimizer: function_optimizer did nothing. time = 0.005ms.\n",
      "  function_optimizer: function_optimizer did nothing. time = 0.001ms.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=========================Options=============================\n",
      "-max_depth                  10000\n",
      "-min_bytes                  0\n",
      "-min_peak_bytes             0\n",
      "-min_residual_bytes         0\n",
      "-min_output_bytes           0\n",
      "-min_micros                 0\n",
      "-min_accelerator_micros     0\n",
      "-min_cpu_micros             0\n",
      "-min_params                 0\n",
      "-min_float_ops              1\n",
      "-min_occurrence             0\n",
      "-step                       -1\n",
      "-order_by                   float_ops\n",
      "-account_type_regexes       .*\n",
      "-start_name_regexes         .*\n",
      "-trim_name_regexes          \n",
      "-show_name_regexes          .*\n",
      "-hide_name_regexes          \n",
      "-account_displayed_op_only  true\n",
      "-select                     float_ops\n",
      "-output                     stdout:\n",
      "\n",
      "==================Model Analysis Report======================\n",
      "\n",
      "Doc:\n",
      "scope: The nodes in the model graph are organized by their names, which is hierarchical like filesystem.\n",
      "flops: Number of float operations. Note: Please read the implementation for the math behind it.\n",
      "\n",
      "Profile:\n",
      "node name | # float_ops\n",
      "_TFProfRoot (--/20.23m flops)\n",
      "  model_8/conv2d_123/Conv2D (2.00m/2.00m flops)\n",
      "  model_8/conv2d_122/Conv2D (1.98m/1.98m flops)\n",
      "  model_8/conv2d_120/Conv2D (1.95m/1.95m flops)\n",
      "  model_8/conv2d_121/Conv2D (1.94m/1.94m flops)\n",
      "  model_8/conv2d_119/Conv2D (1.93m/1.93m flops)\n",
      "  model_8/conv2d_125/Conv2D (1.86m/1.86m flops)\n",
      "  model_8/conv2d_117/Conv2D (1.55m/1.55m flops)\n",
      "  model_8/conv2d_115/Conv2D (1.49m/1.49m flops)\n",
      "  model_8/conv2d_124/Conv2D (948.35k/948.35k flops)\n",
      "  model_8/conv2d_113/Conv2D (917.50k/917.50k flops)\n",
      "  model_8/conv2d_118/Conv2D (885.92k/885.92k flops)\n",
      "  model_8/conv2d_116/Conv2D (849.15k/849.15k flops)\n",
      "  model_8/conv2d_114/Conv2D (673.79k/673.79k flops)\n",
      "  model_8/conv2d_112/Conv2D (262.14k/262.14k flops)\n",
      "  model_8/depthwise_conv2d_104/depthwise (147.46k/147.46k flops)\n",
      "  model_8/depthwise_conv2d_106/depthwise (108.29k/108.29k flops)\n",
      "  model_8/depthwise_conv2d_105/depthwise (64.51k/64.51k flops)\n",
      "  model_8/depthwise_conv2d_108/depthwise (61.63k/61.63k flops)\n",
      "  model_8/depthwise_conv2d_114/depthwise (36.29k/36.29k flops)\n",
      "  model_8/depthwise_conv2d_107/depthwise (35.71k/35.71k flops)\n",
      "  model_8/depthwise_conv2d_112/depthwise (35.71k/35.71k flops)\n",
      "  model_8/depthwise_conv2d_111/depthwise (35.42k/35.42k flops)\n",
      "  model_8/depthwise_conv2d_110/depthwise (35.28k/35.28k flops)\n",
      "  model_8/depthwise_conv2d_113/depthwise (35.28k/35.28k flops)\n",
      "  model_8/batch_normalization_218/FusedBatchNormV3 (29.01k/29.01k flops)\n",
      "  model_8/dense_8/MatMul (19.44k/19.44k flops)\n",
      "  model_8/depthwise_conv2d_116/depthwise (17.21k/17.21k flops)\n",
      "  model_8/batch_normalization_222/FusedBatchNormV3 (16.62k/16.62k flops)\n",
      "  model_8/batch_normalization_217/FusedBatchNormV3 (16.58k/16.58k flops)\n",
      "  model_8/batch_normalization_216/FusedBatchNormV3 (16.58k/16.58k flops)\n",
      "  model_8/depthwise_conv2d_109/depthwise (16.27k/16.27k flops)\n",
      "  model_8/conv2d_113/BiasAdd (14.34k/14.34k flops)\n",
      "  model_8/batch_normalization_220/FusedBatchNormV3 (12.60k/12.60k flops)\n",
      "  model_8/batch_normalization_221/FusedBatchNormV3 (12.60k/12.60k flops)\n",
      "  model_8/depthwise_conv2d_115/depthwise (8.93k/8.93k flops)\n",
      "  model_8/batch_normalization_226/FusedBatchNormV3 (8.59k/8.59k flops)\n",
      "  model_8/depthwise_conv2d_104/BiasAdd (8.19k/8.19k flops)\n",
      "  model_8/conv2d_112/BiasAdd (8.19k/8.19k flops)\n",
      "  model_8/batch_normalization_225/FusedBatchNormV3 (8.13k/8.13k flops)\n",
      "  model_8/batch_normalization_224/FusedBatchNormV3 (8.13k/8.13k flops)\n",
      "  model_8/conv2d_115/BiasAdd (7.94k/7.94k flops)\n",
      "  model_8/batch_normalization_242/FusedBatchNormV3 (7.78k/7.78k flops)\n",
      "  model_8/batch_normalization_241/FusedBatchNormV3 (7.65k/7.65k flops)\n",
      "  model_8/batch_normalization_240/FusedBatchNormV3 (7.65k/7.65k flops)\n",
      "  model_8/batch_normalization_219/FusedBatchNormV3 (7.50k/7.50k flops)\n",
      "  model_8/batch_normalization_236/FusedBatchNormV3 (7.06k/7.06k flops)\n",
      "  model_8/batch_normalization_237/FusedBatchNormV3 (7.06k/7.06k flops)\n",
      "  model_8/batch_normalization_238/FusedBatchNormV3 (6.94k/6.94k flops)\n",
      "  model_8/batch_normalization_232/FusedBatchNormV3 (6.94k/6.94k flops)\n",
      "  model_8/batch_normalization_233/FusedBatchNormV3 (6.94k/6.94k flops)\n",
      "  model_8/batch_normalization_231/FusedBatchNormV3 (6.89k/6.89k flops)\n",
      "  model_8/batch_normalization_230/FusedBatchNormV3 (6.89k/6.89k flops)\n",
      "  model_8/batch_normalization_234/FusedBatchNormV3 (6.86k/6.86k flops)\n",
      "  model_8/batch_normalization_228/FusedBatchNormV3 (6.86k/6.86k flops)\n",
      "  model_8/batch_normalization_235/FusedBatchNormV3 (6.86k/6.86k flops)\n",
      "  model_8/batch_normalization_229/FusedBatchNormV3 (6.86k/6.86k flops)\n",
      "  model_8/depthwise_conv2d_106/BiasAdd (6.02k/6.02k flops)\n",
      "  model_8/conv2d_114/BiasAdd (6.02k/6.02k flops)\n",
      "  model_8/batch_normalization_223/FusedBatchNormV3 (4.71k/4.71k flops)\n",
      "  model_8/batch_normalization_239/FusedBatchNormV3 (3.97k/3.97k flops)\n",
      "  model_8/conv2d_117/BiasAdd (3.62k/3.62k flops)\n",
      "  model_8/depthwise_conv2d_105/BiasAdd (3.58k/3.58k flops)\n",
      "  model_8/depthwise_conv2d_108/BiasAdd (3.42k/3.42k flops)\n",
      "  model_8/conv2d_116/BiasAdd (3.42k/3.42k flops)\n",
      "  model_8/batch_normalization_227/FusedBatchNormV3 (3.16k/3.16k flops)\n",
      "  model_8/conv2d_122/BiasAdd (2.02k/2.02k flops)\n",
      "  model_8/depthwise_conv2d_114/BiasAdd (2.02k/2.02k flops)\n",
      "  model_8/depthwise_conv2d_107/BiasAdd (1.98k/1.98k flops)\n",
      "  model_8/conv2d_123/BiasAdd (1.98k/1.98k flops)\n",
      "  model_8/conv2d_120/BiasAdd (1.98k/1.98k flops)\n",
      "  model_8/depthwise_conv2d_112/BiasAdd (1.98k/1.98k flops)\n",
      "  model_8/depthwise_conv2d_111/BiasAdd (1.97k/1.97k flops)\n",
      "  model_8/conv2d_119/BiasAdd (1.97k/1.97k flops)\n",
      "  model_8/conv2d_121/BiasAdd (1.96k/1.96k flops)\n",
      "  model_8/depthwise_conv2d_110/BiasAdd (1.96k/1.96k flops)\n",
      "  model_8/conv2d_118/BiasAdd (1.96k/1.96k flops)\n",
      "  model_8/depthwise_conv2d_113/BiasAdd (1.96k/1.96k flops)\n",
      "  model_8/global_average_pooling2d_8/Mean (972/972 flops)\n",
      "  model_8/conv2d_125/BiasAdd (972/972 flops)\n",
      "  model_8/depthwise_conv2d_116/BiasAdd (956/956 flops)\n",
      "  model_8/conv2d_124/BiasAdd (956/956 flops)\n",
      "  model_8/depthwise_conv2d_109/BiasAdd (904/904 flops)\n",
      "  model_8/depthwise_conv2d_115/BiasAdd (496/496 flops)\n",
      "  model_8/dense_8/Softmax (50/50 flops)\n",
      "  model_8/dense_8/BiasAdd (10/10 flops)\n",
      "\n",
      "======================End of Report==========================\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "0.963276\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-30 13:39:45.399405: I tensorflow/core/grappler/devices.cc:66] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0\n",
      "2022-04-30 13:39:45.399522: I tensorflow/core/grappler/clusters/single_machine.cc:357] Starting new session\n",
      "2022-04-30 13:39:45.403691: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:1137] Optimization results for grappler item: graph_to_optimize\n",
      "  function_optimizer: function_optimizer did nothing. time = 0.004ms.\n",
      "  function_optimizer: function_optimizer did nothing. time = 0.001ms.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=========================Options=============================\n",
      "-max_depth                  10000\n",
      "-min_bytes                  0\n",
      "-min_peak_bytes             0\n",
      "-min_residual_bytes         0\n",
      "-min_output_bytes           0\n",
      "-min_micros                 0\n",
      "-min_accelerator_micros     0\n",
      "-min_cpu_micros             0\n",
      "-min_params                 0\n",
      "-min_float_ops              1\n",
      "-min_occurrence             0\n",
      "-step                       -1\n",
      "-order_by                   float_ops\n",
      "-account_type_regexes       .*\n",
      "-start_name_regexes         .*\n",
      "-trim_name_regexes          \n",
      "-show_name_regexes          .*\n",
      "-hide_name_regexes          \n",
      "-account_displayed_op_only  true\n",
      "-select                     float_ops\n",
      "-output                     stdout:\n",
      "\n",
      "==================Model Analysis Report======================\n",
      "\n",
      "Doc:\n",
      "scope: The nodes in the model graph are organized by their names, which is hierarchical like filesystem.\n",
      "flops: Number of float operations. Note: Please read the implementation for the math behind it.\n",
      "\n",
      "Profile:\n",
      "node name | # float_ops\n",
      "_TFProfRoot (--/13.78m flops)\n",
      "  model_9/conv2d_134/Conv2D (1.86m/1.86m flops)\n",
      "  model_9/conv2d_135/Conv2D (1.45m/1.45m flops)\n",
      "  model_9/conv2d_136/Conv2D (1.31m/1.31m flops)\n",
      "  model_9/conv2d_139/Conv2D (1.27m/1.27m flops)\n",
      "  model_9/conv2d_133/Conv2D (1.27m/1.27m flops)\n",
      "  model_9/conv2d_137/Conv2D (1.18m/1.18m flops)\n",
      "  model_9/conv2d_127/Conv2D (983.04k/983.04k flops)\n",
      "  model_9/conv2d_129/Conv2D (824.32k/824.32k flops)\n",
      "  model_9/conv2d_131/Conv2D (631.68k/631.68k flops)\n",
      "  model_9/conv2d_132/Conv2D (547.68k/547.68k flops)\n",
      "  model_9/conv2d_128/Conv2D (537.60k/537.60k flops)\n",
      "  model_9/conv2d_138/Conv2D (522.88k/522.88k flops)\n",
      "  model_9/conv2d_130/Conv2D (276.74k/276.74k flops)\n",
      "  model_9/conv2d_126/Conv2D (262.14k/262.14k flops)\n",
      "  model_9/depthwise_conv2d_117/depthwise (147.46k/147.46k flops)\n",
      "  model_9/depthwise_conv2d_119/depthwise (80.64k/80.64k flops)\n",
      "  model_9/depthwise_conv2d_118/depthwise (69.12k/69.12k flops)\n",
      "  model_9/depthwise_conv2d_124/depthwise (35.14k/35.14k flops)\n",
      "  model_9/depthwise_conv2d_125/depthwise (34.27k/34.27k flops)\n",
      "  model_9/batch_normalization_245/FusedBatchNormV3 (31.08k/31.08k flops)\n",
      "  model_9/depthwise_conv2d_127/depthwise (30.82k/30.82k flops)\n",
      "  model_9/depthwise_conv2d_126/depthwise (27.50k/27.50k flops)\n",
      "  model_9/depthwise_conv2d_121/depthwise (27.07k/27.07k flops)\n",
      "  model_9/depthwise_conv2d_120/depthwise (26.50k/26.50k flops)\n",
      "  model_9/depthwise_conv2d_123/depthwise (23.47k/23.47k flops)\n",
      "  model_9/dense_9/MatMul (16.76k/16.76k flops)\n",
      "  model_9/batch_normalization_244/FusedBatchNormV3 (16.58k/16.58k flops)\n",
      "  model_9/batch_normalization_243/FusedBatchNormV3 (16.58k/16.58k flops)\n",
      "  model_9/conv2d_127/BiasAdd (15.36k/15.36k flops)\n",
      "  model_9/depthwise_conv2d_122/depthwise (15.12k/15.12k flops)\n",
      "  model_9/depthwise_conv2d_129/depthwise (13.68k/13.68k flops)\n",
      "  model_9/batch_normalization_249/FusedBatchNormV3 (12.33k/12.33k flops)\n",
      "  model_9/batch_normalization_248/FusedBatchNormV3 (9.38k/9.38k flops)\n",
      "  model_9/batch_normalization_247/FusedBatchNormV3 (9.38k/9.38k flops)\n",
      "  model_9/conv2d_126/BiasAdd (8.19k/8.19k flops)\n",
      "  model_9/depthwise_conv2d_117/BiasAdd (8.19k/8.19k flops)\n",
      "  model_9/batch_normalization_246/FusedBatchNormV3 (8.04k/8.04k flops)\n",
      "  model_9/batch_normalization_253/FusedBatchNormV3 (7.98k/7.98k flops)\n",
      "  model_9/batch_normalization_257/FusedBatchNormV3 (6.83k/6.83k flops)\n",
      "  model_9/batch_normalization_258/FusedBatchNormV3 (6.83k/6.83k flops)\n",
      "  model_9/batch_normalization_269/FusedBatchNormV3 (6.70k/6.70k flops)\n",
      "  model_9/batch_normalization_259/FusedBatchNormV3 (6.66k/6.66k flops)\n",
      "  model_9/batch_normalization_260/FusedBatchNormV3 (6.66k/6.66k flops)\n",
      "  model_9/depthwise_conv2d_128/depthwise (6.19k/6.19k flops)\n",
      "  model_9/batch_normalization_267/FusedBatchNormV3 (6.08k/6.08k flops)\n",
      "  model_9/batch_normalization_268/FusedBatchNormV3 (6.08k/6.08k flops)\n",
      "  model_9/batch_normalization_263/FusedBatchNormV3 (5.99k/5.99k flops)\n",
      "  model_9/batch_normalization_264/FusedBatchNormV3 (5.99k/5.99k flops)\n",
      "  model_9/conv2d_129/BiasAdd (5.89k/5.89k flops)\n",
      "  model_9/batch_normalization_261/FusedBatchNormV3 (5.35k/5.35k flops)\n",
      "  model_9/batch_normalization_262/FusedBatchNormV3 (5.35k/5.35k flops)\n",
      "  model_9/batch_normalization_265/FusedBatchNormV3 (4.82k/4.82k flops)\n",
      "  model_9/batch_normalization_255/FusedBatchNormV3 (4.56k/4.56k flops)\n",
      "  model_9/batch_normalization_256/FusedBatchNormV3 (4.56k/4.56k flops)\n",
      "  model_9/conv2d_128/BiasAdd (4.48k/4.48k flops)\n",
      "  model_9/depthwise_conv2d_119/BiasAdd (4.48k/4.48k flops)\n",
      "  model_9/depthwise_conv2d_118/BiasAdd (3.84k/3.84k flops)\n",
      "  model_9/batch_normalization_252/FusedBatchNormV3 (3.57k/3.57k flops)\n",
      "  model_9/batch_normalization_251/FusedBatchNormV3 (3.57k/3.57k flops)\n",
      "  model_9/batch_normalization_250/FusedBatchNormV3 (3.50k/3.50k flops)\n",
      "  model_9/conv2d_131/BiasAdd (3.36k/3.36k flops)\n",
      "  model_9/batch_normalization_254/FusedBatchNormV3 (2.94k/2.94k flops)\n",
      "  model_9/batch_normalization_266/FusedBatchNormV3 (2.75k/2.75k flops)\n",
      "  model_9/depthwise_conv2d_124/BiasAdd (1.95k/1.95k flops)\n",
      "  model_9/conv2d_133/BiasAdd (1.95k/1.95k flops)\n",
      "  model_9/conv2d_134/BiasAdd (1.90k/1.90k flops)\n",
      "  model_9/depthwise_conv2d_125/BiasAdd (1.90k/1.90k flops)\n",
      "  model_9/conv2d_136/BiasAdd (1.71k/1.71k flops)\n",
      "  model_9/depthwise_conv2d_127/BiasAdd (1.71k/1.71k flops)\n",
      "  model_9/depthwise_conv2d_126/BiasAdd (1.53k/1.53k flops)\n",
      "  model_9/conv2d_135/BiasAdd (1.53k/1.53k flops)\n",
      "  model_9/conv2d_130/BiasAdd (1.50k/1.50k flops)\n",
      "  model_9/depthwise_conv2d_121/BiasAdd (1.50k/1.50k flops)\n",
      "  model_9/depthwise_conv2d_120/BiasAdd (1.47k/1.47k flops)\n",
      "  model_9/conv2d_137/BiasAdd (1.38k/1.38k flops)\n",
      "  model_9/depthwise_conv2d_123/BiasAdd (1.30k/1.30k flops)\n",
      "  model_9/conv2d_132/BiasAdd (1.30k/1.30k flops)\n",
      "  model_9/depthwise_conv2d_122/BiasAdd (840/840 flops)\n",
      "  model_9/conv2d_139/BiasAdd (838/838 flops)\n",
      "  model_9/global_average_pooling2d_9/Mean (838/838 flops)\n",
      "  model_9/depthwise_conv2d_129/BiasAdd (760/760 flops)\n",
      "  model_9/conv2d_138/BiasAdd (760/760 flops)\n",
      "  model_9/depthwise_conv2d_128/BiasAdd (344/344 flops)\n",
      "  model_9/dense_9/Softmax (50/50 flops)\n",
      "  model_9/dense_9/BiasAdd (10/10 flops)\n",
      "\n",
      "======================End of Report==========================\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "0.94414\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-30 13:39:46.326844: I tensorflow/core/grappler/devices.cc:66] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0\n",
      "2022-04-30 13:39:46.326959: I tensorflow/core/grappler/clusters/single_machine.cc:357] Starting new session\n",
      "2022-04-30 13:39:46.331051: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:1137] Optimization results for grappler item: graph_to_optimize\n",
      "  function_optimizer: function_optimizer did nothing. time = 0.005ms.\n",
      "  function_optimizer: function_optimizer did nothing. time = 0.001ms.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=========================Options=============================\n",
      "-max_depth                  10000\n",
      "-min_bytes                  0\n",
      "-min_peak_bytes             0\n",
      "-min_residual_bytes         0\n",
      "-min_output_bytes           0\n",
      "-min_micros                 0\n",
      "-min_accelerator_micros     0\n",
      "-min_cpu_micros             0\n",
      "-min_params                 0\n",
      "-min_float_ops              1\n",
      "-min_occurrence             0\n",
      "-step                       -1\n",
      "-order_by                   float_ops\n",
      "-account_type_regexes       .*\n",
      "-start_name_regexes         .*\n",
      "-trim_name_regexes          \n",
      "-show_name_regexes          .*\n",
      "-hide_name_regexes          \n",
      "-account_displayed_op_only  true\n",
      "-select                     float_ops\n",
      "-output                     stdout:\n",
      "\n",
      "==================Model Analysis Report======================\n",
      "\n",
      "Doc:\n",
      "scope: The nodes in the model graph are organized by their names, which is hierarchical like filesystem.\n",
      "flops: Number of float operations. Note: Please read the implementation for the math behind it.\n",
      "\n",
      "Profile:\n",
      "node name | # float_ops\n",
      "_TFProfRoot (--/13.78m flops)\n",
      "  model_10/conv2d_145/Conv2D (2.03m/2.03m flops)\n",
      "  model_10/conv2d_153/Conv2D (1.50m/1.50m flops)\n",
      "  model_10/conv2d_148/Conv2D (1.29m/1.29m flops)\n",
      "  model_10/conv2d_147/Conv2D (1.19m/1.19m flops)\n",
      "  model_10/conv2d_149/Conv2D (1.10m/1.10m flops)\n",
      "  model_10/conv2d_150/Conv2D (1.03m/1.03m flops)\n",
      "  model_10/conv2d_143/Conv2D (861.70k/861.70k flops)\n",
      "  model_10/conv2d_144/Conv2D (822.53k/822.53k flops)\n",
      "  model_10/conv2d_151/Conv2D (739.33k/739.33k flops)\n",
      "  model_10/conv2d_141/Conv2D (688.13k/688.13k flops)\n",
      "  model_10/conv2d_146/Conv2D (604.80k/604.80k flops)\n",
      "  model_10/conv2d_152/Conv2D (457.22k/457.22k flops)\n",
      "  model_10/conv2d_142/Conv2D (354.82k/354.82k flops)\n",
      "  model_10/conv2d_140/Conv2D (262.14k/262.14k flops)\n",
      "  model_10/depthwise_conv2d_130/depthwise (147.46k/147.46k flops)\n",
      "  model_10/depthwise_conv2d_132/depthwise (76.03k/76.03k flops)\n",
      "  model_10/depthwise_conv2d_134/depthwise (72.58k/72.58k flops)\n",
      "  model_10/depthwise_conv2d_131/depthwise (48.38k/48.38k flops)\n",
      "  model_10/depthwise_conv2d_137/depthwise (35.71k/35.71k flops)\n",
      "  model_10/depthwise_conv2d_139/depthwise (30.53k/30.53k flops)\n",
      "  model_10/depthwise_conv2d_133/depthwise (29.38k/29.38k flops)\n",
      "  model_10/depthwise_conv2d_138/depthwise (23.33k/23.33k flops)\n",
      "  model_10/depthwise_conv2d_140/depthwise (21.89k/21.89k flops)\n",
      "  model_10/batch_normalization_272/FusedBatchNormV3 (21.76k/21.76k flops)\n",
      "  model_10/depthwise_conv2d_136/depthwise (21.60k/21.60k flops)\n",
      "  model_10/dense_10/MatMul (19.96k/19.96k flops)\n",
      "  model_10/depthwise_conv2d_135/depthwise (18.14k/18.14k flops)\n",
      "  model_10/batch_normalization_271/FusedBatchNormV3 (16.58k/16.58k flops)\n",
      "  model_10/batch_normalization_270/FusedBatchNormV3 (16.58k/16.58k flops)\n",
      "  model_10/batch_normalization_276/FusedBatchNormV3 (13.67k/13.67k flops)\n",
      "  model_10/depthwise_conv2d_142/depthwise (13.54k/13.54k flops)\n",
      "  model_10/conv2d_141/BiasAdd (10.75k/10.75k flops)\n",
      "  model_10/batch_normalization_280/FusedBatchNormV3 (9.58k/9.58k flops)\n",
      "  model_10/batch_normalization_279/FusedBatchNormV3 (9.58k/9.58k flops)\n",
      "  model_10/batch_normalization_278/FusedBatchNormV3 (9.58k/9.58k flops)\n",
      "  model_10/batch_normalization_275/FusedBatchNormV3 (8.84k/8.84k flops)\n",
      "  model_10/batch_normalization_274/FusedBatchNormV3 (8.84k/8.84k flops)\n",
      "  model_10/depthwise_conv2d_130/BiasAdd (8.19k/8.19k flops)\n",
      "  model_10/conv2d_140/BiasAdd (8.19k/8.19k flops)\n",
      "  model_10/batch_normalization_296/FusedBatchNormV3 (7.98k/7.98k flops)\n",
      "  model_10/batch_normalization_284/FusedBatchNormV3 (6.94k/6.94k flops)\n",
      "  model_10/batch_normalization_285/FusedBatchNormV3 (6.94k/6.94k flops)\n",
      "  model_10/conv2d_143/BiasAdd (6.53k/6.53k flops)\n",
      "  model_10/batch_normalization_295/FusedBatchNormV3 (6.02k/6.02k flops)\n",
      "  model_10/batch_normalization_294/FusedBatchNormV3 (6.02k/6.02k flops)\n",
      "  model_10/batch_normalization_289/FusedBatchNormV3 (5.94k/5.94k flops)\n",
      "  model_10/batch_normalization_288/FusedBatchNormV3 (5.94k/5.94k flops)\n",
      "  model_10/batch_normalization_273/FusedBatchNormV3 (5.63k/5.63k flops)\n",
      "  model_10/depthwise_conv2d_141/depthwise (5.47k/5.47k flops)\n",
      "  model_10/batch_normalization_287/FusedBatchNormV3 (4.54k/4.54k flops)\n",
      "  model_10/batch_normalization_286/FusedBatchNormV3 (4.54k/4.54k flops)\n",
      "  model_10/batch_normalization_290/FusedBatchNormV3 (4.26k/4.26k flops)\n",
      "  model_10/batch_normalization_291/FusedBatchNormV3 (4.26k/4.26k flops)\n",
      "  model_10/batch_normalization_292/FusedBatchNormV3 (4.26k/4.26k flops)\n",
      "  model_10/conv2d_142/BiasAdd (4.22k/4.22k flops)\n",
      "  model_10/depthwise_conv2d_132/BiasAdd (4.22k/4.22k flops)\n",
      "  model_10/batch_normalization_283/FusedBatchNormV3 (4.20k/4.20k flops)\n",
      "  model_10/batch_normalization_282/FusedBatchNormV3 (4.20k/4.20k flops)\n",
      "  model_10/conv2d_144/BiasAdd (4.03k/4.03k flops)\n",
      "  model_10/conv2d_145/BiasAdd (4.03k/4.03k flops)\n",
      "  model_10/depthwise_conv2d_134/BiasAdd (4.03k/4.03k flops)\n",
      "  model_10/batch_normalization_277/FusedBatchNormV3 (3.88k/3.88k flops)\n",
      "  model_10/batch_normalization_281/FusedBatchNormV3 (3.53k/3.53k flops)\n",
      "  model_10/depthwise_conv2d_131/BiasAdd (2.69k/2.69k flops)\n",
      "  model_10/batch_normalization_293/FusedBatchNormV3 (2.43k/2.43k flops)\n",
      "  model_10/conv2d_147/BiasAdd (1.98k/1.98k flops)\n",
      "  model_10/depthwise_conv2d_137/BiasAdd (1.98k/1.98k flops)\n",
      "  model_10/depthwise_conv2d_139/BiasAdd (1.70k/1.70k flops)\n",
      "  model_10/conv2d_149/BiasAdd (1.70k/1.70k flops)\n",
      "  model_10/depthwise_conv2d_133/BiasAdd (1.63k/1.63k flops)\n",
      "  model_10/depthwise_conv2d_138/BiasAdd (1.30k/1.30k flops)\n",
      "  model_10/conv2d_148/BiasAdd (1.30k/1.30k flops)\n",
      "  model_10/depthwise_conv2d_140/BiasAdd (1.22k/1.22k flops)\n",
      "  model_10/conv2d_150/BiasAdd (1.22k/1.22k flops)\n",
      "  model_10/conv2d_151/BiasAdd (1.22k/1.22k flops)\n",
      "  model_10/depthwise_conv2d_136/BiasAdd (1.20k/1.20k flops)\n",
      "  model_10/conv2d_146/BiasAdd (1.20k/1.20k flops)\n",
      "  model_10/depthwise_conv2d_135/BiasAdd (1.01k/1.01k flops)\n",
      "  model_10/global_average_pooling2d_10/Mean (998/998 flops)\n",
      "  model_10/conv2d_153/BiasAdd (998/998 flops)\n",
      "  model_10/conv2d_152/BiasAdd (752/752 flops)\n",
      "  model_10/depthwise_conv2d_142/BiasAdd (752/752 flops)\n",
      "  model_10/depthwise_conv2d_141/BiasAdd (304/304 flops)\n",
      "  model_10/dense_10/Softmax (50/50 flops)\n",
      "  model_10/dense_10/BiasAdd (10/10 flops)\n",
      "\n",
      "======================End of Report==========================\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "4.441956\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-30 13:39:47.343728: I tensorflow/core/grappler/devices.cc:66] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0\n",
      "2022-04-30 13:39:47.343847: I tensorflow/core/grappler/clusters/single_machine.cc:357] Starting new session\n",
      "2022-04-30 13:39:47.348008: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:1137] Optimization results for grappler item: graph_to_optimize\n",
      "  function_optimizer: function_optimizer did nothing. time = 0.005ms.\n",
      "  function_optimizer: function_optimizer did nothing. time = 0.001ms.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=========================Options=============================\n",
      "-max_depth                  10000\n",
      "-min_bytes                  0\n",
      "-min_peak_bytes             0\n",
      "-min_residual_bytes         0\n",
      "-min_output_bytes           0\n",
      "-min_micros                 0\n",
      "-min_accelerator_micros     0\n",
      "-min_cpu_micros             0\n",
      "-min_params                 0\n",
      "-min_float_ops              1\n",
      "-min_occurrence             0\n",
      "-step                       -1\n",
      "-order_by                   float_ops\n",
      "-account_type_regexes       .*\n",
      "-start_name_regexes         .*\n",
      "-trim_name_regexes          \n",
      "-show_name_regexes          .*\n",
      "-hide_name_regexes          \n",
      "-account_displayed_op_only  true\n",
      "-select                     float_ops\n",
      "-output                     stdout:\n",
      "\n",
      "==================Model Analysis Report======================\n",
      "\n",
      "Doc:\n",
      "scope: The nodes in the model graph are organized by their names, which is hierarchical like filesystem.\n",
      "flops: Number of float operations. Note: Please read the implementation for the math behind it.\n",
      "\n",
      "Profile:\n",
      "node name | # float_ops\n",
      "_TFProfRoot (--/77.68m flops)\n",
      "  model_11/conv2d_162/Conv2D (8.16m/8.16m flops)\n",
      "  model_11/conv2d_165/Conv2D (8.13m/8.13m flops)\n",
      "  model_11/conv2d_161/Conv2D (8.09m/8.09m flops)\n",
      "  model_11/conv2d_163/Conv2D (7.94m/7.94m flops)\n",
      "  model_11/conv2d_164/Conv2D (7.90m/7.90m flops)\n",
      "  model_11/conv2d_159/Conv2D (7.74m/7.74m flops)\n",
      "  model_11/conv2d_157/Conv2D (5.81m/5.81m flops)\n",
      "  model_11/conv2d_160/Conv2D (4.00m/4.00m flops)\n",
      "  model_11/conv2d_158/Conv2D (3.87m/3.87m flops)\n",
      "  model_11/conv2d_155/Conv2D (3.67m/3.67m flops)\n",
      "  model_11/conv2d_166/Conv2D (3.44m/3.44m flops)\n",
      "  model_11/conv2d_156/Conv2D (2.58m/2.58m flops)\n",
      "  model_11/conv2d_167/Conv2D (1.58m/1.58m flops)\n",
      "  model_11/conv2d_154/Conv2D (1.05m/1.05m flops)\n",
      "  model_11/depthwise_conv2d_143/depthwise (589.82k/589.82k flops)\n",
      "  model_11/depthwise_conv2d_145/depthwise (414.72k/414.72k flops)\n",
      "  model_11/depthwise_conv2d_147/depthwise (276.48k/276.48k flops)\n",
      "  model_11/depthwise_conv2d_144/depthwise (258.05k/258.05k flops)\n",
      "  model_11/depthwise_conv2d_150/depthwise (146.88k/146.88k flops)\n",
      "  model_11/depthwise_conv2d_146/depthwise (145.15k/145.15k flops)\n",
      "  model_11/depthwise_conv2d_151/depthwise (144.00k/144.00k flops)\n",
      "  model_11/depthwise_conv2d_153/depthwise (143.42k/143.42k flops)\n",
      "  model_11/depthwise_conv2d_149/depthwise (142.85k/142.85k flops)\n",
      "  model_11/depthwise_conv2d_152/depthwise (142.85k/142.85k flops)\n",
      "  model_11/batch_normalization_299/FusedBatchNormV3 (115.02k/115.02k flops)\n",
      "  model_11/depthwise_conv2d_148/depthwise (72.58k/72.58k flops)\n",
      "  model_11/batch_normalization_298/FusedBatchNormV3 (65.73k/65.73k flops)\n",
      "  model_11/batch_normalization_297/FusedBatchNormV3 (65.73k/65.73k flops)\n",
      "  model_11/batch_normalization_303/FusedBatchNormV3 (65.27k/65.27k flops)\n",
      "  model_11/conv2d_155/BiasAdd (57.34k/57.34k flops)\n",
      "  model_11/batch_normalization_302/FusedBatchNormV3 (46.62k/46.62k flops)\n",
      "  model_11/batch_normalization_301/FusedBatchNormV3 (46.62k/46.62k flops)\n",
      "  model_11/depthwise_conv2d_154/depthwise (36.72k/36.72k flops)\n",
      "  model_11/batch_normalization_307/FusedBatchNormV3 (33.77k/33.77k flops)\n",
      "  model_11/conv2d_154/BiasAdd (32.77k/32.77k flops)\n",
      "  model_11/depthwise_conv2d_143/BiasAdd (32.77k/32.77k flops)\n",
      "  model_11/conv2d_157/BiasAdd (32.26k/32.26k flops)\n",
      "  model_11/batch_normalization_305/FusedBatchNormV3 (32.16k/32.16k flops)\n",
      "  model_11/batch_normalization_306/FusedBatchNormV3 (32.16k/32.16k flops)\n",
      "  model_11/batch_normalization_300/FusedBatchNormV3 (29.01k/29.01k flops)\n",
      "  model_11/conv2d_156/BiasAdd (23.04k/23.04k flops)\n",
      "  model_11/depthwise_conv2d_145/BiasAdd (23.04k/23.04k flops)\n",
      "  model_11/batch_normalization_319/FusedBatchNormV3 (19.38k/19.38k flops)\n",
      "  model_11/batch_normalization_311/FusedBatchNormV3 (19.38k/19.38k flops)\n",
      "  model_11/batch_normalization_312/FusedBatchNormV3 (19.38k/19.38k flops)\n",
      "  model_11/batch_normalization_314/FusedBatchNormV3 (19.00k/19.00k flops)\n",
      "  model_11/batch_normalization_313/FusedBatchNormV3 (19.00k/19.00k flops)\n",
      "  model_11/batch_normalization_317/FusedBatchNormV3 (18.92k/18.92k flops)\n",
      "  model_11/batch_normalization_318/FusedBatchNormV3 (18.92k/18.92k flops)\n",
      "  model_11/batch_normalization_315/FusedBatchNormV3 (18.85k/18.85k flops)\n",
      "  model_11/batch_normalization_316/FusedBatchNormV3 (18.85k/18.85k flops)\n",
      "  model_11/batch_normalization_309/FusedBatchNormV3 (18.85k/18.85k flops)\n",
      "  model_11/batch_normalization_310/FusedBatchNormV3 (18.85k/18.85k flops)\n",
      "  model_11/dense_11/MatMul (18.80k/18.80k flops)\n",
      "  model_11/batch_normalization_304/FusedBatchNormV3 (16.88k/16.88k flops)\n",
      "  model_11/conv2d_159/BiasAdd (16.13k/16.13k flops)\n",
      "  model_11/conv2d_158/BiasAdd (15.36k/15.36k flops)\n",
      "  model_11/depthwise_conv2d_147/BiasAdd (15.36k/15.36k flops)\n",
      "  model_11/depthwise_conv2d_155/depthwise (15.16k/15.16k flops)\n",
      "  model_11/depthwise_conv2d_144/BiasAdd (14.34k/14.34k flops)\n",
      "  model_11/batch_normalization_321/FusedBatchNormV3 (11.79k/11.79k flops)\n",
      "  model_11/batch_normalization_308/FusedBatchNormV3 (9.58k/9.58k flops)\n",
      "  model_11/conv2d_165/BiasAdd (8.16k/8.16k flops)\n",
      "  model_11/conv2d_161/BiasAdd (8.16k/8.16k flops)\n",
      "  model_11/depthwise_conv2d_150/BiasAdd (8.16k/8.16k flops)\n",
      "  model_11/depthwise_conv2d_146/BiasAdd (8.06k/8.06k flops)\n",
      "  model_11/depthwise_conv2d_151/BiasAdd (8.00k/8.00k flops)\n",
      "  model_11/conv2d_162/BiasAdd (8.00k/8.00k flops)\n",
      "  model_11/conv2d_164/BiasAdd (7.97k/7.97k flops)\n",
      "  model_11/depthwise_conv2d_153/BiasAdd (7.97k/7.97k flops)\n",
      "  model_11/conv2d_163/BiasAdd (7.94k/7.94k flops)\n",
      "  model_11/depthwise_conv2d_149/BiasAdd (7.94k/7.94k flops)\n",
      "  model_11/conv2d_160/BiasAdd (7.94k/7.94k flops)\n",
      "  model_11/depthwise_conv2d_152/BiasAdd (7.94k/7.94k flops)\n",
      "  model_11/batch_normalization_323/FusedBatchNormV3 (7.52k/7.52k flops)\n",
      "  model_11/batch_normalization_320/FusedBatchNormV3 (7.14k/7.14k flops)\n",
      "  model_11/batch_normalization_322/FusedBatchNormV3 (6.74k/6.74k flops)\n",
      "  model_11/depthwise_conv2d_148/BiasAdd (4.03k/4.03k flops)\n",
      "  model_11/conv2d_166/BiasAdd (3.37k/3.37k flops)\n",
      "  model_11/depthwise_conv2d_154/BiasAdd (2.04k/2.04k flops)\n",
      "  model_11/conv2d_167/BiasAdd (940/940 flops)\n",
      "  model_11/global_average_pooling2d_11/Mean (940/940 flops)\n",
      "  model_11/depthwise_conv2d_155/BiasAdd (842/842 flops)\n",
      "  model_11/dense_11/Softmax (50/50 flops)\n",
      "  model_11/dense_11/BiasAdd (10/10 flops)\n",
      "\n",
      "======================End of Report==========================\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "3.26218\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-30 13:39:48.275065: I tensorflow/core/grappler/devices.cc:66] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0\n",
      "2022-04-30 13:39:48.275180: I tensorflow/core/grappler/clusters/single_machine.cc:357] Starting new session\n",
      "2022-04-30 13:39:48.279279: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:1137] Optimization results for grappler item: graph_to_optimize\n",
      "  function_optimizer: function_optimizer did nothing. time = 0.004ms.\n",
      "  function_optimizer: function_optimizer did nothing. time = 0.001ms.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=========================Options=============================\n",
      "-max_depth                  10000\n",
      "-min_bytes                  0\n",
      "-min_peak_bytes             0\n",
      "-min_residual_bytes         0\n",
      "-min_output_bytes           0\n",
      "-min_micros                 0\n",
      "-min_accelerator_micros     0\n",
      "-min_cpu_micros             0\n",
      "-min_params                 0\n",
      "-min_float_ops              1\n",
      "-min_occurrence             0\n",
      "-step                       -1\n",
      "-order_by                   float_ops\n",
      "-account_type_regexes       .*\n",
      "-start_name_regexes         .*\n",
      "-trim_name_regexes          \n",
      "-show_name_regexes          .*\n",
      "-hide_name_regexes          \n",
      "-account_displayed_op_only  true\n",
      "-select                     float_ops\n",
      "-output                     stdout:\n",
      "\n",
      "==================Model Analysis Report======================\n",
      "\n",
      "Doc:\n",
      "scope: The nodes in the model graph are organized by their names, which is hierarchical like filesystem.\n",
      "flops: Number of float operations. Note: Please read the implementation for the math behind it.\n",
      "\n",
      "Profile:\n",
      "node name | # float_ops\n",
      "_TFProfRoot (--/41.57m flops)\n",
      "  model_12/conv2d_176/Conv2D (5.10m/5.10m flops)\n",
      "  model_12/conv2d_177/Conv2D (4.88m/4.88m flops)\n",
      "  model_12/conv2d_173/Conv2D (4.07m/4.07m flops)\n",
      "  model_12/conv2d_175/Conv2D (3.73m/3.73m flops)\n",
      "  model_12/conv2d_178/Conv2D (3.66m/3.66m flops)\n",
      "  model_12/conv2d_179/Conv2D (3.56m/3.56m flops)\n",
      "  model_12/conv2d_171/Conv2D (2.73m/2.73m flops)\n",
      "  model_12/conv2d_172/Conv2D (2.23m/2.23m flops)\n",
      "  model_12/conv2d_174/Conv2D (2.10m/2.10m flops)\n",
      "  model_12/conv2d_169/Conv2D (2.10m/2.10m flops)\n",
      "  model_12/conv2d_180/Conv2D (1.78m/1.78m flops)\n",
      "  model_12/conv2d_181/Conv2D (1.08m/1.08m flops)\n",
      "  model_12/conv2d_168/Conv2D (1.05m/1.05m flops)\n",
      "  model_12/conv2d_170/Conv2D (753.66k/753.66k flops)\n",
      "  model_12/depthwise_conv2d_156/depthwise (589.82k/589.82k flops)\n",
      "  model_12/depthwise_conv2d_158/depthwise (211.97k/211.97k flops)\n",
      "  model_12/depthwise_conv2d_160/depthwise (172.80k/172.80k flops)\n",
      "  model_12/depthwise_conv2d_157/depthwise (147.46k/147.46k flops)\n",
      "  model_12/depthwise_conv2d_159/depthwise (133.63k/133.63k flops)\n",
      "  model_12/depthwise_conv2d_164/depthwise (122.11k/122.11k flops)\n",
      "  model_12/depthwise_conv2d_163/depthwise (108.29k/108.29k flops)\n",
      "  model_12/depthwise_conv2d_165/depthwise (103.68k/103.68k flops)\n",
      "  model_12/depthwise_conv2d_166/depthwise (91.58k/91.58k flops)\n",
      "  model_12/depthwise_conv2d_162/depthwise (89.28k/89.28k flops)\n",
      "  model_12/batch_normalization_325/FusedBatchNormV3 (65.73k/65.73k flops)\n",
      "  model_12/batch_normalization_324/FusedBatchNormV3 (65.73k/65.73k flops)\n",
      "  model_12/batch_normalization_326/FusedBatchNormV3 (65.73k/65.73k flops)\n",
      "  model_12/depthwise_conv2d_161/depthwise (61.06k/61.06k flops)\n",
      "  model_12/batch_normalization_330/FusedBatchNormV3 (60.09k/60.09k flops)\n",
      "  model_12/conv2d_168/BiasAdd (32.77k/32.77k flops)\n",
      "  model_12/conv2d_169/BiasAdd (32.77k/32.77k flops)\n",
      "  model_12/depthwise_conv2d_156/BiasAdd (32.77k/32.77k flops)\n",
      "  model_12/conv2d_171/BiasAdd (29.70k/29.70k flops)\n",
      "  model_12/batch_normalization_334/FusedBatchNormV3 (28.41k/28.41k flops)\n",
      "  model_12/depthwise_conv2d_167/depthwise (25.20k/25.20k flops)\n",
      "  model_12/batch_normalization_328/FusedBatchNormV3 (23.83k/23.83k flops)\n",
      "  model_12/batch_normalization_329/FusedBatchNormV3 (23.83k/23.83k flops)\n",
      "  model_12/batch_normalization_332/FusedBatchNormV3 (20.10k/20.10k flops)\n",
      "  model_12/batch_normalization_333/FusedBatchNormV3 (20.10k/20.10k flops)\n",
      "  model_12/dense_12/MatMul (16.96k/16.96k flops)\n",
      "  model_12/batch_normalization_327/FusedBatchNormV3 (16.58k/16.58k flops)\n",
      "  model_12/batch_normalization_341/FusedBatchNormV3 (16.11k/16.11k flops)\n",
      "  model_12/batch_normalization_340/FusedBatchNormV3 (16.11k/16.11k flops)\n",
      "  model_12/batch_normalization_331/FusedBatchNormV3 (15.54k/15.54k flops)\n",
      "  model_12/batch_normalization_339/FusedBatchNormV3 (14.29k/14.29k flops)\n",
      "  model_12/batch_normalization_338/FusedBatchNormV3 (14.29k/14.29k flops)\n",
      "  model_12/batch_normalization_342/FusedBatchNormV3 (13.68k/13.68k flops)\n",
      "  model_12/batch_normalization_343/FusedBatchNormV3 (13.68k/13.68k flops)\n",
      "  model_12/conv2d_173/BiasAdd (13.57k/13.57k flops)\n",
      "  model_12/batch_normalization_346/FusedBatchNormV3 (13.30k/13.30k flops)\n",
      "  model_12/batch_normalization_345/FusedBatchNormV3 (12.08k/12.08k flops)\n",
      "  model_12/batch_normalization_344/FusedBatchNormV3 (12.08k/12.08k flops)\n",
      "  model_12/batch_normalization_337/FusedBatchNormV3 (11.78k/11.78k flops)\n",
      "  model_12/batch_normalization_336/FusedBatchNormV3 (11.78k/11.78k flops)\n",
      "  model_12/depthwise_conv2d_158/BiasAdd (11.78k/11.78k flops)\n",
      "  model_12/conv2d_170/BiasAdd (11.78k/11.78k flops)\n",
      "  model_12/depthwise_conv2d_168/depthwise (11.41k/11.41k flops)\n",
      "  model_12/conv2d_172/BiasAdd (9.60k/9.60k flops)\n",
      "  model_12/depthwise_conv2d_160/BiasAdd (9.60k/9.60k flops)\n",
      "  model_12/batch_normalization_348/FusedBatchNormV3 (8.88k/8.88k flops)\n",
      "  model_12/depthwise_conv2d_157/BiasAdd (8.19k/8.19k flops)\n",
      "  model_12/batch_normalization_335/FusedBatchNormV3 (8.06k/8.06k flops)\n",
      "  model_12/depthwise_conv2d_159/BiasAdd (7.42k/7.42k flops)\n",
      "  model_12/depthwise_conv2d_164/BiasAdd (6.78k/6.78k flops)\n",
      "  model_12/batch_normalization_350/FusedBatchNormV3 (6.78k/6.78k flops)\n",
      "  model_12/conv2d_176/BiasAdd (6.78k/6.78k flops)\n",
      "  model_12/conv2d_175/BiasAdd (6.02k/6.02k flops)\n",
      "  model_12/depthwise_conv2d_163/BiasAdd (6.02k/6.02k flops)\n",
      "  model_12/depthwise_conv2d_165/BiasAdd (5.76k/5.76k flops)\n",
      "  model_12/conv2d_177/BiasAdd (5.76k/5.76k flops)\n",
      "  model_12/conv2d_179/BiasAdd (5.60k/5.60k flops)\n",
      "  model_12/conv2d_178/BiasAdd (5.09k/5.09k flops)\n",
      "  model_12/depthwise_conv2d_166/BiasAdd (5.09k/5.09k flops)\n",
      "  model_12/batch_normalization_349/FusedBatchNormV3 (5.07k/5.07k flops)\n",
      "  model_12/depthwise_conv2d_162/BiasAdd (4.96k/4.96k flops)\n",
      "  model_12/conv2d_174/BiasAdd (4.96k/4.96k flops)\n",
      "  model_12/batch_normalization_347/FusedBatchNormV3 (4.90k/4.90k flops)\n",
      "  model_12/depthwise_conv2d_161/BiasAdd (3.39k/3.39k flops)\n",
      "  model_12/conv2d_180/BiasAdd (2.54k/2.54k flops)\n",
      "  model_12/depthwise_conv2d_167/BiasAdd (1.40k/1.40k flops)\n",
      "  model_12/global_average_pooling2d_12/Mean (848/848 flops)\n",
      "  model_12/conv2d_181/BiasAdd (848/848 flops)\n",
      "  model_12/depthwise_conv2d_168/BiasAdd (634/634 flops)\n",
      "  model_12/dense_12/Softmax (50/50 flops)\n",
      "  model_12/dense_12/BiasAdd (10/10 flops)\n",
      "\n",
      "======================End of Report==========================\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "4.321676\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-30 13:39:49.291601: I tensorflow/core/grappler/devices.cc:66] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0\n",
      "2022-04-30 13:39:49.291715: I tensorflow/core/grappler/clusters/single_machine.cc:357] Starting new session\n",
      "2022-04-30 13:39:49.296118: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:1137] Optimization results for grappler item: graph_to_optimize\n",
      "  function_optimizer: function_optimizer did nothing. time = 0.006ms.\n",
      "  function_optimizer: function_optimizer did nothing. time = 0.001ms.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=========================Options=============================\n",
      "-max_depth                  10000\n",
      "-min_bytes                  0\n",
      "-min_peak_bytes             0\n",
      "-min_residual_bytes         0\n",
      "-min_output_bytes           0\n",
      "-min_micros                 0\n",
      "-min_accelerator_micros     0\n",
      "-min_cpu_micros             0\n",
      "-min_params                 0\n",
      "-min_float_ops              1\n",
      "-min_occurrence             0\n",
      "-step                       -1\n",
      "-order_by                   float_ops\n",
      "-account_type_regexes       .*\n",
      "-start_name_regexes         .*\n",
      "-trim_name_regexes          \n",
      "-show_name_regexes          .*\n",
      "-hide_name_regexes          \n",
      "-account_displayed_op_only  true\n",
      "-select                     float_ops\n",
      "-output                     stdout:\n",
      "\n",
      "==================Model Analysis Report======================\n",
      "\n",
      "Doc:\n",
      "scope: The nodes in the model graph are organized by their names, which is hierarchical like filesystem.\n",
      "flops: Number of float operations. Note: Please read the implementation for the math behind it.\n",
      "\n",
      "Profile:\n",
      "node name | # float_ops\n",
      "_TFProfRoot (--/57.88m flops)\n",
      "  model_13/conv2d_185/Conv2D (8.13m/8.13m flops)\n",
      "  model_13/conv2d_190/Conv2D (6.00m/6.00m flops)\n",
      "  model_13/conv2d_189/Conv2D (4.83m/4.83m flops)\n",
      "  model_13/conv2d_192/Conv2D (4.70m/4.70m flops)\n",
      "  model_13/conv2d_193/Conv2D (4.64m/4.64m flops)\n",
      "  model_13/conv2d_187/Conv2D (4.53m/4.53m flops)\n",
      "  model_13/conv2d_183/Conv2D (3.93m/3.93m flops)\n",
      "  model_13/conv2d_184/Conv2D (3.87m/3.87m flops)\n",
      "  model_13/conv2d_191/Conv2D (3.75m/3.75m flops)\n",
      "  model_13/conv2d_186/Conv2D (2.42m/2.42m flops)\n",
      "  model_13/conv2d_188/Conv2D (2.30m/2.30m flops)\n",
      "  model_13/conv2d_194/Conv2D (2.27m/2.27m flops)\n",
      "  model_13/conv2d_195/Conv2D (1.87m/1.87m flops)\n",
      "  model_13/conv2d_182/Conv2D (1.05m/1.05m flops)\n",
      "  model_13/depthwise_conv2d_169/depthwise (589.82k/589.82k flops)\n",
      "  model_13/depthwise_conv2d_171/depthwise (580.61k/580.61k flops)\n",
      "  model_13/depthwise_conv2d_170/depthwise (276.48k/276.48k flops)\n",
      "  model_13/depthwise_conv2d_173/depthwise (172.80k/172.80k flops)\n",
      "  model_13/depthwise_conv2d_172/depthwise (145.15k/145.15k flops)\n",
      "  model_13/depthwise_conv2d_176/depthwise (142.85k/142.85k flops)\n",
      "  model_13/depthwise_conv2d_179/depthwise (136.51k/136.51k flops)\n",
      "  model_13/batch_normalization_353/FusedBatchNormV3 (123.24k/123.24k flops)\n",
      "  model_13/depthwise_conv2d_177/depthwise (108.86k/108.86k flops)\n",
      "  model_13/depthwise_conv2d_178/depthwise (89.28k/89.28k flops)\n",
      "  model_13/depthwise_conv2d_175/depthwise (87.55k/87.55k flops)\n",
      "  model_13/depthwise_conv2d_174/depthwise (67.97k/67.97k flops)\n",
      "  model_13/batch_normalization_352/FusedBatchNormV3 (65.73k/65.73k flops)\n",
      "  model_13/batch_normalization_351/FusedBatchNormV3 (65.73k/65.73k flops)\n",
      "  model_13/batch_normalization_357/FusedBatchNormV3 (65.27k/65.27k flops)\n",
      "  model_13/batch_normalization_356/FusedBatchNormV3 (65.27k/65.27k flops)\n",
      "  model_13/batch_normalization_355/FusedBatchNormV3 (65.27k/65.27k flops)\n",
      "  model_13/conv2d_183/BiasAdd (61.44k/61.44k flops)\n",
      "  model_13/conv2d_182/BiasAdd (32.77k/32.77k flops)\n",
      "  model_13/depthwise_conv2d_169/BiasAdd (32.77k/32.77k flops)\n",
      "  model_13/depthwise_conv2d_171/BiasAdd (32.26k/32.26k flops)\n",
      "  model_13/conv2d_185/BiasAdd (32.26k/32.26k flops)\n",
      "  model_13/conv2d_184/BiasAdd (32.26k/32.26k flops)\n",
      "  model_13/batch_normalization_361/FusedBatchNormV3 (31.62k/31.62k flops)\n",
      "  model_13/batch_normalization_354/FusedBatchNormV3 (31.08k/31.08k flops)\n",
      "  model_13/depthwise_conv2d_180/depthwise (22.03k/22.03k flops)\n",
      "  model_13/dense_13/MatMul (20.16k/20.16k flops)\n",
      "  model_13/batch_normalization_360/FusedBatchNormV3 (20.10k/20.10k flops)\n",
      "  model_13/batch_normalization_359/FusedBatchNormV3 (20.10k/20.10k flops)\n",
      "  model_13/batch_normalization_365/FusedBatchNormV3 (18.85k/18.85k flops)\n",
      "  model_13/batch_normalization_366/FusedBatchNormV3 (18.85k/18.85k flops)\n",
      "  model_13/batch_normalization_372/FusedBatchNormV3 (18.01k/18.01k flops)\n",
      "  model_13/batch_normalization_371/FusedBatchNormV3 (18.01k/18.01k flops)\n",
      "  model_13/batch_normalization_358/FusedBatchNormV3 (16.88k/16.88k flops)\n",
      "  model_13/depthwise_conv2d_181/depthwise (16.70k/16.70k flops)\n",
      "  model_13/depthwise_conv2d_170/BiasAdd (15.36k/15.36k flops)\n",
      "  model_13/conv2d_187/BiasAdd (15.10k/15.10k flops)\n",
      "  model_13/batch_normalization_367/FusedBatchNormV3 (14.36k/14.36k flops)\n",
      "  model_13/batch_normalization_368/FusedBatchNormV3 (14.36k/14.36k flops)\n",
      "  model_13/batch_normalization_375/FusedBatchNormV3 (12.99k/12.99k flops)\n",
      "  model_13/batch_normalization_369/FusedBatchNormV3 (11.78k/11.78k flops)\n",
      "  model_13/batch_normalization_370/FusedBatchNormV3 (11.78k/11.78k flops)\n",
      "  model_13/batch_normalization_373/FusedBatchNormV3 (11.63k/11.63k flops)\n",
      "  model_13/batch_normalization_364/FusedBatchNormV3 (11.55k/11.55k flops)\n",
      "  model_13/batch_normalization_363/FusedBatchNormV3 (11.55k/11.55k flops)\n",
      "  model_13/depthwise_conv2d_173/BiasAdd (9.60k/9.60k flops)\n",
      "  model_13/conv2d_186/BiasAdd (9.60k/9.60k flops)\n",
      "  model_13/batch_normalization_362/FusedBatchNormV3 (8.97k/8.97k flops)\n",
      "  model_13/depthwise_conv2d_172/BiasAdd (8.06k/8.06k flops)\n",
      "  model_13/batch_normalization_377/FusedBatchNormV3 (8.06k/8.06k flops)\n",
      "  model_13/conv2d_189/BiasAdd (7.94k/7.94k flops)\n",
      "  model_13/depthwise_conv2d_176/BiasAdd (7.94k/7.94k flops)\n",
      "  model_13/depthwise_conv2d_179/BiasAdd (7.58k/7.58k flops)\n",
      "  model_13/conv2d_192/BiasAdd (7.58k/7.58k flops)\n",
      "  model_13/batch_normalization_376/FusedBatchNormV3 (7.42k/7.42k flops)\n",
      "  model_13/depthwise_conv2d_177/BiasAdd (6.05k/6.05k flops)\n",
      "  model_13/conv2d_190/BiasAdd (6.05k/6.05k flops)\n",
      "  model_13/conv2d_191/BiasAdd (4.96k/4.96k flops)\n",
      "  model_13/depthwise_conv2d_178/BiasAdd (4.96k/4.96k flops)\n",
      "  model_13/conv2d_193/BiasAdd (4.90k/4.90k flops)\n",
      "  model_13/depthwise_conv2d_175/BiasAdd (4.86k/4.86k flops)\n",
      "  model_13/conv2d_188/BiasAdd (4.86k/4.86k flops)\n",
      "  model_13/batch_normalization_374/FusedBatchNormV3 (4.28k/4.28k flops)\n",
      "  model_13/depthwise_conv2d_174/BiasAdd (3.78k/3.78k flops)\n",
      "  model_13/conv2d_194/BiasAdd (3.71k/3.71k flops)\n",
      "  model_13/depthwise_conv2d_180/BiasAdd (1.22k/1.22k flops)\n",
      "  model_13/global_average_pooling2d_13/Mean (1.01k/1.01k flops)\n",
      "  model_13/conv2d_195/BiasAdd (1.01k/1.01k flops)\n",
      "  model_13/depthwise_conv2d_181/BiasAdd (928/928 flops)\n",
      "  model_13/dense_13/Softmax (50/50 flops)\n",
      "  model_13/dense_13/BiasAdd (10/10 flops)\n",
      "\n",
      "======================End of Report==========================\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "4.214092\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-30 13:39:50.225950: I tensorflow/core/grappler/devices.cc:66] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0\n",
      "2022-04-30 13:39:50.226064: I tensorflow/core/grappler/clusters/single_machine.cc:357] Starting new session\n",
      "2022-04-30 13:39:50.230110: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:1137] Optimization results for grappler item: graph_to_optimize\n",
      "  function_optimizer: function_optimizer did nothing. time = 0.004ms.\n",
      "  function_optimizer: function_optimizer did nothing. time = 0.001ms.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=========================Options=============================\n",
      "-max_depth                  10000\n",
      "-min_bytes                  0\n",
      "-min_peak_bytes             0\n",
      "-min_residual_bytes         0\n",
      "-min_output_bytes           0\n",
      "-min_micros                 0\n",
      "-min_accelerator_micros     0\n",
      "-min_cpu_micros             0\n",
      "-min_params                 0\n",
      "-min_float_ops              1\n",
      "-min_occurrence             0\n",
      "-step                       -1\n",
      "-order_by                   float_ops\n",
      "-account_type_regexes       .*\n",
      "-start_name_regexes         .*\n",
      "-trim_name_regexes          \n",
      "-show_name_regexes          .*\n",
      "-hide_name_regexes          \n",
      "-account_displayed_op_only  true\n",
      "-select                     float_ops\n",
      "-output                     stdout:\n",
      "\n",
      "==================Model Analysis Report======================\n",
      "\n",
      "Doc:\n",
      "scope: The nodes in the model graph are organized by their names, which is hierarchical like filesystem.\n",
      "flops: Number of float operations. Note: Please read the implementation for the math behind it.\n",
      "\n",
      "Profile:\n",
      "node name | # float_ops\n",
      "_TFProfRoot (--/61.35m flops)\n",
      "  model_14/conv2d_201/Conv2D (7.87m/7.87m flops)\n",
      "  model_14/conv2d_204/Conv2D (6.66m/6.66m flops)\n",
      "  model_14/conv2d_203/Conv2D (5.95m/5.95m flops)\n",
      "  model_14/conv2d_207/Conv2D (5.64m/5.64m flops)\n",
      "  model_14/conv2d_206/Conv2D (5.32m/5.32m flops)\n",
      "  model_14/conv2d_205/Conv2D (5.25m/5.25m flops)\n",
      "  model_14/conv2d_199/Conv2D (4.44m/4.44m flops)\n",
      "  model_14/conv2d_197/Conv2D (4.06m/4.06m flops)\n",
      "  model_14/conv2d_200/Conv2D (3.56m/3.56m flops)\n",
      "  model_14/conv2d_202/Conv2D (2.95m/2.95m flops)\n",
      "  model_14/conv2d_198/Conv2D (2.41m/2.41m flops)\n",
      "  model_14/conv2d_208/Conv2D (1.74m/1.74m flops)\n",
      "  model_14/conv2d_196/Conv2D (1.05m/1.05m flops)\n",
      "  model_14/conv2d_209/Conv2D (960.51k/960.51k flops)\n",
      "  model_14/depthwise_conv2d_182/depthwise (589.82k/589.82k flops)\n",
      "  model_14/depthwise_conv2d_184/depthwise (350.21k/350.21k flops)\n",
      "  model_14/depthwise_conv2d_183/depthwise (285.70k/285.70k flops)\n",
      "  model_14/depthwise_conv2d_186/depthwise (281.09k/281.09k flops)\n",
      "  model_14/depthwise_conv2d_189/depthwise (146.30k/146.30k flops)\n",
      "  model_14/depthwise_conv2d_185/depthwise (131.33k/131.33k flops)\n",
      "  model_14/batch_normalization_380/FusedBatchNormV3 (127.35k/127.35k flops)\n",
      "  model_14/depthwise_conv2d_192/depthwise (119.81k/119.81k flops)\n",
      "  model_14/depthwise_conv2d_190/depthwise (118.08k/118.08k flops)\n",
      "  model_14/depthwise_conv2d_191/depthwise (115.20k/115.20k flops)\n",
      "  model_14/depthwise_conv2d_188/depthwise (105.41k/105.41k flops)\n",
      "  model_14/depthwise_conv2d_187/depthwise (72.58k/72.58k flops)\n",
      "  model_14/batch_normalization_379/FusedBatchNormV3 (65.73k/65.73k flops)\n",
      "  model_14/batch_normalization_378/FusedBatchNormV3 (65.73k/65.73k flops)\n",
      "  model_14/conv2d_197/BiasAdd (63.49k/63.49k flops)\n",
      "  model_14/batch_normalization_384/FusedBatchNormV3 (59.05k/59.05k flops)\n",
      "  model_14/batch_normalization_383/FusedBatchNormV3 (39.37k/39.37k flops)\n",
      "  model_14/batch_normalization_382/FusedBatchNormV3 (39.37k/39.37k flops)\n",
      "  model_14/batch_normalization_388/FusedBatchNormV3 (33.77k/33.77k flops)\n",
      "  model_14/conv2d_196/BiasAdd (32.77k/32.77k flops)\n",
      "  model_14/depthwise_conv2d_182/BiasAdd (32.77k/32.77k flops)\n",
      "  model_14/batch_normalization_386/FusedBatchNormV3 (32.70k/32.70k flops)\n",
      "  model_14/batch_normalization_387/FusedBatchNormV3 (32.70k/32.70k flops)\n",
      "  model_14/batch_normalization_381/FusedBatchNormV3 (32.12k/32.12k flops)\n",
      "  model_14/depthwise_conv2d_193/depthwise (30.53k/30.53k flops)\n",
      "  model_14/conv2d_199/BiasAdd (29.18k/29.18k flops)\n",
      "  model_14/conv2d_198/BiasAdd (19.46k/19.46k flops)\n",
      "  model_14/depthwise_conv2d_184/BiasAdd (19.46k/19.46k flops)\n",
      "  model_14/batch_normalization_393/FusedBatchNormV3 (19.30k/19.30k flops)\n",
      "  model_14/batch_normalization_392/FusedBatchNormV3 (19.30k/19.30k flops)\n",
      "  model_14/dense_14/MatMul (18.76k/18.76k flops)\n",
      "  model_14/conv2d_201/BiasAdd (16.13k/16.13k flops)\n",
      "  model_14/batch_normalization_400/FusedBatchNormV3 (16.11k/16.11k flops)\n",
      "  model_14/depthwise_conv2d_183/BiasAdd (15.87k/15.87k flops)\n",
      "  model_14/batch_normalization_398/FusedBatchNormV3 (15.81k/15.81k flops)\n",
      "  model_14/batch_normalization_399/FusedBatchNormV3 (15.81k/15.81k flops)\n",
      "  model_14/depthwise_conv2d_186/BiasAdd (15.62k/15.62k flops)\n",
      "  model_14/conv2d_200/BiasAdd (15.62k/15.62k flops)\n",
      "  model_14/batch_normalization_394/FusedBatchNormV3 (15.58k/15.58k flops)\n",
      "  model_14/batch_normalization_395/FusedBatchNormV3 (15.58k/15.58k flops)\n",
      "  model_14/batch_normalization_385/FusedBatchNormV3 (15.28k/15.28k flops)\n",
      "  model_14/batch_normalization_396/FusedBatchNormV3 (15.20k/15.20k flops)\n",
      "  model_14/batch_normalization_397/FusedBatchNormV3 (15.20k/15.20k flops)\n",
      "  model_14/batch_normalization_391/FusedBatchNormV3 (13.91k/13.91k flops)\n",
      "  model_14/batch_normalization_390/FusedBatchNormV3 (13.91k/13.91k flops)\n",
      "  model_14/batch_normalization_389/FusedBatchNormV3 (9.58k/9.58k flops)\n",
      "  model_14/depthwise_conv2d_194/depthwise (9.22k/9.22k flops)\n",
      "  model_14/depthwise_conv2d_189/BiasAdd (8.13k/8.13k flops)\n",
      "  model_14/conv2d_203/BiasAdd (8.13k/8.13k flops)\n",
      "  model_14/batch_normalization_404/FusedBatchNormV3 (7.50k/7.50k flops)\n",
      "  model_14/depthwise_conv2d_185/BiasAdd (7.30k/7.30k flops)\n",
      "  model_14/batch_normalization_402/FusedBatchNormV3 (7.17k/7.17k flops)\n",
      "  model_14/conv2d_207/BiasAdd (6.78k/6.78k flops)\n",
      "  model_14/conv2d_206/BiasAdd (6.66k/6.66k flops)\n",
      "  model_14/depthwise_conv2d_192/BiasAdd (6.66k/6.66k flops)\n",
      "  model_14/depthwise_conv2d_190/BiasAdd (6.56k/6.56k flops)\n",
      "  model_14/conv2d_204/BiasAdd (6.56k/6.56k flops)\n",
      "  model_14/conv2d_205/BiasAdd (6.40k/6.40k flops)\n",
      "  model_14/depthwise_conv2d_191/BiasAdd (6.40k/6.40k flops)\n",
      "  model_14/batch_normalization_401/FusedBatchNormV3 (5.94k/5.94k flops)\n",
      "  model_14/depthwise_conv2d_188/BiasAdd (5.86k/5.86k flops)\n",
      "  model_14/conv2d_202/BiasAdd (5.86k/5.86k flops)\n",
      "  model_14/batch_normalization_403/FusedBatchNormV3 (4.10k/4.10k flops)\n",
      "  model_14/depthwise_conv2d_187/BiasAdd (4.03k/4.03k flops)\n",
      "  model_14/conv2d_208/BiasAdd (2.05k/2.05k flops)\n",
      "  model_14/depthwise_conv2d_193/BiasAdd (1.70k/1.70k flops)\n",
      "  model_14/global_average_pooling2d_14/Mean (938/938 flops)\n",
      "  model_14/conv2d_209/BiasAdd (938/938 flops)\n",
      "  model_14/depthwise_conv2d_194/BiasAdd (512/512 flops)\n",
      "  model_14/dense_14/Softmax (50/50 flops)\n",
      "  model_14/dense_14/BiasAdd (10/10 flops)\n",
      "\n",
      "======================End of Report==========================\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "4.268892\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-30 13:39:51.141759: I tensorflow/core/grappler/devices.cc:66] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0\n",
      "2022-04-30 13:39:51.141873: I tensorflow/core/grappler/clusters/single_machine.cc:357] Starting new session\n",
      "2022-04-30 13:39:51.145834: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:1137] Optimization results for grappler item: graph_to_optimize\n",
      "  function_optimizer: function_optimizer did nothing. time = 0.004ms.\n",
      "  function_optimizer: function_optimizer did nothing. time = 0.001ms.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=========================Options=============================\n",
      "-max_depth                  10000\n",
      "-min_bytes                  0\n",
      "-min_peak_bytes             0\n",
      "-min_residual_bytes         0\n",
      "-min_output_bytes           0\n",
      "-min_micros                 0\n",
      "-min_accelerator_micros     0\n",
      "-min_cpu_micros             0\n",
      "-min_params                 0\n",
      "-min_float_ops              1\n",
      "-min_occurrence             0\n",
      "-step                       -1\n",
      "-order_by                   float_ops\n",
      "-account_type_regexes       .*\n",
      "-start_name_regexes         .*\n",
      "-trim_name_regexes          \n",
      "-show_name_regexes          .*\n",
      "-hide_name_regexes          \n",
      "-account_displayed_op_only  true\n",
      "-select                     float_ops\n",
      "-output                     stdout:\n",
      "\n",
      "==================Model Analysis Report======================\n",
      "\n",
      "Doc:\n",
      "scope: The nodes in the model graph are organized by their names, which is hierarchical like filesystem.\n",
      "flops: Number of float operations. Note: Please read the implementation for the math behind it.\n",
      "\n",
      "Profile:\n",
      "node name | # float_ops\n",
      "_TFProfRoot (--/69.22m flops)\n",
      "  model_15/conv2d_221/Conv2D (8.03m/8.03m flops)\n",
      "  model_15/conv2d_220/Conv2D (8.00m/8.00m flops)\n",
      "  model_15/conv2d_219/Conv2D (7.84m/7.84m flops)\n",
      "  model_15/conv2d_218/Conv2D (7.65m/7.65m flops)\n",
      "  model_15/conv2d_217/Conv2D (7.37m/7.37m flops)\n",
      "  model_15/conv2d_213/Conv2D (6.30m/6.30m flops)\n",
      "  model_15/conv2d_211/Conv2D (3.67m/3.67m flops)\n",
      "  model_15/conv2d_215/Conv2D (3.27m/3.27m flops)\n",
      "  model_15/conv2d_222/Conv2D (3.19m/3.19m flops)\n",
      "  model_15/conv2d_212/Conv2D (3.10m/3.10m flops)\n",
      "  model_15/conv2d_216/Conv2D (2.51m/2.51m flops)\n",
      "  model_15/conv2d_214/Conv2D (2.28m/2.28m flops)\n",
      "  model_15/conv2d_223/Conv2D (1.36m/1.36m flops)\n",
      "  model_15/conv2d_210/Conv2D (1.05m/1.05m flops)\n",
      "  model_15/depthwise_conv2d_195/depthwise (589.82k/589.82k flops)\n",
      "  model_15/depthwise_conv2d_197/depthwise (497.66k/497.66k flops)\n",
      "  model_15/depthwise_conv2d_196/depthwise (258.05k/258.05k flops)\n",
      "  model_15/depthwise_conv2d_199/depthwise (179.71k/179.71k flops)\n",
      "  model_15/depthwise_conv2d_205/depthwise (145.73k/145.73k flops)\n",
      "  model_15/depthwise_conv2d_203/depthwise (142.85k/142.85k flops)\n",
      "  model_15/depthwise_conv2d_204/depthwise (142.27k/142.27k flops)\n",
      "  model_15/depthwise_conv2d_202/depthwise (138.82k/138.82k flops)\n",
      "  model_15/depthwise_conv2d_201/depthwise (137.66k/137.66k flops)\n",
      "  model_15/depthwise_conv2d_198/depthwise (131.33k/131.33k flops)\n",
      "  model_15/batch_normalization_407/FusedBatchNormV3 (115.02k/115.02k flops)\n",
      "  model_15/batch_normalization_406/FusedBatchNormV3 (65.73k/65.73k flops)\n",
      "  model_15/batch_normalization_405/FusedBatchNormV3 (65.73k/65.73k flops)\n",
      "  model_15/batch_normalization_411/FusedBatchNormV3 (59.05k/59.05k flops)\n",
      "  model_15/conv2d_211/BiasAdd (57.34k/57.34k flops)\n",
      "  model_15/batch_normalization_410/FusedBatchNormV3 (55.94k/55.94k flops)\n",
      "  model_15/batch_normalization_409/FusedBatchNormV3 (55.94k/55.94k flops)\n",
      "  model_15/depthwise_conv2d_200/depthwise (47.23k/47.23k flops)\n",
      "  model_15/depthwise_conv2d_206/depthwise (35.71k/35.71k flops)\n",
      "  model_15/conv2d_210/BiasAdd (32.77k/32.77k flops)\n",
      "  model_15/depthwise_conv2d_195/BiasAdd (32.77k/32.77k flops)\n",
      "  model_15/conv2d_213/BiasAdd (29.18k/29.18k flops)\n",
      "  model_15/batch_normalization_408/FusedBatchNormV3 (29.01k/29.01k flops)\n",
      "  model_15/depthwise_conv2d_197/BiasAdd (27.65k/27.65k flops)\n",
      "  model_15/conv2d_212/BiasAdd (27.65k/27.65k flops)\n",
      "  model_15/batch_normalization_415/FusedBatchNormV3 (21.98k/21.98k flops)\n",
      "  model_15/batch_normalization_413/FusedBatchNormV3 (20.90k/20.90k flops)\n",
      "  model_15/batch_normalization_414/FusedBatchNormV3 (20.90k/20.90k flops)\n",
      "  model_15/batch_normalization_426/FusedBatchNormV3 (19.23k/19.23k flops)\n",
      "  model_15/batch_normalization_425/FusedBatchNormV3 (19.23k/19.23k flops)\n",
      "  model_15/batch_normalization_422/FusedBatchNormV3 (18.85k/18.85k flops)\n",
      "  model_15/batch_normalization_421/FusedBatchNormV3 (18.85k/18.85k flops)\n",
      "  model_15/batch_normalization_427/FusedBatchNormV3 (18.85k/18.85k flops)\n",
      "  model_15/batch_normalization_424/FusedBatchNormV3 (18.77k/18.77k flops)\n",
      "  model_15/batch_normalization_423/FusedBatchNormV3 (18.77k/18.77k flops)\n",
      "  model_15/batch_normalization_419/FusedBatchNormV3 (18.32k/18.32k flops)\n",
      "  model_15/batch_normalization_420/FusedBatchNormV3 (18.32k/18.32k flops)\n",
      "  model_15/batch_normalization_418/FusedBatchNormV3 (18.16k/18.16k flops)\n",
      "  model_15/batch_normalization_417/FusedBatchNormV3 (18.16k/18.16k flops)\n",
      "  model_15/dense_15/MatMul (16.88k/16.88k flops)\n",
      "  model_15/batch_normalization_412/FusedBatchNormV3 (15.28k/15.28k flops)\n",
      "  model_15/depthwise_conv2d_207/depthwise (14.47k/14.47k flops)\n",
      "  model_15/depthwise_conv2d_196/BiasAdd (14.34k/14.34k flops)\n",
      "  model_15/batch_normalization_429/FusedBatchNormV3 (11.26k/11.26k flops)\n",
      "  model_15/conv2d_215/BiasAdd (10.50k/10.50k flops)\n",
      "  model_15/conv2d_214/BiasAdd (9.98k/9.98k flops)\n",
      "  model_15/depthwise_conv2d_199/BiasAdd (9.98k/9.98k flops)\n",
      "  model_15/depthwise_conv2d_205/BiasAdd (8.10k/8.10k flops)\n",
      "  model_15/conv2d_220/BiasAdd (8.10k/8.10k flops)\n",
      "  model_15/depthwise_conv2d_203/BiasAdd (7.94k/7.94k flops)\n",
      "  model_15/conv2d_218/BiasAdd (7.94k/7.94k flops)\n",
      "  model_15/conv2d_221/BiasAdd (7.94k/7.94k flops)\n",
      "  model_15/conv2d_219/BiasAdd (7.90k/7.90k flops)\n",
      "  model_15/depthwise_conv2d_204/BiasAdd (7.90k/7.90k flops)\n",
      "  model_15/conv2d_217/BiasAdd (7.71k/7.71k flops)\n",
      "  model_15/depthwise_conv2d_202/BiasAdd (7.71k/7.71k flops)\n",
      "  model_15/conv2d_216/BiasAdd (7.65k/7.65k flops)\n",
      "  model_15/depthwise_conv2d_201/BiasAdd (7.65k/7.65k flops)\n",
      "  model_15/depthwise_conv2d_198/BiasAdd (7.30k/7.30k flops)\n",
      "  model_15/batch_normalization_428/FusedBatchNormV3 (6.94k/6.94k flops)\n",
      "  model_15/batch_normalization_431/FusedBatchNormV3 (6.75k/6.75k flops)\n",
      "  model_15/batch_normalization_430/FusedBatchNormV3 (6.43k/6.43k flops)\n",
      "  model_15/batch_normalization_416/FusedBatchNormV3 (6.23k/6.23k flops)\n",
      "  model_15/conv2d_222/BiasAdd (3.22k/3.22k flops)\n",
      "  model_15/depthwise_conv2d_200/BiasAdd (2.62k/2.62k flops)\n",
      "  model_15/depthwise_conv2d_206/BiasAdd (1.98k/1.98k flops)\n",
      "  model_15/global_average_pooling2d_15/Mean (844/844 flops)\n",
      "  model_15/conv2d_223/BiasAdd (844/844 flops)\n",
      "  model_15/depthwise_conv2d_207/BiasAdd (804/804 flops)\n",
      "  model_15/dense_15/Softmax (50/50 flops)\n",
      "  model_15/dense_15/BiasAdd (10/10 flops)\n",
      "\n",
      "======================End of Report==========================\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "4.04318\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-30 13:39:52.167695: I tensorflow/core/grappler/devices.cc:66] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0\n",
      "2022-04-30 13:39:52.167812: I tensorflow/core/grappler/clusters/single_machine.cc:357] Starting new session\n",
      "2022-04-30 13:39:52.171826: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:1137] Optimization results for grappler item: graph_to_optimize\n",
      "  function_optimizer: function_optimizer did nothing. time = 0.004ms.\n",
      "  function_optimizer: function_optimizer did nothing. time = 0.001ms.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=========================Options=============================\n",
      "-max_depth                  10000\n",
      "-min_bytes                  0\n",
      "-min_peak_bytes             0\n",
      "-min_residual_bytes         0\n",
      "-min_output_bytes           0\n",
      "-min_micros                 0\n",
      "-min_accelerator_micros     0\n",
      "-min_cpu_micros             0\n",
      "-min_params                 0\n",
      "-min_float_ops              1\n",
      "-min_occurrence             0\n",
      "-step                       -1\n",
      "-order_by                   float_ops\n",
      "-account_type_regexes       .*\n",
      "-start_name_regexes         .*\n",
      "-trim_name_regexes          \n",
      "-show_name_regexes          .*\n",
      "-hide_name_regexes          \n",
      "-account_displayed_op_only  true\n",
      "-select                     float_ops\n",
      "-output                     stdout:\n",
      "\n",
      "==================Model Analysis Report======================\n",
      "\n",
      "Doc:\n",
      "scope: The nodes in the model graph are organized by their names, which is hierarchical like filesystem.\n",
      "flops: Number of float operations. Note: Please read the implementation for the math behind it.\n",
      "\n",
      "Profile:\n",
      "node name | # float_ops\n",
      "_TFProfRoot (--/61.15m flops)\n",
      "  model_16/conv2d_227/Conv2D (7.62m/7.62m flops)\n",
      "  model_16/conv2d_232/Conv2D (6.79m/6.79m flops)\n",
      "  model_16/conv2d_231/Conv2D (6.63m/6.63m flops)\n",
      "  model_16/conv2d_234/Conv2D (6.54m/6.54m flops)\n",
      "  model_16/conv2d_235/Conv2D (6.45m/6.45m flops)\n",
      "  model_16/conv2d_233/Conv2D (5.78m/5.78m flops)\n",
      "  model_16/conv2d_229/Conv2D (3.61m/3.61m flops)\n",
      "  model_16/conv2d_225/Conv2D (2.62m/2.62m flops)\n",
      "  model_16/conv2d_230/Conv2D (2.61m/2.61m flops)\n",
      "  model_16/conv2d_226/Conv2D (2.50m/2.50m flops)\n",
      "  model_16/conv2d_236/Conv2D (2.27m/2.27m flops)\n",
      "  model_16/conv2d_228/Conv2D (2.25m/2.25m flops)\n",
      "  model_16/conv2d_224/Conv2D (1.05m/1.05m flops)\n",
      "  model_16/conv2d_237/Conv2D (962.88k/962.88k flops)\n",
      "  model_16/depthwise_conv2d_208/depthwise (589.82k/589.82k flops)\n",
      "  model_16/depthwise_conv2d_210/depthwise (562.18k/562.18k flops)\n",
      "  model_16/depthwise_conv2d_209/depthwise (184.32k/184.32k flops)\n",
      "  model_16/depthwise_conv2d_212/depthwise (165.89k/165.89k flops)\n",
      "  model_16/depthwise_conv2d_215/depthwise (143.42k/143.42k flops)\n",
      "  model_16/depthwise_conv2d_211/depthwise (140.54k/140.54k flops)\n",
      "  model_16/depthwise_conv2d_218/depthwise (138.82k/138.82k flops)\n",
      "  model_16/depthwise_conv2d_216/depthwise (122.69k/122.69k flops)\n",
      "  model_16/depthwise_conv2d_217/depthwise (122.11k/122.11k flops)\n",
      "  model_16/depthwise_conv2d_214/depthwise (119.81k/119.81k flops)\n",
      "  model_16/batch_normalization_434/FusedBatchNormV3 (82.16k/82.16k flops)\n",
      "  model_16/batch_normalization_433/FusedBatchNormV3 (65.73k/65.73k flops)\n",
      "  model_16/batch_normalization_432/FusedBatchNormV3 (65.73k/65.73k flops)\n",
      "  model_16/batch_normalization_436/FusedBatchNormV3 (63.20k/63.20k flops)\n",
      "  model_16/batch_normalization_437/FusedBatchNormV3 (63.20k/63.20k flops)\n",
      "  model_16/batch_normalization_438/FusedBatchNormV3 (63.20k/63.20k flops)\n",
      "  model_16/depthwise_conv2d_213/depthwise (56.45k/56.45k flops)\n",
      "  model_16/conv2d_225/BiasAdd (40.96k/40.96k flops)\n",
      "  model_16/conv2d_224/BiasAdd (32.77k/32.77k flops)\n",
      "  model_16/depthwise_conv2d_208/BiasAdd (32.77k/32.77k flops)\n",
      "  model_16/depthwise_conv2d_210/BiasAdd (31.23k/31.23k flops)\n",
      "  model_16/conv2d_226/BiasAdd (31.23k/31.23k flops)\n",
      "  model_16/conv2d_227/BiasAdd (31.23k/31.23k flops)\n",
      "  model_16/depthwise_conv2d_219/depthwise (30.10k/30.10k flops)\n",
      "  model_16/batch_normalization_442/FusedBatchNormV3 (26.26k/26.26k flops)\n",
      "  model_16/batch_normalization_435/FusedBatchNormV3 (20.72k/20.72k flops)\n",
      "  model_16/batch_normalization_440/FusedBatchNormV3 (19.30k/19.30k flops)\n",
      "  model_16/batch_normalization_441/FusedBatchNormV3 (19.30k/19.30k flops)\n",
      "  model_16/batch_normalization_447/FusedBatchNormV3 (18.92k/18.92k flops)\n",
      "  model_16/batch_normalization_446/FusedBatchNormV3 (18.92k/18.92k flops)\n",
      "  model_16/batch_normalization_452/FusedBatchNormV3 (18.32k/18.32k flops)\n",
      "  model_16/batch_normalization_453/FusedBatchNormV3 (18.32k/18.32k flops)\n",
      "  model_16/batch_normalization_439/FusedBatchNormV3 (16.35k/16.35k flops)\n",
      "  model_16/batch_normalization_449/FusedBatchNormV3 (16.19k/16.19k flops)\n",
      "  model_16/batch_normalization_448/FusedBatchNormV3 (16.19k/16.19k flops)\n",
      "  model_16/batch_normalization_451/FusedBatchNormV3 (16.11k/16.11k flops)\n",
      "  model_16/batch_normalization_450/FusedBatchNormV3 (16.11k/16.11k flops)\n",
      "  model_16/batch_normalization_454/FusedBatchNormV3 (15.88k/15.88k flops)\n",
      "  model_16/batch_normalization_445/FusedBatchNormV3 (15.81k/15.81k flops)\n",
      "  model_16/batch_normalization_444/FusedBatchNormV3 (15.81k/15.81k flops)\n",
      "  model_16/dense_16/MatMul (14.16k/14.16k flops)\n",
      "  model_16/conv2d_229/BiasAdd (12.54k/12.54k flops)\n",
      "  model_16/depthwise_conv2d_220/depthwise (12.24k/12.24k flops)\n",
      "  model_16/depthwise_conv2d_209/BiasAdd (10.24k/10.24k flops)\n",
      "  model_16/batch_normalization_456/FusedBatchNormV3 (9.52k/9.52k flops)\n",
      "  model_16/depthwise_conv2d_212/BiasAdd (9.22k/9.22k flops)\n",
      "  model_16/conv2d_228/BiasAdd (9.22k/9.22k flops)\n",
      "  model_16/conv2d_231/BiasAdd (7.97k/7.97k flops)\n",
      "  model_16/depthwise_conv2d_215/BiasAdd (7.97k/7.97k flops)\n",
      "  model_16/depthwise_conv2d_211/BiasAdd (7.81k/7.81k flops)\n",
      "  model_16/depthwise_conv2d_218/BiasAdd (7.71k/7.71k flops)\n",
      "  model_16/conv2d_234/BiasAdd (7.71k/7.71k flops)\n",
      "  model_16/batch_normalization_443/FusedBatchNormV3 (7.45k/7.45k flops)\n",
      "  model_16/conv2d_232/BiasAdd (6.82k/6.82k flops)\n",
      "  model_16/depthwise_conv2d_216/BiasAdd (6.82k/6.82k flops)\n",
      "  model_16/conv2d_233/BiasAdd (6.78k/6.78k flops)\n",
      "  model_16/depthwise_conv2d_217/BiasAdd (6.78k/6.78k flops)\n",
      "  model_16/conv2d_235/BiasAdd (6.69k/6.69k flops)\n",
      "  model_16/depthwise_conv2d_214/BiasAdd (6.66k/6.66k flops)\n",
      "  model_16/conv2d_230/BiasAdd (6.66k/6.66k flops)\n",
      "  model_16/batch_normalization_455/FusedBatchNormV3 (5.85k/5.85k flops)\n",
      "  model_16/batch_normalization_458/FusedBatchNormV3 (5.66k/5.66k flops)\n",
      "  model_16/batch_normalization_457/FusedBatchNormV3 (5.44k/5.44k flops)\n",
      "  model_16/depthwise_conv2d_213/BiasAdd (3.14k/3.14k flops)\n",
      "  model_16/conv2d_236/BiasAdd (2.72k/2.72k flops)\n",
      "  model_16/depthwise_conv2d_219/BiasAdd (1.67k/1.67k flops)\n",
      "  model_16/global_average_pooling2d_16/Mean (708/708 flops)\n",
      "  model_16/conv2d_237/BiasAdd (708/708 flops)\n",
      "  model_16/depthwise_conv2d_220/BiasAdd (680/680 flops)\n",
      "  model_16/dense_16/Softmax (50/50 flops)\n",
      "  model_16/dense_16/BiasAdd (10/10 flops)\n",
      "\n",
      "======================End of Report==========================\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "4.312476\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-30 13:39:53.083635: I tensorflow/core/grappler/devices.cc:66] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0\n",
      "2022-04-30 13:39:53.083761: I tensorflow/core/grappler/clusters/single_machine.cc:357] Starting new session\n",
      "2022-04-30 13:39:53.087763: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:1137] Optimization results for grappler item: graph_to_optimize\n",
      "  function_optimizer: function_optimizer did nothing. time = 0.006ms.\n",
      "  function_optimizer: function_optimizer did nothing. time = 0.001ms.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=========================Options=============================\n",
      "-max_depth                  10000\n",
      "-min_bytes                  0\n",
      "-min_peak_bytes             0\n",
      "-min_residual_bytes         0\n",
      "-min_output_bytes           0\n",
      "-min_micros                 0\n",
      "-min_accelerator_micros     0\n",
      "-min_cpu_micros             0\n",
      "-min_params                 0\n",
      "-min_float_ops              1\n",
      "-min_occurrence             0\n",
      "-step                       -1\n",
      "-order_by                   float_ops\n",
      "-account_type_regexes       .*\n",
      "-start_name_regexes         .*\n",
      "-trim_name_regexes          \n",
      "-show_name_regexes          .*\n",
      "-hide_name_regexes          \n",
      "-account_displayed_op_only  true\n",
      "-select                     float_ops\n",
      "-output                     stdout:\n",
      "\n",
      "==================Model Analysis Report======================\n",
      "\n",
      "Doc:\n",
      "scope: The nodes in the model graph are organized by their names, which is hierarchical like filesystem.\n",
      "flops: Number of float operations. Note: Please read the implementation for the math behind it.\n",
      "\n",
      "Profile:\n",
      "node name | # float_ops\n",
      "_TFProfRoot (--/72.47m flops)\n",
      "  model_17/conv2d_247/Conv2D (7.80m/7.80m flops)\n",
      "  model_17/conv2d_248/Conv2D (7.80m/7.80m flops)\n",
      "  model_17/conv2d_243/Conv2D (7.75m/7.75m flops)\n",
      "  model_17/conv2d_249/Conv2D (7.53m/7.53m flops)\n",
      "  model_17/conv2d_246/Conv2D (7.22m/7.22m flops)\n",
      "  model_17/conv2d_241/Conv2D (6.89m/6.89m flops)\n",
      "  model_17/conv2d_245/Conv2D (6.65m/6.65m flops)\n",
      "  model_17/conv2d_242/Conv2D (3.72m/3.72m flops)\n",
      "  model_17/conv2d_244/Conv2D (3.50m/3.50m flops)\n",
      "  model_17/conv2d_239/Conv2D (2.88m/2.88m flops)\n",
      "  model_17/conv2d_240/Conv2D (2.57m/2.57m flops)\n",
      "  model_17/conv2d_250/Conv2D (2.26m/2.26m flops)\n",
      "  model_17/conv2d_251/Conv2D (1.16m/1.16m flops)\n",
      "  model_17/conv2d_238/Conv2D (1.05m/1.05m flops)\n",
      "  model_17/depthwise_conv2d_221/depthwise (589.82k/589.82k flops)\n",
      "  model_17/depthwise_conv2d_223/depthwise (525.31k/525.31k flops)\n",
      "  model_17/depthwise_conv2d_225/depthwise (283.39k/283.39k flops)\n",
      "  model_17/depthwise_conv2d_222/depthwise (202.75k/202.75k flops)\n",
      "  model_17/depthwise_conv2d_230/depthwise (145.73k/145.73k flops)\n",
      "  model_17/depthwise_conv2d_229/depthwise (138.82k/138.82k flops)\n",
      "  model_17/depthwise_conv2d_231/depthwise (138.82k/138.82k flops)\n",
      "  model_17/depthwise_conv2d_224/depthwise (135.94k/135.94k flops)\n",
      "  model_17/depthwise_conv2d_228/depthwise (134.78k/134.78k flops)\n",
      "  model_17/depthwise_conv2d_227/depthwise (127.87k/127.87k flops)\n",
      "  model_17/batch_normalization_461/FusedBatchNormV3 (90.38k/90.38k flops)\n",
      "  model_17/depthwise_conv2d_226/depthwise (70.85k/70.85k flops)\n",
      "  model_17/batch_normalization_460/FusedBatchNormV3 (65.73k/65.73k flops)\n",
      "  model_17/batch_normalization_459/FusedBatchNormV3 (65.73k/65.73k flops)\n",
      "  model_17/batch_normalization_465/FusedBatchNormV3 (61.12k/61.12k flops)\n",
      "  model_17/batch_normalization_464/FusedBatchNormV3 (59.05k/59.05k flops)\n",
      "  model_17/batch_normalization_463/FusedBatchNormV3 (59.05k/59.05k flops)\n",
      "  model_17/conv2d_239/BiasAdd (45.06k/45.06k flops)\n",
      "  model_17/depthwise_conv2d_232/depthwise (35.14k/35.14k flops)\n",
      "  model_17/batch_normalization_468/FusedBatchNormV3 (32.96k/32.96k flops)\n",
      "  model_17/batch_normalization_469/FusedBatchNormV3 (32.96k/32.96k flops)\n",
      "  model_17/batch_normalization_467/FusedBatchNormV3 (32.96k/32.96k flops)\n",
      "  model_17/conv2d_238/BiasAdd (32.77k/32.77k flops)\n",
      "  model_17/depthwise_conv2d_221/BiasAdd (32.77k/32.77k flops)\n",
      "  model_17/conv2d_241/BiasAdd (30.21k/30.21k flops)\n",
      "  model_17/depthwise_conv2d_223/BiasAdd (29.18k/29.18k flops)\n",
      "  model_17/conv2d_240/BiasAdd (29.18k/29.18k flops)\n",
      "  model_17/batch_normalization_462/FusedBatchNormV3 (22.79k/22.79k flops)\n",
      "  model_17/dense_17/MatMul (20.00k/20.00k flops)\n",
      "  model_17/batch_normalization_478/FusedBatchNormV3 (19.23k/19.23k flops)\n",
      "  model_17/batch_normalization_477/FusedBatchNormV3 (19.23k/19.23k flops)\n",
      "  model_17/batch_normalization_481/FusedBatchNormV3 (18.54k/18.54k flops)\n",
      "  model_17/batch_normalization_476/FusedBatchNormV3 (18.32k/18.32k flops)\n",
      "  model_17/batch_normalization_475/FusedBatchNormV3 (18.32k/18.32k flops)\n",
      "  model_17/batch_normalization_479/FusedBatchNormV3 (18.32k/18.32k flops)\n",
      "  model_17/batch_normalization_480/FusedBatchNormV3 (18.32k/18.32k flops)\n",
      "  model_17/batch_normalization_474/FusedBatchNormV3 (17.78k/17.78k flops)\n",
      "  model_17/batch_normalization_473/FusedBatchNormV3 (17.78k/17.78k flops)\n",
      "  model_17/batch_normalization_471/FusedBatchNormV3 (16.87k/16.87k flops)\n",
      "  model_17/batch_normalization_472/FusedBatchNormV3 (16.87k/16.87k flops)\n",
      "  model_17/batch_normalization_466/FusedBatchNormV3 (15.81k/15.81k flops)\n",
      "  model_17/conv2d_243/BiasAdd (15.74k/15.74k flops)\n",
      "  model_17/depthwise_conv2d_225/BiasAdd (15.74k/15.74k flops)\n",
      "  model_17/conv2d_242/BiasAdd (15.74k/15.74k flops)\n",
      "  model_17/depthwise_conv2d_222/BiasAdd (11.26k/11.26k flops)\n",
      "  model_17/depthwise_conv2d_233/depthwise (10.44k/10.44k flops)\n",
      "  model_17/batch_normalization_470/FusedBatchNormV3 (9.35k/9.35k flops)\n",
      "  model_17/batch_normalization_483/FusedBatchNormV3 (8.12k/8.12k flops)\n",
      "  model_17/conv2d_247/BiasAdd (8.10k/8.10k flops)\n",
      "  model_17/depthwise_conv2d_230/BiasAdd (8.10k/8.10k flops)\n",
      "  model_17/batch_normalization_485/FusedBatchNormV3 (8.00k/8.00k flops)\n",
      "  model_17/conv2d_249/BiasAdd (7.81k/7.81k flops)\n",
      "  model_17/depthwise_conv2d_229/BiasAdd (7.71k/7.71k flops)\n",
      "  model_17/conv2d_248/BiasAdd (7.71k/7.71k flops)\n",
      "  model_17/conv2d_246/BiasAdd (7.71k/7.71k flops)\n",
      "  model_17/depthwise_conv2d_231/BiasAdd (7.71k/7.71k flops)\n",
      "  model_17/depthwise_conv2d_224/BiasAdd (7.55k/7.55k flops)\n",
      "  model_17/depthwise_conv2d_228/BiasAdd (7.49k/7.49k flops)\n",
      "  model_17/conv2d_245/BiasAdd (7.49k/7.49k flops)\n",
      "  model_17/depthwise_conv2d_227/BiasAdd (7.10k/7.10k flops)\n",
      "  model_17/conv2d_244/BiasAdd (7.10k/7.10k flops)\n",
      "  model_17/batch_normalization_482/FusedBatchNormV3 (6.83k/6.83k flops)\n",
      "  model_17/batch_normalization_484/FusedBatchNormV3 (4.64k/4.64k flops)\n",
      "  model_17/depthwise_conv2d_226/BiasAdd (3.94k/3.94k flops)\n",
      "  model_17/conv2d_250/BiasAdd (2.32k/2.32k flops)\n",
      "  model_17/depthwise_conv2d_232/BiasAdd (1.95k/1.95k flops)\n",
      "  model_17/global_average_pooling2d_17/Mean (1.00k/1.00k flops)\n",
      "  model_17/conv2d_251/BiasAdd (1.00k/1.00k flops)\n",
      "  model_17/depthwise_conv2d_233/BiasAdd (580/580 flops)\n",
      "  model_17/dense_17/Softmax (50/50 flops)\n",
      "  model_17/dense_17/BiasAdd (10/10 flops)\n",
      "\n",
      "======================End of Report==========================\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "4.194244\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-30 13:39:54.133718: I tensorflow/core/grappler/devices.cc:66] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0\n",
      "2022-04-30 13:39:54.133833: I tensorflow/core/grappler/clusters/single_machine.cc:357] Starting new session\n",
      "2022-04-30 13:39:54.138085: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:1137] Optimization results for grappler item: graph_to_optimize\n",
      "  function_optimizer: function_optimizer did nothing. time = 0.006ms.\n",
      "  function_optimizer: function_optimizer did nothing. time = 0.001ms.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=========================Options=============================\n",
      "-max_depth                  10000\n",
      "-min_bytes                  0\n",
      "-min_peak_bytes             0\n",
      "-min_residual_bytes         0\n",
      "-min_output_bytes           0\n",
      "-min_micros                 0\n",
      "-min_accelerator_micros     0\n",
      "-min_cpu_micros             0\n",
      "-min_params                 0\n",
      "-min_float_ops              1\n",
      "-min_occurrence             0\n",
      "-step                       -1\n",
      "-order_by                   float_ops\n",
      "-account_type_regexes       .*\n",
      "-start_name_regexes         .*\n",
      "-trim_name_regexes          \n",
      "-show_name_regexes          .*\n",
      "-hide_name_regexes          \n",
      "-account_displayed_op_only  true\n",
      "-select                     float_ops\n",
      "-output                     stdout:\n",
      "\n",
      "==================Model Analysis Report======================\n",
      "\n",
      "Doc:\n",
      "scope: The nodes in the model graph are organized by their names, which is hierarchical like filesystem.\n",
      "flops: Number of float operations. Note: Please read the implementation for the math behind it.\n",
      "\n",
      "Profile:\n",
      "node name | # float_ops\n",
      "_TFProfRoot (--/71.47m flops)\n",
      "  model_18/conv2d_263/Conv2D (8.00m/8.00m flops)\n",
      "  model_18/conv2d_260/Conv2D (7.84m/7.84m flops)\n",
      "  model_18/conv2d_262/Conv2D (7.84m/7.84m flops)\n",
      "  model_18/conv2d_261/Conv2D (7.81m/7.81m flops)\n",
      "  model_18/conv2d_259/Conv2D (7.43m/7.43m flops)\n",
      "  model_18/conv2d_257/Conv2D (7.42m/7.42m flops)\n",
      "  model_18/conv2d_255/Conv2D (5.02m/5.02m flops)\n",
      "  model_18/conv2d_258/Conv2D (3.82m/3.82m flops)\n",
      "  model_18/conv2d_256/Conv2D (3.39m/3.39m flops)\n",
      "  model_18/conv2d_253/Conv2D (3.15m/3.15m flops)\n",
      "  model_18/conv2d_264/Conv2D (2.19m/2.19m flops)\n",
      "  model_18/conv2d_254/Conv2D (2.11m/2.11m flops)\n",
      "  model_18/conv2d_252/Conv2D (1.05m/1.05m flops)\n",
      "  model_18/conv2d_265/Conv2D (853.16k/853.16k flops)\n",
      "  model_18/depthwise_conv2d_234/depthwise (589.82k/589.82k flops)\n",
      "  model_18/depthwise_conv2d_236/depthwise (396.29k/396.29k flops)\n",
      "  model_18/depthwise_conv2d_238/depthwise (267.26k/267.26k flops)\n",
      "  model_18/depthwise_conv2d_235/depthwise (221.18k/221.18k flops)\n",
      "  model_18/depthwise_conv2d_244/depthwise (145.73k/145.73k flops)\n",
      "  model_18/depthwise_conv2d_242/depthwise (145.15k/145.15k flops)\n",
      "  model_18/depthwise_conv2d_241/depthwise (139.97k/139.97k flops)\n",
      "  model_18/depthwise_conv2d_243/depthwise (139.39k/139.39k flops)\n",
      "  model_18/depthwise_conv2d_240/depthwise (137.66k/137.66k flops)\n",
      "  model_18/depthwise_conv2d_237/depthwise (131.33k/131.33k flops)\n",
      "  model_18/batch_normalization_488/FusedBatchNormV3 (98.59k/98.59k flops)\n",
      "  model_18/depthwise_conv2d_239/depthwise (72.00k/72.00k flops)\n",
      "  model_18/batch_normalization_487/FusedBatchNormV3 (65.73k/65.73k flops)\n",
      "  model_18/batch_normalization_486/FusedBatchNormV3 (65.73k/65.73k flops)\n",
      "  model_18/batch_normalization_492/FusedBatchNormV3 (59.05k/59.05k flops)\n",
      "  model_18/conv2d_253/BiasAdd (49.15k/49.15k flops)\n",
      "  model_18/batch_normalization_490/FusedBatchNormV3 (44.55k/44.55k flops)\n",
      "  model_18/batch_normalization_491/FusedBatchNormV3 (44.55k/44.55k flops)\n",
      "  model_18/depthwise_conv2d_245/depthwise (35.57k/35.57k flops)\n",
      "  model_18/batch_normalization_496/FusedBatchNormV3 (33.50k/33.50k flops)\n",
      "  model_18/conv2d_252/BiasAdd (32.77k/32.77k flops)\n",
      "  model_18/depthwise_conv2d_234/BiasAdd (32.77k/32.77k flops)\n",
      "  model_18/batch_normalization_494/FusedBatchNormV3 (31.09k/31.09k flops)\n",
      "  model_18/batch_normalization_495/FusedBatchNormV3 (31.09k/31.09k flops)\n",
      "  model_18/conv2d_255/BiasAdd (29.18k/29.18k flops)\n",
      "  model_18/batch_normalization_489/FusedBatchNormV3 (24.86k/24.86k flops)\n",
      "  model_18/depthwise_conv2d_236/BiasAdd (22.02k/22.02k flops)\n",
      "  model_18/conv2d_254/BiasAdd (22.02k/22.02k flops)\n",
      "  model_18/batch_normalization_506/FusedBatchNormV3 (19.23k/19.23k flops)\n",
      "  model_18/batch_normalization_507/FusedBatchNormV3 (19.23k/19.23k flops)\n",
      "  model_18/batch_normalization_503/FusedBatchNormV3 (19.15k/19.15k flops)\n",
      "  model_18/batch_normalization_502/FusedBatchNormV3 (19.15k/19.15k flops)\n",
      "  model_18/batch_normalization_508/FusedBatchNormV3 (18.77k/18.77k flops)\n",
      "  model_18/batch_normalization_501/FusedBatchNormV3 (18.47k/18.47k flops)\n",
      "  model_18/batch_normalization_500/FusedBatchNormV3 (18.47k/18.47k flops)\n",
      "  model_18/batch_normalization_505/FusedBatchNormV3 (18.39k/18.39k flops)\n",
      "  model_18/batch_normalization_504/FusedBatchNormV3 (18.39k/18.39k flops)\n",
      "  model_18/batch_normalization_499/FusedBatchNormV3 (18.16k/18.16k flops)\n",
      "  model_18/batch_normalization_498/FusedBatchNormV3 (18.16k/18.16k flops)\n",
      "  model_18/conv2d_257/BiasAdd (16.00k/16.00k flops)\n",
      "  model_18/dense_18/MatMul (15.40k/15.40k flops)\n",
      "  model_18/batch_normalization_493/FusedBatchNormV3 (15.28k/15.28k flops)\n",
      "  model_18/conv2d_256/BiasAdd (14.85k/14.85k flops)\n",
      "  model_18/depthwise_conv2d_238/BiasAdd (14.85k/14.85k flops)\n",
      "  model_18/depthwise_conv2d_235/BiasAdd (12.29k/12.29k flops)\n",
      "  model_18/depthwise_conv2d_246/depthwise (9.97k/9.97k flops)\n",
      "  model_18/batch_normalization_497/FusedBatchNormV3 (9.50k/9.50k flops)\n",
      "  model_18/depthwise_conv2d_244/BiasAdd (8.10k/8.10k flops)\n",
      "  model_18/conv2d_262/BiasAdd (8.10k/8.10k flops)\n",
      "  model_18/depthwise_conv2d_242/BiasAdd (8.06k/8.06k flops)\n",
      "  model_18/conv2d_260/BiasAdd (8.06k/8.06k flops)\n",
      "  model_18/conv2d_263/BiasAdd (7.90k/7.90k flops)\n",
      "  model_18/conv2d_259/BiasAdd (7.78k/7.78k flops)\n",
      "  model_18/depthwise_conv2d_241/BiasAdd (7.78k/7.78k flops)\n",
      "  model_18/batch_normalization_510/FusedBatchNormV3 (7.76k/7.76k flops)\n",
      "  model_18/depthwise_conv2d_243/BiasAdd (7.74k/7.74k flops)\n",
      "  model_18/conv2d_261/BiasAdd (7.74k/7.74k flops)\n",
      "  model_18/depthwise_conv2d_240/BiasAdd (7.65k/7.65k flops)\n",
      "  model_18/conv2d_258/BiasAdd (7.65k/7.65k flops)\n",
      "  model_18/depthwise_conv2d_237/BiasAdd (7.30k/7.30k flops)\n",
      "  model_18/batch_normalization_509/FusedBatchNormV3 (6.92k/6.92k flops)\n",
      "  model_18/batch_normalization_512/FusedBatchNormV3 (6.16k/6.16k flops)\n",
      "  model_18/batch_normalization_511/FusedBatchNormV3 (4.43k/4.43k flops)\n",
      "  model_18/depthwise_conv2d_239/BiasAdd (4.00k/4.00k flops)\n",
      "  model_18/conv2d_264/BiasAdd (2.22k/2.22k flops)\n",
      "  model_18/depthwise_conv2d_245/BiasAdd (1.98k/1.98k flops)\n",
      "  model_18/conv2d_265/BiasAdd (770/770 flops)\n",
      "  model_18/global_average_pooling2d_18/Mean (770/770 flops)\n",
      "  model_18/depthwise_conv2d_246/BiasAdd (554/554 flops)\n",
      "  model_18/dense_18/Softmax (50/50 flops)\n",
      "  model_18/dense_18/BiasAdd (10/10 flops)\n",
      "\n",
      "======================End of Report==========================\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "3.829612\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-30 13:39:55.058427: I tensorflow/core/grappler/devices.cc:66] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0\n",
      "2022-04-30 13:39:55.058542: I tensorflow/core/grappler/clusters/single_machine.cc:357] Starting new session\n",
      "2022-04-30 13:39:55.062580: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:1137] Optimization results for grappler item: graph_to_optimize\n",
      "  function_optimizer: function_optimizer did nothing. time = 0.005ms.\n",
      "  function_optimizer: function_optimizer did nothing. time = 0ms.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=========================Options=============================\n",
      "-max_depth                  10000\n",
      "-min_bytes                  0\n",
      "-min_peak_bytes             0\n",
      "-min_residual_bytes         0\n",
      "-min_output_bytes           0\n",
      "-min_micros                 0\n",
      "-min_accelerator_micros     0\n",
      "-min_cpu_micros             0\n",
      "-min_params                 0\n",
      "-min_float_ops              1\n",
      "-min_occurrence             0\n",
      "-step                       -1\n",
      "-order_by                   float_ops\n",
      "-account_type_regexes       .*\n",
      "-start_name_regexes         .*\n",
      "-trim_name_regexes          \n",
      "-show_name_regexes          .*\n",
      "-hide_name_regexes          \n",
      "-account_displayed_op_only  true\n",
      "-select                     float_ops\n",
      "-output                     stdout:\n",
      "\n",
      "==================Model Analysis Report======================\n",
      "\n",
      "Doc:\n",
      "scope: The nodes in the model graph are organized by their names, which is hierarchical like filesystem.\n",
      "flops: Number of float operations. Note: Please read the implementation for the math behind it.\n",
      "\n",
      "Profile:\n",
      "node name | # float_ops\n",
      "_TFProfRoot (--/48.62m flops)\n",
      "  model_19/conv2d_277/Conv2D (5.29m/5.29m flops)\n",
      "  model_19/conv2d_274/Conv2D (5.02m/5.02m flops)\n",
      "  model_19/conv2d_269/Conv2D (4.90m/4.90m flops)\n",
      "  model_19/conv2d_275/Conv2D (3.82m/3.82m flops)\n",
      "  model_19/conv2d_267/Conv2D (3.67m/3.67m flops)\n",
      "  model_19/conv2d_278/Conv2D (3.66m/3.66m flops)\n",
      "  model_19/conv2d_273/Conv2D (3.61m/3.61m flops)\n",
      "  model_19/conv2d_276/Conv2D (3.36m/3.36m flops)\n",
      "  model_19/conv2d_271/Conv2D (3.15m/3.15m flops)\n",
      "  model_19/conv2d_268/Conv2D (2.18m/2.18m flops)\n",
      "  model_19/conv2d_270/Conv2D (2.06m/2.06m flops)\n",
      "  model_19/conv2d_279/Conv2D (1.98m/1.98m flops)\n",
      "  model_19/conv2d_272/Conv2D (1.76m/1.76m flops)\n",
      "  model_19/conv2d_266/Conv2D (1.05m/1.05m flops)\n",
      "  model_19/depthwise_conv2d_247/depthwise (589.82k/589.82k flops)\n",
      "  model_19/depthwise_conv2d_249/depthwise (350.21k/350.21k flops)\n",
      "  model_19/depthwise_conv2d_248/depthwise (258.05k/258.05k flops)\n",
      "  model_19/depthwise_conv2d_251/depthwise (147.46k/147.46k flops)\n",
      "  model_19/depthwise_conv2d_250/depthwise (145.15k/145.15k flops)\n",
      "  model_19/batch_normalization_515/FusedBatchNormV3 (115.02k/115.02k flops)\n",
      "  model_19/depthwise_conv2d_255/depthwise (114.62k/114.62k flops)\n",
      "  model_19/depthwise_conv2d_254/depthwise (113.47k/113.47k flops)\n",
      "  model_19/depthwise_conv2d_257/depthwise (100.80k/100.80k flops)\n",
      "  model_19/depthwise_conv2d_256/depthwise (86.40k/86.40k flops)\n",
      "  model_19/depthwise_conv2d_253/depthwise (82.37k/82.37k flops)\n",
      "  model_19/batch_normalization_514/FusedBatchNormV3 (65.73k/65.73k flops)\n",
      "  model_19/batch_normalization_513/FusedBatchNormV3 (65.73k/65.73k flops)\n",
      "  model_19/batch_normalization_519/FusedBatchNormV3 (65.27k/65.27k flops)\n",
      "  model_19/conv2d_267/BiasAdd (57.34k/57.34k flops)\n",
      "  model_19/depthwise_conv2d_252/depthwise (55.30k/55.30k flops)\n",
      "  model_19/batch_normalization_518/FusedBatchNormV3 (39.37k/39.37k flops)\n",
      "  model_19/batch_normalization_517/FusedBatchNormV3 (39.37k/39.37k flops)\n",
      "  model_19/depthwise_conv2d_258/depthwise (33.98k/33.98k flops)\n",
      "  model_19/conv2d_266/BiasAdd (32.77k/32.77k flops)\n",
      "  model_19/depthwise_conv2d_247/BiasAdd (32.77k/32.77k flops)\n",
      "  model_19/conv2d_269/BiasAdd (32.26k/32.26k flops)\n",
      "  model_19/batch_normalization_516/FusedBatchNormV3 (29.01k/29.01k flops)\n",
      "  model_19/batch_normalization_523/FusedBatchNormV3 (25.73k/25.73k flops)\n",
      "  model_19/dense_19/MatMul (20.44k/20.44k flops)\n",
      "  model_19/depthwise_conv2d_249/BiasAdd (19.46k/19.46k flops)\n",
      "  model_19/conv2d_268/BiasAdd (19.46k/19.46k flops)\n",
      "  model_19/batch_normalization_535/FusedBatchNormV3 (17.94k/17.94k flops)\n",
      "  model_19/depthwise_conv2d_259/depthwise (17.42k/17.42k flops)\n",
      "  model_19/batch_normalization_522/FusedBatchNormV3 (17.15k/17.15k flops)\n",
      "  model_19/batch_normalization_521/FusedBatchNormV3 (17.15k/17.15k flops)\n",
      "  model_19/batch_normalization_520/FusedBatchNormV3 (16.88k/16.88k flops)\n",
      "  model_19/batch_normalization_529/FusedBatchNormV3 (15.12k/15.12k flops)\n",
      "  model_19/batch_normalization_530/FusedBatchNormV3 (15.12k/15.12k flops)\n",
      "  model_19/batch_normalization_528/FusedBatchNormV3 (14.97k/14.97k flops)\n",
      "  model_19/batch_normalization_527/FusedBatchNormV3 (14.97k/14.97k flops)\n",
      "  model_19/depthwise_conv2d_248/BiasAdd (14.34k/14.34k flops)\n",
      "  model_19/batch_normalization_537/FusedBatchNormV3 (13.55k/13.55k flops)\n",
      "  model_19/batch_normalization_534/FusedBatchNormV3 (13.30k/13.30k flops)\n",
      "  model_19/batch_normalization_533/FusedBatchNormV3 (13.30k/13.30k flops)\n",
      "  model_19/conv2d_271/BiasAdd (12.29k/12.29k flops)\n",
      "  model_19/batch_normalization_531/FusedBatchNormV3 (11.40k/11.40k flops)\n",
      "  model_19/batch_normalization_532/FusedBatchNormV3 (11.40k/11.40k flops)\n",
      "  model_19/batch_normalization_525/FusedBatchNormV3 (10.87k/10.87k flops)\n",
      "  model_19/batch_normalization_526/FusedBatchNormV3 (10.87k/10.87k flops)\n",
      "  model_19/depthwise_conv2d_251/BiasAdd (8.19k/8.19k flops)\n",
      "  model_19/conv2d_270/BiasAdd (8.19k/8.19k flops)\n",
      "  model_19/batch_normalization_539/FusedBatchNormV3 (8.18k/8.18k flops)\n",
      "  model_19/depthwise_conv2d_250/BiasAdd (8.06k/8.06k flops)\n",
      "  model_19/batch_normalization_538/FusedBatchNormV3 (7.74k/7.74k flops)\n",
      "  model_19/conv2d_277/BiasAdd (7.55k/7.55k flops)\n",
      "  model_19/batch_normalization_524/FusedBatchNormV3 (7.30k/7.30k flops)\n",
      "  model_19/batch_normalization_536/FusedBatchNormV3 (6.61k/6.61k flops)\n",
      "  model_19/conv2d_274/BiasAdd (6.37k/6.37k flops)\n",
      "  model_19/depthwise_conv2d_255/BiasAdd (6.37k/6.37k flops)\n",
      "  model_19/depthwise_conv2d_254/BiasAdd (6.30k/6.30k flops)\n",
      "  model_19/conv2d_273/BiasAdd (6.30k/6.30k flops)\n",
      "  model_19/conv2d_276/BiasAdd (5.60k/5.60k flops)\n",
      "  model_19/depthwise_conv2d_257/BiasAdd (5.60k/5.60k flops)\n",
      "  model_19/conv2d_275/BiasAdd (4.80k/4.80k flops)\n",
      "  model_19/depthwise_conv2d_256/BiasAdd (4.80k/4.80k flops)\n",
      "  model_19/depthwise_conv2d_253/BiasAdd (4.58k/4.58k flops)\n",
      "  model_19/conv2d_272/BiasAdd (4.58k/4.58k flops)\n",
      "  model_19/conv2d_278/BiasAdd (3.87k/3.87k flops)\n",
      "  model_19/depthwise_conv2d_252/BiasAdd (3.07k/3.07k flops)\n",
      "  model_19/depthwise_conv2d_258/BiasAdd (1.89k/1.89k flops)\n",
      "  model_19/global_average_pooling2d_19/Mean (1.02k/1.02k flops)\n",
      "  model_19/conv2d_279/BiasAdd (1.02k/1.02k flops)\n",
      "  model_19/depthwise_conv2d_259/BiasAdd (968/968 flops)\n",
      "  model_19/dense_19/Softmax (50/50 flops)\n",
      "  model_19/dense_19/BiasAdd (10/10 flops)\n",
      "\n",
      "======================End of Report==========================\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "4.00602\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-30 13:39:56.120328: I tensorflow/core/grappler/devices.cc:66] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0\n",
      "2022-04-30 13:39:56.120441: I tensorflow/core/grappler/clusters/single_machine.cc:357] Starting new session\n",
      "2022-04-30 13:39:56.124751: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:1137] Optimization results for grappler item: graph_to_optimize\n",
      "  function_optimizer: function_optimizer did nothing. time = 0.006ms.\n",
      "  function_optimizer: function_optimizer did nothing. time = 0.001ms.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=========================Options=============================\n",
      "-max_depth                  10000\n",
      "-min_bytes                  0\n",
      "-min_peak_bytes             0\n",
      "-min_residual_bytes         0\n",
      "-min_output_bytes           0\n",
      "-min_micros                 0\n",
      "-min_accelerator_micros     0\n",
      "-min_cpu_micros             0\n",
      "-min_params                 0\n",
      "-min_float_ops              1\n",
      "-min_occurrence             0\n",
      "-step                       -1\n",
      "-order_by                   float_ops\n",
      "-account_type_regexes       .*\n",
      "-start_name_regexes         .*\n",
      "-trim_name_regexes          \n",
      "-show_name_regexes          .*\n",
      "-hide_name_regexes          \n",
      "-account_displayed_op_only  true\n",
      "-select                     float_ops\n",
      "-output                     stdout:\n",
      "\n",
      "==================Model Analysis Report======================\n",
      "\n",
      "Doc:\n",
      "scope: The nodes in the model graph are organized by their names, which is hierarchical like filesystem.\n",
      "flops: Number of float operations. Note: Please read the implementation for the math behind it.\n",
      "\n",
      "Profile:\n",
      "node name | # float_ops\n",
      "_TFProfRoot (--/66.64m flops)\n",
      "  model_20/conv2d_288/Conv2D (8.03m/8.03m flops)\n",
      "  model_20/conv2d_291/Conv2D (7.78m/7.78m flops)\n",
      "  model_20/conv2d_289/Conv2D (7.74m/7.74m flops)\n",
      "  model_20/conv2d_290/Conv2D (7.74m/7.74m flops)\n",
      "  model_20/conv2d_287/Conv2D (7.71m/7.71m flops)\n",
      "  model_20/conv2d_285/Conv2D (3.81m/3.81m flops)\n",
      "  model_20/conv2d_281/Conv2D (3.80m/3.80m flops)\n",
      "  model_20/conv2d_286/Conv2D (3.73m/3.73m flops)\n",
      "  model_20/conv2d_292/Conv2D (3.51m/3.51m flops)\n",
      "  model_20/conv2d_283/Conv2D (3.11m/3.11m flops)\n",
      "  model_20/conv2d_282/Conv2D (2.26m/2.26m flops)\n",
      "  model_20/conv2d_293/Conv2D (1.76m/1.76m flops)\n",
      "  model_20/conv2d_284/Conv2D (1.25m/1.25m flops)\n",
      "  model_20/conv2d_280/Conv2D (1.05m/1.05m flops)\n",
      "  model_20/depthwise_conv2d_260/depthwise (589.82k/589.82k flops)\n",
      "  model_20/depthwise_conv2d_262/depthwise (350.21k/350.21k flops)\n",
      "  model_20/depthwise_conv2d_261/depthwise (267.26k/267.26k flops)\n",
      "  model_20/depthwise_conv2d_267/depthwise (145.15k/145.15k flops)\n",
      "  model_20/depthwise_conv2d_268/depthwise (143.42k/143.42k flops)\n",
      "  model_20/depthwise_conv2d_270/depthwise (143.42k/143.42k flops)\n",
      "  model_20/depthwise_conv2d_264/depthwise (140.54k/140.54k flops)\n",
      "  model_20/depthwise_conv2d_269/depthwise (139.97k/139.97k flops)\n",
      "  model_20/depthwise_conv2d_266/depthwise (137.66k/137.66k flops)\n",
      "  model_20/batch_normalization_542/FusedBatchNormV3 (119.13k/119.13k flops)\n",
      "  model_20/depthwise_conv2d_263/depthwise (92.16k/92.16k flops)\n",
      "  model_20/depthwise_conv2d_265/depthwise (70.27k/70.27k flops)\n",
      "  model_20/batch_normalization_541/FusedBatchNormV3 (65.73k/65.73k flops)\n",
      "  model_20/batch_normalization_540/FusedBatchNormV3 (65.73k/65.73k flops)\n",
      "  model_20/conv2d_281/BiasAdd (59.39k/59.39k flops)\n",
      "  model_20/batch_normalization_546/FusedBatchNormV3 (41.44k/41.44k flops)\n",
      "  model_20/batch_normalization_545/FusedBatchNormV3 (39.37k/39.37k flops)\n",
      "  model_20/batch_normalization_544/FusedBatchNormV3 (39.37k/39.37k flops)\n",
      "  model_20/depthwise_conv2d_271/depthwise (35.14k/35.14k flops)\n",
      "  model_20/conv2d_280/BiasAdd (32.77k/32.77k flops)\n",
      "  model_20/depthwise_conv2d_260/BiasAdd (32.77k/32.77k flops)\n",
      "  model_20/batch_normalization_550/FusedBatchNormV3 (32.70k/32.70k flops)\n",
      "  model_20/batch_normalization_543/FusedBatchNormV3 (30.04k/30.04k flops)\n",
      "  model_20/conv2d_283/BiasAdd (20.48k/20.48k flops)\n",
      "  model_20/dense_20/MatMul (19.64k/19.64k flops)\n",
      "  model_20/depthwise_conv2d_262/BiasAdd (19.46k/19.46k flops)\n",
      "  model_20/conv2d_282/BiasAdd (19.46k/19.46k flops)\n",
      "  model_20/batch_normalization_554/FusedBatchNormV3 (19.15k/19.15k flops)\n",
      "  model_20/batch_normalization_555/FusedBatchNormV3 (19.15k/19.15k flops)\n",
      "  model_20/batch_normalization_561/FusedBatchNormV3 (18.92k/18.92k flops)\n",
      "  model_20/batch_normalization_560/FusedBatchNormV3 (18.92k/18.92k flops)\n",
      "  model_20/batch_normalization_557/FusedBatchNormV3 (18.92k/18.92k flops)\n",
      "  model_20/batch_normalization_556/FusedBatchNormV3 (18.92k/18.92k flops)\n",
      "  model_20/batch_normalization_562/FusedBatchNormV3 (18.54k/18.54k flops)\n",
      "  model_20/batch_normalization_558/FusedBatchNormV3 (18.47k/18.47k flops)\n",
      "  model_20/batch_normalization_559/FusedBatchNormV3 (18.47k/18.47k flops)\n",
      "  model_20/batch_normalization_553/FusedBatchNormV3 (18.16k/18.16k flops)\n",
      "  model_20/batch_normalization_552/FusedBatchNormV3 (18.16k/18.16k flops)\n",
      "  model_20/batch_normalization_549/FusedBatchNormV3 (16.35k/16.35k flops)\n",
      "  model_20/batch_normalization_548/FusedBatchNormV3 (16.35k/16.35k flops)\n",
      "  model_20/depthwise_conv2d_272/depthwise (16.16k/16.16k flops)\n",
      "  model_20/conv2d_285/BiasAdd (15.62k/15.62k flops)\n",
      "  model_20/depthwise_conv2d_261/BiasAdd (14.85k/14.85k flops)\n",
      "  model_20/batch_normalization_564/FusedBatchNormV3 (12.57k/12.57k flops)\n",
      "  model_20/batch_normalization_547/FusedBatchNormV3 (10.72k/10.72k flops)\n",
      "  model_20/batch_normalization_551/FusedBatchNormV3 (9.27k/9.27k flops)\n",
      "  model_20/depthwise_conv2d_267/BiasAdd (8.06k/8.06k flops)\n",
      "  model_20/conv2d_287/BiasAdd (8.06k/8.06k flops)\n",
      "  model_20/depthwise_conv2d_268/BiasAdd (7.97k/7.97k flops)\n",
      "  model_20/conv2d_290/BiasAdd (7.97k/7.97k flops)\n",
      "  model_20/conv2d_288/BiasAdd (7.97k/7.97k flops)\n",
      "  model_20/depthwise_conv2d_270/BiasAdd (7.97k/7.97k flops)\n",
      "  model_20/batch_normalization_566/FusedBatchNormV3 (7.86k/7.86k flops)\n",
      "  model_20/depthwise_conv2d_264/BiasAdd (7.81k/7.81k flops)\n",
      "  model_20/conv2d_284/BiasAdd (7.81k/7.81k flops)\n",
      "  model_20/conv2d_291/BiasAdd (7.81k/7.81k flops)\n",
      "  model_20/depthwise_conv2d_269/BiasAdd (7.78k/7.78k flops)\n",
      "  model_20/conv2d_289/BiasAdd (7.78k/7.78k flops)\n",
      "  model_20/depthwise_conv2d_266/BiasAdd (7.65k/7.65k flops)\n",
      "  model_20/conv2d_286/BiasAdd (7.65k/7.65k flops)\n",
      "  model_20/batch_normalization_565/FusedBatchNormV3 (7.18k/7.18k flops)\n",
      "  model_20/batch_normalization_563/FusedBatchNormV3 (6.83k/6.83k flops)\n",
      "  model_20/depthwise_conv2d_263/BiasAdd (5.12k/5.12k flops)\n",
      "  model_20/depthwise_conv2d_265/BiasAdd (3.90k/3.90k flops)\n",
      "  model_20/conv2d_292/BiasAdd (3.59k/3.59k flops)\n",
      "  model_20/depthwise_conv2d_271/BiasAdd (1.95k/1.95k flops)\n",
      "  model_20/conv2d_293/BiasAdd (982/982 flops)\n",
      "  model_20/global_average_pooling2d_20/Mean (982/982 flops)\n",
      "  model_20/depthwise_conv2d_272/BiasAdd (898/898 flops)\n",
      "  model_20/dense_20/Softmax (50/50 flops)\n",
      "  model_20/dense_20/BiasAdd (10/10 flops)\n",
      "\n",
      "======================End of Report==========================\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "10.655708\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-30 13:39:57.074551: I tensorflow/core/grappler/devices.cc:66] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0\n",
      "2022-04-30 13:39:57.074665: I tensorflow/core/grappler/clusters/single_machine.cc:357] Starting new session\n",
      "2022-04-30 13:39:57.078738: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:1137] Optimization results for grappler item: graph_to_optimize\n",
      "  function_optimizer: function_optimizer did nothing. time = 0.005ms.\n",
      "  function_optimizer: function_optimizer did nothing. time = 0.001ms.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=========================Options=============================\n",
      "-max_depth                  10000\n",
      "-min_bytes                  0\n",
      "-min_peak_bytes             0\n",
      "-min_residual_bytes         0\n",
      "-min_output_bytes           0\n",
      "-min_micros                 0\n",
      "-min_accelerator_micros     0\n",
      "-min_cpu_micros             0\n",
      "-min_params                 0\n",
      "-min_float_ops              1\n",
      "-min_occurrence             0\n",
      "-step                       -1\n",
      "-order_by                   float_ops\n",
      "-account_type_regexes       .*\n",
      "-start_name_regexes         .*\n",
      "-trim_name_regexes          \n",
      "-show_name_regexes          .*\n",
      "-hide_name_regexes          \n",
      "-account_displayed_op_only  true\n",
      "-select                     float_ops\n",
      "-output                     stdout:\n",
      "\n",
      "==================Model Analysis Report======================\n",
      "\n",
      "Doc:\n",
      "scope: The nodes in the model graph are organized by their names, which is hierarchical like filesystem.\n",
      "flops: Number of float operations. Note: Please read the implementation for the math behind it.\n",
      "\n",
      "Profile:\n",
      "node name | # float_ops\n",
      "_TFProfRoot (--/183.72m flops)\n",
      "  model_21/conv2d_302/Conv2D (18.51m/18.51m flops)\n",
      "  model_21/conv2d_305/Conv2D (18.43m/18.43m flops)\n",
      "  model_21/conv2d_301/Conv2D (18.43m/18.43m flops)\n",
      "  model_21/conv2d_303/Conv2D (18.36m/18.36m flops)\n",
      "  model_21/conv2d_304/Conv2D (18.36m/18.36m flops)\n",
      "  model_21/conv2d_297/Conv2D (18.29m/18.29m flops)\n",
      "  model_21/conv2d_299/Conv2D (17.86m/17.86m flops)\n",
      "  model_21/conv2d_300/Conv2D (9.07m/9.07m flops)\n",
      "  model_21/conv2d_298/Conv2D (9.00m/9.00m flops)\n",
      "  model_21/conv2d_295/Conv2D (8.85m/8.85m flops)\n",
      "  model_21/conv2d_296/Conv2D (8.71m/8.71m flops)\n",
      "  model_21/conv2d_306/Conv2D (5.37m/5.37m flops)\n",
      "  model_21/conv2d_307/Conv2D (3.23m/3.23m flops)\n",
      "  model_21/conv2d_294/Conv2D (2.36m/2.36m flops)\n",
      "  model_21/depthwise_conv2d_273/depthwise (1.33m/1.33m flops)\n",
      "  model_21/depthwise_conv2d_275/depthwise (1.31m/1.31m flops)\n",
      "  model_21/depthwise_conv2d_277/depthwise (642.82k/642.82k flops)\n",
      "  model_21/depthwise_conv2d_274/depthwise (622.08k/622.08k flops)\n",
      "  model_21/depthwise_conv2d_280/depthwise (329.18k/329.18k flops)\n",
      "  model_21/depthwise_conv2d_281/depthwise (327.89k/327.89k flops)\n",
      "  model_21/depthwise_conv2d_283/depthwise (327.89k/327.89k flops)\n",
      "  model_21/depthwise_conv2d_276/depthwise (326.59k/326.59k flops)\n",
      "  model_21/depthwise_conv2d_279/depthwise (326.59k/326.59k flops)\n",
      "  model_21/depthwise_conv2d_282/depthwise (326.59k/326.59k flops)\n",
      "  model_21/batch_normalization_569/FusedBatchNormV3 (276.84k/276.84k flops)\n",
      "  model_21/depthwise_conv2d_278/depthwise (162.00k/162.00k flops)\n",
      "  model_21/batch_normalization_568/FusedBatchNormV3 (147.65k/147.65k flops)\n",
      "  model_21/batch_normalization_567/FusedBatchNormV3 (147.65k/147.65k flops)\n",
      "  model_21/batch_normalization_571/FusedBatchNormV3 (145.91k/145.91k flops)\n",
      "  model_21/batch_normalization_572/FusedBatchNormV3 (145.91k/145.91k flops)\n",
      "  model_21/batch_normalization_573/FusedBatchNormV3 (145.91k/145.91k flops)\n",
      "  model_21/conv2d_295/BiasAdd (138.24k/138.24k flops)\n",
      "  model_21/depthwise_conv2d_284/depthwise (81.97k/81.97k flops)\n",
      "  model_21/conv2d_294/BiasAdd (73.73k/73.73k flops)\n",
      "  model_21/depthwise_conv2d_273/BiasAdd (73.73k/73.73k flops)\n",
      "  model_21/batch_normalization_577/FusedBatchNormV3 (73.50k/73.50k flops)\n",
      "  model_21/batch_normalization_575/FusedBatchNormV3 (72.91k/72.91k flops)\n",
      "  model_21/batch_normalization_576/FusedBatchNormV3 (72.91k/72.91k flops)\n",
      "  model_21/conv2d_296/BiasAdd (72.58k/72.58k flops)\n",
      "  model_21/depthwise_conv2d_275/BiasAdd (72.58k/72.58k flops)\n",
      "  model_21/conv2d_297/BiasAdd (72.58k/72.58k flops)\n",
      "  model_21/batch_normalization_570/FusedBatchNormV3 (69.48k/69.48k flops)\n",
      "  model_21/depthwise_conv2d_285/depthwise (42.48k/42.48k flops)\n",
      "  model_21/batch_normalization_582/FusedBatchNormV3 (39.62k/39.62k flops)\n",
      "  model_21/batch_normalization_581/FusedBatchNormV3 (39.62k/39.62k flops)\n",
      "  model_21/batch_normalization_589/FusedBatchNormV3 (39.47k/39.47k flops)\n",
      "  model_21/batch_normalization_588/FusedBatchNormV3 (39.47k/39.47k flops)\n",
      "  model_21/batch_normalization_587/FusedBatchNormV3 (39.47k/39.47k flops)\n",
      "  model_21/batch_normalization_584/FusedBatchNormV3 (39.47k/39.47k flops)\n",
      "  model_21/batch_normalization_583/FusedBatchNormV3 (39.47k/39.47k flops)\n",
      "  model_21/batch_normalization_580/FusedBatchNormV3 (39.31k/39.31k flops)\n",
      "  model_21/batch_normalization_579/FusedBatchNormV3 (39.31k/39.31k flops)\n",
      "  model_21/batch_normalization_585/FusedBatchNormV3 (39.31k/39.31k flops)\n",
      "  model_21/batch_normalization_586/FusedBatchNormV3 (39.31k/39.31k flops)\n",
      "  model_21/batch_normalization_574/FusedBatchNormV3 (37.04k/37.04k flops)\n",
      "  model_21/conv2d_299/BiasAdd (36.00k/36.00k flops)\n",
      "  model_21/conv2d_298/BiasAdd (35.71k/35.71k flops)\n",
      "  model_21/depthwise_conv2d_277/BiasAdd (35.71k/35.71k flops)\n",
      "  model_21/depthwise_conv2d_274/BiasAdd (34.56k/34.56k flops)\n",
      "  model_21/batch_normalization_578/FusedBatchNormV3 (19.50k/19.50k flops)\n",
      "  model_21/depthwise_conv2d_280/BiasAdd (18.29k/18.29k flops)\n",
      "  model_21/conv2d_301/BiasAdd (18.29k/18.29k flops)\n",
      "  model_21/conv2d_302/BiasAdd (18.22k/18.22k flops)\n",
      "  model_21/conv2d_304/BiasAdd (18.22k/18.22k flops)\n",
      "  model_21/depthwise_conv2d_283/BiasAdd (18.22k/18.22k flops)\n",
      "  model_21/conv2d_305/BiasAdd (18.22k/18.22k flops)\n",
      "  model_21/depthwise_conv2d_281/BiasAdd (18.22k/18.22k flops)\n",
      "  model_21/depthwise_conv2d_276/BiasAdd (18.14k/18.14k flops)\n",
      "  model_21/conv2d_303/BiasAdd (18.14k/18.14k flops)\n",
      "  model_21/conv2d_300/BiasAdd (18.14k/18.14k flops)\n",
      "  model_21/depthwise_conv2d_282/BiasAdd (18.14k/18.14k flops)\n",
      "  model_21/depthwise_conv2d_279/BiasAdd (18.14k/18.14k flops)\n",
      "  model_21/batch_normalization_591/FusedBatchNormV3 (14.16k/14.16k flops)\n",
      "  model_21/dense_21/MatMul (13.68k/13.68k flops)\n",
      "  model_21/batch_normalization_590/FusedBatchNormV3 (12.14k/12.14k flops)\n",
      "  model_21/batch_normalization_593/FusedBatchNormV3 (9.58k/9.58k flops)\n",
      "  model_21/depthwise_conv2d_278/BiasAdd (9.00k/9.00k flops)\n",
      "  model_21/batch_normalization_592/FusedBatchNormV3 (8.26k/8.26k flops)\n",
      "  model_21/conv2d_306/BiasAdd (5.31k/5.31k flops)\n",
      "  model_21/depthwise_conv2d_284/BiasAdd (4.55k/4.55k flops)\n",
      "  model_21/conv2d_307/BiasAdd (2.74k/2.74k flops)\n",
      "  model_21/global_average_pooling2d_21/Mean (2.74k/2.74k flops)\n",
      "  model_21/depthwise_conv2d_285/BiasAdd (2.36k/2.36k flops)\n",
      "  model_21/dense_21/Softmax (50/50 flops)\n",
      "  model_21/dense_21/BiasAdd (10/10 flops)\n",
      "\n",
      "======================End of Report==========================\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "8.94914\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-30 13:39:58.110819: I tensorflow/core/grappler/devices.cc:66] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0\n",
      "2022-04-30 13:39:58.110934: I tensorflow/core/grappler/clusters/single_machine.cc:357] Starting new session\n",
      "2022-04-30 13:39:58.115245: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:1137] Optimization results for grappler item: graph_to_optimize\n",
      "  function_optimizer: function_optimizer did nothing. time = 0.006ms.\n",
      "  function_optimizer: function_optimizer did nothing. time = 0.001ms.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=========================Options=============================\n",
      "-max_depth                  10000\n",
      "-min_bytes                  0\n",
      "-min_peak_bytes             0\n",
      "-min_residual_bytes         0\n",
      "-min_output_bytes           0\n",
      "-min_micros                 0\n",
      "-min_accelerator_micros     0\n",
      "-min_cpu_micros             0\n",
      "-min_params                 0\n",
      "-min_float_ops              1\n",
      "-min_occurrence             0\n",
      "-step                       -1\n",
      "-order_by                   float_ops\n",
      "-account_type_regexes       .*\n",
      "-start_name_regexes         .*\n",
      "-trim_name_regexes          \n",
      "-show_name_regexes          .*\n",
      "-hide_name_regexes          \n",
      "-account_displayed_op_only  true\n",
      "-select                     float_ops\n",
      "-output                     stdout:\n",
      "\n",
      "==================Model Analysis Report======================\n",
      "\n",
      "Doc:\n",
      "scope: The nodes in the model graph are organized by their names, which is hierarchical like filesystem.\n",
      "flops: Number of float operations. Note: Please read the implementation for the math behind it.\n",
      "\n",
      "Profile:\n",
      "node name | # float_ops\n",
      "_TFProfRoot (--/127.24m flops)\n",
      "  model_22/conv2d_311/Conv2D (18.29m/18.29m flops)\n",
      "  model_22/conv2d_313/Conv2D (12.10m/12.10m flops)\n",
      "  model_22/conv2d_316/Conv2D (11.93m/11.93m flops)\n",
      "  model_22/conv2d_319/Conv2D (10.78m/10.78m flops)\n",
      "  model_22/conv2d_318/Conv2D (10.51m/10.51m flops)\n",
      "  model_22/conv2d_315/Conv2D (10.43m/10.43m flops)\n",
      "  model_22/conv2d_321/Conv2D (8.21m/8.21m flops)\n",
      "  model_22/conv2d_317/Conv2D (7.50m/7.50m flops)\n",
      "  model_22/conv2d_312/Conv2D (7.33m/7.33m flops)\n",
      "  model_22/conv2d_320/Conv2D (5.83m/5.83m flops)\n",
      "  model_22/conv2d_309/Conv2D (5.01m/5.01m flops)\n",
      "  model_22/conv2d_310/Conv2D (4.94m/4.94m flops)\n",
      "  model_22/conv2d_314/Conv2D (4.37m/4.37m flops)\n",
      "  model_22/conv2d_308/Conv2D (2.36m/2.36m flops)\n",
      "  model_22/depthwise_conv2d_286/depthwise (1.33m/1.33m flops)\n",
      "  model_22/depthwise_conv2d_288/depthwise (1.31m/1.31m flops)\n",
      "  model_22/depthwise_conv2d_290/depthwise (523.58k/523.58k flops)\n",
      "  model_22/depthwise_conv2d_287/depthwise (352.51k/352.51k flops)\n",
      "  model_22/depthwise_conv2d_289/depthwise (326.59k/326.59k flops)\n",
      "  model_22/depthwise_conv2d_293/depthwise (321.41k/321.41k flops)\n",
      "  model_22/depthwise_conv2d_296/depthwise (303.26k/303.26k flops)\n",
      "  model_22/depthwise_conv2d_294/depthwise (216.43k/216.43k flops)\n",
      "  model_22/depthwise_conv2d_295/depthwise (202.18k/202.18k flops)\n",
      "  model_22/depthwise_conv2d_292/depthwise (189.22k/189.22k flops)\n",
      "  model_22/batch_normalization_596/FusedBatchNormV3 (156.88k/156.88k flops)\n",
      "  model_22/batch_normalization_595/FusedBatchNormV3 (147.65k/147.65k flops)\n",
      "  model_22/batch_normalization_594/FusedBatchNormV3 (147.65k/147.65k flops)\n",
      "  model_22/batch_normalization_598/FusedBatchNormV3 (145.91k/145.91k flops)\n",
      "  model_22/batch_normalization_599/FusedBatchNormV3 (145.91k/145.91k flops)\n",
      "  model_22/batch_normalization_600/FusedBatchNormV3 (145.91k/145.91k flops)\n",
      "  model_22/depthwise_conv2d_291/depthwise (134.78k/134.78k flops)\n",
      "  model_22/conv2d_309/BiasAdd (78.34k/78.34k flops)\n",
      "  model_22/conv2d_308/BiasAdd (73.73k/73.73k flops)\n",
      "  model_22/depthwise_conv2d_286/BiasAdd (73.73k/73.73k flops)\n",
      "  model_22/depthwise_conv2d_298/depthwise (72.86k/72.86k flops)\n",
      "  model_22/conv2d_311/BiasAdd (72.58k/72.58k flops)\n",
      "  model_22/conv2d_310/BiasAdd (72.58k/72.58k flops)\n",
      "  model_22/depthwise_conv2d_288/BiasAdd (72.58k/72.58k flops)\n",
      "  model_22/batch_normalization_604/FusedBatchNormV3 (61.15k/61.15k flops)\n",
      "  model_22/batch_normalization_603/FusedBatchNormV3 (59.39k/59.39k flops)\n",
      "  model_22/batch_normalization_602/FusedBatchNormV3 (59.39k/59.39k flops)\n",
      "  model_22/depthwise_conv2d_297/depthwise (51.84k/51.84k flops)\n",
      "  model_22/batch_normalization_597/FusedBatchNormV3 (39.37k/39.37k flops)\n",
      "  model_22/batch_normalization_609/FusedBatchNormV3 (38.69k/38.69k flops)\n",
      "  model_22/batch_normalization_608/FusedBatchNormV3 (38.69k/38.69k flops)\n",
      "  model_22/batch_normalization_601/FusedBatchNormV3 (37.04k/37.04k flops)\n",
      "  model_22/batch_normalization_614/FusedBatchNormV3 (36.50k/36.50k flops)\n",
      "  model_22/batch_normalization_615/FusedBatchNormV3 (36.50k/36.50k flops)\n",
      "  model_22/conv2d_313/BiasAdd (29.95k/29.95k flops)\n",
      "  model_22/depthwise_conv2d_290/BiasAdd (29.09k/29.09k flops)\n",
      "  model_22/conv2d_312/BiasAdd (29.09k/29.09k flops)\n",
      "  model_22/batch_normalization_611/FusedBatchNormV3 (26.05k/26.05k flops)\n",
      "  model_22/batch_normalization_610/FusedBatchNormV3 (26.05k/26.05k flops)\n",
      "  model_22/batch_normalization_616/FusedBatchNormV3 (24.96k/24.96k flops)\n",
      "  model_22/batch_normalization_613/FusedBatchNormV3 (24.34k/24.34k flops)\n",
      "  model_22/batch_normalization_612/FusedBatchNormV3 (24.34k/24.34k flops)\n",
      "  model_22/batch_normalization_618/FusedBatchNormV3 (24.29k/24.29k flops)\n",
      "  model_22/batch_normalization_607/FusedBatchNormV3 (22.78k/22.78k flops)\n",
      "  model_22/batch_normalization_606/FusedBatchNormV3 (22.78k/22.78k flops)\n",
      "  model_22/dense_22/MatMul (20.28k/20.28k flops)\n",
      "  model_22/depthwise_conv2d_287/BiasAdd (19.58k/19.58k flops)\n",
      "  model_22/depthwise_conv2d_289/BiasAdd (18.14k/18.14k flops)\n",
      "  model_22/depthwise_conv2d_293/BiasAdd (17.86k/17.86k flops)\n",
      "  model_22/conv2d_315/BiasAdd (17.86k/17.86k flops)\n",
      "  model_22/conv2d_318/BiasAdd (16.85k/16.85k flops)\n",
      "  model_22/depthwise_conv2d_296/BiasAdd (16.85k/16.85k flops)\n",
      "  model_22/batch_normalization_605/FusedBatchNormV3 (16.22k/16.22k flops)\n",
      "  model_22/batch_normalization_620/FusedBatchNormV3 (14.20k/14.20k flops)\n",
      "  model_22/batch_normalization_619/FusedBatchNormV3 (14.17k/14.17k flops)\n",
      "  model_22/conv2d_316/BiasAdd (12.02k/12.02k flops)\n",
      "  model_22/depthwise_conv2d_294/BiasAdd (12.02k/12.02k flops)\n",
      "  model_22/conv2d_319/BiasAdd (11.52k/11.52k flops)\n",
      "  model_22/conv2d_317/BiasAdd (11.23k/11.23k flops)\n",
      "  model_22/depthwise_conv2d_295/BiasAdd (11.23k/11.23k flops)\n",
      "  model_22/depthwise_conv2d_292/BiasAdd (10.51k/10.51k flops)\n",
      "  model_22/conv2d_314/BiasAdd (10.51k/10.51k flops)\n",
      "  model_22/conv2d_320/BiasAdd (9.11k/9.11k flops)\n",
      "  model_22/batch_normalization_617/FusedBatchNormV3 (7.68k/7.68k flops)\n",
      "  model_22/depthwise_conv2d_291/BiasAdd (7.49k/7.49k flops)\n",
      "  model_22/global_average_pooling2d_22/Mean (4.06k/4.06k flops)\n",
      "  model_22/conv2d_321/BiasAdd (4.06k/4.06k flops)\n",
      "  model_22/depthwise_conv2d_298/BiasAdd (4.05k/4.05k flops)\n",
      "  model_22/depthwise_conv2d_297/BiasAdd (2.88k/2.88k flops)\n",
      "  model_22/dense_22/Softmax (50/50 flops)\n",
      "  model_22/dense_22/BiasAdd (10/10 flops)\n",
      "\n",
      "======================End of Report==========================\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "8.765508\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-30 13:39:59.044970: I tensorflow/core/grappler/devices.cc:66] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0\n",
      "2022-04-30 13:39:59.045085: I tensorflow/core/grappler/clusters/single_machine.cc:357] Starting new session\n",
      "2022-04-30 13:39:59.049143: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:1137] Optimization results for grappler item: graph_to_optimize\n",
      "  function_optimizer: function_optimizer did nothing. time = 0.005ms.\n",
      "  function_optimizer: function_optimizer did nothing. time = 0.001ms.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=========================Options=============================\n",
      "-max_depth                  10000\n",
      "-min_bytes                  0\n",
      "-min_peak_bytes             0\n",
      "-min_residual_bytes         0\n",
      "-min_output_bytes           0\n",
      "-min_micros                 0\n",
      "-min_accelerator_micros     0\n",
      "-min_cpu_micros             0\n",
      "-min_params                 0\n",
      "-min_float_ops              1\n",
      "-min_occurrence             0\n",
      "-step                       -1\n",
      "-order_by                   float_ops\n",
      "-account_type_regexes       .*\n",
      "-start_name_regexes         .*\n",
      "-trim_name_regexes          \n",
      "-show_name_regexes          .*\n",
      "-hide_name_regexes          \n",
      "-account_displayed_op_only  true\n",
      "-select                     float_ops\n",
      "-output                     stdout:\n",
      "\n",
      "==================Model Analysis Report======================\n",
      "\n",
      "Doc:\n",
      "scope: The nodes in the model graph are organized by their names, which is hierarchical like filesystem.\n",
      "flops: Number of float operations. Note: Please read the implementation for the math behind it.\n",
      "\n",
      "Profile:\n",
      "node name | # float_ops\n",
      "_TFProfRoot (--/123.43m flops)\n",
      "  model_23/conv2d_330/Conv2D (14.53m/14.53m flops)\n",
      "  model_23/conv2d_329/Conv2D (12.58m/12.58m flops)\n",
      "  model_23/conv2d_327/Conv2D (11.98m/11.98m flops)\n",
      "  model_23/conv2d_332/Conv2D (11.59m/11.59m flops)\n",
      "  model_23/conv2d_333/Conv2D (11.47m/11.47m flops)\n",
      "  model_23/conv2d_331/Conv2D (10.94m/10.94m flops)\n",
      "  model_23/conv2d_325/Conv2D (9.04m/9.04m flops)\n",
      "  model_23/conv2d_323/Conv2D (7.67m/7.67m flops)\n",
      "  model_23/conv2d_326/Conv2D (6.11m/6.11m flops)\n",
      "  model_23/conv2d_328/Conv2D (5.21m/5.21m flops)\n",
      "  model_23/conv2d_334/Conv2D (4.56m/4.56m flops)\n",
      "  model_23/conv2d_324/Conv2D (4.43m/4.43m flops)\n",
      "  model_23/conv2d_335/Conv2D (3.70m/3.70m flops)\n",
      "  model_23/conv2d_322/Conv2D (2.36m/2.36m flops)\n",
      "  model_23/depthwise_conv2d_299/depthwise (1.33m/1.33m flops)\n",
      "  model_23/depthwise_conv2d_301/depthwise (767.23k/767.23k flops)\n",
      "  model_23/depthwise_conv2d_300/depthwise (539.14k/539.14k flops)\n",
      "  model_23/depthwise_conv2d_303/depthwise (518.40k/518.40k flops)\n",
      "  model_23/depthwise_conv2d_306/depthwise (325.30k/325.30k flops)\n",
      "  model_23/depthwise_conv2d_309/depthwise (276.05k/276.05k flops)\n",
      "  model_23/depthwise_conv2d_302/depthwise (274.75k/274.75k flops)\n",
      "  model_23/depthwise_conv2d_307/depthwise (260.50k/260.50k flops)\n",
      "  model_23/depthwise_conv2d_308/depthwise (244.94k/244.94k flops)\n",
      "  model_23/batch_normalization_623/FusedBatchNormV3 (239.93k/239.93k flops)\n",
      "  model_23/depthwise_conv2d_305/depthwise (225.50k/225.50k flops)\n",
      "  model_23/batch_normalization_622/FusedBatchNormV3 (147.65k/147.65k flops)\n",
      "  model_23/batch_normalization_621/FusedBatchNormV3 (147.65k/147.65k flops)\n",
      "  model_23/depthwise_conv2d_304/depthwise (134.78k/134.78k flops)\n",
      "  model_23/batch_normalization_627/FusedBatchNormV3 (122.75k/122.75k flops)\n",
      "  model_23/conv2d_323/BiasAdd (119.81k/119.81k flops)\n",
      "  model_23/batch_normalization_626/FusedBatchNormV3 (85.69k/85.69k flops)\n",
      "  model_23/batch_normalization_625/FusedBatchNormV3 (85.69k/85.69k flops)\n",
      "  model_23/conv2d_322/BiasAdd (73.73k/73.73k flops)\n",
      "  model_23/depthwise_conv2d_299/BiasAdd (73.73k/73.73k flops)\n",
      "  model_23/batch_normalization_631/FusedBatchNormV3 (61.15k/61.15k flops)\n",
      "  model_23/conv2d_325/BiasAdd (61.06k/61.06k flops)\n",
      "  model_23/depthwise_conv2d_310/depthwise (60.59k/60.59k flops)\n",
      "  model_23/batch_normalization_624/FusedBatchNormV3 (60.22k/60.22k flops)\n",
      "  model_23/batch_normalization_629/FusedBatchNormV3 (58.80k/58.80k flops)\n",
      "  model_23/batch_normalization_630/FusedBatchNormV3 (58.80k/58.80k flops)\n",
      "  model_23/depthwise_conv2d_311/depthwise (48.82k/48.82k flops)\n",
      "  model_23/conv2d_324/BiasAdd (42.62k/42.62k flops)\n",
      "  model_23/depthwise_conv2d_301/BiasAdd (42.62k/42.62k flops)\n",
      "  model_23/batch_normalization_635/FusedBatchNormV3 (39.16k/39.16k flops)\n",
      "  model_23/batch_normalization_636/FusedBatchNormV3 (39.16k/39.16k flops)\n",
      "  model_23/batch_normalization_642/FusedBatchNormV3 (33.23k/33.23k flops)\n",
      "  model_23/batch_normalization_641/FusedBatchNormV3 (33.23k/33.23k flops)\n",
      "  model_23/batch_normalization_637/FusedBatchNormV3 (31.36k/31.36k flops)\n",
      "  model_23/batch_normalization_638/FusedBatchNormV3 (31.36k/31.36k flops)\n",
      "  model_23/batch_normalization_628/FusedBatchNormV3 (31.16k/31.16k flops)\n",
      "  model_23/depthwise_conv2d_300/BiasAdd (29.95k/29.95k flops)\n",
      "  model_23/conv2d_327/BiasAdd (29.95k/29.95k flops)\n",
      "  model_23/batch_normalization_639/FusedBatchNormV3 (29.48k/29.48k flops)\n",
      "  model_23/batch_normalization_640/FusedBatchNormV3 (29.48k/29.48k flops)\n",
      "  model_23/batch_normalization_643/FusedBatchNormV3 (29.17k/29.17k flops)\n",
      "  model_23/conv2d_326/BiasAdd (28.80k/28.80k flops)\n",
      "  model_23/depthwise_conv2d_303/BiasAdd (28.80k/28.80k flops)\n",
      "  model_23/batch_normalization_634/FusedBatchNormV3 (27.14k/27.14k flops)\n",
      "  model_23/batch_normalization_633/FusedBatchNormV3 (27.14k/27.14k flops)\n",
      "  model_23/conv2d_329/BiasAdd (18.07k/18.07k flops)\n",
      "  model_23/depthwise_conv2d_306/BiasAdd (18.07k/18.07k flops)\n",
      "  model_23/batch_normalization_645/FusedBatchNormV3 (16.27k/16.27k flops)\n",
      "  model_23/batch_normalization_632/FusedBatchNormV3 (16.22k/16.22k flops)\n",
      "  model_23/depthwise_conv2d_309/BiasAdd (15.34k/15.34k flops)\n",
      "  model_23/conv2d_332/BiasAdd (15.34k/15.34k flops)\n",
      "  model_23/depthwise_conv2d_302/BiasAdd (15.26k/15.26k flops)\n",
      "  model_23/depthwise_conv2d_307/BiasAdd (14.47k/14.47k flops)\n",
      "  model_23/conv2d_330/BiasAdd (14.47k/14.47k flops)\n",
      "  model_23/dense_23/MatMul (13.64k/13.64k flops)\n",
      "  model_23/depthwise_conv2d_308/BiasAdd (13.61k/13.61k flops)\n",
      "  model_23/conv2d_331/BiasAdd (13.61k/13.61k flops)\n",
      "  model_23/conv2d_333/BiasAdd (13.46k/13.46k flops)\n",
      "  model_23/depthwise_conv2d_305/BiasAdd (12.53k/12.53k flops)\n",
      "  model_23/conv2d_328/BiasAdd (12.53k/12.53k flops)\n",
      "  model_23/batch_normalization_647/FusedBatchNormV3 (9.55k/9.55k flops)\n",
      "  model_23/batch_normalization_646/FusedBatchNormV3 (9.49k/9.49k flops)\n",
      "  model_23/batch_normalization_644/FusedBatchNormV3 (8.98k/8.98k flops)\n",
      "  model_23/depthwise_conv2d_304/BiasAdd (7.49k/7.49k flops)\n",
      "  model_23/conv2d_334/BiasAdd (6.10k/6.10k flops)\n",
      "  model_23/depthwise_conv2d_310/BiasAdd (3.37k/3.37k flops)\n",
      "  model_23/global_average_pooling2d_23/Mean (2.73k/2.73k flops)\n",
      "  model_23/conv2d_335/BiasAdd (2.73k/2.73k flops)\n",
      "  model_23/depthwise_conv2d_311/BiasAdd (2.71k/2.71k flops)\n",
      "  model_23/dense_23/Softmax (50/50 flops)\n",
      "  model_23/dense_23/BiasAdd (10/10 flops)\n",
      "\n",
      "======================End of Report==========================\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "9.32306\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-30 13:40:00.057146: I tensorflow/core/grappler/devices.cc:66] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0\n",
      "2022-04-30 13:40:00.057264: I tensorflow/core/grappler/clusters/single_machine.cc:357] Starting new session\n",
      "2022-04-30 13:40:00.061710: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:1137] Optimization results for grappler item: graph_to_optimize\n",
      "  function_optimizer: function_optimizer did nothing. time = 0.005ms.\n",
      "  function_optimizer: function_optimizer did nothing. time = 0.001ms.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=========================Options=============================\n",
      "-max_depth                  10000\n",
      "-min_bytes                  0\n",
      "-min_peak_bytes             0\n",
      "-min_residual_bytes         0\n",
      "-min_output_bytes           0\n",
      "-min_micros                 0\n",
      "-min_accelerator_micros     0\n",
      "-min_cpu_micros             0\n",
      "-min_params                 0\n",
      "-min_float_ops              1\n",
      "-min_occurrence             0\n",
      "-step                       -1\n",
      "-order_by                   float_ops\n",
      "-account_type_regexes       .*\n",
      "-start_name_regexes         .*\n",
      "-trim_name_regexes          \n",
      "-show_name_regexes          .*\n",
      "-hide_name_regexes          \n",
      "-account_displayed_op_only  true\n",
      "-select                     float_ops\n",
      "-output                     stdout:\n",
      "\n",
      "==================Model Analysis Report======================\n",
      "\n",
      "Doc:\n",
      "scope: The nodes in the model graph are organized by their names, which is hierarchical like filesystem.\n",
      "flops: Number of float operations. Note: Please read the implementation for the math behind it.\n",
      "\n",
      "Profile:\n",
      "node name | # float_ops\n",
      "_TFProfRoot (--/158.05m flops)\n",
      "  model_24/conv2d_345/Conv2D (17.29m/17.29m flops)\n",
      "  model_24/conv2d_346/Conv2D (17.22m/17.22m flops)\n",
      "  model_24/conv2d_347/Conv2D (17.22m/17.22m flops)\n",
      "  model_24/conv2d_344/Conv2D (16.58m/16.58m flops)\n",
      "  model_24/conv2d_343/Conv2D (16.04m/16.04m flops)\n",
      "  model_24/conv2d_341/Conv2D (11.11m/11.11m flops)\n",
      "  model_24/conv2d_339/Conv2D (9.29m/9.29m flops)\n",
      "  model_24/conv2d_348/Conv2D (8.91m/8.91m flops)\n",
      "  model_24/conv2d_337/Conv2D (8.26m/8.26m flops)\n",
      "  model_24/conv2d_349/Conv2D (8.21m/8.21m flops)\n",
      "  model_24/conv2d_342/Conv2D (7.20m/7.20m flops)\n",
      "  model_24/conv2d_340/Conv2D (6.60m/6.60m flops)\n",
      "  model_24/conv2d_338/Conv2D (4.13m/4.13m flops)\n",
      "  model_24/conv2d_336/Conv2D (2.36m/2.36m flops)\n",
      "  model_24/depthwise_conv2d_312/depthwise (1.33m/1.33m flops)\n",
      "  model_24/depthwise_conv2d_314/depthwise (663.55k/663.55k flops)\n",
      "  model_24/depthwise_conv2d_313/depthwise (580.61k/580.61k flops)\n",
      "  model_24/depthwise_conv2d_316/depthwise (471.74k/471.74k flops)\n",
      "  model_24/depthwise_conv2d_315/depthwise (326.59k/326.59k flops)\n",
      "  model_24/depthwise_conv2d_321/depthwise (318.82k/318.82k flops)\n",
      "  model_24/depthwise_conv2d_320/depthwise (316.22k/316.22k flops)\n",
      "  model_24/depthwise_conv2d_322/depthwise (314.93k/314.93k flops)\n",
      "  model_24/depthwise_conv2d_318/depthwise (305.86k/305.86k flops)\n",
      "  model_24/depthwise_conv2d_319/depthwise (305.86k/305.86k flops)\n",
      "  model_24/batch_normalization_650/FusedBatchNormV3 (258.38k/258.38k flops)\n",
      "  model_24/batch_normalization_649/FusedBatchNormV3 (147.65k/147.65k flops)\n",
      "  model_24/batch_normalization_648/FusedBatchNormV3 (147.65k/147.65k flops)\n",
      "  model_24/batch_normalization_654/FusedBatchNormV3 (145.91k/145.91k flops)\n",
      "  model_24/depthwise_conv2d_317/depthwise (137.38k/137.38k flops)\n",
      "  model_24/conv2d_337/BiasAdd (129.02k/129.02k flops)\n",
      "  model_24/depthwise_conv2d_323/depthwise (79.70k/79.70k flops)\n",
      "  model_24/batch_normalization_653/FusedBatchNormV3 (74.11k/74.11k flops)\n",
      "  model_24/batch_normalization_652/FusedBatchNormV3 (74.11k/74.11k flops)\n",
      "  model_24/depthwise_conv2d_312/BiasAdd (73.73k/73.73k flops)\n",
      "  model_24/conv2d_336/BiasAdd (73.73k/73.73k flops)\n",
      "  model_24/conv2d_339/BiasAdd (72.58k/72.58k flops)\n",
      "  model_24/depthwise_conv2d_324/depthwise (72.43k/72.43k flops)\n",
      "  model_24/batch_normalization_651/FusedBatchNormV3 (64.85k/64.85k flops)\n",
      "  model_24/batch_normalization_658/FusedBatchNormV3 (62.33k/62.33k flops)\n",
      "  model_24/batch_normalization_656/FusedBatchNormV3 (53.51k/53.51k flops)\n",
      "  model_24/batch_normalization_657/FusedBatchNormV3 (53.51k/53.51k flops)\n",
      "  model_24/batch_normalization_670/FusedBatchNormV3 (38.38k/38.38k flops)\n",
      "  model_24/batch_normalization_667/FusedBatchNormV3 (38.38k/38.38k flops)\n",
      "  model_24/batch_normalization_666/FusedBatchNormV3 (38.38k/38.38k flops)\n",
      "  model_24/batch_normalization_665/FusedBatchNormV3 (38.06k/38.06k flops)\n",
      "  model_24/batch_normalization_664/FusedBatchNormV3 (38.06k/38.06k flops)\n",
      "  model_24/batch_normalization_669/FusedBatchNormV3 (37.91k/37.91k flops)\n",
      "  model_24/batch_normalization_668/FusedBatchNormV3 (37.91k/37.91k flops)\n",
      "  model_24/batch_normalization_655/FusedBatchNormV3 (37.04k/37.04k flops)\n",
      "  model_24/depthwise_conv2d_314/BiasAdd (36.86k/36.86k flops)\n",
      "  model_24/conv2d_338/BiasAdd (36.86k/36.86k flops)\n",
      "  model_24/batch_normalization_662/FusedBatchNormV3 (36.82k/36.82k flops)\n",
      "  model_24/batch_normalization_660/FusedBatchNormV3 (36.82k/36.82k flops)\n",
      "  model_24/batch_normalization_661/FusedBatchNormV3 (36.82k/36.82k flops)\n",
      "  model_24/batch_normalization_663/FusedBatchNormV3 (36.82k/36.82k flops)\n",
      "  model_24/depthwise_conv2d_313/BiasAdd (32.26k/32.26k flops)\n",
      "  model_24/conv2d_341/BiasAdd (30.53k/30.53k flops)\n",
      "  model_24/conv2d_340/BiasAdd (26.21k/26.21k flops)\n",
      "  model_24/depthwise_conv2d_316/BiasAdd (26.21k/26.21k flops)\n",
      "  model_24/batch_normalization_672/FusedBatchNormV3 (24.14k/24.14k flops)\n",
      "  model_24/dense_24/MatMul (20.40k/20.40k flops)\n",
      "  model_24/depthwise_conv2d_315/BiasAdd (18.14k/18.14k flops)\n",
      "  model_24/conv2d_345/BiasAdd (17.71k/17.71k flops)\n",
      "  model_24/depthwise_conv2d_321/BiasAdd (17.71k/17.71k flops)\n",
      "  model_24/conv2d_347/BiasAdd (17.71k/17.71k flops)\n",
      "  model_24/conv2d_344/BiasAdd (17.57k/17.57k flops)\n",
      "  model_24/depthwise_conv2d_320/BiasAdd (17.57k/17.57k flops)\n",
      "  model_24/conv2d_346/BiasAdd (17.50k/17.50k flops)\n",
      "  model_24/depthwise_conv2d_322/BiasAdd (17.50k/17.50k flops)\n",
      "  model_24/conv2d_343/BiasAdd (16.99k/16.99k flops)\n",
      "  model_24/conv2d_342/BiasAdd (16.99k/16.99k flops)\n",
      "  model_24/depthwise_conv2d_318/BiasAdd (16.99k/16.99k flops)\n",
      "  model_24/depthwise_conv2d_319/BiasAdd (16.99k/16.99k flops)\n",
      "  model_24/batch_normalization_659/FusedBatchNormV3 (16.54k/16.54k flops)\n",
      "  model_24/batch_normalization_674/FusedBatchNormV3 (14.28k/14.28k flops)\n",
      "  model_24/batch_normalization_673/FusedBatchNormV3 (14.08k/14.08k flops)\n",
      "  model_24/batch_normalization_671/FusedBatchNormV3 (11.81k/11.81k flops)\n",
      "  model_24/conv2d_348/BiasAdd (9.05k/9.05k flops)\n",
      "  model_24/depthwise_conv2d_317/BiasAdd (7.63k/7.63k flops)\n",
      "  model_24/depthwise_conv2d_323/BiasAdd (4.43k/4.43k flops)\n",
      "  model_24/global_average_pooling2d_24/Mean (4.08k/4.08k flops)\n",
      "  model_24/conv2d_349/BiasAdd (4.08k/4.08k flops)\n",
      "  model_24/depthwise_conv2d_324/BiasAdd (4.02k/4.02k flops)\n",
      "  model_24/dense_24/Softmax (50/50 flops)\n",
      "  model_24/dense_24/BiasAdd (10/10 flops)\n",
      "\n",
      "======================End of Report==========================\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "9.616172\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-30 13:40:01.040091: I tensorflow/core/grappler/devices.cc:66] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0\n",
      "2022-04-30 13:40:01.040181: I tensorflow/core/grappler/clusters/single_machine.cc:357] Starting new session\n",
      "2022-04-30 13:40:01.044364: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:1137] Optimization results for grappler item: graph_to_optimize\n",
      "  function_optimizer: function_optimizer did nothing. time = 0.005ms.\n",
      "  function_optimizer: function_optimizer did nothing. time = 0.001ms.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=========================Options=============================\n",
      "-max_depth                  10000\n",
      "-min_bytes                  0\n",
      "-min_peak_bytes             0\n",
      "-min_residual_bytes         0\n",
      "-min_output_bytes           0\n",
      "-min_micros                 0\n",
      "-min_accelerator_micros     0\n",
      "-min_cpu_micros             0\n",
      "-min_params                 0\n",
      "-min_float_ops              1\n",
      "-min_occurrence             0\n",
      "-step                       -1\n",
      "-order_by                   float_ops\n",
      "-account_type_regexes       .*\n",
      "-start_name_regexes         .*\n",
      "-trim_name_regexes          \n",
      "-show_name_regexes          .*\n",
      "-hide_name_regexes          \n",
      "-account_displayed_op_only  true\n",
      "-select                     float_ops\n",
      "-output                     stdout:\n",
      "\n",
      "==================Model Analysis Report======================\n",
      "\n",
      "Doc:\n",
      "scope: The nodes in the model graph are organized by their names, which is hierarchical like filesystem.\n",
      "flops: Number of float operations. Note: Please read the implementation for the math behind it.\n",
      "\n",
      "Profile:\n",
      "node name | # float_ops\n",
      "_TFProfRoot (--/169.57m flops)\n",
      "  model_25/conv2d_358/Conv2D (18.51m/18.51m flops)\n",
      "  model_25/conv2d_359/Conv2D (18.51m/18.51m flops)\n",
      "  model_25/conv2d_360/Conv2D (18.43m/18.43m flops)\n",
      "  model_25/conv2d_361/Conv2D (18.36m/18.36m flops)\n",
      "  model_25/conv2d_357/Conv2D (18.07m/18.07m flops)\n",
      "  model_25/conv2d_355/Conv2D (14.71m/14.71m flops)\n",
      "  model_25/conv2d_353/Conv2D (8.93m/8.93m flops)\n",
      "  model_25/conv2d_351/Conv2D (8.55m/8.55m flops)\n",
      "  model_25/conv2d_362/Conv2D (8.40m/8.40m flops)\n",
      "  model_25/conv2d_356/Conv2D (8.11m/8.11m flops)\n",
      "  model_25/conv2d_363/Conv2D (6.99m/6.99m flops)\n",
      "  model_25/conv2d_354/Conv2D (6.58m/6.58m flops)\n",
      "  model_25/conv2d_352/Conv2D (5.08m/5.08m flops)\n",
      "  model_25/conv2d_350/Conv2D (2.36m/2.36m flops)\n",
      "  model_25/depthwise_conv2d_325/depthwise (1.33m/1.33m flops)\n",
      "  model_25/depthwise_conv2d_327/depthwise (787.97k/787.97k flops)\n",
      "  model_25/depthwise_conv2d_326/depthwise (601.34k/601.34k flops)\n",
      "  model_25/depthwise_conv2d_329/depthwise (580.61k/580.61k flops)\n",
      "  model_25/depthwise_conv2d_332/depthwise (329.18k/329.18k flops)\n",
      "  model_25/depthwise_conv2d_334/depthwise (329.18k/329.18k flops)\n",
      "  model_25/depthwise_conv2d_333/depthwise (327.89k/327.89k flops)\n",
      "  model_25/depthwise_conv2d_335/depthwise (326.59k/326.59k flops)\n",
      "  model_25/depthwise_conv2d_331/depthwise (320.11k/320.11k flops)\n",
      "  model_25/batch_normalization_677/FusedBatchNormV3 (267.61k/267.61k flops)\n",
      "  model_25/depthwise_conv2d_328/depthwise (264.38k/264.38k flops)\n",
      "  model_25/depthwise_conv2d_330/depthwise (147.74k/147.74k flops)\n",
      "  model_25/batch_normalization_676/FusedBatchNormV3 (147.65k/147.65k flops)\n",
      "  model_25/batch_normalization_675/FusedBatchNormV3 (147.65k/147.65k flops)\n",
      "  model_25/conv2d_351/BiasAdd (133.63k/133.63k flops)\n",
      "  model_25/batch_normalization_681/FusedBatchNormV3 (118.12k/118.12k flops)\n",
      "  model_25/batch_normalization_680/FusedBatchNormV3 (88.01k/88.01k flops)\n",
      "  model_25/batch_normalization_679/FusedBatchNormV3 (88.01k/88.01k flops)\n",
      "  model_25/depthwise_conv2d_336/depthwise (81.97k/81.97k flops)\n",
      "  model_25/conv2d_350/BiasAdd (73.73k/73.73k flops)\n",
      "  model_25/depthwise_conv2d_325/BiasAdd (73.73k/73.73k flops)\n",
      "  model_25/batch_normalization_678/FusedBatchNormV3 (67.16k/67.16k flops)\n",
      "  model_25/batch_normalization_685/FusedBatchNormV3 (67.03k/67.03k flops)\n",
      "  model_25/depthwise_conv2d_337/depthwise (66.38k/66.38k flops)\n",
      "  model_25/batch_normalization_683/FusedBatchNormV3 (65.86k/65.86k flops)\n",
      "  model_25/batch_normalization_684/FusedBatchNormV3 (65.86k/65.86k flops)\n",
      "  model_25/conv2d_353/BiasAdd (58.75k/58.75k flops)\n",
      "  model_25/conv2d_352/BiasAdd (43.78k/43.78k flops)\n",
      "  model_25/depthwise_conv2d_327/BiasAdd (43.78k/43.78k flops)\n",
      "  model_25/batch_normalization_694/FusedBatchNormV3 (39.62k/39.62k flops)\n",
      "  model_25/batch_normalization_693/FusedBatchNormV3 (39.62k/39.62k flops)\n",
      "  model_25/batch_normalization_689/FusedBatchNormV3 (39.62k/39.62k flops)\n",
      "  model_25/batch_normalization_690/FusedBatchNormV3 (39.62k/39.62k flops)\n",
      "  model_25/batch_normalization_697/FusedBatchNormV3 (39.47k/39.47k flops)\n",
      "  model_25/batch_normalization_691/FusedBatchNormV3 (39.47k/39.47k flops)\n",
      "  model_25/batch_normalization_692/FusedBatchNormV3 (39.47k/39.47k flops)\n",
      "  model_25/batch_normalization_696/FusedBatchNormV3 (39.31k/39.31k flops)\n",
      "  model_25/batch_normalization_695/FusedBatchNormV3 (39.31k/39.31k flops)\n",
      "  model_25/batch_normalization_688/FusedBatchNormV3 (38.53k/38.53k flops)\n",
      "  model_25/batch_normalization_687/FusedBatchNormV3 (38.53k/38.53k flops)\n",
      "  model_25/depthwise_conv2d_326/BiasAdd (33.41k/33.41k flops)\n",
      "  model_25/conv2d_355/BiasAdd (32.83k/32.83k flops)\n",
      "  model_25/depthwise_conv2d_329/BiasAdd (32.26k/32.26k flops)\n",
      "  model_25/conv2d_354/BiasAdd (32.26k/32.26k flops)\n",
      "  model_25/batch_normalization_682/FusedBatchNormV3 (29.99k/29.99k flops)\n",
      "  model_25/batch_normalization_699/FusedBatchNormV3 (22.13k/22.13k flops)\n",
      "  model_25/dense_25/MatMul (18.96k/18.96k flops)\n",
      "  model_25/depthwise_conv2d_334/BiasAdd (18.29k/18.29k flops)\n",
      "  model_25/conv2d_357/BiasAdd (18.29k/18.29k flops)\n",
      "  model_25/depthwise_conv2d_332/BiasAdd (18.29k/18.29k flops)\n",
      "  model_25/conv2d_359/BiasAdd (18.29k/18.29k flops)\n",
      "  model_25/depthwise_conv2d_333/BiasAdd (18.22k/18.22k flops)\n",
      "  model_25/conv2d_361/BiasAdd (18.22k/18.22k flops)\n",
      "  model_25/conv2d_358/BiasAdd (18.22k/18.22k flops)\n",
      "  model_25/depthwise_conv2d_335/BiasAdd (18.14k/18.14k flops)\n",
      "  model_25/conv2d_360/BiasAdd (18.14k/18.14k flops)\n",
      "  model_25/conv2d_356/BiasAdd (17.78k/17.78k flops)\n",
      "  model_25/batch_normalization_686/FusedBatchNormV3 (17.78k/17.78k flops)\n",
      "  model_25/depthwise_conv2d_331/BiasAdd (17.78k/17.78k flops)\n",
      "  model_25/depthwise_conv2d_328/BiasAdd (14.69k/14.69k flops)\n",
      "  model_25/batch_normalization_701/FusedBatchNormV3 (13.27k/13.27k flops)\n",
      "  model_25/batch_normalization_700/FusedBatchNormV3 (12.91k/12.91k flops)\n",
      "  model_25/batch_normalization_698/FusedBatchNormV3 (12.14k/12.14k flops)\n",
      "  model_25/conv2d_362/BiasAdd (8.30k/8.30k flops)\n",
      "  model_25/depthwise_conv2d_330/BiasAdd (8.21k/8.21k flops)\n",
      "  model_25/depthwise_conv2d_336/BiasAdd (4.55k/4.55k flops)\n",
      "  model_25/conv2d_363/BiasAdd (3.79k/3.79k flops)\n",
      "  model_25/global_average_pooling2d_25/Mean (3.79k/3.79k flops)\n",
      "  model_25/depthwise_conv2d_337/BiasAdd (3.69k/3.69k flops)\n",
      "  model_25/dense_25/Softmax (50/50 flops)\n",
      "  model_25/dense_25/BiasAdd (10/10 flops)\n",
      "\n",
      "======================End of Report==========================\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "8.1667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-30 13:40:02.003663: I tensorflow/core/grappler/devices.cc:66] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0\n",
      "2022-04-30 13:40:02.003779: I tensorflow/core/grappler/clusters/single_machine.cc:357] Starting new session\n",
      "2022-04-30 13:40:02.007780: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:1137] Optimization results for grappler item: graph_to_optimize\n",
      "  function_optimizer: function_optimizer did nothing. time = 0.004ms.\n",
      "  function_optimizer: function_optimizer did nothing. time = 0.001ms.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=========================Options=============================\n",
      "-max_depth                  10000\n",
      "-min_bytes                  0\n",
      "-min_peak_bytes             0\n",
      "-min_residual_bytes         0\n",
      "-min_output_bytes           0\n",
      "-min_micros                 0\n",
      "-min_accelerator_micros     0\n",
      "-min_cpu_micros             0\n",
      "-min_params                 0\n",
      "-min_float_ops              1\n",
      "-min_occurrence             0\n",
      "-step                       -1\n",
      "-order_by                   float_ops\n",
      "-account_type_regexes       .*\n",
      "-start_name_regexes         .*\n",
      "-trim_name_regexes          \n",
      "-show_name_regexes          .*\n",
      "-hide_name_regexes          \n",
      "-account_displayed_op_only  true\n",
      "-select                     float_ops\n",
      "-output                     stdout:\n",
      "\n",
      "==================Model Analysis Report======================\n",
      "\n",
      "Doc:\n",
      "scope: The nodes in the model graph are organized by their names, which is hierarchical like filesystem.\n",
      "flops: Number of float operations. Note: Please read the implementation for the math behind it.\n",
      "\n",
      "Profile:\n",
      "node name | # float_ops\n",
      "_TFProfRoot (--/126.06m flops)\n",
      "  model_26/conv2d_374/Conv2D (16.67m/16.67m flops)\n",
      "  model_26/conv2d_369/Conv2D (16.17m/16.17m flops)\n",
      "  model_26/conv2d_373/Conv2D (14.91m/14.91m flops)\n",
      "  model_26/conv2d_375/Conv2D (13.93m/13.93m flops)\n",
      "  model_26/conv2d_372/Conv2D (9.47m/9.47m flops)\n",
      "  model_26/conv2d_377/Conv2D (8.05m/8.05m flops)\n",
      "  model_26/conv2d_376/Conv2D (7.59m/7.59m flops)\n",
      "  model_26/conv2d_371/Conv2D (6.81m/6.81m flops)\n",
      "  model_26/conv2d_365/Conv2D (6.78m/6.78m flops)\n",
      "  model_26/conv2d_370/Conv2D (5.05m/5.05m flops)\n",
      "  model_26/conv2d_368/Conv2D (4.31m/4.31m flops)\n",
      "  model_26/conv2d_367/Conv2D (4.13m/4.13m flops)\n",
      "  model_26/conv2d_366/Conv2D (2.97m/2.97m flops)\n",
      "  model_26/conv2d_364/Conv2D (2.36m/2.36m flops)\n",
      "  model_26/depthwise_conv2d_338/depthwise (1.33m/1.33m flops)\n",
      "  model_26/depthwise_conv2d_342/depthwise (606.53k/606.53k flops)\n",
      "  model_26/depthwise_conv2d_340/depthwise (580.61k/580.61k flops)\n",
      "  model_26/depthwise_conv2d_339/depthwise (476.93k/476.93k flops)\n",
      "  model_26/depthwise_conv2d_347/depthwise (330.48k/330.48k flops)\n",
      "  model_26/depthwise_conv2d_348/depthwise (294.19k/294.19k flops)\n",
      "  model_26/depthwise_conv2d_346/depthwise (263.09k/263.09k flops)\n",
      "  model_26/batch_normalization_704/FusedBatchNormV3 (212.24k/212.24k flops)\n",
      "  model_26/depthwise_conv2d_345/depthwise (209.95k/209.95k flops)\n",
      "  model_26/depthwise_conv2d_344/depthwise (189.22k/189.22k flops)\n",
      "  model_26/depthwise_conv2d_341/depthwise (165.89k/165.89k flops)\n",
      "  model_26/depthwise_conv2d_343/depthwise (155.52k/155.52k flops)\n",
      "  model_26/batch_normalization_703/FusedBatchNormV3 (147.65k/147.65k flops)\n",
      "  model_26/batch_normalization_702/FusedBatchNormV3 (147.65k/147.65k flops)\n",
      "  model_26/conv2d_365/BiasAdd (105.98k/105.98k flops)\n",
      "  model_26/batch_normalization_708/FusedBatchNormV3 (74.11k/74.11k flops)\n",
      "  model_26/conv2d_364/BiasAdd (73.73k/73.73k flops)\n",
      "  model_26/depthwise_conv2d_338/BiasAdd (73.73k/73.73k flops)\n",
      "  model_26/depthwise_conv2d_350/depthwise (71.28k/71.28k flops)\n",
      "  model_26/batch_normalization_712/FusedBatchNormV3 (70.56k/70.56k flops)\n",
      "  model_26/depthwise_conv2d_349/depthwise (69.01k/69.01k flops)\n",
      "  model_26/batch_normalization_711/FusedBatchNormV3 (68.80k/68.80k flops)\n",
      "  model_26/batch_normalization_710/FusedBatchNormV3 (68.80k/68.80k flops)\n",
      "  model_26/batch_normalization_706/FusedBatchNormV3 (64.85k/64.85k flops)\n",
      "  model_26/batch_normalization_707/FusedBatchNormV3 (64.85k/64.85k flops)\n",
      "  model_26/batch_normalization_705/FusedBatchNormV3 (53.27k/53.27k flops)\n",
      "  model_26/batch_normalization_721/FusedBatchNormV3 (39.78k/39.78k flops)\n",
      "  model_26/batch_normalization_720/FusedBatchNormV3 (39.78k/39.78k flops)\n",
      "  model_26/conv2d_367/BiasAdd (36.86k/36.86k flops)\n",
      "  model_26/batch_normalization_722/FusedBatchNormV3 (35.41k/35.41k flops)\n",
      "  model_26/batch_normalization_723/FusedBatchNormV3 (35.41k/35.41k flops)\n",
      "  model_26/conv2d_369/BiasAdd (34.56k/34.56k flops)\n",
      "  model_26/depthwise_conv2d_342/BiasAdd (33.70k/33.70k flops)\n",
      "  model_26/conv2d_368/BiasAdd (33.70k/33.70k flops)\n",
      "  model_26/batch_normalization_724/FusedBatchNormV3 (33.23k/33.23k flops)\n",
      "  model_26/conv2d_366/BiasAdd (32.26k/32.26k flops)\n",
      "  model_26/depthwise_conv2d_340/BiasAdd (32.26k/32.26k flops)\n",
      "  model_26/batch_normalization_718/FusedBatchNormV3 (31.67k/31.67k flops)\n",
      "  model_26/batch_normalization_719/FusedBatchNormV3 (31.67k/31.67k flops)\n",
      "  model_26/depthwise_conv2d_339/BiasAdd (26.50k/26.50k flops)\n",
      "  model_26/batch_normalization_717/FusedBatchNormV3 (25.27k/25.27k flops)\n",
      "  model_26/batch_normalization_716/FusedBatchNormV3 (25.27k/25.27k flops)\n",
      "  model_26/batch_normalization_726/FusedBatchNormV3 (23.76k/23.76k flops)\n",
      "  model_26/batch_normalization_715/FusedBatchNormV3 (22.78k/22.78k flops)\n",
      "  model_26/batch_normalization_714/FusedBatchNormV3 (22.78k/22.78k flops)\n",
      "  model_26/dense_26/MatMul (20.32k/20.32k flops)\n",
      "  model_26/batch_normalization_709/FusedBatchNormV3 (18.82k/18.82k flops)\n",
      "  model_26/batch_normalization_713/FusedBatchNormV3 (18.72k/18.72k flops)\n",
      "  model_26/conv2d_373/BiasAdd (18.36k/18.36k flops)\n",
      "  model_26/depthwise_conv2d_347/BiasAdd (18.36k/18.36k flops)\n",
      "  model_26/conv2d_374/BiasAdd (16.34k/16.34k flops)\n",
      "  model_26/depthwise_conv2d_348/BiasAdd (16.34k/16.34k flops)\n",
      "  model_26/conv2d_375/BiasAdd (15.34k/15.34k flops)\n",
      "  model_26/conv2d_372/BiasAdd (14.62k/14.62k flops)\n",
      "  model_26/depthwise_conv2d_346/BiasAdd (14.62k/14.62k flops)\n",
      "  model_26/batch_normalization_728/FusedBatchNormV3 (14.22k/14.22k flops)\n",
      "  model_26/batch_normalization_727/FusedBatchNormV3 (13.86k/13.86k flops)\n",
      "  model_26/depthwise_conv2d_345/BiasAdd (11.66k/11.66k flops)\n",
      "  model_26/conv2d_371/BiasAdd (11.66k/11.66k flops)\n",
      "  model_26/depthwise_conv2d_344/BiasAdd (10.51k/10.51k flops)\n",
      "  model_26/conv2d_370/BiasAdd (10.51k/10.51k flops)\n",
      "  model_26/batch_normalization_725/FusedBatchNormV3 (10.22k/10.22k flops)\n",
      "  model_26/depthwise_conv2d_341/BiasAdd (9.22k/9.22k flops)\n",
      "  model_26/conv2d_376/BiasAdd (8.91k/8.91k flops)\n",
      "  model_26/depthwise_conv2d_343/BiasAdd (8.64k/8.64k flops)\n",
      "  model_26/conv2d_377/BiasAdd (4.06k/4.06k flops)\n",
      "  model_26/global_average_pooling2d_26/Mean (4.06k/4.06k flops)\n",
      "  model_26/depthwise_conv2d_350/BiasAdd (3.96k/3.96k flops)\n",
      "  model_26/depthwise_conv2d_349/BiasAdd (3.83k/3.83k flops)\n",
      "  model_26/dense_26/Softmax (50/50 flops)\n",
      "  model_26/dense_26/BiasAdd (10/10 flops)\n",
      "\n",
      "======================End of Report==========================\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "7.697532\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-30 13:40:03.054028: I tensorflow/core/grappler/devices.cc:66] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0\n",
      "2022-04-30 13:40:03.054151: I tensorflow/core/grappler/clusters/single_machine.cc:357] Starting new session\n",
      "2022-04-30 13:40:03.058232: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:1137] Optimization results for grappler item: graph_to_optimize\n",
      "  function_optimizer: function_optimizer did nothing. time = 0.004ms.\n",
      "  function_optimizer: function_optimizer did nothing. time = 0.001ms.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=========================Options=============================\n",
      "-max_depth                  10000\n",
      "-min_bytes                  0\n",
      "-min_peak_bytes             0\n",
      "-min_residual_bytes         0\n",
      "-min_output_bytes           0\n",
      "-min_micros                 0\n",
      "-min_accelerator_micros     0\n",
      "-min_cpu_micros             0\n",
      "-min_params                 0\n",
      "-min_float_ops              1\n",
      "-min_occurrence             0\n",
      "-step                       -1\n",
      "-order_by                   float_ops\n",
      "-account_type_regexes       .*\n",
      "-start_name_regexes         .*\n",
      "-trim_name_regexes          \n",
      "-show_name_regexes          .*\n",
      "-hide_name_regexes          \n",
      "-account_displayed_op_only  true\n",
      "-select                     float_ops\n",
      "-output                     stdout:\n",
      "\n",
      "==================Model Analysis Report======================\n",
      "\n",
      "Doc:\n",
      "scope: The nodes in the model graph are organized by their names, which is hierarchical like filesystem.\n",
      "flops: Number of float operations. Note: Please read the implementation for the math behind it.\n",
      "\n",
      "Profile:\n",
      "node name | # float_ops\n",
      "_TFProfRoot (--/95.98m flops)\n",
      "  model_27/conv2d_389/Conv2D (9.90m/9.90m flops)\n",
      "  model_27/conv2d_383/Conv2D (9.47m/9.47m flops)\n",
      "  model_27/conv2d_386/Conv2D (8.30m/8.30m flops)\n",
      "  model_27/conv2d_390/Conv2D (8.26m/8.26m flops)\n",
      "  model_27/conv2d_387/Conv2D (7.98m/7.98m flops)\n",
      "  model_27/conv2d_391/Conv2D (7.60m/7.60m flops)\n",
      "  model_27/conv2d_379/Conv2D (6.78m/6.78m flops)\n",
      "  model_27/conv2d_388/Conv2D (6.22m/6.22m flops)\n",
      "  model_27/conv2d_385/Conv2D (5.94m/5.94m flops)\n",
      "  model_27/conv2d_381/Conv2D (5.62m/5.62m flops)\n",
      "  model_27/conv2d_382/Conv2D (5.07m/5.07m flops)\n",
      "  model_27/conv2d_384/Conv2D (3.79m/3.79m flops)\n",
      "  model_27/conv2d_380/Conv2D (2.44m/2.44m flops)\n",
      "  model_27/conv2d_378/Conv2D (2.36m/2.36m flops)\n",
      "  model_27/depthwise_conv2d_351/depthwise (1.33m/1.33m flops)\n",
      "  model_27/depthwise_conv2d_352/depthwise (476.93k/476.93k flops)\n",
      "  model_27/depthwise_conv2d_353/depthwise (476.93k/476.93k flops)\n",
      "  model_27/depthwise_conv2d_355/depthwise (430.27k/430.27k flops)\n",
      "  model_27/depthwise_conv2d_354/depthwise (274.75k/274.75k flops)\n",
      "  model_27/depthwise_conv2d_359/depthwise (241.06k/241.06k flops)\n",
      "  model_27/batch_normalization_731/FusedBatchNormV3 (212.24k/212.24k flops)\n",
      "  model_27/depthwise_conv2d_358/depthwise (200.88k/200.88k flops)\n",
      "  model_27/depthwise_conv2d_360/depthwise (193.10k/193.10k flops)\n",
      "  model_27/depthwise_conv2d_361/depthwise (187.92k/187.92k flops)\n",
      "  model_27/depthwise_conv2d_357/depthwise (172.37k/172.37k flops)\n",
      "  model_27/batch_normalization_730/FusedBatchNormV3 (147.65k/147.65k flops)\n",
      "  model_27/batch_normalization_729/FusedBatchNormV3 (147.65k/147.65k flops)\n",
      "  model_27/depthwise_conv2d_356/depthwise (128.30k/128.30k flops)\n",
      "  model_27/batch_normalization_735/FusedBatchNormV3 (122.75k/122.75k flops)\n",
      "  model_27/conv2d_379/BiasAdd (105.98k/105.98k flops)\n",
      "  model_27/depthwise_conv2d_362/depthwise (76.79k/76.79k flops)\n",
      "  model_27/conv2d_378/BiasAdd (73.73k/73.73k flops)\n",
      "  model_27/depthwise_conv2d_351/BiasAdd (73.73k/73.73k flops)\n",
      "  model_27/depthwise_conv2d_363/depthwise (69.70k/69.70k flops)\n",
      "  model_27/conv2d_381/BiasAdd (61.06k/61.06k flops)\n",
      "  model_27/batch_normalization_739/FusedBatchNormV3 (58.21k/58.21k flops)\n",
      "  model_27/batch_normalization_733/FusedBatchNormV3 (53.27k/53.27k flops)\n",
      "  model_27/batch_normalization_732/FusedBatchNormV3 (53.27k/53.27k flops)\n",
      "  model_27/batch_normalization_734/FusedBatchNormV3 (53.27k/53.27k flops)\n",
      "  model_27/batch_normalization_738/FusedBatchNormV3 (48.80k/48.80k flops)\n",
      "  model_27/batch_normalization_737/FusedBatchNormV3 (48.80k/48.80k flops)\n",
      "  model_27/batch_normalization_751/FusedBatchNormV3 (36.97k/36.97k flops)\n",
      "  model_27/batch_normalization_736/FusedBatchNormV3 (31.16k/31.16k flops)\n",
      "  model_27/batch_normalization_746/FusedBatchNormV3 (29.02k/29.02k flops)\n",
      "  model_27/batch_normalization_745/FusedBatchNormV3 (29.02k/29.02k flops)\n",
      "  model_27/conv2d_383/BiasAdd (28.51k/28.51k flops)\n",
      "  model_27/depthwise_conv2d_353/BiasAdd (26.50k/26.50k flops)\n",
      "  model_27/conv2d_380/BiasAdd (26.50k/26.50k flops)\n",
      "  model_27/depthwise_conv2d_352/BiasAdd (26.50k/26.50k flops)\n",
      "  model_27/batch_normalization_744/FusedBatchNormV3 (24.18k/24.18k flops)\n",
      "  model_27/batch_normalization_743/FusedBatchNormV3 (24.18k/24.18k flops)\n",
      "  model_27/conv2d_382/BiasAdd (23.90k/23.90k flops)\n",
      "  model_27/depthwise_conv2d_355/BiasAdd (23.90k/23.90k flops)\n",
      "  model_27/batch_normalization_747/FusedBatchNormV3 (23.24k/23.24k flops)\n",
      "  model_27/batch_normalization_748/FusedBatchNormV3 (23.24k/23.24k flops)\n",
      "  model_27/batch_normalization_753/FusedBatchNormV3 (23.23k/23.23k flops)\n",
      "  model_27/batch_normalization_749/FusedBatchNormV3 (22.62k/22.62k flops)\n",
      "  model_27/batch_normalization_750/FusedBatchNormV3 (22.62k/22.62k flops)\n",
      "  model_27/batch_normalization_742/FusedBatchNormV3 (20.75k/20.75k flops)\n",
      "  model_27/batch_normalization_741/FusedBatchNormV3 (20.75k/20.75k flops)\n",
      "  model_27/dense_27/MatMul (19.64k/19.64k flops)\n",
      "  model_27/conv2d_389/BiasAdd (17.06k/17.06k flops)\n",
      "  model_27/batch_normalization_740/FusedBatchNormV3 (15.44k/15.44k flops)\n",
      "  model_27/depthwise_conv2d_354/BiasAdd (15.26k/15.26k flops)\n",
      "  model_27/batch_normalization_755/FusedBatchNormV3 (13.75k/13.75k flops)\n",
      "  model_27/batch_normalization_754/FusedBatchNormV3 (13.55k/13.55k flops)\n",
      "  model_27/conv2d_386/BiasAdd (13.39k/13.39k flops)\n",
      "  model_27/depthwise_conv2d_359/BiasAdd (13.39k/13.39k flops)\n",
      "  model_27/batch_normalization_752/FusedBatchNormV3 (11.38k/11.38k flops)\n",
      "  model_27/depthwise_conv2d_358/BiasAdd (11.16k/11.16k flops)\n",
      "  model_27/conv2d_385/BiasAdd (11.16k/11.16k flops)\n",
      "  model_27/conv2d_387/BiasAdd (10.73k/10.73k flops)\n",
      "  model_27/depthwise_conv2d_360/BiasAdd (10.73k/10.73k flops)\n",
      "  model_27/conv2d_388/BiasAdd (10.44k/10.44k flops)\n",
      "  model_27/depthwise_conv2d_361/BiasAdd (10.44k/10.44k flops)\n",
      "  model_27/depthwise_conv2d_357/BiasAdd (9.58k/9.58k flops)\n",
      "  model_27/conv2d_384/BiasAdd (9.58k/9.58k flops)\n",
      "  model_27/conv2d_390/BiasAdd (8.71k/8.71k flops)\n",
      "  model_27/depthwise_conv2d_356/BiasAdd (7.13k/7.13k flops)\n",
      "  model_27/depthwise_conv2d_362/BiasAdd (4.27k/4.27k flops)\n",
      "  model_27/global_average_pooling2d_27/Mean (3.93k/3.93k flops)\n",
      "  model_27/conv2d_391/BiasAdd (3.93k/3.93k flops)\n",
      "  model_27/depthwise_conv2d_363/BiasAdd (3.87k/3.87k flops)\n",
      "  model_27/dense_27/Softmax (50/50 flops)\n",
      "  model_27/dense_27/BiasAdd (10/10 flops)\n",
      "\n",
      "======================End of Report==========================\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "9.345412\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-30 13:40:03.976591: I tensorflow/core/grappler/devices.cc:66] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0\n",
      "2022-04-30 13:40:03.976705: I tensorflow/core/grappler/clusters/single_machine.cc:357] Starting new session\n",
      "2022-04-30 13:40:03.980727: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:1137] Optimization results for grappler item: graph_to_optimize\n",
      "  function_optimizer: function_optimizer did nothing. time = 0.005ms.\n",
      "  function_optimizer: function_optimizer did nothing. time = 0.001ms.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=========================Options=============================\n",
      "-max_depth                  10000\n",
      "-min_bytes                  0\n",
      "-min_peak_bytes             0\n",
      "-min_residual_bytes         0\n",
      "-min_output_bytes           0\n",
      "-min_micros                 0\n",
      "-min_accelerator_micros     0\n",
      "-min_cpu_micros             0\n",
      "-min_params                 0\n",
      "-min_float_ops              1\n",
      "-min_occurrence             0\n",
      "-step                       -1\n",
      "-order_by                   float_ops\n",
      "-account_type_regexes       .*\n",
      "-start_name_regexes         .*\n",
      "-trim_name_regexes          \n",
      "-show_name_regexes          .*\n",
      "-hide_name_regexes          \n",
      "-account_displayed_op_only  true\n",
      "-select                     float_ops\n",
      "-output                     stdout:\n",
      "\n",
      "==================Model Analysis Report======================\n",
      "\n",
      "Doc:\n",
      "scope: The nodes in the model graph are organized by their names, which is hierarchical like filesystem.\n",
      "flops: Number of float operations. Note: Please read the implementation for the math behind it.\n",
      "\n",
      "Profile:\n",
      "node name | # float_ops\n",
      "_TFProfRoot (--/127.54m flops)\n",
      "  model_28/conv2d_395/Conv2D (15.48m/15.48m flops)\n",
      "  model_28/conv2d_397/Conv2D (14.97m/14.97m flops)\n",
      "  model_28/conv2d_400/Conv2D (12.27m/12.27m flops)\n",
      "  model_28/conv2d_401/Conv2D (10.85m/10.85m flops)\n",
      "  model_28/conv2d_403/Conv2D (9.91m/9.91m flops)\n",
      "  model_28/conv2d_399/Conv2D (8.93m/8.93m flops)\n",
      "  model_28/conv2d_402/Conv2D (8.67m/8.67m flops)\n",
      "  model_28/conv2d_396/Conv2D (7.88m/7.88m flops)\n",
      "  model_28/conv2d_393/Conv2D (7.37m/7.37m flops)\n",
      "  model_28/conv2d_394/Conv2D (6.45m/6.45m flops)\n",
      "  model_28/conv2d_404/Conv2D (5.60m/5.60m flops)\n",
      "  model_28/conv2d_405/Conv2D (4.99m/4.99m flops)\n",
      "  model_28/conv2d_398/Conv2D (4.04m/4.04m flops)\n",
      "  model_28/conv2d_392/Conv2D (2.36m/2.36m flops)\n",
      "  model_28/depthwise_conv2d_364/depthwise (1.33m/1.33m flops)\n",
      "  model_28/depthwise_conv2d_366/depthwise (1.16m/1.16m flops)\n",
      "  model_28/depthwise_conv2d_368/depthwise (590.98k/590.98k flops)\n",
      "  model_28/depthwise_conv2d_365/depthwise (518.40k/518.40k flops)\n",
      "  model_28/depthwise_conv2d_371/depthwise (326.59k/326.59k flops)\n",
      "  model_28/depthwise_conv2d_367/depthwise (311.04k/311.04k flops)\n",
      "  model_28/depthwise_conv2d_373/depthwise (289.01k/289.01k flops)\n",
      "  model_28/batch_normalization_758/FusedBatchNormV3 (230.70k/230.70k flops)\n",
      "  model_28/depthwise_conv2d_372/depthwise (219.02k/219.02k flops)\n",
      "  model_28/depthwise_conv2d_374/depthwise (174.96k/174.96k flops)\n",
      "  model_28/depthwise_conv2d_370/depthwise (159.41k/159.41k flops)\n",
      "  model_28/depthwise_conv2d_369/depthwise (147.74k/147.74k flops)\n",
      "  model_28/batch_normalization_757/FusedBatchNormV3 (147.65k/147.65k flops)\n",
      "  model_28/batch_normalization_756/FusedBatchNormV3 (147.65k/147.65k flops)\n",
      "  model_28/batch_normalization_762/FusedBatchNormV3 (138.96k/138.96k flops)\n",
      "  model_28/batch_normalization_760/FusedBatchNormV3 (129.70k/129.70k flops)\n",
      "  model_28/batch_normalization_761/FusedBatchNormV3 (129.70k/129.70k flops)\n",
      "  model_28/conv2d_393/BiasAdd (115.20k/115.20k flops)\n",
      "  model_28/depthwise_conv2d_375/depthwise (82.62k/82.62k flops)\n",
      "  model_28/conv2d_392/BiasAdd (73.73k/73.73k flops)\n",
      "  model_28/depthwise_conv2d_364/BiasAdd (73.73k/73.73k flops)\n",
      "  model_28/conv2d_395/BiasAdd (69.12k/69.12k flops)\n",
      "  model_28/batch_normalization_766/FusedBatchNormV3 (67.03k/67.03k flops)\n",
      "  model_28/batch_normalization_765/FusedBatchNormV3 (67.03k/67.03k flops)\n",
      "  model_28/batch_normalization_764/FusedBatchNormV3 (67.03k/67.03k flops)\n",
      "  model_28/depthwise_conv2d_366/BiasAdd (64.51k/64.51k flops)\n",
      "  model_28/conv2d_394/BiasAdd (64.51k/64.51k flops)\n",
      "  model_28/batch_normalization_759/FusedBatchNormV3 (57.90k/57.90k flops)\n",
      "  model_28/depthwise_conv2d_376/depthwise (43.92k/43.92k flops)\n",
      "  model_28/batch_normalization_778/FusedBatchNormV3 (39.78k/39.78k flops)\n",
      "  model_28/batch_normalization_770/FusedBatchNormV3 (39.31k/39.31k flops)\n",
      "  model_28/batch_normalization_771/FusedBatchNormV3 (39.31k/39.31k flops)\n",
      "  model_28/batch_normalization_763/FusedBatchNormV3 (35.28k/35.28k flops)\n",
      "  model_28/batch_normalization_774/FusedBatchNormV3 (34.79k/34.79k flops)\n",
      "  model_28/batch_normalization_775/FusedBatchNormV3 (34.79k/34.79k flops)\n",
      "  model_28/depthwise_conv2d_368/BiasAdd (32.83k/32.83k flops)\n",
      "  model_28/conv2d_396/BiasAdd (32.83k/32.83k flops)\n",
      "  model_28/conv2d_397/BiasAdd (32.83k/32.83k flops)\n",
      "  model_28/depthwise_conv2d_365/BiasAdd (28.80k/28.80k flops)\n",
      "  model_28/batch_normalization_772/FusedBatchNormV3 (26.36k/26.36k flops)\n",
      "  model_28/batch_normalization_773/FusedBatchNormV3 (26.36k/26.36k flops)\n",
      "  model_28/batch_normalization_776/FusedBatchNormV3 (21.06k/21.06k flops)\n",
      "  model_28/batch_normalization_777/FusedBatchNormV3 (21.06k/21.06k flops)\n",
      "  model_28/dense_28/MatMul (20.44k/20.44k flops)\n",
      "  model_28/batch_normalization_768/FusedBatchNormV3 (19.19k/19.19k flops)\n",
      "  model_28/batch_normalization_769/FusedBatchNormV3 (19.19k/19.19k flops)\n",
      "  model_28/conv2d_403/BiasAdd (18.36k/18.36k flops)\n",
      "  model_28/conv2d_399/BiasAdd (18.14k/18.14k flops)\n",
      "  model_28/depthwise_conv2d_371/BiasAdd (18.14k/18.14k flops)\n",
      "  model_28/batch_normalization_767/FusedBatchNormV3 (17.78k/17.78k flops)\n",
      "  model_28/depthwise_conv2d_367/BiasAdd (17.28k/17.28k flops)\n",
      "  model_28/depthwise_conv2d_373/BiasAdd (16.06k/16.06k flops)\n",
      "  model_28/conv2d_401/BiasAdd (16.06k/16.06k flops)\n",
      "  model_28/batch_normalization_780/FusedBatchNormV3 (14.64k/14.64k flops)\n",
      "  model_28/batch_normalization_782/FusedBatchNormV3 (14.31k/14.31k flops)\n",
      "  model_28/batch_normalization_779/FusedBatchNormV3 (12.24k/12.24k flops)\n",
      "  model_28/depthwise_conv2d_372/BiasAdd (12.17k/12.17k flops)\n",
      "  model_28/conv2d_400/BiasAdd (12.17k/12.17k flops)\n",
      "  model_28/conv2d_402/BiasAdd (9.72k/9.72k flops)\n",
      "  model_28/depthwise_conv2d_374/BiasAdd (9.72k/9.72k flops)\n",
      "  model_28/depthwise_conv2d_370/BiasAdd (8.86k/8.86k flops)\n",
      "  model_28/conv2d_398/BiasAdd (8.86k/8.86k flops)\n",
      "  model_28/batch_normalization_781/FusedBatchNormV3 (8.54k/8.54k flops)\n",
      "  model_28/depthwise_conv2d_369/BiasAdd (8.21k/8.21k flops)\n",
      "  model_28/conv2d_404/BiasAdd (5.49k/5.49k flops)\n",
      "  model_28/depthwise_conv2d_375/BiasAdd (4.59k/4.59k flops)\n",
      "  model_28/conv2d_405/BiasAdd (4.09k/4.09k flops)\n",
      "  model_28/global_average_pooling2d_28/Mean (4.09k/4.09k flops)\n",
      "  model_28/depthwise_conv2d_376/BiasAdd (2.44k/2.44k flops)\n",
      "  model_28/dense_28/Softmax (50/50 flops)\n",
      "  model_28/dense_28/BiasAdd (10/10 flops)\n",
      "\n",
      "======================End of Report==========================\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "8.593828\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-30 13:40:05.005685: I tensorflow/core/grappler/devices.cc:66] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0\n",
      "2022-04-30 13:40:05.005804: I tensorflow/core/grappler/clusters/single_machine.cc:357] Starting new session\n",
      "2022-04-30 13:40:05.009922: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:1137] Optimization results for grappler item: graph_to_optimize\n",
      "  function_optimizer: function_optimizer did nothing. time = 0.005ms.\n",
      "  function_optimizer: function_optimizer did nothing. time = 0.001ms.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=========================Options=============================\n",
      "-max_depth                  10000\n",
      "-min_bytes                  0\n",
      "-min_peak_bytes             0\n",
      "-min_residual_bytes         0\n",
      "-min_output_bytes           0\n",
      "-min_micros                 0\n",
      "-min_accelerator_micros     0\n",
      "-min_cpu_micros             0\n",
      "-min_params                 0\n",
      "-min_float_ops              1\n",
      "-min_occurrence             0\n",
      "-step                       -1\n",
      "-order_by                   float_ops\n",
      "-account_type_regexes       .*\n",
      "-start_name_regexes         .*\n",
      "-trim_name_regexes          \n",
      "-show_name_regexes          .*\n",
      "-hide_name_regexes          \n",
      "-account_displayed_op_only  true\n",
      "-select                     float_ops\n",
      "-output                     stdout:\n",
      "\n",
      "==================Model Analysis Report======================\n",
      "\n",
      "Doc:\n",
      "scope: The nodes in the model graph are organized by their names, which is hierarchical like filesystem.\n",
      "flops: Number of float operations. Note: Please read the implementation for the math behind it.\n",
      "\n",
      "Profile:\n",
      "node name | # float_ops\n",
      "_TFProfRoot (--/138.69m flops)\n",
      "  model_29/conv2d_411/Conv2D (18.58m/18.58m flops)\n",
      "  model_29/conv2d_415/Conv2D (17.15m/17.15m flops)\n",
      "  model_29/conv2d_416/Conv2D (16.86m/16.86m flops)\n",
      "  model_29/conv2d_414/Conv2D (14.07m/14.07m flops)\n",
      "  model_29/conv2d_417/Conv2D (13.84m/13.84m flops)\n",
      "  model_29/conv2d_413/Conv2D (11.06m/11.06m flops)\n",
      "  model_29/conv2d_410/Conv2D (7.46m/7.46m flops)\n",
      "  model_29/conv2d_412/Conv2D (6.99m/6.99m flops)\n",
      "  model_29/conv2d_407/Conv2D (6.78m/6.78m flops)\n",
      "  model_29/conv2d_409/Conv2D (5.41m/5.41m flops)\n",
      "  model_29/conv2d_418/Conv2D (4.78m/4.78m flops)\n",
      "  model_29/conv2d_419/Conv2D (3.78m/3.78m flops)\n",
      "  model_29/conv2d_408/Conv2D (2.44m/2.44m flops)\n",
      "  model_29/conv2d_406/Conv2D (2.36m/2.36m flops)\n",
      "  model_29/depthwise_conv2d_377/depthwise (1.33m/1.33m flops)\n",
      "  model_29/depthwise_conv2d_381/depthwise (658.37k/658.37k flops)\n",
      "  model_29/depthwise_conv2d_378/depthwise (476.93k/476.93k flops)\n",
      "  model_29/depthwise_conv2d_379/depthwise (476.93k/476.93k flops)\n",
      "  model_29/depthwise_conv2d_386/depthwise (317.52k/317.52k flops)\n",
      "  model_29/depthwise_conv2d_385/depthwise (314.93k/314.93k flops)\n",
      "  model_29/depthwise_conv2d_387/depthwise (309.74k/309.74k flops)\n",
      "  model_29/depthwise_conv2d_380/depthwise (264.38k/264.38k flops)\n",
      "  model_29/depthwise_conv2d_384/depthwise (260.50k/260.50k flops)\n",
      "  model_29/depthwise_conv2d_383/depthwise (247.54k/247.54k flops)\n",
      "  model_29/batch_normalization_785/FusedBatchNormV3 (212.24k/212.24k flops)\n",
      "  model_29/depthwise_conv2d_382/depthwise (164.59k/164.59k flops)\n",
      "  model_29/batch_normalization_784/FusedBatchNormV3 (147.65k/147.65k flops)\n",
      "  model_29/batch_normalization_783/FusedBatchNormV3 (147.65k/147.65k flops)\n",
      "  model_29/batch_normalization_789/FusedBatchNormV3 (118.12k/118.12k flops)\n",
      "  model_29/conv2d_407/BiasAdd (105.98k/105.98k flops)\n",
      "  model_29/batch_normalization_791/FusedBatchNormV3 (74.68k/74.68k flops)\n",
      "  model_29/batch_normalization_792/FusedBatchNormV3 (74.68k/74.68k flops)\n",
      "  model_29/batch_normalization_793/FusedBatchNormV3 (74.68k/74.68k flops)\n",
      "  model_29/conv2d_406/BiasAdd (73.73k/73.73k flops)\n",
      "  model_29/depthwise_conv2d_377/BiasAdd (73.73k/73.73k flops)\n",
      "  model_29/depthwise_conv2d_388/depthwise (65.12k/65.12k flops)\n",
      "  model_29/conv2d_409/BiasAdd (58.75k/58.75k flops)\n",
      "  model_29/batch_normalization_786/FusedBatchNormV3 (53.27k/53.27k flops)\n",
      "  model_29/batch_normalization_788/FusedBatchNormV3 (53.27k/53.27k flops)\n",
      "  model_29/batch_normalization_787/FusedBatchNormV3 (53.27k/53.27k flops)\n",
      "  model_29/depthwise_conv2d_389/depthwise (47.52k/47.52k flops)\n",
      "  model_29/batch_normalization_802/FusedBatchNormV3 (38.22k/38.22k flops)\n",
      "  model_29/batch_normalization_801/FusedBatchNormV3 (38.22k/38.22k flops)\n",
      "  model_29/batch_normalization_800/FusedBatchNormV3 (37.91k/37.91k flops)\n",
      "  model_29/batch_normalization_799/FusedBatchNormV3 (37.91k/37.91k flops)\n",
      "  model_29/batch_normalization_803/FusedBatchNormV3 (37.28k/37.28k flops)\n",
      "  model_29/batch_normalization_804/FusedBatchNormV3 (37.28k/37.28k flops)\n",
      "  model_29/depthwise_conv2d_381/BiasAdd (36.58k/36.58k flops)\n",
      "  model_29/conv2d_411/BiasAdd (36.58k/36.58k flops)\n",
      "  model_29/conv2d_410/BiasAdd (36.58k/36.58k flops)\n",
      "  model_29/batch_normalization_805/FusedBatchNormV3 (31.36k/31.36k flops)\n",
      "  model_29/batch_normalization_797/FusedBatchNormV3 (31.36k/31.36k flops)\n",
      "  model_29/batch_normalization_798/FusedBatchNormV3 (31.36k/31.36k flops)\n",
      "  model_29/batch_normalization_790/FusedBatchNormV3 (29.99k/29.99k flops)\n",
      "  model_29/batch_normalization_796/FusedBatchNormV3 (29.80k/29.80k flops)\n",
      "  model_29/batch_normalization_795/FusedBatchNormV3 (29.80k/29.80k flops)\n",
      "  model_29/depthwise_conv2d_378/BiasAdd (26.50k/26.50k flops)\n",
      "  model_29/depthwise_conv2d_379/BiasAdd (26.50k/26.50k flops)\n",
      "  model_29/conv2d_408/BiasAdd (26.50k/26.50k flops)\n",
      "  model_29/batch_normalization_794/FusedBatchNormV3 (19.81k/19.81k flops)\n",
      "  model_29/depthwise_conv2d_386/BiasAdd (17.64k/17.64k flops)\n",
      "  model_29/conv2d_415/BiasAdd (17.64k/17.64k flops)\n",
      "  model_29/depthwise_conv2d_385/BiasAdd (17.50k/17.50k flops)\n",
      "  model_29/conv2d_414/BiasAdd (17.50k/17.50k flops)\n",
      "  model_29/depthwise_conv2d_387/BiasAdd (17.21k/17.21k flops)\n",
      "  model_29/conv2d_416/BiasAdd (17.21k/17.21k flops)\n",
      "  model_29/batch_normalization_807/FusedBatchNormV3 (15.84k/15.84k flops)\n",
      "  model_29/depthwise_conv2d_380/BiasAdd (14.69k/14.69k flops)\n",
      "  model_29/conv2d_413/BiasAdd (14.47k/14.47k flops)\n",
      "  model_29/depthwise_conv2d_384/BiasAdd (14.47k/14.47k flops)\n",
      "  model_29/conv2d_417/BiasAdd (14.47k/14.47k flops)\n",
      "  model_29/dense_29/MatMul (14.32k/14.32k flops)\n",
      "  model_29/depthwise_conv2d_383/BiasAdd (13.75k/13.75k flops)\n",
      "  model_29/conv2d_412/BiasAdd (13.75k/13.75k flops)\n",
      "  model_29/batch_normalization_809/FusedBatchNormV3 (10.02k/10.02k flops)\n",
      "  model_29/batch_normalization_806/FusedBatchNormV3 (9.65k/9.65k flops)\n",
      "  model_29/batch_normalization_808/FusedBatchNormV3 (9.24k/9.24k flops)\n",
      "  model_29/depthwise_conv2d_382/BiasAdd (9.14k/9.14k flops)\n",
      "  model_29/conv2d_418/BiasAdd (5.94k/5.94k flops)\n",
      "  model_29/depthwise_conv2d_388/BiasAdd (3.62k/3.62k flops)\n",
      "  model_29/conv2d_419/BiasAdd (2.86k/2.86k flops)\n",
      "  model_29/global_average_pooling2d_29/Mean (2.86k/2.86k flops)\n",
      "  model_29/depthwise_conv2d_389/BiasAdd (2.64k/2.64k flops)\n",
      "  model_29/dense_29/Softmax (50/50 flops)\n",
      "  model_29/dense_29/BiasAdd (10/10 flops)\n",
      "\n",
      "======================End of Report==========================\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "8.258116\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-30 13:40:05.932383: I tensorflow/core/grappler/devices.cc:66] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0\n",
      "2022-04-30 13:40:05.932494: I tensorflow/core/grappler/clusters/single_machine.cc:357] Starting new session\n",
      "2022-04-30 13:40:05.936590: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:1137] Optimization results for grappler item: graph_to_optimize\n",
      "  function_optimizer: function_optimizer did nothing. time = 0.005ms.\n",
      "  function_optimizer: function_optimizer did nothing. time = 0.001ms.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=========================Options=============================\n",
      "-max_depth                  10000\n",
      "-min_bytes                  0\n",
      "-min_peak_bytes             0\n",
      "-min_residual_bytes         0\n",
      "-min_output_bytes           0\n",
      "-min_micros                 0\n",
      "-min_accelerator_micros     0\n",
      "-min_cpu_micros             0\n",
      "-min_params                 0\n",
      "-min_float_ops              1\n",
      "-min_occurrence             0\n",
      "-step                       -1\n",
      "-order_by                   float_ops\n",
      "-account_type_regexes       .*\n",
      "-start_name_regexes         .*\n",
      "-trim_name_regexes          \n",
      "-show_name_regexes          .*\n",
      "-hide_name_regexes          \n",
      "-account_displayed_op_only  true\n",
      "-select                     float_ops\n",
      "-output                     stdout:\n",
      "\n",
      "==================Model Analysis Report======================\n",
      "\n",
      "Doc:\n",
      "scope: The nodes in the model graph are organized by their names, which is hierarchical like filesystem.\n",
      "flops: Number of float operations. Note: Please read the implementation for the math behind it.\n",
      "\n",
      "Profile:\n",
      "node name | # float_ops\n",
      "_TFProfRoot (--/103.62m flops)\n",
      "  model_30/conv2d_423/Conv2D (16.28m/16.28m flops)\n",
      "  model_30/conv2d_431/Conv2D (10.62m/10.62m flops)\n",
      "  model_30/conv2d_430/Conv2D (9.76m/9.76m flops)\n",
      "  model_30/conv2d_433/Conv2D (7.34m/7.34m flops)\n",
      "  model_30/conv2d_425/Conv2D (7.26m/7.26m flops)\n",
      "  model_30/conv2d_429/Conv2D (7.12m/7.12m flops)\n",
      "  model_30/conv2d_428/Conv2D (6.78m/6.78m flops)\n",
      "  model_30/conv2d_427/Conv2D (5.60m/5.60m flops)\n",
      "  model_30/conv2d_432/Conv2D (5.46m/5.46m flops)\n",
      "  model_30/conv2d_421/Conv2D (5.01m/5.01m flops)\n",
      "  model_30/conv2d_424/Conv2D (5.00m/5.00m flops)\n",
      "  model_30/conv2d_422/Conv2D (4.47m/4.47m flops)\n",
      "  model_30/conv2d_426/Conv2D (3.58m/3.58m flops)\n",
      "  model_30/conv2d_420/Conv2D (2.36m/2.36m flops)\n",
      "  model_30/depthwise_conv2d_390/depthwise (1.33m/1.33m flops)\n",
      "  model_30/depthwise_conv2d_392/depthwise (1.18m/1.18m flops)\n",
      "  model_30/depthwise_conv2d_394/depthwise (362.88k/362.88k flops)\n",
      "  model_30/depthwise_conv2d_391/depthwise (352.51k/352.51k flops)\n",
      "  model_30/depthwise_conv2d_393/depthwise (321.41k/321.41k flops)\n",
      "  model_30/depthwise_conv2d_400/depthwise (296.78k/296.78k flops)\n",
      "  model_30/depthwise_conv2d_398/depthwise (216.43k/216.43k flops)\n",
      "  model_30/depthwise_conv2d_399/depthwise (191.81k/191.81k flops)\n",
      "  model_30/depthwise_conv2d_397/depthwise (182.74k/182.74k flops)\n",
      "  model_30/depthwise_conv2d_396/depthwise (178.85k/178.85k flops)\n",
      "  model_30/batch_normalization_812/FusedBatchNormV3 (156.88k/156.88k flops)\n",
      "  model_30/batch_normalization_811/FusedBatchNormV3 (147.65k/147.65k flops)\n",
      "  model_30/batch_normalization_810/FusedBatchNormV3 (147.65k/147.65k flops)\n",
      "  model_30/batch_normalization_816/FusedBatchNormV3 (143.59k/143.59k flops)\n",
      "  model_30/batch_normalization_814/FusedBatchNormV3 (132.01k/132.01k flops)\n",
      "  model_30/batch_normalization_815/FusedBatchNormV3 (132.01k/132.01k flops)\n",
      "  model_30/depthwise_conv2d_395/depthwise (116.64k/116.64k flops)\n",
      "  model_30/conv2d_421/BiasAdd (78.34k/78.34k flops)\n",
      "  model_30/conv2d_420/BiasAdd (73.73k/73.73k flops)\n",
      "  model_30/depthwise_conv2d_390/BiasAdd (73.73k/73.73k flops)\n",
      "  model_30/conv2d_423/BiasAdd (71.42k/71.42k flops)\n",
      "  model_30/depthwise_conv2d_402/depthwise (67.82k/67.82k flops)\n",
      "  model_30/depthwise_conv2d_392/BiasAdd (65.66k/65.66k flops)\n",
      "  model_30/conv2d_422/BiasAdd (65.66k/65.66k flops)\n",
      "  model_30/batch_normalization_820/FusedBatchNormV3 (52.92k/52.92k flops)\n",
      "  model_30/depthwise_conv2d_401/depthwise (52.16k/52.16k flops)\n",
      "  model_30/batch_normalization_819/FusedBatchNormV3 (41.16k/41.16k flops)\n",
      "  model_30/batch_normalization_818/FusedBatchNormV3 (41.16k/41.16k flops)\n",
      "  model_30/batch_normalization_813/FusedBatchNormV3 (39.37k/39.37k flops)\n",
      "  model_30/batch_normalization_817/FusedBatchNormV3 (36.46k/36.46k flops)\n",
      "  model_30/batch_normalization_831/FusedBatchNormV3 (35.72k/35.72k flops)\n",
      "  model_30/batch_normalization_830/FusedBatchNormV3 (35.72k/35.72k flops)\n",
      "  model_30/batch_normalization_826/FusedBatchNormV3 (26.05k/26.05k flops)\n",
      "  model_30/batch_normalization_827/FusedBatchNormV3 (26.05k/26.05k flops)\n",
      "  model_30/conv2d_425/BiasAdd (25.92k/25.92k flops)\n",
      "  model_30/batch_normalization_832/FusedBatchNormV3 (25.12k/25.12k flops)\n",
      "  model_30/batch_normalization_828/FusedBatchNormV3 (23.09k/23.09k flops)\n",
      "  model_30/batch_normalization_829/FusedBatchNormV3 (23.09k/23.09k flops)\n",
      "  model_30/batch_normalization_834/FusedBatchNormV3 (22.61k/22.61k flops)\n",
      "  model_30/batch_normalization_825/FusedBatchNormV3 (22.00k/22.00k flops)\n",
      "  model_30/batch_normalization_824/FusedBatchNormV3 (22.00k/22.00k flops)\n",
      "  model_30/batch_normalization_823/FusedBatchNormV3 (21.53k/21.53k flops)\n",
      "  model_30/batch_normalization_822/FusedBatchNormV3 (21.53k/21.53k flops)\n",
      "  model_30/depthwise_conv2d_394/BiasAdd (20.16k/20.16k flops)\n",
      "  model_30/conv2d_424/BiasAdd (20.16k/20.16k flops)\n",
      "  model_30/depthwise_conv2d_391/BiasAdd (19.58k/19.58k flops)\n",
      "  model_30/dense_30/MatMul (19.48k/19.48k flops)\n",
      "  model_30/depthwise_conv2d_393/BiasAdd (17.86k/17.86k flops)\n",
      "  model_30/depthwise_conv2d_400/BiasAdd (16.49k/16.49k flops)\n",
      "  model_30/conv2d_430/BiasAdd (16.49k/16.49k flops)\n",
      "  model_30/batch_normalization_821/FusedBatchNormV3 (14.04k/14.04k flops)\n",
      "  model_30/batch_normalization_836/FusedBatchNormV3 (13.64k/13.64k flops)\n",
      "  model_30/batch_normalization_835/FusedBatchNormV3 (13.19k/13.19k flops)\n",
      "  model_30/conv2d_428/BiasAdd (12.02k/12.02k flops)\n",
      "  model_30/depthwise_conv2d_398/BiasAdd (12.02k/12.02k flops)\n",
      "  model_30/conv2d_431/BiasAdd (11.59k/11.59k flops)\n",
      "  model_30/conv2d_429/BiasAdd (10.66k/10.66k flops)\n",
      "  model_30/depthwise_conv2d_399/BiasAdd (10.66k/10.66k flops)\n",
      "  model_30/depthwise_conv2d_397/BiasAdd (10.15k/10.15k flops)\n",
      "  model_30/conv2d_427/BiasAdd (10.15k/10.15k flops)\n",
      "  model_30/depthwise_conv2d_396/BiasAdd (9.94k/9.94k flops)\n",
      "  model_30/conv2d_426/BiasAdd (9.94k/9.94k flops)\n",
      "  model_30/conv2d_432/BiasAdd (8.48k/8.48k flops)\n",
      "  model_30/batch_normalization_833/FusedBatchNormV3 (7.73k/7.73k flops)\n",
      "  model_30/depthwise_conv2d_395/BiasAdd (6.48k/6.48k flops)\n",
      "  model_30/global_average_pooling2d_30/Mean (3.90k/3.90k flops)\n",
      "  model_30/conv2d_433/BiasAdd (3.90k/3.90k flops)\n",
      "  model_30/depthwise_conv2d_402/BiasAdd (3.77k/3.77k flops)\n",
      "  model_30/depthwise_conv2d_401/BiasAdd (2.90k/2.90k flops)\n",
      "  model_30/dense_30/Softmax (50/50 flops)\n",
      "  model_30/dense_30/BiasAdd (10/10 flops)\n",
      "\n",
      "======================End of Report==========================\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "15.585996\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-30 13:40:06.963374: I tensorflow/core/grappler/devices.cc:66] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0\n",
      "2022-04-30 13:40:06.963488: I tensorflow/core/grappler/clusters/single_machine.cc:357] Starting new session\n",
      "2022-04-30 13:40:06.967782: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:1137] Optimization results for grappler item: graph_to_optimize\n",
      "  function_optimizer: function_optimizer did nothing. time = 0.005ms.\n",
      "  function_optimizer: function_optimizer did nothing. time = 0.001ms.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=========================Options=============================\n",
      "-max_depth                  10000\n",
      "-min_bytes                  0\n",
      "-min_peak_bytes             0\n",
      "-min_residual_bytes         0\n",
      "-min_output_bytes           0\n",
      "-min_micros                 0\n",
      "-min_accelerator_micros     0\n",
      "-min_cpu_micros             0\n",
      "-min_params                 0\n",
      "-min_float_ops              1\n",
      "-min_occurrence             0\n",
      "-step                       -1\n",
      "-order_by                   float_ops\n",
      "-account_type_regexes       .*\n",
      "-start_name_regexes         .*\n",
      "-trim_name_regexes          \n",
      "-show_name_regexes          .*\n",
      "-hide_name_regexes          \n",
      "-account_displayed_op_only  true\n",
      "-select                     float_ops\n",
      "-output                     stdout:\n",
      "\n",
      "==================Model Analysis Report======================\n",
      "\n",
      "Doc:\n",
      "scope: The nodes in the model graph are organized by their names, which is hierarchical like filesystem.\n",
      "flops: Number of float operations. Note: Please read the implementation for the math behind it.\n",
      "\n",
      "Profile:\n",
      "node name | # float_ops\n",
      "_TFProfRoot (--/217.27m flops)\n",
      "  model_31/conv2d_443/Conv2D (29.91m/29.91m flops)\n",
      "  model_31/conv2d_444/Conv2D (29.39m/29.39m flops)\n",
      "  model_31/conv2d_445/Conv2D (27.08m/27.08m flops)\n",
      "  model_31/conv2d_442/Conv2D (17.08m/17.08m flops)\n",
      "  model_31/conv2d_435/Conv2D (15.73m/15.73m flops)\n",
      "  model_31/conv2d_437/Conv2D (15.15m/15.15m flops)\n",
      "  model_31/conv2d_446/Conv2D (13.57m/13.57m flops)\n",
      "  model_31/conv2d_439/Conv2D (12.78m/12.78m flops)\n",
      "  model_31/conv2d_436/Conv2D (10.57m/10.57m flops)\n",
      "  model_31/conv2d_441/Conv2D (9.73m/9.73m flops)\n",
      "  model_31/conv2d_447/Conv2D (7.07m/7.07m flops)\n",
      "  model_31/conv2d_438/Conv2D (6.87m/6.87m flops)\n",
      "  model_31/conv2d_440/Conv2D (5.37m/5.37m flops)\n",
      "  model_31/conv2d_434/Conv2D (4.19m/4.19m flops)\n",
      "  model_31/depthwise_conv2d_403/depthwise (2.36m/2.36m flops)\n",
      "  model_31/depthwise_conv2d_405/depthwise (1.59m/1.59m flops)\n",
      "  model_31/depthwise_conv2d_404/depthwise (1.11m/1.11m flops)\n",
      "  model_31/depthwise_conv2d_407/depthwise (718.85k/718.85k flops)\n",
      "  model_31/depthwise_conv2d_412/depthwise (585.22k/585.22k flops)\n",
      "  model_31/depthwise_conv2d_411/depthwise (529.92k/529.92k flops)\n",
      "  model_31/depthwise_conv2d_413/depthwise (520.70k/520.70k flops)\n",
      "  model_31/batch_normalization_839/FusedBatchNormV3 (491.88k/491.88k flops)\n",
      "  model_31/depthwise_conv2d_406/depthwise (396.29k/396.29k flops)\n",
      "  model_31/depthwise_conv2d_410/depthwise (334.08k/334.08k flops)\n",
      "  model_31/depthwise_conv2d_409/depthwise (301.82k/301.82k flops)\n",
      "  model_31/batch_normalization_838/FusedBatchNormV3 (262.34k/262.34k flops)\n",
      "  model_31/batch_normalization_837/FusedBatchNormV3 (262.34k/262.34k flops)\n",
      "  model_31/conv2d_435/BiasAdd (245.76k/245.76k flops)\n",
      "  model_31/depthwise_conv2d_408/depthwise (184.32k/184.32k flops)\n",
      "  model_31/batch_normalization_841/FusedBatchNormV3 (176.64k/176.64k flops)\n",
      "  model_31/batch_normalization_843/FusedBatchNormV3 (176.64k/176.64k flops)\n",
      "  model_31/batch_normalization_842/FusedBatchNormV3 (176.64k/176.64k flops)\n",
      "  model_31/depthwise_conv2d_414/depthwise (134.78k/134.78k flops)\n",
      "  model_31/conv2d_434/BiasAdd (131.07k/131.07k flops)\n",
      "  model_31/depthwise_conv2d_403/BiasAdd (131.07k/131.07k flops)\n",
      "  model_31/batch_normalization_840/FusedBatchNormV3 (123.24k/123.24k flops)\n",
      "  model_31/depthwise_conv2d_405/BiasAdd (88.06k/88.06k flops)\n",
      "  model_31/conv2d_437/BiasAdd (88.06k/88.06k flops)\n",
      "  model_31/conv2d_436/BiasAdd (88.06k/88.06k flops)\n",
      "  model_31/batch_normalization_847/FusedBatchNormV3 (82.88k/82.88k flops)\n",
      "  model_31/batch_normalization_846/FusedBatchNormV3 (80.81k/80.81k flops)\n",
      "  model_31/batch_normalization_845/FusedBatchNormV3 (80.81k/80.81k flops)\n",
      "  model_31/batch_normalization_856/FusedBatchNormV3 (68.07k/68.07k flops)\n",
      "  model_31/batch_normalization_855/FusedBatchNormV3 (68.07k/68.07k flops)\n",
      "  model_31/depthwise_conv2d_415/depthwise (65.23k/65.23k flops)\n",
      "  model_31/batch_normalization_859/FusedBatchNormV3 (62.71k/62.71k flops)\n",
      "  model_31/batch_normalization_854/FusedBatchNormV3 (61.64k/61.64k flops)\n",
      "  model_31/batch_normalization_853/FusedBatchNormV3 (61.64k/61.64k flops)\n",
      "  model_31/depthwise_conv2d_404/BiasAdd (61.44k/61.44k flops)\n",
      "  model_31/batch_normalization_858/FusedBatchNormV3 (60.57k/60.57k flops)\n",
      "  model_31/batch_normalization_857/FusedBatchNormV3 (60.57k/60.57k flops)\n",
      "  model_31/batch_normalization_844/FusedBatchNormV3 (44.55k/44.55k flops)\n",
      "  model_31/conv2d_439/BiasAdd (40.96k/40.96k flops)\n",
      "  model_31/depthwise_conv2d_407/BiasAdd (39.94k/39.94k flops)\n",
      "  model_31/conv2d_438/BiasAdd (39.94k/39.94k flops)\n",
      "  model_31/batch_normalization_851/FusedBatchNormV3 (38.86k/38.86k flops)\n",
      "  model_31/batch_normalization_852/FusedBatchNormV3 (38.86k/38.86k flops)\n",
      "  model_31/batch_normalization_850/FusedBatchNormV3 (35.11k/35.11k flops)\n",
      "  model_31/batch_normalization_849/FusedBatchNormV3 (35.11k/35.11k flops)\n",
      "  model_31/batch_normalization_861/FusedBatchNormV3 (34.43k/34.43k flops)\n",
      "  model_31/depthwise_conv2d_412/BiasAdd (32.51k/32.51k flops)\n",
      "  model_31/conv2d_443/BiasAdd (32.51k/32.51k flops)\n",
      "  model_31/conv2d_445/BiasAdd (29.95k/29.95k flops)\n",
      "  model_31/conv2d_442/BiasAdd (29.44k/29.44k flops)\n",
      "  model_31/depthwise_conv2d_411/BiasAdd (29.44k/29.44k flops)\n",
      "  model_31/depthwise_conv2d_413/BiasAdd (28.93k/28.93k flops)\n",
      "  model_31/conv2d_444/BiasAdd (28.93k/28.93k flops)\n",
      "  model_31/depthwise_conv2d_406/BiasAdd (22.02k/22.02k flops)\n",
      "  model_31/batch_normalization_848/FusedBatchNormV3 (21.44k/21.44k flops)\n",
      "  model_31/dense_31/MatMul (19.52k/19.52k flops)\n",
      "  model_31/conv2d_441/BiasAdd (18.56k/18.56k flops)\n",
      "  model_31/depthwise_conv2d_410/BiasAdd (18.56k/18.56k flops)\n",
      "  model_31/batch_normalization_860/FusedBatchNormV3 (17.78k/17.78k flops)\n",
      "  model_31/depthwise_conv2d_409/BiasAdd (16.77k/16.77k flops)\n",
      "  model_31/conv2d_440/BiasAdd (16.77k/16.77k flops)\n",
      "  model_31/conv2d_446/BiasAdd (14.50k/14.50k flops)\n",
      "  model_31/batch_normalization_863/FusedBatchNormV3 (13.66k/13.66k flops)\n",
      "  model_31/batch_normalization_862/FusedBatchNormV3 (12.68k/12.68k flops)\n",
      "  model_31/depthwise_conv2d_408/BiasAdd (10.24k/10.24k flops)\n",
      "  model_31/depthwise_conv2d_414/BiasAdd (7.49k/7.49k flops)\n",
      "  model_31/global_average_pooling2d_31/Mean (3.90k/3.90k flops)\n",
      "  model_31/conv2d_447/BiasAdd (3.90k/3.90k flops)\n",
      "  model_31/depthwise_conv2d_415/BiasAdd (3.62k/3.62k flops)\n",
      "  model_31/dense_31/Softmax (50/50 flops)\n",
      "  model_31/dense_31/BiasAdd (10/10 flops)\n",
      "\n",
      "======================End of Report==========================\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "15.85354\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-30 13:40:07.911426: I tensorflow/core/grappler/devices.cc:66] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0\n",
      "2022-04-30 13:40:07.911548: I tensorflow/core/grappler/clusters/single_machine.cc:357] Starting new session\n",
      "2022-04-30 13:40:07.915570: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:1137] Optimization results for grappler item: graph_to_optimize\n",
      "  function_optimizer: function_optimizer did nothing. time = 0.005ms.\n",
      "  function_optimizer: function_optimizer did nothing. time = 0.001ms.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=========================Options=============================\n",
      "-max_depth                  10000\n",
      "-min_bytes                  0\n",
      "-min_peak_bytes             0\n",
      "-min_residual_bytes         0\n",
      "-min_output_bytes           0\n",
      "-min_micros                 0\n",
      "-min_accelerator_micros     0\n",
      "-min_cpu_micros             0\n",
      "-min_params                 0\n",
      "-min_float_ops              1\n",
      "-min_occurrence             0\n",
      "-step                       -1\n",
      "-order_by                   float_ops\n",
      "-account_type_regexes       .*\n",
      "-start_name_regexes         .*\n",
      "-trim_name_regexes          \n",
      "-show_name_regexes          .*\n",
      "-hide_name_regexes          \n",
      "-account_displayed_op_only  true\n",
      "-select                     float_ops\n",
      "-output                     stdout:\n",
      "\n",
      "==================Model Analysis Report======================\n",
      "\n",
      "Doc:\n",
      "scope: The nodes in the model graph are organized by their names, which is hierarchical like filesystem.\n",
      "flops: Number of float operations. Note: Please read the implementation for the math behind it.\n",
      "\n",
      "Profile:\n",
      "node name | # float_ops\n",
      "_TFProfRoot (--/238.26m flops)\n",
      "  model_32/conv2d_458/Conv2D (28.00m/28.00m flops)\n",
      "  model_32/conv2d_459/Conv2D (27.88m/27.88m flops)\n",
      "  model_32/conv2d_451/Conv2D (26.58m/26.58m flops)\n",
      "  model_32/conv2d_457/Conv2D (26.50m/26.50m flops)\n",
      "  model_32/conv2d_456/Conv2D (25.09m/25.09m flops)\n",
      "  model_32/conv2d_455/Conv2D (23.01m/23.01m flops)\n",
      "  model_32/conv2d_449/Conv2D (11.53m/11.53m flops)\n",
      "  model_32/conv2d_460/Conv2D (10.89m/10.89m flops)\n",
      "  model_32/conv2d_453/Conv2D (10.14m/10.14m flops)\n",
      "  model_32/conv2d_450/Conv2D (9.91m/9.91m flops)\n",
      "  model_32/conv2d_454/Conv2D (8.06m/8.06m flops)\n",
      "  model_32/conv2d_452/Conv2D (7.97m/7.97m flops)\n",
      "  model_32/conv2d_461/Conv2D (5.16m/5.16m flops)\n",
      "  model_32/conv2d_448/Conv2D (4.19m/4.19m flops)\n",
      "  model_32/depthwise_conv2d_416/depthwise (2.36m/2.36m flops)\n",
      "  model_32/depthwise_conv2d_418/depthwise (2.03m/2.03m flops)\n",
      "  model_32/depthwise_conv2d_417/depthwise (811.01k/811.01k flops)\n",
      "  model_32/depthwise_conv2d_420/depthwise (608.26k/608.26k flops)\n",
      "  model_32/depthwise_conv2d_426/depthwise (557.57k/557.57k flops)\n",
      "  model_32/depthwise_conv2d_419/depthwise (543.74k/543.74k flops)\n",
      "  model_32/depthwise_conv2d_424/depthwise (527.62k/527.62k flops)\n",
      "  model_32/depthwise_conv2d_425/depthwise (520.70k/520.70k flops)\n",
      "  model_32/depthwise_conv2d_423/depthwise (493.06k/493.06k flops)\n",
      "  model_32/depthwise_conv2d_422/depthwise (483.84k/483.84k flops)\n",
      "  model_32/batch_normalization_866/FusedBatchNormV3 (360.71k/360.71k flops)\n",
      "  model_32/batch_normalization_865/FusedBatchNormV3 (262.34k/262.34k flops)\n",
      "  model_32/batch_normalization_864/FusedBatchNormV3 (262.34k/262.34k flops)\n",
      "  model_32/batch_normalization_870/FusedBatchNormV3 (242.37k/242.37k flops)\n",
      "  model_32/batch_normalization_868/FusedBatchNormV3 (225.94k/225.94k flops)\n",
      "  model_32/batch_normalization_869/FusedBatchNormV3 (225.94k/225.94k flops)\n",
      "  model_32/conv2d_449/BiasAdd (180.22k/180.22k flops)\n",
      "  model_32/depthwise_conv2d_421/depthwise (172.80k/172.80k flops)\n",
      "  model_32/conv2d_448/BiasAdd (131.07k/131.07k flops)\n",
      "  model_32/depthwise_conv2d_416/BiasAdd (131.07k/131.07k flops)\n",
      "  model_32/depthwise_conv2d_427/depthwise (129.60k/129.60k flops)\n",
      "  model_32/conv2d_451/BiasAdd (120.83k/120.83k flops)\n",
      "  model_32/depthwise_conv2d_418/BiasAdd (112.64k/112.64k flops)\n",
      "  model_32/conv2d_450/BiasAdd (112.64k/112.64k flops)\n",
      "  model_32/batch_normalization_867/FusedBatchNormV3 (90.38k/90.38k flops)\n",
      "  model_32/batch_normalization_874/FusedBatchNormV3 (77.70k/77.70k flops)\n",
      "  model_32/batch_normalization_872/FusedBatchNormV3 (68.38k/68.38k flops)\n",
      "  model_32/batch_normalization_873/FusedBatchNormV3 (68.38k/68.38k flops)\n",
      "  model_32/batch_normalization_885/FusedBatchNormV3 (64.86k/64.86k flops)\n",
      "  model_32/batch_normalization_884/FusedBatchNormV3 (64.86k/64.86k flops)\n",
      "  model_32/batch_normalization_880/FusedBatchNormV3 (61.37k/61.37k flops)\n",
      "  model_32/batch_normalization_881/FusedBatchNormV3 (61.37k/61.37k flops)\n",
      "  model_32/batch_normalization_871/FusedBatchNormV3 (61.12k/61.12k flops)\n",
      "  model_32/batch_normalization_882/FusedBatchNormV3 (60.57k/60.57k flops)\n",
      "  model_32/batch_normalization_883/FusedBatchNormV3 (60.57k/60.57k flops)\n",
      "  model_32/batch_normalization_886/FusedBatchNormV3 (60.30k/60.30k flops)\n",
      "  model_32/batch_normalization_879/FusedBatchNormV3 (57.35k/57.35k flops)\n",
      "  model_32/batch_normalization_878/FusedBatchNormV3 (57.35k/57.35k flops)\n",
      "  model_32/batch_normalization_877/FusedBatchNormV3 (56.28k/56.28k flops)\n",
      "  model_32/batch_normalization_876/FusedBatchNormV3 (56.28k/56.28k flops)\n",
      "  model_32/depthwise_conv2d_428/depthwise (54.43k/54.43k flops)\n",
      "  model_32/depthwise_conv2d_417/BiasAdd (45.06k/45.06k flops)\n",
      "  model_32/conv2d_453/BiasAdd (38.40k/38.40k flops)\n",
      "  model_32/conv2d_452/BiasAdd (33.79k/33.79k flops)\n",
      "  model_32/depthwise_conv2d_420/BiasAdd (33.79k/33.79k flops)\n",
      "  model_32/depthwise_conv2d_426/BiasAdd (30.98k/30.98k flops)\n",
      "  model_32/conv2d_458/BiasAdd (30.98k/30.98k flops)\n",
      "  model_32/depthwise_conv2d_419/BiasAdd (30.21k/30.21k flops)\n",
      "  model_32/conv2d_456/BiasAdd (29.31k/29.31k flops)\n",
      "  model_32/depthwise_conv2d_424/BiasAdd (29.31k/29.31k flops)\n",
      "  model_32/depthwise_conv2d_425/BiasAdd (28.93k/28.93k flops)\n",
      "  model_32/conv2d_457/BiasAdd (28.93k/28.93k flops)\n",
      "  model_32/conv2d_459/BiasAdd (28.80k/28.80k flops)\n",
      "  model_32/batch_normalization_888/FusedBatchNormV3 (28.73k/28.73k flops)\n",
      "  model_32/conv2d_455/BiasAdd (27.39k/27.39k flops)\n",
      "  model_32/depthwise_conv2d_423/BiasAdd (27.39k/27.39k flops)\n",
      "  model_32/depthwise_conv2d_422/BiasAdd (26.88k/26.88k flops)\n",
      "  model_32/conv2d_454/BiasAdd (26.88k/26.88k flops)\n",
      "  model_32/batch_normalization_875/FusedBatchNormV3 (20.10k/20.10k flops)\n",
      "  model_32/batch_normalization_887/FusedBatchNormV3 (17.10k/17.10k flops)\n",
      "  model_32/dense_32/MatMul (17.08k/17.08k flops)\n",
      "  model_32/conv2d_460/BiasAdd (12.10k/12.10k flops)\n",
      "  model_32/batch_normalization_890/FusedBatchNormV3 (11.96k/11.96k flops)\n",
      "  model_32/batch_normalization_889/FusedBatchNormV3 (10.58k/10.58k flops)\n",
      "  model_32/depthwise_conv2d_421/BiasAdd (9.60k/9.60k flops)\n",
      "  model_32/depthwise_conv2d_427/BiasAdd (7.20k/7.20k flops)\n",
      "  model_32/global_average_pooling2d_32/Mean (3.42k/3.42k flops)\n",
      "  model_32/conv2d_461/BiasAdd (3.42k/3.42k flops)\n",
      "  model_32/depthwise_conv2d_428/BiasAdd (3.02k/3.02k flops)\n",
      "  model_32/dense_32/Softmax (50/50 flops)\n",
      "  model_32/dense_32/BiasAdd (10/10 flops)\n",
      "\n",
      "======================End of Report==========================\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "16.444772\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-30 13:40:08.942238: I tensorflow/core/grappler/devices.cc:66] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0\n",
      "2022-04-30 13:40:08.942353: I tensorflow/core/grappler/clusters/single_machine.cc:357] Starting new session\n",
      "2022-04-30 13:40:08.946845: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:1137] Optimization results for grappler item: graph_to_optimize\n",
      "  function_optimizer: function_optimizer did nothing. time = 0.005ms.\n",
      "  function_optimizer: function_optimizer did nothing. time = 0ms.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=========================Options=============================\n",
      "-max_depth                  10000\n",
      "-min_bytes                  0\n",
      "-min_peak_bytes             0\n",
      "-min_residual_bytes         0\n",
      "-min_output_bytes           0\n",
      "-min_micros                 0\n",
      "-min_accelerator_micros     0\n",
      "-min_cpu_micros             0\n",
      "-min_params                 0\n",
      "-min_float_ops              1\n",
      "-min_occurrence             0\n",
      "-step                       -1\n",
      "-order_by                   float_ops\n",
      "-account_type_regexes       .*\n",
      "-start_name_regexes         .*\n",
      "-trim_name_regexes          \n",
      "-show_name_regexes          .*\n",
      "-hide_name_regexes          \n",
      "-account_displayed_op_only  true\n",
      "-select                     float_ops\n",
      "-output                     stdout:\n",
      "\n",
      "==================Model Analysis Report======================\n",
      "\n",
      "Doc:\n",
      "scope: The nodes in the model graph are organized by their names, which is hierarchical like filesystem.\n",
      "flops: Number of float operations. Note: Please read the implementation for the math behind it.\n",
      "\n",
      "Profile:\n",
      "node name | # float_ops\n",
      "_TFProfRoot (--/218.61m flops)\n",
      "  model_33/conv2d_465/Conv2D (31.49m/31.49m flops)\n",
      "  model_33/conv2d_467/Conv2D (21.87m/21.87m flops)\n",
      "  model_33/conv2d_473/Conv2D (20.52m/20.52m flops)\n",
      "  model_33/conv2d_472/Conv2D (20.07m/20.07m flops)\n",
      "  model_33/conv2d_470/Conv2D (16.27m/16.27m flops)\n",
      "  model_33/conv2d_469/Conv2D (15.38m/15.38m flops)\n",
      "  model_33/conv2d_471/Conv2D (14.94m/14.94m flops)\n",
      "  model_33/conv2d_463/Conv2D (12.58m/12.58m flops)\n",
      "  model_33/conv2d_464/Conv2D (12.19m/12.19m flops)\n",
      "  model_33/conv2d_466/Conv2D (11.30m/11.30m flops)\n",
      "  model_33/conv2d_468/Conv2D (9.46m/9.46m flops)\n",
      "  model_33/conv2d_474/Conv2D (9.42m/9.42m flops)\n",
      "  model_33/conv2d_475/Conv2D (5.29m/5.29m flops)\n",
      "  model_33/conv2d_462/Conv2D (4.19m/4.19m flops)\n",
      "  model_33/depthwise_conv2d_429/depthwise (2.36m/2.36m flops)\n",
      "  model_33/depthwise_conv2d_431/depthwise (2.29m/2.29m flops)\n",
      "  model_33/depthwise_conv2d_430/depthwise (884.74k/884.74k flops)\n",
      "  model_33/depthwise_conv2d_433/depthwise (820.22k/820.22k flops)\n",
      "  model_33/depthwise_conv2d_432/depthwise (571.39k/571.39k flops)\n",
      "  model_33/depthwise_conv2d_439/depthwise (504.58k/504.58k flops)\n",
      "  model_33/depthwise_conv2d_436/depthwise (449.28k/449.28k flops)\n",
      "  model_33/depthwise_conv2d_438/depthwise (412.42k/412.42k flops)\n",
      "  model_33/batch_normalization_893/FusedBatchNormV3 (393.50k/393.50k flops)\n",
      "  model_33/depthwise_conv2d_437/depthwise (375.55k/375.55k flops)\n",
      "  model_33/depthwise_conv2d_435/depthwise (354.82k/354.82k flops)\n",
      "  model_33/depthwise_conv2d_434/depthwise (276.48k/276.48k flops)\n",
      "  model_33/batch_normalization_892/FusedBatchNormV3 (262.34k/262.34k flops)\n",
      "  model_33/batch_normalization_891/FusedBatchNormV3 (262.34k/262.34k flops)\n",
      "  model_33/batch_normalization_895/FusedBatchNormV3 (254.70k/254.70k flops)\n",
      "  model_33/batch_normalization_896/FusedBatchNormV3 (254.70k/254.70k flops)\n",
      "  model_33/batch_normalization_897/FusedBatchNormV3 (254.70k/254.70k flops)\n",
      "  model_33/conv2d_463/BiasAdd (196.61k/196.61k flops)\n",
      "  model_33/conv2d_462/BiasAdd (131.07k/131.07k flops)\n",
      "  model_33/depthwise_conv2d_429/BiasAdd (131.07k/131.07k flops)\n",
      "  model_33/conv2d_464/BiasAdd (126.98k/126.98k flops)\n",
      "  model_33/conv2d_465/BiasAdd (126.98k/126.98k flops)\n",
      "  model_33/depthwise_conv2d_431/BiasAdd (126.98k/126.98k flops)\n",
      "  model_33/batch_normalization_901/FusedBatchNormV3 (124.32k/124.32k flops)\n",
      "  model_33/depthwise_conv2d_440/depthwise (105.41k/105.41k flops)\n",
      "  model_33/batch_normalization_894/FusedBatchNormV3 (98.59k/98.59k flops)\n",
      "  model_33/batch_normalization_899/FusedBatchNormV3 (92.20k/92.20k flops)\n",
      "  model_33/batch_normalization_900/FusedBatchNormV3 (92.20k/92.20k flops)\n",
      "  model_33/batch_normalization_898/FusedBatchNormV3 (64.23k/64.23k flops)\n",
      "  model_33/conv2d_467/BiasAdd (61.44k/61.44k flops)\n",
      "  model_33/batch_normalization_911/FusedBatchNormV3 (58.69k/58.69k flops)\n",
      "  model_33/batch_normalization_912/FusedBatchNormV3 (58.69k/58.69k flops)\n",
      "  model_33/depthwise_conv2d_441/depthwise (57.89k/57.89k flops)\n",
      "  model_33/batch_normalization_906/FusedBatchNormV3 (52.26k/52.26k flops)\n",
      "  model_33/batch_normalization_905/FusedBatchNormV3 (52.26k/52.26k flops)\n",
      "  model_33/depthwise_conv2d_430/BiasAdd (49.15k/49.15k flops)\n",
      "  model_33/batch_normalization_913/FusedBatchNormV3 (49.04k/49.04k flops)\n",
      "  model_33/batch_normalization_910/FusedBatchNormV3 (47.97k/47.97k flops)\n",
      "  model_33/batch_normalization_909/FusedBatchNormV3 (47.97k/47.97k flops)\n",
      "  model_33/depthwise_conv2d_433/BiasAdd (45.57k/45.57k flops)\n",
      "  model_33/conv2d_466/BiasAdd (45.57k/45.57k flops)\n",
      "  model_33/batch_normalization_908/FusedBatchNormV3 (43.68k/43.68k flops)\n",
      "  model_33/batch_normalization_907/FusedBatchNormV3 (43.68k/43.68k flops)\n",
      "  model_33/batch_normalization_904/FusedBatchNormV3 (41.27k/41.27k flops)\n",
      "  model_33/batch_normalization_903/FusedBatchNormV3 (41.27k/41.27k flops)\n",
      "  model_33/batch_normalization_902/FusedBatchNormV3 (32.16k/32.16k flops)\n",
      "  model_33/depthwise_conv2d_432/BiasAdd (31.74k/31.74k flops)\n",
      "  model_33/batch_normalization_915/FusedBatchNormV3 (30.55k/30.55k flops)\n",
      "  model_33/conv2d_472/BiasAdd (28.03k/28.03k flops)\n",
      "  model_33/depthwise_conv2d_439/BiasAdd (28.03k/28.03k flops)\n",
      "  model_33/conv2d_469/BiasAdd (24.96k/24.96k flops)\n",
      "  model_33/depthwise_conv2d_436/BiasAdd (24.96k/24.96k flops)\n",
      "  model_33/conv2d_473/BiasAdd (23.42k/23.42k flops)\n",
      "  model_33/conv2d_471/BiasAdd (22.91k/22.91k flops)\n",
      "  model_33/depthwise_conv2d_438/BiasAdd (22.91k/22.91k flops)\n",
      "  model_33/depthwise_conv2d_437/BiasAdd (20.86k/20.86k flops)\n",
      "  model_33/conv2d_470/BiasAdd (20.86k/20.86k flops)\n",
      "  model_33/conv2d_468/BiasAdd (19.71k/19.71k flops)\n",
      "  model_33/depthwise_conv2d_435/BiasAdd (19.71k/19.71k flops)\n",
      "  model_33/dense_33/MatMul (16.44k/16.44k flops)\n",
      "  model_33/depthwise_conv2d_434/BiasAdd (15.36k/15.36k flops)\n",
      "  model_33/batch_normalization_914/FusedBatchNormV3 (13.91k/13.91k flops)\n",
      "  model_33/conv2d_474/BiasAdd (12.86k/12.86k flops)\n",
      "  model_33/batch_normalization_917/FusedBatchNormV3 (11.51k/11.51k flops)\n",
      "  model_33/batch_normalization_916/FusedBatchNormV3 (11.26k/11.26k flops)\n",
      "  model_33/depthwise_conv2d_440/BiasAdd (5.86k/5.86k flops)\n",
      "  model_33/conv2d_475/BiasAdd (3.29k/3.29k flops)\n",
      "  model_33/global_average_pooling2d_33/Mean (3.29k/3.29k flops)\n",
      "  model_33/depthwise_conv2d_441/BiasAdd (3.22k/3.22k flops)\n",
      "  model_33/dense_33/Softmax (50/50 flops)\n",
      "  model_33/dense_33/BiasAdd (10/10 flops)\n",
      "\n",
      "======================End of Report==========================\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "14.5363\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-30 13:40:09.860514: I tensorflow/core/grappler/devices.cc:66] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0\n",
      "2022-04-30 13:40:09.860626: I tensorflow/core/grappler/clusters/single_machine.cc:357] Starting new session\n",
      "2022-04-30 13:40:09.864766: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:1137] Optimization results for grappler item: graph_to_optimize\n",
      "  function_optimizer: function_optimizer did nothing. time = 0.005ms.\n",
      "  function_optimizer: function_optimizer did nothing. time = 0.001ms.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=========================Options=============================\n",
      "-max_depth                  10000\n",
      "-min_bytes                  0\n",
      "-min_peak_bytes             0\n",
      "-min_residual_bytes         0\n",
      "-min_output_bytes           0\n",
      "-min_micros                 0\n",
      "-min_accelerator_micros     0\n",
      "-min_cpu_micros             0\n",
      "-min_params                 0\n",
      "-min_float_ops              1\n",
      "-min_occurrence             0\n",
      "-step                       -1\n",
      "-order_by                   float_ops\n",
      "-account_type_regexes       .*\n",
      "-start_name_regexes         .*\n",
      "-trim_name_regexes          \n",
      "-show_name_regexes          .*\n",
      "-hide_name_regexes          \n",
      "-account_displayed_op_only  true\n",
      "-select                     float_ops\n",
      "-output                     stdout:\n",
      "\n",
      "==================Model Analysis Report======================\n",
      "\n",
      "Doc:\n",
      "scope: The nodes in the model graph are organized by their names, which is hierarchical like filesystem.\n",
      "flops: Number of float operations. Note: Please read the implementation for the math behind it.\n",
      "\n",
      "Profile:\n",
      "node name | # float_ops\n",
      "_TFProfRoot (--/248.56m flops)\n",
      "  model_34/conv2d_487/Conv2D (30.98m/30.98m flops)\n",
      "  model_34/conv2d_486/Conv2D (30.36m/30.36m flops)\n",
      "  model_34/conv2d_484/Conv2D (29.65m/29.65m flops)\n",
      "  model_34/conv2d_485/Conv2D (28.48m/28.48m flops)\n",
      "  model_34/conv2d_483/Conv2D (27.70m/27.70m flops)\n",
      "  model_34/conv2d_481/Conv2D (25.66m/25.66m flops)\n",
      "  model_34/conv2d_482/Conv2D (12.65m/12.65m flops)\n",
      "  model_34/conv2d_488/Conv2D (10.42m/10.42m flops)\n",
      "  model_34/conv2d_479/Conv2D (9.50m/9.50m flops)\n",
      "  model_34/conv2d_477/Conv2D (9.44m/9.44m flops)\n",
      "  model_34/conv2d_480/Conv2D (8.85m/8.85m flops)\n",
      "  model_34/conv2d_478/Conv2D (4.28m/4.28m flops)\n",
      "  model_34/conv2d_476/Conv2D (4.19m/4.19m flops)\n",
      "  model_34/conv2d_489/Conv2D (4.06m/4.06m flops)\n",
      "  model_34/depthwise_conv2d_442/depthwise (2.36m/2.36m flops)\n",
      "  model_34/depthwise_conv2d_444/depthwise (1.07m/1.07m flops)\n",
      "  model_34/depthwise_conv2d_446/depthwise (995.33k/995.33k flops)\n",
      "  model_34/depthwise_conv2d_443/depthwise (663.55k/663.55k flops)\n",
      "  model_34/depthwise_conv2d_449/depthwise (585.22k/585.22k flops)\n",
      "  model_34/depthwise_conv2d_451/depthwise (562.18k/562.18k flops)\n",
      "  model_34/depthwise_conv2d_452/depthwise (559.87k/559.87k flops)\n",
      "  model_34/depthwise_conv2d_450/depthwise (525.31k/525.31k flops)\n",
      "  model_34/depthwise_conv2d_448/depthwise (490.75k/490.75k flops)\n",
      "  model_34/depthwise_conv2d_445/depthwise (368.64k/368.64k flops)\n",
      "  model_34/batch_normalization_920/FusedBatchNormV3 (295.13k/295.13k flops)\n",
      "  model_34/depthwise_conv2d_447/depthwise (267.26k/267.26k flops)\n",
      "  model_34/batch_normalization_919/FusedBatchNormV3 (262.34k/262.34k flops)\n",
      "  model_34/batch_normalization_918/FusedBatchNormV3 (262.34k/262.34k flops)\n",
      "  model_34/batch_normalization_924/FusedBatchNormV3 (164.32k/164.32k flops)\n",
      "  model_34/conv2d_477/BiasAdd (147.46k/147.46k flops)\n",
      "  model_34/depthwise_conv2d_453/depthwise (143.42k/143.42k flops)\n",
      "  model_34/conv2d_476/BiasAdd (131.07k/131.07k flops)\n",
      "  model_34/depthwise_conv2d_442/BiasAdd (131.07k/131.07k flops)\n",
      "  model_34/batch_normalization_928/FusedBatchNormV3 (120.18k/120.18k flops)\n",
      "  model_34/batch_normalization_922/FusedBatchNormV3 (119.13k/119.13k flops)\n",
      "  model_34/batch_normalization_923/FusedBatchNormV3 (119.13k/119.13k flops)\n",
      "  model_34/batch_normalization_926/FusedBatchNormV3 (111.89k/111.89k flops)\n",
      "  model_34/batch_normalization_927/FusedBatchNormV3 (111.89k/111.89k flops)\n",
      "  model_34/conv2d_479/BiasAdd (81.92k/81.92k flops)\n",
      "  model_34/batch_normalization_921/FusedBatchNormV3 (73.94k/73.94k flops)\n",
      "  model_34/batch_normalization_932/FusedBatchNormV3 (68.07k/68.07k flops)\n",
      "  model_34/batch_normalization_933/FusedBatchNormV3 (68.07k/68.07k flops)\n",
      "  model_34/batch_normalization_940/FusedBatchNormV3 (66.73k/66.73k flops)\n",
      "  model_34/batch_normalization_937/FusedBatchNormV3 (65.39k/65.39k flops)\n",
      "  model_34/batch_normalization_936/FusedBatchNormV3 (65.39k/65.39k flops)\n",
      "  model_34/batch_normalization_939/FusedBatchNormV3 (65.12k/65.12k flops)\n",
      "  model_34/batch_normalization_938/FusedBatchNormV3 (65.12k/65.12k flops)\n",
      "  model_34/batch_normalization_935/FusedBatchNormV3 (61.10k/61.10k flops)\n",
      "  model_34/batch_normalization_934/FusedBatchNormV3 (61.10k/61.10k flops)\n",
      "  model_34/depthwise_conv2d_444/BiasAdd (59.39k/59.39k flops)\n",
      "  model_34/conv2d_481/BiasAdd (59.39k/59.39k flops)\n",
      "  model_34/conv2d_478/BiasAdd (59.39k/59.39k flops)\n",
      "  model_34/batch_normalization_931/FusedBatchNormV3 (57.08k/57.08k flops)\n",
      "  model_34/batch_normalization_930/FusedBatchNormV3 (57.08k/57.08k flops)\n",
      "  model_34/depthwise_conv2d_446/BiasAdd (55.30k/55.30k flops)\n",
      "  model_34/conv2d_480/BiasAdd (55.30k/55.30k flops)\n",
      "  model_34/depthwise_conv2d_454/depthwise (47.09k/47.09k flops)\n",
      "  model_34/batch_normalization_925/FusedBatchNormV3 (41.44k/41.44k flops)\n",
      "  model_34/depthwise_conv2d_443/BiasAdd (36.86k/36.86k flops)\n",
      "  model_34/conv2d_483/BiasAdd (32.51k/32.51k flops)\n",
      "  model_34/depthwise_conv2d_449/BiasAdd (32.51k/32.51k flops)\n",
      "  model_34/conv2d_487/BiasAdd (31.87k/31.87k flops)\n",
      "  model_34/depthwise_conv2d_451/BiasAdd (31.23k/31.23k flops)\n",
      "  model_34/conv2d_485/BiasAdd (31.23k/31.23k flops)\n",
      "  model_34/depthwise_conv2d_452/BiasAdd (31.10k/31.10k flops)\n",
      "  model_34/conv2d_486/BiasAdd (31.10k/31.10k flops)\n",
      "  model_34/batch_normalization_929/FusedBatchNormV3 (31.09k/31.09k flops)\n",
      "  model_34/depthwise_conv2d_450/BiasAdd (29.18k/29.18k flops)\n",
      "  model_34/conv2d_484/BiasAdd (29.18k/29.18k flops)\n",
      "  model_34/conv2d_482/BiasAdd (27.26k/27.26k flops)\n",
      "  model_34/depthwise_conv2d_448/BiasAdd (27.26k/27.26k flops)\n",
      "  model_34/batch_normalization_942/FusedBatchNormV3 (24.85k/24.85k flops)\n",
      "  model_34/depthwise_conv2d_445/BiasAdd (20.48k/20.48k flops)\n",
      "  model_34/batch_normalization_941/FusedBatchNormV3 (18.92k/18.92k flops)\n",
      "  model_34/dense_34/MatMul (15.52k/15.52k flops)\n",
      "  model_34/depthwise_conv2d_447/BiasAdd (14.85k/14.85k flops)\n",
      "  model_34/batch_normalization_944/FusedBatchNormV3 (10.86k/10.86k flops)\n",
      "  model_34/conv2d_488/BiasAdd (10.46k/10.46k flops)\n",
      "  model_34/batch_normalization_943/FusedBatchNormV3 (9.16k/9.16k flops)\n",
      "  model_34/depthwise_conv2d_453/BiasAdd (7.97k/7.97k flops)\n",
      "  model_34/conv2d_489/BiasAdd (3.10k/3.10k flops)\n",
      "  model_34/global_average_pooling2d_34/Mean (3.10k/3.10k flops)\n",
      "  model_34/depthwise_conv2d_454/BiasAdd (2.62k/2.62k flops)\n",
      "  model_34/dense_34/Softmax (50/50 flops)\n",
      "  model_34/dense_34/BiasAdd (10/10 flops)\n",
      "\n",
      "======================End of Report==========================\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "16.797996\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-30 13:40:10.887036: I tensorflow/core/grappler/devices.cc:66] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0\n",
      "2022-04-30 13:40:10.887155: I tensorflow/core/grappler/clusters/single_machine.cc:357] Starting new session\n",
      "2022-04-30 13:40:10.891677: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:1137] Optimization results for grappler item: graph_to_optimize\n",
      "  function_optimizer: function_optimizer did nothing. time = 0.005ms.\n",
      "  function_optimizer: function_optimizer did nothing. time = 0ms.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=========================Options=============================\n",
      "-max_depth                  10000\n",
      "-min_bytes                  0\n",
      "-min_peak_bytes             0\n",
      "-min_residual_bytes         0\n",
      "-min_output_bytes           0\n",
      "-min_micros                 0\n",
      "-min_accelerator_micros     0\n",
      "-min_cpu_micros             0\n",
      "-min_params                 0\n",
      "-min_float_ops              1\n",
      "-min_occurrence             0\n",
      "-step                       -1\n",
      "-order_by                   float_ops\n",
      "-account_type_regexes       .*\n",
      "-start_name_regexes         .*\n",
      "-trim_name_regexes          \n",
      "-show_name_regexes          .*\n",
      "-hide_name_regexes          \n",
      "-account_displayed_op_only  true\n",
      "-select                     float_ops\n",
      "-output                     stdout:\n",
      "\n",
      "==================Model Analysis Report======================\n",
      "\n",
      "Doc:\n",
      "scope: The nodes in the model graph are organized by their names, which is hierarchical like filesystem.\n",
      "flops: Number of float operations. Note: Please read the implementation for the math behind it.\n",
      "\n",
      "Profile:\n",
      "node name | # float_ops\n",
      "_TFProfRoot (--/250.43m flops)\n",
      "  model_35/conv2d_495/Conv2D (28.03m/28.03m flops)\n",
      "  model_35/conv2d_493/Conv2D (27.87m/27.87m flops)\n",
      "  model_35/conv2d_500/Conv2D (23.87m/23.87m flops)\n",
      "  model_35/conv2d_501/Conv2D (23.87m/23.87m flops)\n",
      "  model_35/conv2d_499/Conv2D (23.74m/23.74m flops)\n",
      "  model_35/conv2d_498/Conv2D (17.90m/17.90m flops)\n",
      "  model_35/conv2d_497/Conv2D (17.43m/17.43m flops)\n",
      "  model_35/conv2d_494/Conv2D (14.97m/14.97m flops)\n",
      "  model_35/conv2d_502/Conv2D (13.81m/13.81m flops)\n",
      "  model_35/conv2d_491/Conv2D (12.58m/12.58m flops)\n",
      "  model_35/conv2d_496/Conv2D (11.00m/11.00m flops)\n",
      "  model_35/conv2d_492/Conv2D (10.62m/10.62m flops)\n",
      "  model_35/conv2d_503/Conv2D (6.63m/6.63m flops)\n",
      "  model_35/conv2d_490/Conv2D (4.19m/4.19m flops)\n",
      "  model_35/depthwise_conv2d_455/depthwise (2.36m/2.36m flops)\n",
      "  model_35/depthwise_conv2d_457/depthwise (1.99m/1.99m flops)\n",
      "  model_35/depthwise_conv2d_459/depthwise (1.07m/1.07m flops)\n",
      "  model_35/depthwise_conv2d_456/depthwise (884.74k/884.74k flops)\n",
      "  model_35/depthwise_conv2d_458/depthwise (580.61k/580.61k flops)\n",
      "  model_35/depthwise_conv2d_464/depthwise (571.39k/571.39k flops)\n",
      "  model_35/depthwise_conv2d_465/depthwise (433.15k/433.15k flops)\n",
      "  model_35/depthwise_conv2d_462/depthwise (430.85k/430.85k flops)\n",
      "  model_35/depthwise_conv2d_463/depthwise (430.85k/430.85k flops)\n",
      "  model_35/depthwise_conv2d_461/depthwise (419.33k/419.33k flops)\n",
      "  model_35/batch_normalization_947/FusedBatchNormV3 (393.50k/393.50k flops)\n",
      "  model_35/depthwise_conv2d_460/depthwise (271.87k/271.87k flops)\n",
      "  model_35/batch_normalization_946/FusedBatchNormV3 (262.34k/262.34k flops)\n",
      "  model_35/batch_normalization_945/FusedBatchNormV3 (262.34k/262.34k flops)\n",
      "  model_35/batch_normalization_951/FusedBatchNormV3 (258.80k/258.80k flops)\n",
      "  model_35/batch_normalization_949/FusedBatchNormV3 (221.83k/221.83k flops)\n",
      "  model_35/batch_normalization_950/FusedBatchNormV3 (221.83k/221.83k flops)\n",
      "  model_35/conv2d_491/BiasAdd (196.61k/196.61k flops)\n",
      "  model_35/depthwise_conv2d_466/depthwise (142.85k/142.85k flops)\n",
      "  model_35/conv2d_490/BiasAdd (131.07k/131.07k flops)\n",
      "  model_35/depthwise_conv2d_455/BiasAdd (131.07k/131.07k flops)\n",
      "  model_35/conv2d_493/BiasAdd (129.02k/129.02k flops)\n",
      "  model_35/batch_normalization_955/FusedBatchNormV3 (122.25k/122.25k flops)\n",
      "  model_35/batch_normalization_953/FusedBatchNormV3 (120.18k/120.18k flops)\n",
      "  model_35/batch_normalization_954/FusedBatchNormV3 (120.18k/120.18k flops)\n",
      "  model_35/conv2d_492/BiasAdd (110.59k/110.59k flops)\n",
      "  model_35/depthwise_conv2d_457/BiasAdd (110.59k/110.59k flops)\n",
      "  model_35/batch_normalization_948/FusedBatchNormV3 (98.59k/98.59k flops)\n",
      "  model_35/batch_normalization_964/FusedBatchNormV3 (66.46k/66.46k flops)\n",
      "  model_35/batch_normalization_963/FusedBatchNormV3 (66.46k/66.46k flops)\n",
      "  model_35/batch_normalization_967/FusedBatchNormV3 (66.46k/66.46k flops)\n",
      "  model_35/batch_normalization_952/FusedBatchNormV3 (65.27k/65.27k flops)\n",
      "  model_35/depthwise_conv2d_467/depthwise (62.64k/62.64k flops)\n",
      "  model_35/conv2d_495/BiasAdd (60.42k/60.42k flops)\n",
      "  model_35/depthwise_conv2d_459/BiasAdd (59.39k/59.39k flops)\n",
      "  model_35/conv2d_494/BiasAdd (59.39k/59.39k flops)\n",
      "  model_35/batch_normalization_966/FusedBatchNormV3 (50.38k/50.38k flops)\n",
      "  model_35/batch_normalization_965/FusedBatchNormV3 (50.38k/50.38k flops)\n",
      "  model_35/batch_normalization_962/FusedBatchNormV3 (50.12k/50.12k flops)\n",
      "  model_35/batch_normalization_959/FusedBatchNormV3 (50.12k/50.12k flops)\n",
      "  model_35/batch_normalization_960/FusedBatchNormV3 (50.12k/50.12k flops)\n",
      "  model_35/batch_normalization_961/FusedBatchNormV3 (50.12k/50.12k flops)\n",
      "  model_35/depthwise_conv2d_456/BiasAdd (49.15k/49.15k flops)\n",
      "  model_35/batch_normalization_958/FusedBatchNormV3 (48.78k/48.78k flops)\n",
      "  model_35/batch_normalization_957/FusedBatchNormV3 (48.78k/48.78k flops)\n",
      "  model_35/batch_normalization_969/FusedBatchNormV3 (33.06k/33.06k flops)\n",
      "  model_35/depthwise_conv2d_458/BiasAdd (32.26k/32.26k flops)\n",
      "  model_35/depthwise_conv2d_464/BiasAdd (31.74k/31.74k flops)\n",
      "  model_35/conv2d_501/BiasAdd (31.74k/31.74k flops)\n",
      "  model_35/conv2d_499/BiasAdd (31.74k/31.74k flops)\n",
      "  model_35/batch_normalization_956/FusedBatchNormV3 (31.62k/31.62k flops)\n",
      "  model_35/conv2d_500/BiasAdd (24.06k/24.06k flops)\n",
      "  model_35/depthwise_conv2d_465/BiasAdd (24.06k/24.06k flops)\n",
      "  model_35/depthwise_conv2d_463/BiasAdd (23.94k/23.94k flops)\n",
      "  model_35/depthwise_conv2d_462/BiasAdd (23.94k/23.94k flops)\n",
      "  model_35/conv2d_498/BiasAdd (23.94k/23.94k flops)\n",
      "  model_35/conv2d_497/BiasAdd (23.94k/23.94k flops)\n",
      "  model_35/depthwise_conv2d_461/BiasAdd (23.30k/23.30k flops)\n",
      "  model_35/conv2d_496/BiasAdd (23.30k/23.30k flops)\n",
      "  model_35/dense_35/MatMul (19.04k/19.04k flops)\n",
      "  model_35/batch_normalization_968/FusedBatchNormV3 (18.85k/18.85k flops)\n",
      "  model_35/depthwise_conv2d_460/BiasAdd (15.10k/15.10k flops)\n",
      "  model_35/conv2d_502/BiasAdd (13.92k/13.92k flops)\n",
      "  model_35/batch_normalization_971/FusedBatchNormV3 (13.33k/13.33k flops)\n",
      "  model_35/batch_normalization_970/FusedBatchNormV3 (12.18k/12.18k flops)\n",
      "  model_35/depthwise_conv2d_466/BiasAdd (7.94k/7.94k flops)\n",
      "  model_35/conv2d_503/BiasAdd (3.81k/3.81k flops)\n",
      "  model_35/global_average_pooling2d_35/Mean (3.81k/3.81k flops)\n",
      "  model_35/depthwise_conv2d_467/BiasAdd (3.48k/3.48k flops)\n",
      "  model_35/dense_35/Softmax (50/50 flops)\n",
      "  model_35/dense_35/BiasAdd (10/10 flops)\n",
      "\n",
      "======================End of Report==========================\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "14.648732\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-30 13:40:11.816044: I tensorflow/core/grappler/devices.cc:66] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0\n",
      "2022-04-30 13:40:11.816130: I tensorflow/core/grappler/clusters/single_machine.cc:357] Starting new session\n",
      "2022-04-30 13:40:11.820184: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:1137] Optimization results for grappler item: graph_to_optimize\n",
      "  function_optimizer: function_optimizer did nothing. time = 0.005ms.\n",
      "  function_optimizer: function_optimizer did nothing. time = 0.001ms.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=========================Options=============================\n",
      "-max_depth                  10000\n",
      "-min_bytes                  0\n",
      "-min_peak_bytes             0\n",
      "-min_residual_bytes         0\n",
      "-min_output_bytes           0\n",
      "-min_micros                 0\n",
      "-min_accelerator_micros     0\n",
      "-min_cpu_micros             0\n",
      "-min_params                 0\n",
      "-min_float_ops              1\n",
      "-min_occurrence             0\n",
      "-step                       -1\n",
      "-order_by                   float_ops\n",
      "-account_type_regexes       .*\n",
      "-start_name_regexes         .*\n",
      "-trim_name_regexes          \n",
      "-show_name_regexes          .*\n",
      "-hide_name_regexes          \n",
      "-account_displayed_op_only  true\n",
      "-select                     float_ops\n",
      "-output                     stdout:\n",
      "\n",
      "==================Model Analysis Report======================\n",
      "\n",
      "Doc:\n",
      "scope: The nodes in the model graph are organized by their names, which is hierarchical like filesystem.\n",
      "flops: Number of float operations. Note: Please read the implementation for the math behind it.\n",
      "\n",
      "Profile:\n",
      "node name | # float_ops\n",
      "_TFProfRoot (--/223.72m flops)\n",
      "  model_36/conv2d_513/Conv2D (31.35m/31.35m flops)\n",
      "  model_36/conv2d_514/Conv2D (30.11m/30.11m flops)\n",
      "  model_36/conv2d_515/Conv2D (25.01m/25.01m flops)\n",
      "  model_36/conv2d_512/Conv2D (24.74m/24.74m flops)\n",
      "  model_36/conv2d_509/Conv2D (22.88m/22.88m flops)\n",
      "  model_36/conv2d_511/Conv2D (18.38m/18.38m flops)\n",
      "  model_36/conv2d_505/Conv2D (12.06m/12.06m flops)\n",
      "  model_36/conv2d_510/Conv2D (10.97m/10.97m flops)\n",
      "  model_36/conv2d_507/Conv2D (9.27m/9.27m flops)\n",
      "  model_36/conv2d_508/Conv2D (7.83m/7.83m flops)\n",
      "  model_36/conv2d_516/Conv2D (6.33m/6.33m flops)\n",
      "  model_36/conv2d_506/Conv2D (5.46m/5.46m flops)\n",
      "  model_36/conv2d_504/Conv2D (4.19m/4.19m flops)\n",
      "  model_36/conv2d_517/Conv2D (2.88m/2.88m flops)\n",
      "  model_36/depthwise_conv2d_468/depthwise (2.36m/2.36m flops)\n",
      "  model_36/depthwise_conv2d_470/depthwise (1.07m/1.07m flops)\n",
      "  model_36/depthwise_conv2d_472/depthwise (903.17k/903.17k flops)\n",
      "  model_36/depthwise_conv2d_469/depthwise (847.87k/847.87k flops)\n",
      "  model_36/depthwise_conv2d_476/depthwise (582.91k/582.91k flops)\n",
      "  model_36/depthwise_conv2d_478/depthwise (559.87k/559.87k flops)\n",
      "  model_36/depthwise_conv2d_477/depthwise (557.57k/557.57k flops)\n",
      "  model_36/depthwise_conv2d_475/depthwise (440.06k/440.06k flops)\n",
      "  model_36/depthwise_conv2d_474/depthwise (433.15k/433.15k flops)\n",
      "  model_36/batch_normalization_974/FusedBatchNormV3 (377.11k/377.11k flops)\n",
      "  model_36/depthwise_conv2d_471/depthwise (359.42k/359.42k flops)\n",
      "  model_36/depthwise_conv2d_473/depthwise (262.66k/262.66k flops)\n",
      "  model_36/batch_normalization_973/FusedBatchNormV3 (262.34k/262.34k flops)\n",
      "  model_36/batch_normalization_972/FusedBatchNormV3 (262.34k/262.34k flops)\n",
      "  model_36/conv2d_505/BiasAdd (188.42k/188.42k flops)\n",
      "  model_36/batch_normalization_978/FusedBatchNormV3 (160.21k/160.21k flops)\n",
      "  model_36/conv2d_504/BiasAdd (131.07k/131.07k flops)\n",
      "  model_36/depthwise_conv2d_468/BiasAdd (131.07k/131.07k flops)\n",
      "  model_36/batch_normalization_976/FusedBatchNormV3 (119.13k/119.13k flops)\n",
      "  model_36/batch_normalization_977/FusedBatchNormV3 (119.13k/119.13k flops)\n",
      "  model_36/batch_normalization_982/FusedBatchNormV3 (118.10k/118.10k flops)\n",
      "  model_36/depthwise_conv2d_479/depthwise (115.78k/115.78k flops)\n",
      "  model_36/batch_normalization_981/FusedBatchNormV3 (101.53k/101.53k flops)\n",
      "  model_36/batch_normalization_980/FusedBatchNormV3 (101.53k/101.53k flops)\n",
      "  model_36/batch_normalization_975/FusedBatchNormV3 (94.48k/94.48k flops)\n",
      "  model_36/conv2d_507/BiasAdd (79.87k/79.87k flops)\n",
      "  model_36/batch_normalization_989/FusedBatchNormV3 (67.80k/67.80k flops)\n",
      "  model_36/batch_normalization_988/FusedBatchNormV3 (67.80k/67.80k flops)\n",
      "  model_36/batch_normalization_993/FusedBatchNormV3 (65.12k/65.12k flops)\n",
      "  model_36/batch_normalization_992/FusedBatchNormV3 (65.12k/65.12k flops)\n",
      "  model_36/batch_normalization_991/FusedBatchNormV3 (64.86k/64.86k flops)\n",
      "  model_36/batch_normalization_990/FusedBatchNormV3 (64.86k/64.86k flops)\n",
      "  model_36/depthwise_conv2d_470/BiasAdd (59.39k/59.39k flops)\n",
      "  model_36/conv2d_506/BiasAdd (59.39k/59.39k flops)\n",
      "  model_36/conv2d_509/BiasAdd (58.37k/58.37k flops)\n",
      "  model_36/batch_normalization_994/FusedBatchNormV3 (53.87k/53.87k flops)\n",
      "  model_36/batch_normalization_986/FusedBatchNormV3 (51.19k/51.19k flops)\n",
      "  model_36/batch_normalization_987/FusedBatchNormV3 (51.19k/51.19k flops)\n",
      "  model_36/batch_normalization_985/FusedBatchNormV3 (50.38k/50.38k flops)\n",
      "  model_36/batch_normalization_984/FusedBatchNormV3 (50.38k/50.38k flops)\n",
      "  model_36/conv2d_508/BiasAdd (50.18k/50.18k flops)\n",
      "  model_36/depthwise_conv2d_472/BiasAdd (50.18k/50.18k flops)\n",
      "  model_36/depthwise_conv2d_469/BiasAdd (47.10k/47.10k flops)\n",
      "  model_36/batch_normalization_979/FusedBatchNormV3 (40.40k/40.40k flops)\n",
      "  model_36/depthwise_conv2d_480/depthwise (35.42k/35.42k flops)\n",
      "  model_36/depthwise_conv2d_476/BiasAdd (32.38k/32.38k flops)\n",
      "  model_36/conv2d_512/BiasAdd (32.38k/32.38k flops)\n",
      "  model_36/depthwise_conv2d_478/BiasAdd (31.10k/31.10k flops)\n",
      "  model_36/conv2d_514/BiasAdd (31.10k/31.10k flops)\n",
      "  model_36/depthwise_conv2d_477/BiasAdd (30.98k/30.98k flops)\n",
      "  model_36/conv2d_513/BiasAdd (30.98k/30.98k flops)\n",
      "  model_36/batch_normalization_983/FusedBatchNormV3 (30.55k/30.55k flops)\n",
      "  model_36/conv2d_515/BiasAdd (25.73k/25.73k flops)\n",
      "  model_36/conv2d_511/BiasAdd (24.45k/24.45k flops)\n",
      "  model_36/depthwise_conv2d_475/BiasAdd (24.45k/24.45k flops)\n",
      "  model_36/conv2d_510/BiasAdd (24.06k/24.06k flops)\n",
      "  model_36/depthwise_conv2d_474/BiasAdd (24.06k/24.06k flops)\n",
      "  model_36/depthwise_conv2d_471/BiasAdd (19.97k/19.97k flops)\n",
      "  model_36/batch_normalization_996/FusedBatchNormV3 (18.70k/18.70k flops)\n",
      "  model_36/batch_normalization_995/FusedBatchNormV3 (15.28k/15.28k flops)\n",
      "  model_36/dense_36/MatMul (14.64k/14.64k flops)\n",
      "  model_36/depthwise_conv2d_473/BiasAdd (14.59k/14.59k flops)\n",
      "  model_36/batch_normalization_998/FusedBatchNormV3 (10.25k/10.25k flops)\n",
      "  model_36/conv2d_516/BiasAdd (7.87k/7.87k flops)\n",
      "  model_36/batch_normalization_997/FusedBatchNormV3 (6.89k/6.89k flops)\n",
      "  model_36/depthwise_conv2d_479/BiasAdd (6.43k/6.43k flops)\n",
      "  model_36/conv2d_517/BiasAdd (2.93k/2.93k flops)\n",
      "  model_36/global_average_pooling2d_36/Mean (2.93k/2.93k flops)\n",
      "  model_36/depthwise_conv2d_480/BiasAdd (1.97k/1.97k flops)\n",
      "  model_36/dense_36/Softmax (50/50 flops)\n",
      "  model_36/dense_36/BiasAdd (10/10 flops)\n",
      "\n",
      "======================End of Report==========================\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "16.847524\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-30 13:40:12.825480: I tensorflow/core/grappler/devices.cc:66] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0\n",
      "2022-04-30 13:40:12.825608: I tensorflow/core/grappler/clusters/single_machine.cc:357] Starting new session\n",
      "2022-04-30 13:40:12.830187: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:1137] Optimization results for grappler item: graph_to_optimize\n",
      "  function_optimizer: function_optimizer did nothing. time = 0.006ms.\n",
      "  function_optimizer: function_optimizer did nothing. time = 0.001ms.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=========================Options=============================\n",
      "-max_depth                  10000\n",
      "-min_bytes                  0\n",
      "-min_peak_bytes             0\n",
      "-min_residual_bytes         0\n",
      "-min_output_bytes           0\n",
      "-min_micros                 0\n",
      "-min_accelerator_micros     0\n",
      "-min_cpu_micros             0\n",
      "-min_params                 0\n",
      "-min_float_ops              1\n",
      "-min_occurrence             0\n",
      "-step                       -1\n",
      "-order_by                   float_ops\n",
      "-account_type_regexes       .*\n",
      "-start_name_regexes         .*\n",
      "-trim_name_regexes          \n",
      "-show_name_regexes          .*\n",
      "-hide_name_regexes          \n",
      "-account_displayed_op_only  true\n",
      "-select                     float_ops\n",
      "-output                     stdout:\n",
      "\n",
      "==================Model Analysis Report======================\n",
      "\n",
      "Doc:\n",
      "scope: The nodes in the model graph are organized by their names, which is hierarchical like filesystem.\n",
      "flops: Number of float operations. Note: Please read the implementation for the math behind it.\n",
      "\n",
      "Profile:\n",
      "node name | # float_ops\n",
      "_TFProfRoot (--/276.45m flops)\n",
      "  model_37/conv2d_527/Conv2D (32.90m/32.90m flops)\n",
      "  model_37/conv2d_528/Conv2D (32.90m/32.90m flops)\n",
      "  model_37/conv2d_526/Conv2D (32.25m/32.25m flops)\n",
      "  model_37/conv2d_529/Conv2D (31.47m/31.47m flops)\n",
      "  model_37/conv2d_525/Conv2D (30.73m/30.73m flops)\n",
      "  model_37/conv2d_521/Conv2D (22.53m/22.53m flops)\n",
      "  model_37/conv2d_519/Conv2D (14.68m/14.68m flops)\n",
      "  model_37/conv2d_523/Conv2D (13.84m/13.84m flops)\n",
      "  model_37/conv2d_524/Conv2D (12.89m/12.89m flops)\n",
      "  model_37/conv2d_520/Conv2D (11.47m/11.47m flops)\n",
      "  model_37/conv2d_530/Conv2D (10.28m/10.28m flops)\n",
      "  model_37/conv2d_522/Conv2D (7.32m/7.32m flops)\n",
      "  model_37/conv2d_531/Conv2D (5.05m/5.05m flops)\n",
      "  model_37/conv2d_518/Conv2D (4.19m/4.19m flops)\n",
      "  model_37/depthwise_conv2d_481/depthwise (2.36m/2.36m flops)\n",
      "  model_37/depthwise_conv2d_483/depthwise (1.84m/1.84m flops)\n",
      "  model_37/depthwise_conv2d_482/depthwise (1.03m/1.03m flops)\n",
      "  model_37/depthwise_conv2d_485/depthwise (599.04k/599.04k flops)\n",
      "  model_37/depthwise_conv2d_489/depthwise (585.22k/585.22k flops)\n",
      "  model_37/depthwise_conv2d_491/depthwise (585.22k/585.22k flops)\n",
      "  model_37/depthwise_conv2d_490/depthwise (582.91k/582.91k flops)\n",
      "  model_37/depthwise_conv2d_488/depthwise (571.39k/571.39k flops)\n",
      "  model_37/depthwise_conv2d_487/depthwise (557.57k/557.57k flops)\n",
      "  model_37/depthwise_conv2d_484/depthwise (506.88k/506.88k flops)\n",
      "  model_37/batch_normalization_1001/FusedBatchNormV3 (459.09k/459.09k flops)\n",
      "  model_37/batch_normalization_999/FusedBatchNormV3 (262.34k/262.34k flops)\n",
      "  model_37/batch_normalization_1000/FusedBatchNormV3 (262.34k/262.34k flops)\n",
      "  model_37/depthwise_conv2d_486/depthwise (239.62k/239.62k flops)\n",
      "  model_37/conv2d_519/BiasAdd (229.38k/229.38k flops)\n",
      "  model_37/batch_normalization_1005/FusedBatchNormV3 (225.94k/225.94k flops)\n",
      "  model_37/batch_normalization_1003/FusedBatchNormV3 (205.40k/205.40k flops)\n",
      "  model_37/batch_normalization_1004/FusedBatchNormV3 (205.40k/205.40k flops)\n",
      "  model_37/depthwise_conv2d_492/depthwise (139.39k/139.39k flops)\n",
      "  model_37/depthwise_conv2d_481/BiasAdd (131.07k/131.07k flops)\n",
      "  model_37/conv2d_518/BiasAdd (131.07k/131.07k flops)\n",
      "  model_37/batch_normalization_1002/FusedBatchNormV3 (115.02k/115.02k flops)\n",
      "  model_37/conv2d_521/BiasAdd (112.64k/112.64k flops)\n",
      "  model_37/batch_normalization_1009/FusedBatchNormV3 (107.74k/107.74k flops)\n",
      "  model_37/conv2d_520/BiasAdd (102.40k/102.40k flops)\n",
      "  model_37/depthwise_conv2d_483/BiasAdd (102.40k/102.40k flops)\n",
      "  model_37/batch_normalization_1016/FusedBatchNormV3 (68.07k/68.07k flops)\n",
      "  model_37/batch_normalization_1015/FusedBatchNormV3 (68.07k/68.07k flops)\n",
      "  model_37/batch_normalization_1019/FusedBatchNormV3 (68.07k/68.07k flops)\n",
      "  model_37/batch_normalization_1020/FusedBatchNormV3 (68.07k/68.07k flops)\n",
      "  model_37/batch_normalization_1017/FusedBatchNormV3 (67.80k/67.80k flops)\n",
      "  model_37/batch_normalization_1018/FusedBatchNormV3 (67.80k/67.80k flops)\n",
      "  model_37/batch_normalization_1007/FusedBatchNormV3 (67.34k/67.34k flops)\n",
      "  model_37/batch_normalization_1008/FusedBatchNormV3 (67.34k/67.34k flops)\n",
      "  model_37/batch_normalization_1014/FusedBatchNormV3 (66.46k/66.46k flops)\n",
      "  model_37/batch_normalization_1013/FusedBatchNormV3 (66.46k/66.46k flops)\n",
      "  model_37/batch_normalization_1021/FusedBatchNormV3 (64.86k/64.86k flops)\n",
      "  model_37/batch_normalization_1012/FusedBatchNormV3 (64.86k/64.86k flops)\n",
      "  model_37/batch_normalization_1011/FusedBatchNormV3 (64.86k/64.86k flops)\n",
      "  model_37/depthwise_conv2d_482/BiasAdd (57.34k/57.34k flops)\n",
      "  model_37/batch_normalization_1006/FusedBatchNormV3 (56.98k/56.98k flops)\n",
      "  model_37/conv2d_523/BiasAdd (53.25k/53.25k flops)\n",
      "  model_37/depthwise_conv2d_493/depthwise (47.81k/47.81k flops)\n",
      "  model_37/depthwise_conv2d_485/BiasAdd (33.28k/33.28k flops)\n",
      "  model_37/conv2d_522/BiasAdd (33.28k/33.28k flops)\n",
      "  model_37/depthwise_conv2d_489/BiasAdd (32.51k/32.51k flops)\n",
      "  model_37/depthwise_conv2d_491/BiasAdd (32.51k/32.51k flops)\n",
      "  model_37/conv2d_528/BiasAdd (32.51k/32.51k flops)\n",
      "  model_37/conv2d_526/BiasAdd (32.51k/32.51k flops)\n",
      "  model_37/conv2d_527/BiasAdd (32.38k/32.38k flops)\n",
      "  model_37/depthwise_conv2d_490/BiasAdd (32.38k/32.38k flops)\n",
      "  model_37/conv2d_525/BiasAdd (31.74k/31.74k flops)\n",
      "  model_37/depthwise_conv2d_488/BiasAdd (31.74k/31.74k flops)\n",
      "  model_37/conv2d_529/BiasAdd (30.98k/30.98k flops)\n",
      "  model_37/depthwise_conv2d_487/BiasAdd (30.98k/30.98k flops)\n",
      "  model_37/conv2d_524/BiasAdd (30.98k/30.98k flops)\n",
      "  model_37/depthwise_conv2d_484/BiasAdd (28.16k/28.16k flops)\n",
      "  model_37/batch_normalization_1010/FusedBatchNormV3 (27.87k/27.87k flops)\n",
      "  model_37/batch_normalization_1023/FusedBatchNormV3 (25.23k/25.23k flops)\n",
      "  model_37/dense_37/MatMul (19.00k/19.00k flops)\n",
      "  model_37/batch_normalization_1022/FusedBatchNormV3 (18.39k/18.39k flops)\n",
      "  model_37/depthwise_conv2d_486/BiasAdd (13.31k/13.31k flops)\n",
      "  model_37/batch_normalization_1025/FusedBatchNormV3 (13.30k/13.30k flops)\n",
      "  model_37/conv2d_530/BiasAdd (10.62k/10.62k flops)\n",
      "  model_37/batch_normalization_1024/FusedBatchNormV3 (9.30k/9.30k flops)\n",
      "  model_37/depthwise_conv2d_492/BiasAdd (7.74k/7.74k flops)\n",
      "  model_37/global_average_pooling2d_37/Mean (3.80k/3.80k flops)\n",
      "  model_37/conv2d_531/BiasAdd (3.80k/3.80k flops)\n",
      "  model_37/depthwise_conv2d_493/BiasAdd (2.66k/2.66k flops)\n",
      "  model_37/dense_37/Softmax (50/50 flops)\n",
      "  model_37/dense_37/BiasAdd (10/10 flops)\n",
      "\n",
      "======================End of Report==========================\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "16.711956\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-30 13:40:13.762486: I tensorflow/core/grappler/devices.cc:66] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0\n",
      "2022-04-30 13:40:13.762603: I tensorflow/core/grappler/clusters/single_machine.cc:357] Starting new session\n",
      "2022-04-30 13:40:13.766680: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:1137] Optimization results for grappler item: graph_to_optimize\n",
      "  function_optimizer: function_optimizer did nothing. time = 0.005ms.\n",
      "  function_optimizer: function_optimizer did nothing. time = 0ms.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=========================Options=============================\n",
      "-max_depth                  10000\n",
      "-min_bytes                  0\n",
      "-min_peak_bytes             0\n",
      "-min_residual_bytes         0\n",
      "-min_output_bytes           0\n",
      "-min_micros                 0\n",
      "-min_accelerator_micros     0\n",
      "-min_cpu_micros             0\n",
      "-min_params                 0\n",
      "-min_float_ops              1\n",
      "-min_occurrence             0\n",
      "-step                       -1\n",
      "-order_by                   float_ops\n",
      "-account_type_regexes       .*\n",
      "-start_name_regexes         .*\n",
      "-trim_name_regexes          \n",
      "-show_name_regexes          .*\n",
      "-hide_name_regexes          \n",
      "-account_displayed_op_only  true\n",
      "-select                     float_ops\n",
      "-output                     stdout:\n",
      "\n",
      "==================Model Analysis Report======================\n",
      "\n",
      "Doc:\n",
      "scope: The nodes in the model graph are organized by their names, which is hierarchical like filesystem.\n",
      "flops: Number of float operations. Note: Please read the implementation for the math behind it.\n",
      "\n",
      "Profile:\n",
      "node name | # float_ops\n",
      "_TFProfRoot (--/272.24m flops)\n",
      "  model_38/conv2d_541/Conv2D (31.73m/31.73m flops)\n",
      "  model_38/conv2d_542/Conv2D (31.34m/31.34m flops)\n",
      "  model_38/conv2d_543/Conv2D (30.48m/30.48m flops)\n",
      "  model_38/conv2d_540/Conv2D (30.11m/30.11m flops)\n",
      "  model_38/conv2d_539/Conv2D (29.00m/29.00m flops)\n",
      "  model_38/conv2d_537/Conv2D (21.50m/21.50m flops)\n",
      "  model_38/conv2d_533/Conv2D (16.25m/16.25m flops)\n",
      "  model_38/conv2d_535/Conv2D (13.77m/13.77m flops)\n",
      "  model_38/conv2d_538/Conv2D (12.63m/12.63m flops)\n",
      "  model_38/conv2d_544/Conv2D (12.58m/12.58m flops)\n",
      "  model_38/conv2d_534/Conv2D (10.41m/10.41m flops)\n",
      "  model_38/conv2d_536/Conv2D (8.40m/8.40m flops)\n",
      "  model_38/conv2d_545/Conv2D (6.02m/6.02m flops)\n",
      "  model_38/conv2d_532/Conv2D (4.19m/4.19m flops)\n",
      "  model_38/depthwise_conv2d_494/depthwise (2.36m/2.36m flops)\n",
      "  model_38/depthwise_conv2d_496/depthwise (1.51m/1.51m flops)\n",
      "  model_38/depthwise_conv2d_495/depthwise (1.14m/1.14m flops)\n",
      "  model_38/depthwise_conv2d_498/depthwise (921.60k/921.60k flops)\n",
      "  model_38/depthwise_conv2d_503/depthwise (585.22k/585.22k flops)\n",
      "  model_38/depthwise_conv2d_502/depthwise (562.18k/562.18k flops)\n",
      "  model_38/depthwise_conv2d_501/depthwise (555.26k/555.26k flops)\n",
      "  model_38/depthwise_conv2d_504/depthwise (555.26k/555.26k flops)\n",
      "  model_38/depthwise_conv2d_500/depthwise (541.44k/541.44k flops)\n",
      "  model_38/batch_normalization_1028/FusedBatchNormV3 (508.28k/508.28k flops)\n",
      "  model_38/depthwise_conv2d_497/depthwise (377.86k/377.86k flops)\n",
      "  model_38/batch_normalization_1027/FusedBatchNormV3 (262.34k/262.34k flops)\n",
      "  model_38/batch_normalization_1026/FusedBatchNormV3 (262.34k/262.34k flops)\n",
      "  model_38/conv2d_533/BiasAdd (253.95k/253.95k flops)\n",
      "  model_38/depthwise_conv2d_499/depthwise (241.92k/241.92k flops)\n",
      "  model_38/batch_normalization_1030/FusedBatchNormV3 (168.43k/168.43k flops)\n",
      "  model_38/batch_normalization_1032/FusedBatchNormV3 (168.43k/168.43k flops)\n",
      "  model_38/batch_normalization_1031/FusedBatchNormV3 (168.43k/168.43k flops)\n",
      "  model_38/depthwise_conv2d_505/depthwise (142.27k/142.27k flops)\n",
      "  model_38/conv2d_532/BiasAdd (131.07k/131.07k flops)\n",
      "  model_38/depthwise_conv2d_494/BiasAdd (131.07k/131.07k flops)\n",
      "  model_38/batch_normalization_1029/FusedBatchNormV3 (127.35k/127.35k flops)\n",
      "  model_38/batch_normalization_1036/FusedBatchNormV3 (108.78k/108.78k flops)\n",
      "  model_38/batch_normalization_1035/FusedBatchNormV3 (103.60k/103.60k flops)\n",
      "  model_38/batch_normalization_1034/FusedBatchNormV3 (103.60k/103.60k flops)\n",
      "  model_38/depthwise_conv2d_496/BiasAdd (83.97k/83.97k flops)\n",
      "  model_38/conv2d_534/BiasAdd (83.97k/83.97k flops)\n",
      "  model_38/conv2d_535/BiasAdd (83.97k/83.97k flops)\n",
      "  model_38/batch_normalization_1045/FusedBatchNormV3 (68.07k/68.07k flops)\n",
      "  model_38/batch_normalization_1044/FusedBatchNormV3 (68.07k/68.07k flops)\n",
      "  model_38/batch_normalization_1048/FusedBatchNormV3 (66.20k/66.20k flops)\n",
      "  model_38/batch_normalization_1043/FusedBatchNormV3 (65.39k/65.39k flops)\n",
      "  model_38/batch_normalization_1042/FusedBatchNormV3 (65.39k/65.39k flops)\n",
      "  model_38/batch_normalization_1046/FusedBatchNormV3 (64.59k/64.59k flops)\n",
      "  model_38/batch_normalization_1041/FusedBatchNormV3 (64.59k/64.59k flops)\n",
      "  model_38/batch_normalization_1047/FusedBatchNormV3 (64.59k/64.59k flops)\n",
      "  model_38/batch_normalization_1040/FusedBatchNormV3 (64.59k/64.59k flops)\n",
      "  model_38/depthwise_conv2d_495/BiasAdd (63.49k/63.49k flops)\n",
      "  model_38/batch_normalization_1039/FusedBatchNormV3 (62.98k/62.98k flops)\n",
      "  model_38/batch_normalization_1038/FusedBatchNormV3 (62.98k/62.98k flops)\n",
      "  model_38/depthwise_conv2d_506/depthwise (57.31k/57.31k flops)\n",
      "  model_38/conv2d_537/BiasAdd (53.76k/53.76k flops)\n",
      "  model_38/depthwise_conv2d_498/BiasAdd (51.20k/51.20k flops)\n",
      "  model_38/conv2d_536/BiasAdd (51.20k/51.20k flops)\n",
      "  model_38/batch_normalization_1033/FusedBatchNormV3 (42.48k/42.48k flops)\n",
      "  model_38/depthwise_conv2d_503/BiasAdd (32.51k/32.51k flops)\n",
      "  model_38/conv2d_541/BiasAdd (32.51k/32.51k flops)\n",
      "  model_38/conv2d_543/BiasAdd (31.62k/31.62k flops)\n",
      "  model_38/conv2d_540/BiasAdd (31.23k/31.23k flops)\n",
      "  model_38/depthwise_conv2d_502/BiasAdd (31.23k/31.23k flops)\n",
      "  model_38/depthwise_conv2d_504/BiasAdd (30.85k/30.85k flops)\n",
      "  model_38/conv2d_542/BiasAdd (30.85k/30.85k flops)\n",
      "  model_38/conv2d_539/BiasAdd (30.85k/30.85k flops)\n",
      "  model_38/depthwise_conv2d_501/BiasAdd (30.85k/30.85k flops)\n",
      "  model_38/batch_normalization_1050/FusedBatchNormV3 (30.25k/30.25k flops)\n",
      "  model_38/depthwise_conv2d_500/BiasAdd (30.08k/30.08k flops)\n",
      "  model_38/conv2d_538/BiasAdd (30.08k/30.08k flops)\n",
      "  model_38/batch_normalization_1037/FusedBatchNormV3 (28.14k/28.14k flops)\n",
      "  model_38/depthwise_conv2d_497/BiasAdd (20.99k/20.99k flops)\n",
      "  model_38/dense_38/MatMul (18.92k/18.92k flops)\n",
      "  model_38/batch_normalization_1049/FusedBatchNormV3 (18.77k/18.77k flops)\n",
      "  model_38/depthwise_conv2d_499/BiasAdd (13.44k/13.44k flops)\n",
      "  model_38/batch_normalization_1052/FusedBatchNormV3 (13.24k/13.24k flops)\n",
      "  model_38/conv2d_544/BiasAdd (12.74k/12.74k flops)\n",
      "  model_38/batch_normalization_1051/FusedBatchNormV3 (11.14k/11.14k flops)\n",
      "  model_38/depthwise_conv2d_505/BiasAdd (7.90k/7.90k flops)\n",
      "  model_38/global_average_pooling2d_38/Mean (3.78k/3.78k flops)\n",
      "  model_38/conv2d_545/BiasAdd (3.78k/3.78k flops)\n",
      "  model_38/depthwise_conv2d_506/BiasAdd (3.18k/3.18k flops)\n",
      "  model_38/dense_38/Softmax (50/50 flops)\n",
      "  model_38/dense_38/BiasAdd (10/10 flops)\n",
      "\n",
      "======================End of Report==========================\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "13.886956\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-30 13:40:14.690181: I tensorflow/core/grappler/devices.cc:66] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0\n",
      "2022-04-30 13:40:14.690297: I tensorflow/core/grappler/clusters/single_machine.cc:357] Starting new session\n",
      "2022-04-30 13:40:14.694295: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:1137] Optimization results for grappler item: graph_to_optimize\n",
      "  function_optimizer: function_optimizer did nothing. time = 0.005ms.\n",
      "  function_optimizer: function_optimizer did nothing. time = 0.001ms.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=========================Options=============================\n",
      "-max_depth                  10000\n",
      "-min_bytes                  0\n",
      "-min_peak_bytes             0\n",
      "-min_residual_bytes         0\n",
      "-min_output_bytes           0\n",
      "-min_micros                 0\n",
      "-min_accelerator_micros     0\n",
      "-min_cpu_micros             0\n",
      "-min_params                 0\n",
      "-min_float_ops              1\n",
      "-min_occurrence             0\n",
      "-step                       -1\n",
      "-order_by                   float_ops\n",
      "-account_type_regexes       .*\n",
      "-start_name_regexes         .*\n",
      "-trim_name_regexes          \n",
      "-show_name_regexes          .*\n",
      "-hide_name_regexes          \n",
      "-account_displayed_op_only  true\n",
      "-select                     float_ops\n",
      "-output                     stdout:\n",
      "\n",
      "==================Model Analysis Report======================\n",
      "\n",
      "Doc:\n",
      "scope: The nodes in the model graph are organized by their names, which is hierarchical like filesystem.\n",
      "flops: Number of float operations. Note: Please read the implementation for the math behind it.\n",
      "\n",
      "Profile:\n",
      "node name | # float_ops\n",
      "_TFProfRoot (--/217.05m flops)\n",
      "  model_39/conv2d_554/Conv2D (28.35m/28.35m flops)\n",
      "  model_39/conv2d_556/Conv2D (26.03m/26.03m flops)\n",
      "  model_39/conv2d_553/Conv2D (25.62m/25.62m flops)\n",
      "  model_39/conv2d_555/Conv2D (25.45m/25.45m flops)\n",
      "  model_39/conv2d_557/Conv2D (23.41m/23.41m flops)\n",
      "  model_39/conv2d_549/Conv2D (14.22m/14.22m flops)\n",
      "  model_39/conv2d_558/Conv2D (12.20m/12.20m flops)\n",
      "  model_39/conv2d_551/Conv2D (10.29m/10.29m flops)\n",
      "  model_39/conv2d_547/Conv2D (8.39m/8.39m flops)\n",
      "  model_39/conv2d_552/Conv2D (8.17m/8.17m flops)\n",
      "  model_39/conv2d_550/Conv2D (7.87m/7.87m flops)\n",
      "  model_39/conv2d_559/Conv2D (7.56m/7.56m flops)\n",
      "  model_39/conv2d_546/Conv2D (4.19m/4.19m flops)\n",
      "  model_39/conv2d_548/Conv2D (3.67m/3.67m flops)\n",
      "  model_39/depthwise_conv2d_507/depthwise (2.36m/2.36m flops)\n",
      "  model_39/depthwise_conv2d_509/depthwise (1.03m/1.03m flops)\n",
      "  model_39/depthwise_conv2d_508/depthwise (589.82k/589.82k flops)\n",
      "  model_39/depthwise_conv2d_514/depthwise (585.22k/585.22k flops)\n",
      "  model_39/depthwise_conv2d_510/depthwise (571.39k/571.39k flops)\n",
      "  model_39/depthwise_conv2d_511/depthwise (571.39k/571.39k flops)\n",
      "  model_39/depthwise_conv2d_516/depthwise (525.31k/525.31k flops)\n",
      "  model_39/depthwise_conv2d_517/depthwise (513.79k/513.79k flops)\n",
      "  model_39/depthwise_conv2d_515/depthwise (502.27k/502.27k flops)\n",
      "  model_39/depthwise_conv2d_513/depthwise (453.89k/453.89k flops)\n",
      "  model_39/batch_normalization_1054/FusedBatchNormV3 (262.34k/262.34k flops)\n",
      "  model_39/batch_normalization_1055/FusedBatchNormV3 (262.34k/262.34k flops)\n",
      "  model_39/batch_normalization_1053/FusedBatchNormV3 (262.34k/262.34k flops)\n",
      "  model_39/batch_normalization_1059/FusedBatchNormV3 (254.70k/254.70k flops)\n",
      "  model_39/depthwise_conv2d_512/depthwise (186.62k/186.62k flops)\n",
      "  model_39/conv2d_546/BiasAdd (131.07k/131.07k flops)\n",
      "  model_39/conv2d_547/BiasAdd (131.07k/131.07k flops)\n",
      "  model_39/depthwise_conv2d_507/BiasAdd (131.07k/131.07k flops)\n",
      "  model_39/conv2d_549/BiasAdd (126.98k/126.98k flops)\n",
      "  model_39/depthwise_conv2d_518/depthwise (118.08k/118.08k flops)\n",
      "  model_39/batch_normalization_1057/FusedBatchNormV3 (115.02k/115.02k flops)\n",
      "  model_39/batch_normalization_1058/FusedBatchNormV3 (115.02k/115.02k flops)\n",
      "  model_39/batch_normalization_1063/FusedBatchNormV3 (83.92k/83.92k flops)\n",
      "  model_39/batch_normalization_1067/FusedBatchNormV3 (68.07k/68.07k flops)\n",
      "  model_39/batch_normalization_1068/FusedBatchNormV3 (68.07k/68.07k flops)\n",
      "  model_39/depthwise_conv2d_519/depthwise (66.96k/66.96k flops)\n",
      "  model_39/batch_normalization_1056/FusedBatchNormV3 (65.73k/65.73k flops)\n",
      "  model_39/batch_normalization_1062/FusedBatchNormV3 (64.23k/64.23k flops)\n",
      "  model_39/batch_normalization_1061/FusedBatchNormV3 (64.23k/64.23k flops)\n",
      "  model_39/batch_normalization_1060/FusedBatchNormV3 (64.23k/64.23k flops)\n",
      "  model_39/batch_normalization_1071/FusedBatchNormV3 (61.10k/61.10k flops)\n",
      "  model_39/batch_normalization_1072/FusedBatchNormV3 (61.10k/61.10k flops)\n",
      "  model_39/batch_normalization_1074/FusedBatchNormV3 (59.76k/59.76k flops)\n",
      "  model_39/batch_normalization_1073/FusedBatchNormV3 (59.76k/59.76k flops)\n",
      "  model_39/batch_normalization_1070/FusedBatchNormV3 (58.42k/58.42k flops)\n",
      "  model_39/batch_normalization_1069/FusedBatchNormV3 (58.42k/58.42k flops)\n",
      "  model_39/depthwise_conv2d_509/BiasAdd (57.34k/57.34k flops)\n",
      "  model_39/conv2d_548/BiasAdd (57.34k/57.34k flops)\n",
      "  model_39/batch_normalization_1075/FusedBatchNormV3 (54.94k/54.94k flops)\n",
      "  model_39/batch_normalization_1066/FusedBatchNormV3 (52.80k/52.80k flops)\n",
      "  model_39/batch_normalization_1065/FusedBatchNormV3 (52.80k/52.80k flops)\n",
      "  model_39/conv2d_551/BiasAdd (41.47k/41.47k flops)\n",
      "  model_39/batch_normalization_1077/FusedBatchNormV3 (35.34k/35.34k flops)\n",
      "  model_39/depthwise_conv2d_508/BiasAdd (32.77k/32.77k flops)\n",
      "  model_39/conv2d_553/BiasAdd (32.51k/32.51k flops)\n",
      "  model_39/depthwise_conv2d_514/BiasAdd (32.51k/32.51k flops)\n",
      "  model_39/depthwise_conv2d_511/BiasAdd (31.74k/31.74k flops)\n",
      "  model_39/depthwise_conv2d_510/BiasAdd (31.74k/31.74k flops)\n",
      "  model_39/conv2d_550/BiasAdd (31.74k/31.74k flops)\n",
      "  model_39/depthwise_conv2d_516/BiasAdd (29.18k/29.18k flops)\n",
      "  model_39/conv2d_555/BiasAdd (29.18k/29.18k flops)\n",
      "  model_39/depthwise_conv2d_517/BiasAdd (28.54k/28.54k flops)\n",
      "  model_39/conv2d_556/BiasAdd (28.54k/28.54k flops)\n",
      "  model_39/conv2d_554/BiasAdd (27.90k/27.90k flops)\n",
      "  model_39/depthwise_conv2d_515/BiasAdd (27.90k/27.90k flops)\n",
      "  model_39/conv2d_557/BiasAdd (26.24k/26.24k flops)\n",
      "  model_39/conv2d_552/BiasAdd (25.22k/25.22k flops)\n",
      "  model_39/depthwise_conv2d_513/BiasAdd (25.22k/25.22k flops)\n",
      "  model_39/batch_normalization_1064/FusedBatchNormV3 (21.71k/21.71k flops)\n",
      "  model_39/dense_39/MatMul (20.32k/20.32k flops)\n",
      "  model_39/batch_normalization_1076/FusedBatchNormV3 (15.58k/15.58k flops)\n",
      "  model_39/conv2d_558/BiasAdd (14.88k/14.88k flops)\n",
      "  model_39/batch_normalization_1079/FusedBatchNormV3 (14.22k/14.22k flops)\n",
      "  model_39/batch_normalization_1078/FusedBatchNormV3 (13.02k/13.02k flops)\n",
      "  model_39/depthwise_conv2d_512/BiasAdd (10.37k/10.37k flops)\n",
      "  model_39/depthwise_conv2d_518/BiasAdd (6.56k/6.56k flops)\n",
      "  model_39/global_average_pooling2d_39/Mean (4.06k/4.06k flops)\n",
      "  model_39/conv2d_559/BiasAdd (4.06k/4.06k flops)\n",
      "  model_39/depthwise_conv2d_519/BiasAdd (3.72k/3.72k flops)\n",
      "  model_39/dense_39/Softmax (50/50 flops)\n",
      "  model_39/dense_39/BiasAdd (10/10 flops)\n",
      "\n",
      "======================End of Report==========================\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "14.648588\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-30 13:40:15.730874: I tensorflow/core/grappler/devices.cc:66] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0\n",
      "2022-04-30 13:40:15.730988: I tensorflow/core/grappler/clusters/single_machine.cc:357] Starting new session\n",
      "2022-04-30 13:40:15.735068: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:1137] Optimization results for grappler item: graph_to_optimize\n",
      "  function_optimizer: function_optimizer did nothing. time = 0.005ms.\n",
      "  function_optimizer: function_optimizer did nothing. time = 0ms.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=========================Options=============================\n",
      "-max_depth                  10000\n",
      "-min_bytes                  0\n",
      "-min_peak_bytes             0\n",
      "-min_residual_bytes         0\n",
      "-min_output_bytes           0\n",
      "-min_micros                 0\n",
      "-min_accelerator_micros     0\n",
      "-min_cpu_micros             0\n",
      "-min_params                 0\n",
      "-min_float_ops              1\n",
      "-min_occurrence             0\n",
      "-step                       -1\n",
      "-order_by                   float_ops\n",
      "-account_type_regexes       .*\n",
      "-start_name_regexes         .*\n",
      "-trim_name_regexes          \n",
      "-show_name_regexes          .*\n",
      "-hide_name_regexes          \n",
      "-account_displayed_op_only  true\n",
      "-select                     float_ops\n",
      "-output                     stdout:\n",
      "\n",
      "==================Model Analysis Report======================\n",
      "\n",
      "Doc:\n",
      "scope: The nodes in the model graph are organized by their names, which is hierarchical like filesystem.\n",
      "flops: Number of float operations. Note: Please read the implementation for the math behind it.\n",
      "\n",
      "Profile:\n",
      "node name | # float_ops\n",
      "_TFProfRoot (--/216.14m flops)\n",
      "  model_40/conv2d_565/Conv2D (28.51m/28.51m flops)\n",
      "  model_40/conv2d_571/Conv2D (26.27m/26.27m flops)\n",
      "  model_40/conv2d_568/Conv2D (24.94m/24.94m flops)\n",
      "  model_40/conv2d_569/Conv2D (23.35m/23.35m flops)\n",
      "  model_40/conv2d_570/Conv2D (21.99m/21.99m flops)\n",
      "  model_40/conv2d_567/Conv2D (18.19m/18.19m flops)\n",
      "  model_40/conv2d_561/Conv2D (12.06m/12.06m flops)\n",
      "  model_40/conv2d_566/Conv2D (10.75m/10.75m flops)\n",
      "  model_40/conv2d_564/Conv2D (9.50m/9.50m flops)\n",
      "  model_40/conv2d_563/Conv2D (8.85m/8.85m flops)\n",
      "  model_40/conv2d_572/Conv2D (6.60m/6.60m flops)\n",
      "  model_40/conv2d_562/Conv2D (5.09m/5.09m flops)\n",
      "  model_40/conv2d_560/Conv2D (4.19m/4.19m flops)\n",
      "  model_40/conv2d_573/Conv2D (3.66m/3.66m flops)\n",
      "  model_40/depthwise_conv2d_520/depthwise (2.36m/2.36m flops)\n",
      "  model_40/depthwise_conv2d_524/depthwise (1.07m/1.07m flops)\n",
      "  model_40/depthwise_conv2d_522/depthwise (995.33k/995.33k flops)\n",
      "  model_40/depthwise_conv2d_521/depthwise (847.87k/847.87k flops)\n",
      "  model_40/depthwise_conv2d_528/depthwise (552.96k/552.96k flops)\n",
      "  model_40/depthwise_conv2d_530/depthwise (520.70k/520.70k flops)\n",
      "  model_40/depthwise_conv2d_527/depthwise (467.71k/467.71k flops)\n",
      "  model_40/depthwise_conv2d_529/depthwise (437.76k/437.76k flops)\n",
      "  model_40/depthwise_conv2d_526/depthwise (403.20k/403.20k flops)\n",
      "  model_40/batch_normalization_1082/FusedBatchNormV3 (377.11k/377.11k flops)\n",
      "  model_40/depthwise_conv2d_523/depthwise (368.64k/368.64k flops)\n",
      "  model_40/depthwise_conv2d_525/depthwise (276.48k/276.48k flops)\n",
      "  model_40/batch_normalization_1081/FusedBatchNormV3 (262.34k/262.34k flops)\n",
      "  model_40/batch_normalization_1080/FusedBatchNormV3 (262.34k/262.34k flops)\n",
      "  model_40/conv2d_561/BiasAdd (188.42k/188.42k flops)\n",
      "  model_40/batch_normalization_1086/FusedBatchNormV3 (164.32k/164.32k flops)\n",
      "  model_40/conv2d_560/BiasAdd (131.07k/131.07k flops)\n",
      "  model_40/depthwise_conv2d_520/BiasAdd (131.07k/131.07k flops)\n",
      "  model_40/depthwise_conv2d_531/depthwise (130.75k/130.75k flops)\n",
      "  model_40/batch_normalization_1090/FusedBatchNormV3 (124.32k/124.32k flops)\n",
      "  model_40/batch_normalization_1089/FusedBatchNormV3 (120.18k/120.18k flops)\n",
      "  model_40/batch_normalization_1088/FusedBatchNormV3 (120.18k/120.18k flops)\n",
      "  model_40/batch_normalization_1085/FusedBatchNormV3 (110.92k/110.92k flops)\n",
      "  model_40/batch_normalization_1084/FusedBatchNormV3 (110.92k/110.92k flops)\n",
      "  model_40/batch_normalization_1083/FusedBatchNormV3 (94.48k/94.48k flops)\n",
      "  model_40/conv2d_563/BiasAdd (81.92k/81.92k flops)\n",
      "  model_40/batch_normalization_1097/FusedBatchNormV3 (64.32k/64.32k flops)\n",
      "  model_40/batch_normalization_1096/FusedBatchNormV3 (64.32k/64.32k flops)\n",
      "  model_40/conv2d_565/BiasAdd (61.44k/61.44k flops)\n",
      "  model_40/batch_normalization_1102/FusedBatchNormV3 (60.84k/60.84k flops)\n",
      "  model_40/batch_normalization_1101/FusedBatchNormV3 (60.57k/60.57k flops)\n",
      "  model_40/batch_normalization_1100/FusedBatchNormV3 (60.57k/60.57k flops)\n",
      "  model_40/depthwise_conv2d_524/BiasAdd (59.39k/59.39k flops)\n",
      "  model_40/conv2d_564/BiasAdd (59.39k/59.39k flops)\n",
      "  model_40/depthwise_conv2d_522/BiasAdd (55.30k/55.30k flops)\n",
      "  model_40/conv2d_562/BiasAdd (55.30k/55.30k flops)\n",
      "  model_40/batch_normalization_1094/FusedBatchNormV3 (54.40k/54.40k flops)\n",
      "  model_40/batch_normalization_1095/FusedBatchNormV3 (54.40k/54.40k flops)\n",
      "  model_40/batch_normalization_1098/FusedBatchNormV3 (50.92k/50.92k flops)\n",
      "  model_40/batch_normalization_1099/FusedBatchNormV3 (50.92k/50.92k flops)\n",
      "  model_40/depthwise_conv2d_521/BiasAdd (47.10k/47.10k flops)\n",
      "  model_40/batch_normalization_1093/FusedBatchNormV3 (46.90k/46.90k flops)\n",
      "  model_40/batch_normalization_1092/FusedBatchNormV3 (46.90k/46.90k flops)\n",
      "  model_40/batch_normalization_1087/FusedBatchNormV3 (41.44k/41.44k flops)\n",
      "  model_40/depthwise_conv2d_532/depthwise (32.69k/32.69k flops)\n",
      "  model_40/batch_normalization_1091/FusedBatchNormV3 (32.16k/32.16k flops)\n",
      "  model_40/depthwise_conv2d_528/BiasAdd (30.72k/30.72k flops)\n",
      "  model_40/conv2d_568/BiasAdd (30.72k/30.72k flops)\n",
      "  model_40/conv2d_571/BiasAdd (29.06k/29.06k flops)\n",
      "  model_40/depthwise_conv2d_530/BiasAdd (28.93k/28.93k flops)\n",
      "  model_40/conv2d_570/BiasAdd (28.93k/28.93k flops)\n",
      "  model_40/depthwise_conv2d_527/BiasAdd (25.98k/25.98k flops)\n",
      "  model_40/conv2d_567/BiasAdd (25.98k/25.98k flops)\n",
      "  model_40/conv2d_569/BiasAdd (24.32k/24.32k flops)\n",
      "  model_40/depthwise_conv2d_529/BiasAdd (24.32k/24.32k flops)\n",
      "  model_40/conv2d_566/BiasAdd (22.40k/22.40k flops)\n",
      "  model_40/depthwise_conv2d_526/BiasAdd (22.40k/22.40k flops)\n",
      "  model_40/depthwise_conv2d_523/BiasAdd (20.48k/20.48k flops)\n",
      "  model_40/dense_40/MatMul (20.16k/20.16k flops)\n",
      "  model_40/batch_normalization_1103/FusedBatchNormV3 (17.25k/17.25k flops)\n",
      "  model_40/batch_normalization_1104/FusedBatchNormV3 (17.25k/17.25k flops)\n",
      "  model_40/depthwise_conv2d_525/BiasAdd (15.36k/15.36k flops)\n",
      "  model_40/batch_normalization_1106/FusedBatchNormV3 (14.11k/14.11k flops)\n",
      "  model_40/depthwise_conv2d_531/BiasAdd (7.26k/7.26k flops)\n",
      "  model_40/conv2d_572/BiasAdd (7.26k/7.26k flops)\n",
      "  model_40/batch_normalization_1105/FusedBatchNormV3 (6.36k/6.36k flops)\n",
      "  model_40/conv2d_573/BiasAdd (4.03k/4.03k flops)\n",
      "  model_40/global_average_pooling2d_40/Mean (4.03k/4.03k flops)\n",
      "  model_40/depthwise_conv2d_532/BiasAdd (1.82k/1.82k flops)\n",
      "  model_40/dense_40/Softmax (50/50 flops)\n",
      "  model_40/dense_40/BiasAdd (10/10 flops)\n",
      "\n",
      "======================End of Report==========================\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "24.744884\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-30 13:40:16.651765: I tensorflow/core/grappler/devices.cc:66] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0\n",
      "2022-04-30 13:40:16.651890: I tensorflow/core/grappler/clusters/single_machine.cc:357] Starting new session\n",
      "2022-04-30 13:40:16.655926: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:1137] Optimization results for grappler item: graph_to_optimize\n",
      "  function_optimizer: function_optimizer did nothing. time = 0.005ms.\n",
      "  function_optimizer: function_optimizer did nothing. time = 0.001ms.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=========================Options=============================\n",
      "-max_depth                  10000\n",
      "-min_bytes                  0\n",
      "-min_peak_bytes             0\n",
      "-min_residual_bytes         0\n",
      "-min_output_bytes           0\n",
      "-min_micros                 0\n",
      "-min_accelerator_micros     0\n",
      "-min_cpu_micros             0\n",
      "-min_params                 0\n",
      "-min_float_ops              1\n",
      "-min_occurrence             0\n",
      "-step                       -1\n",
      "-order_by                   float_ops\n",
      "-account_type_regexes       .*\n",
      "-start_name_regexes         .*\n",
      "-trim_name_regexes          \n",
      "-show_name_regexes          .*\n",
      "-hide_name_regexes          \n",
      "-account_displayed_op_only  true\n",
      "-select                     float_ops\n",
      "-output                     stdout:\n",
      "\n",
      "==================Model Analysis Report======================\n",
      "\n",
      "Doc:\n",
      "scope: The nodes in the model graph are organized by their names, which is hierarchical like filesystem.\n",
      "flops: Number of float operations. Note: Please read the implementation for the math behind it.\n",
      "\n",
      "Profile:\n",
      "node name | # float_ops\n",
      "_TFProfRoot (--/375.54m flops)\n",
      "  model_41/conv2d_577/Conv2D (44.54m/44.54m flops)\n",
      "  model_41/conv2d_585/Conv2D (40.66m/40.66m flops)\n",
      "  model_41/conv2d_582/Conv2D (37.94m/37.94m flops)\n",
      "  model_41/conv2d_583/Conv2D (37.03m/37.03m flops)\n",
      "  model_41/conv2d_584/Conv2D (35.73m/35.73m flops)\n",
      "  model_41/conv2d_579/Conv2D (34.75m/34.75m flops)\n",
      "  model_41/conv2d_581/Conv2D (30.28m/30.28m flops)\n",
      "  model_41/conv2d_580/Conv2D (17.76m/17.76m flops)\n",
      "  model_41/conv2d_578/Conv2D (17.09m/17.09m flops)\n",
      "  model_41/conv2d_586/Conv2D (15.43m/15.43m flops)\n",
      "  model_41/conv2d_575/Conv2D (13.93m/13.93m flops)\n",
      "  model_41/conv2d_576/Conv2D (12.62m/12.62m flops)\n",
      "  model_41/conv2d_587/Conv2D (10.32m/10.32m flops)\n",
      "  model_41/conv2d_574/Conv2D (6.55m/6.55m flops)\n",
      "  model_41/depthwise_conv2d_533/depthwise (3.69m/3.69m flops)\n",
      "  model_41/depthwise_conv2d_535/depthwise (3.34m/3.34m flops)\n",
      "  model_41/depthwise_conv2d_537/depthwise (1.28m/1.28m flops)\n",
      "  model_41/depthwise_conv2d_534/depthwise (979.20k/979.20k flops)\n",
      "  model_41/depthwise_conv2d_536/depthwise (864.00k/864.00k flops)\n",
      "  model_41/depthwise_conv2d_541/depthwise (820.80k/820.80k flops)\n",
      "  model_41/depthwise_conv2d_543/depthwise (792.00k/792.00k flops)\n",
      "  model_41/depthwise_conv2d_540/depthwise (748.80k/748.80k flops)\n",
      "  model_41/depthwise_conv2d_542/depthwise (730.80k/730.80k flops)\n",
      "  model_41/depthwise_conv2d_539/depthwise (655.20k/655.20k flops)\n",
      "  model_41/depthwise_conv2d_538/depthwise (439.20k/439.20k flops)\n",
      "  model_41/batch_normalization_1109/FusedBatchNormV3 (435.40k/435.40k flops)\n",
      "  model_41/batch_normalization_1108/FusedBatchNormV3 (409.79k/409.79k flops)\n",
      "  model_41/batch_normalization_1107/FusedBatchNormV3 (409.79k/409.79k flops)\n",
      "  model_41/batch_normalization_1113/FusedBatchNormV3 (384.72k/384.72k flops)\n",
      "  model_41/batch_normalization_1111/FusedBatchNormV3 (371.90k/371.90k flops)\n",
      "  model_41/batch_normalization_1112/FusedBatchNormV3 (371.90k/371.90k flops)\n",
      "  model_41/conv2d_575/BiasAdd (217.60k/217.60k flops)\n",
      "  model_41/depthwise_conv2d_544/depthwise (207.90k/207.90k flops)\n",
      "  model_41/depthwise_conv2d_533/BiasAdd (204.80k/204.80k flops)\n",
      "  model_41/conv2d_574/BiasAdd (204.80k/204.80k flops)\n",
      "  model_41/batch_normalization_1117/FusedBatchNormV3 (196.66k/196.66k flops)\n",
      "  model_41/conv2d_577/BiasAdd (192.00k/192.00k flops)\n",
      "  model_41/conv2d_576/BiasAdd (185.60k/185.60k flops)\n",
      "  model_41/depthwise_conv2d_535/BiasAdd (185.60k/185.60k flops)\n",
      "  model_41/batch_normalization_1115/FusedBatchNormV3 (143.47k/143.47k flops)\n",
      "  model_41/batch_normalization_1116/FusedBatchNormV3 (143.47k/143.47k flops)\n",
      "  model_41/batch_normalization_1110/FusedBatchNormV3 (109.00k/109.00k flops)\n",
      "  model_41/depthwise_conv2d_545/depthwise (108.22k/108.22k flops)\n",
      "  model_41/conv2d_579/BiasAdd (97.60k/97.60k flops)\n",
      "  model_41/batch_normalization_1114/FusedBatchNormV3 (96.72k/96.72k flops)\n",
      "  model_41/batch_normalization_1129/FusedBatchNormV3 (95.17k/95.17k flops)\n",
      "  model_41/batch_normalization_1124/FusedBatchNormV3 (93.94k/93.94k flops)\n",
      "  model_41/batch_normalization_1123/FusedBatchNormV3 (93.94k/93.94k flops)\n",
      "  model_41/batch_normalization_1127/FusedBatchNormV3 (90.64k/90.64k flops)\n",
      "  model_41/batch_normalization_1128/FusedBatchNormV3 (90.64k/90.64k flops)\n",
      "  model_41/batch_normalization_1122/FusedBatchNormV3 (85.70k/85.70k flops)\n",
      "  model_41/batch_normalization_1121/FusedBatchNormV3 (85.70k/85.70k flops)\n",
      "  model_41/batch_normalization_1126/FusedBatchNormV3 (83.64k/83.64k flops)\n",
      "  model_41/batch_normalization_1125/FusedBatchNormV3 (83.64k/83.64k flops)\n",
      "  model_41/batch_normalization_1120/FusedBatchNormV3 (74.98k/74.98k flops)\n",
      "  model_41/batch_normalization_1119/FusedBatchNormV3 (74.98k/74.98k flops)\n",
      "  model_41/depthwise_conv2d_537/BiasAdd (71.20k/71.20k flops)\n",
      "  model_41/conv2d_578/BiasAdd (71.20k/71.20k flops)\n",
      "  model_41/depthwise_conv2d_534/BiasAdd (54.40k/54.40k flops)\n",
      "  model_41/batch_normalization_1118/FusedBatchNormV3 (50.26k/50.26k flops)\n",
      "  model_41/depthwise_conv2d_536/BiasAdd (48.00k/48.00k flops)\n",
      "  model_41/conv2d_585/BiasAdd (46.20k/46.20k flops)\n",
      "  model_41/conv2d_582/BiasAdd (45.60k/45.60k flops)\n",
      "  model_41/depthwise_conv2d_541/BiasAdd (45.60k/45.60k flops)\n",
      "  model_41/conv2d_584/BiasAdd (44.00k/44.00k flops)\n",
      "  model_41/depthwise_conv2d_543/BiasAdd (44.00k/44.00k flops)\n",
      "  model_41/depthwise_conv2d_540/BiasAdd (41.60k/41.60k flops)\n",
      "  model_41/conv2d_581/BiasAdd (41.60k/41.60k flops)\n",
      "  model_41/depthwise_conv2d_542/BiasAdd (40.60k/40.60k flops)\n",
      "  model_41/conv2d_583/BiasAdd (40.60k/40.60k flops)\n",
      "  model_41/batch_normalization_1131/FusedBatchNormV3 (37.41k/37.41k flops)\n",
      "  model_41/depthwise_conv2d_539/BiasAdd (36.40k/36.40k flops)\n",
      "  model_41/conv2d_580/BiasAdd (36.40k/36.40k flops)\n",
      "  model_41/batch_normalization_1130/FusedBatchNormV3 (25.87k/25.87k flops)\n",
      "  model_41/depthwise_conv2d_538/BiasAdd (24.40k/24.40k flops)\n",
      "  model_41/batch_normalization_1133/FusedBatchNormV3 (20.59k/20.59k flops)\n",
      "  model_41/dense_41/MatMul (17.16k/17.16k flops)\n",
      "  model_41/conv2d_586/BiasAdd (16.70k/16.70k flops)\n",
      "  model_41/batch_normalization_1132/FusedBatchNormV3 (16.03k/16.03k flops)\n",
      "  model_41/depthwise_conv2d_544/BiasAdd (11.55k/11.55k flops)\n",
      "  model_41/conv2d_587/BiasAdd (7.72k/7.72k flops)\n",
      "  model_41/global_average_pooling2d_41/Mean (7.72k/7.72k flops)\n",
      "  model_41/depthwise_conv2d_545/BiasAdd (6.01k/6.01k flops)\n",
      "  model_41/dense_41/Softmax (50/50 flops)\n",
      "  model_41/dense_41/BiasAdd (10/10 flops)\n",
      "\n",
      "======================End of Report==========================\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "24.887988\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-30 13:40:17.680726: I tensorflow/core/grappler/devices.cc:66] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0\n",
      "2022-04-30 13:40:17.680851: I tensorflow/core/grappler/clusters/single_machine.cc:357] Starting new session\n",
      "2022-04-30 13:40:17.685319: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:1137] Optimization results for grappler item: graph_to_optimize\n",
      "  function_optimizer: function_optimizer did nothing. time = 0.005ms.\n",
      "  function_optimizer: function_optimizer did nothing. time = 0.001ms.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=========================Options=============================\n",
      "-max_depth                  10000\n",
      "-min_bytes                  0\n",
      "-min_peak_bytes             0\n",
      "-min_residual_bytes         0\n",
      "-min_output_bytes           0\n",
      "-min_micros                 0\n",
      "-min_accelerator_micros     0\n",
      "-min_cpu_micros             0\n",
      "-min_params                 0\n",
      "-min_float_ops              1\n",
      "-min_occurrence             0\n",
      "-step                       -1\n",
      "-order_by                   float_ops\n",
      "-account_type_regexes       .*\n",
      "-start_name_regexes         .*\n",
      "-trim_name_regexes          \n",
      "-show_name_regexes          .*\n",
      "-hide_name_regexes          \n",
      "-account_displayed_op_only  true\n",
      "-select                     float_ops\n",
      "-output                     stdout:\n",
      "\n",
      "==================Model Analysis Report======================\n",
      "\n",
      "Doc:\n",
      "scope: The nodes in the model graph are organized by their names, which is hierarchical like filesystem.\n",
      "flops: Number of float operations. Note: Please read the implementation for the math behind it.\n",
      "\n",
      "Profile:\n",
      "node name | # float_ops\n",
      "_TFProfRoot (--/454.34m flops)\n",
      "  model_42/conv2d_597/Conv2D (52.02m/52.02m flops)\n",
      "  model_42/conv2d_598/Conv2D (51.61m/51.61m flops)\n",
      "  model_42/conv2d_599/Conv2D (51.21m/51.21m flops)\n",
      "  model_42/conv2d_596/Conv2D (51.20m/51.20m flops)\n",
      "  model_42/conv2d_595/Conv2D (50.40m/50.40m flops)\n",
      "  model_42/conv2d_593/Conv2D (39.01m/39.01m flops)\n",
      "  model_42/conv2d_591/Conv2D (29.45m/29.45m flops)\n",
      "  model_42/conv2d_594/Conv2D (23.09m/23.09m flops)\n",
      "  model_42/conv2d_600/Conv2D (20.80m/20.80m flops)\n",
      "  model_42/conv2d_592/Conv2D (20.01m/20.01m flops)\n",
      "  model_42/conv2d_589/Conv2D (14.75m/14.75m flops)\n",
      "  model_42/conv2d_601/Conv2D (14.26m/14.26m flops)\n",
      "  model_42/conv2d_590/Conv2D (8.99m/8.99m flops)\n",
      "  model_42/conv2d_588/Conv2D (6.55m/6.55m flops)\n",
      "  model_42/depthwise_conv2d_546/depthwise (3.69m/3.69m flops)\n",
      "  model_42/depthwise_conv2d_548/depthwise (2.25m/2.25m flops)\n",
      "  model_42/depthwise_conv2d_550/depthwise (1.53m/1.53m flops)\n",
      "  model_42/depthwise_conv2d_547/depthwise (1.04m/1.04m flops)\n",
      "  model_42/depthwise_conv2d_554/depthwise (918.00k/918.00k flops)\n",
      "  model_42/depthwise_conv2d_555/depthwise (918.00k/918.00k flops)\n",
      "  model_42/depthwise_conv2d_556/depthwise (910.80k/910.80k flops)\n",
      "  model_42/depthwise_conv2d_552/depthwise (903.60k/903.60k flops)\n",
      "  model_42/depthwise_conv2d_553/depthwise (903.60k/903.60k flops)\n",
      "  model_42/depthwise_conv2d_549/depthwise (849.60k/849.60k flops)\n",
      "  model_42/batch_normalization_1136/FusedBatchNormV3 (461.02k/461.02k flops)\n",
      "  model_42/depthwise_conv2d_551/depthwise (414.00k/414.00k flops)\n",
      "  model_42/batch_normalization_1135/FusedBatchNormV3 (409.79k/409.79k flops)\n",
      "  model_42/batch_normalization_1134/FusedBatchNormV3 (409.79k/409.79k flops)\n",
      "  model_42/batch_normalization_1140/FusedBatchNormV3 (378.31k/378.31k flops)\n",
      "  model_42/batch_normalization_1138/FusedBatchNormV3 (250.07k/250.07k flops)\n",
      "  model_42/batch_normalization_1139/FusedBatchNormV3 (250.07k/250.07k flops)\n",
      "  model_42/conv2d_589/BiasAdd (230.40k/230.40k flops)\n",
      "  model_42/depthwise_conv2d_557/depthwise (227.70k/227.70k flops)\n",
      "  model_42/depthwise_conv2d_546/BiasAdd (204.80k/204.80k flops)\n",
      "  model_42/conv2d_588/BiasAdd (204.80k/204.80k flops)\n",
      "  model_42/conv2d_591/BiasAdd (188.80k/188.80k flops)\n",
      "  model_42/batch_normalization_1144/FusedBatchNormV3 (185.38k/185.38k flops)\n",
      "  model_42/batch_normalization_1143/FusedBatchNormV3 (170.87k/170.87k flops)\n",
      "  model_42/batch_normalization_1142/FusedBatchNormV3 (170.87k/170.87k flops)\n",
      "  model_42/depthwise_conv2d_558/depthwise (133.16k/133.16k flops)\n",
      "  model_42/depthwise_conv2d_548/BiasAdd (124.80k/124.80k flops)\n",
      "  model_42/conv2d_590/BiasAdd (124.80k/124.80k flops)\n",
      "  model_42/batch_normalization_1137/FusedBatchNormV3 (115.42k/115.42k flops)\n",
      "  model_42/batch_normalization_1152/FusedBatchNormV3 (105.06k/105.06k flops)\n",
      "  model_42/batch_normalization_1151/FusedBatchNormV3 (105.06k/105.06k flops)\n",
      "  model_42/batch_normalization_1150/FusedBatchNormV3 (105.06k/105.06k flops)\n",
      "  model_42/batch_normalization_1153/FusedBatchNormV3 (105.06k/105.06k flops)\n",
      "  model_42/batch_normalization_1154/FusedBatchNormV3 (104.24k/104.24k flops)\n",
      "  model_42/batch_normalization_1156/FusedBatchNormV3 (104.24k/104.24k flops)\n",
      "  model_42/batch_normalization_1155/FusedBatchNormV3 (104.24k/104.24k flops)\n",
      "  model_42/batch_normalization_1149/FusedBatchNormV3 (103.41k/103.41k flops)\n",
      "  model_42/batch_normalization_1148/FusedBatchNormV3 (103.41k/103.41k flops)\n",
      "  model_42/batch_normalization_1147/FusedBatchNormV3 (103.41k/103.41k flops)\n",
      "  model_42/batch_normalization_1146/FusedBatchNormV3 (103.41k/103.41k flops)\n",
      "  model_42/batch_normalization_1141/FusedBatchNormV3 (95.11k/95.11k flops)\n",
      "  model_42/conv2d_593/BiasAdd (92.00k/92.00k flops)\n",
      "  model_42/depthwise_conv2d_550/BiasAdd (84.80k/84.80k flops)\n",
      "  model_42/conv2d_592/BiasAdd (84.80k/84.80k flops)\n",
      "  model_42/depthwise_conv2d_547/BiasAdd (57.60k/57.60k flops)\n",
      "  model_42/conv2d_596/BiasAdd (51.00k/51.00k flops)\n",
      "  model_42/conv2d_597/BiasAdd (51.00k/51.00k flops)\n",
      "  model_42/depthwise_conv2d_554/BiasAdd (51.00k/51.00k flops)\n",
      "  model_42/depthwise_conv2d_555/BiasAdd (51.00k/51.00k flops)\n",
      "  model_42/depthwise_conv2d_556/BiasAdd (50.60k/50.60k flops)\n",
      "  model_42/conv2d_599/BiasAdd (50.60k/50.60k flops)\n",
      "  model_42/conv2d_598/BiasAdd (50.60k/50.60k flops)\n",
      "  model_42/depthwise_conv2d_552/BiasAdd (50.20k/50.20k flops)\n",
      "  model_42/conv2d_595/BiasAdd (50.20k/50.20k flops)\n",
      "  model_42/depthwise_conv2d_553/BiasAdd (50.20k/50.20k flops)\n",
      "  model_42/conv2d_594/BiasAdd (50.20k/50.20k flops)\n",
      "  model_42/batch_normalization_1145/FusedBatchNormV3 (47.38k/47.38k flops)\n",
      "  model_42/depthwise_conv2d_549/BiasAdd (47.20k/47.20k flops)\n",
      "  model_42/batch_normalization_1158/FusedBatchNormV3 (46.03k/46.03k flops)\n",
      "  model_42/batch_normalization_1157/FusedBatchNormV3 (28.34k/28.34k flops)\n",
      "  model_42/batch_normalization_1160/FusedBatchNormV3 (23.14k/23.14k flops)\n",
      "  model_42/depthwise_conv2d_551/BiasAdd (23.00k/23.00k flops)\n",
      "  model_42/conv2d_600/BiasAdd (20.55k/20.55k flops)\n",
      "  model_42/batch_normalization_1159/FusedBatchNormV3 (19.73k/19.73k flops)\n",
      "  model_42/dense_42/MatMul (19.28k/19.28k flops)\n",
      "  model_42/depthwise_conv2d_557/BiasAdd (12.65k/12.65k flops)\n",
      "  model_42/conv2d_601/BiasAdd (8.68k/8.68k flops)\n",
      "  model_42/global_average_pooling2d_42/Mean (8.68k/8.68k flops)\n",
      "  model_42/depthwise_conv2d_558/BiasAdd (7.40k/7.40k flops)\n",
      "  model_42/dense_42/Softmax (50/50 flops)\n",
      "  model_42/dense_42/BiasAdd (10/10 flops)\n",
      "\n",
      "======================End of Report==========================\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "25.37362\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-30 13:40:18.631204: I tensorflow/core/grappler/devices.cc:66] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0\n",
      "2022-04-30 13:40:18.631321: I tensorflow/core/grappler/clusters/single_machine.cc:357] Starting new session\n",
      "2022-04-30 13:40:18.635376: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:1137] Optimization results for grappler item: graph_to_optimize\n",
      "  function_optimizer: function_optimizer did nothing. time = 0.005ms.\n",
      "  function_optimizer: function_optimizer did nothing. time = 0.001ms.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=========================Options=============================\n",
      "-max_depth                  10000\n",
      "-min_bytes                  0\n",
      "-min_peak_bytes             0\n",
      "-min_residual_bytes         0\n",
      "-min_output_bytes           0\n",
      "-min_micros                 0\n",
      "-min_accelerator_micros     0\n",
      "-min_cpu_micros             0\n",
      "-min_params                 0\n",
      "-min_float_ops              1\n",
      "-min_occurrence             0\n",
      "-step                       -1\n",
      "-order_by                   float_ops\n",
      "-account_type_regexes       .*\n",
      "-start_name_regexes         .*\n",
      "-trim_name_regexes          \n",
      "-show_name_regexes          .*\n",
      "-hide_name_regexes          \n",
      "-account_displayed_op_only  true\n",
      "-select                     float_ops\n",
      "-output                     stdout:\n",
      "\n",
      "==================Model Analysis Report======================\n",
      "\n",
      "Doc:\n",
      "scope: The nodes in the model graph are organized by their names, which is hierarchical like filesystem.\n",
      "flops: Number of float operations. Note: Please read the implementation for the math behind it.\n",
      "\n",
      "Profile:\n",
      "node name | # float_ops\n",
      "_TFProfRoot (--/327.63m flops)\n",
      "  model_43/conv2d_610/Conv2D (39.52m/39.52m flops)\n",
      "  model_43/conv2d_611/Conv2D (37.28m/37.28m flops)\n",
      "  model_43/conv2d_605/Conv2D (33.09m/33.09m flops)\n",
      "  model_43/conv2d_607/Conv2D (32.67m/32.67m flops)\n",
      "  model_43/conv2d_612/Conv2D (26.47m/26.47m flops)\n",
      "  model_43/conv2d_609/Conv2D (25.29m/25.29m flops)\n",
      "  model_43/conv2d_603/Conv2D (24.58m/24.58m flops)\n",
      "  model_43/conv2d_604/Conv2D (18.05m/18.05m flops)\n",
      "  model_43/conv2d_613/Conv2D (17.38m/17.38m flops)\n",
      "  model_43/conv2d_606/Conv2D (15.49m/15.49m flops)\n",
      "  model_43/conv2d_608/Conv2D (11.88m/11.88m flops)\n",
      "  model_43/conv2d_614/Conv2D (9.82m/9.82m flops)\n",
      "  model_43/conv2d_615/Conv2D (8.90m/8.90m flops)\n",
      "  model_43/conv2d_602/Conv2D (6.55m/6.55m flops)\n",
      "  model_43/depthwise_conv2d_559/depthwise (3.69m/3.69m flops)\n",
      "  model_43/depthwise_conv2d_561/depthwise (2.71m/2.71m flops)\n",
      "  model_43/depthwise_conv2d_560/depthwise (1.73m/1.73m flops)\n",
      "  model_43/depthwise_conv2d_563/depthwise (1.27m/1.27m flops)\n",
      "  model_43/depthwise_conv2d_566/depthwise (889.20k/889.20k flops)\n",
      "  model_43/depthwise_conv2d_568/depthwise (838.80k/838.80k flops)\n",
      "  model_43/depthwise_conv2d_562/depthwise (792.00k/792.00k flops)\n",
      "  model_43/batch_normalization_1163/FusedBatchNormV3 (768.36k/768.36k flops)\n",
      "  model_43/depthwise_conv2d_567/depthwise (720.00k/720.00k flops)\n",
      "  model_43/depthwise_conv2d_569/depthwise (511.20k/511.20k flops)\n",
      "  model_43/depthwise_conv2d_565/depthwise (460.80k/460.80k flops)\n",
      "  model_43/depthwise_conv2d_564/depthwise (417.60k/417.60k flops)\n",
      "  model_43/batch_normalization_1162/FusedBatchNormV3 (409.79k/409.79k flops)\n",
      "  model_43/batch_normalization_1161/FusedBatchNormV3 (409.79k/409.79k flops)\n",
      "  model_43/conv2d_603/BiasAdd (384.00k/384.00k flops)\n",
      "  model_43/batch_normalization_1167/FusedBatchNormV3 (352.66k/352.66k flops)\n",
      "  model_43/batch_normalization_1166/FusedBatchNormV3 (301.36k/301.36k flops)\n",
      "  model_43/batch_normalization_1165/FusedBatchNormV3 (301.36k/301.36k flops)\n",
      "  model_43/conv2d_602/BiasAdd (204.80k/204.80k flops)\n",
      "  model_43/depthwise_conv2d_559/BiasAdd (204.80k/204.80k flops)\n",
      "  model_43/batch_normalization_1164/FusedBatchNormV3 (192.36k/192.36k flops)\n",
      "  model_43/batch_normalization_1171/FusedBatchNormV3 (186.99k/186.99k flops)\n",
      "  model_43/conv2d_605/BiasAdd (176.00k/176.00k flops)\n",
      "  model_43/depthwise_conv2d_561/BiasAdd (150.40k/150.40k flops)\n",
      "  model_43/conv2d_604/BiasAdd (150.40k/150.40k flops)\n",
      "  model_43/batch_normalization_1170/FusedBatchNormV3 (141.86k/141.86k flops)\n",
      "  model_43/batch_normalization_1169/FusedBatchNormV3 (141.86k/141.86k flops)\n",
      "  model_43/depthwise_conv2d_570/depthwise (137.70k/137.70k flops)\n",
      "  model_43/depthwise_conv2d_571/depthwise (104.00k/104.00k flops)\n",
      "  model_43/batch_normalization_1175/FusedBatchNormV3 (101.76k/101.76k flops)\n",
      "  model_43/batch_normalization_1176/FusedBatchNormV3 (101.76k/101.76k flops)\n",
      "  model_43/depthwise_conv2d_560/BiasAdd (96.00k/96.00k flops)\n",
      "  model_43/batch_normalization_1180/FusedBatchNormV3 (96.00k/96.00k flops)\n",
      "  model_43/batch_normalization_1179/FusedBatchNormV3 (96.00k/96.00k flops)\n",
      "  model_43/conv2d_607/BiasAdd (92.80k/92.80k flops)\n",
      "  model_43/batch_normalization_1168/FusedBatchNormV3 (88.66k/88.66k flops)\n",
      "  model_43/batch_normalization_1177/FusedBatchNormV3 (82.40k/82.40k flops)\n",
      "  model_43/batch_normalization_1178/FusedBatchNormV3 (82.40k/82.40k flops)\n",
      "  model_43/depthwise_conv2d_563/BiasAdd (70.40k/70.40k flops)\n",
      "  model_43/conv2d_606/BiasAdd (70.40k/70.40k flops)\n",
      "  model_43/batch_normalization_1183/FusedBatchNormV3 (63.04k/63.04k flops)\n",
      "  model_43/batch_normalization_1181/FusedBatchNormV3 (58.50k/58.50k flops)\n",
      "  model_43/batch_normalization_1182/FusedBatchNormV3 (58.50k/58.50k flops)\n",
      "  model_43/batch_normalization_1174/FusedBatchNormV3 (52.74k/52.74k flops)\n",
      "  model_43/batch_normalization_1173/FusedBatchNormV3 (52.74k/52.74k flops)\n",
      "  model_43/depthwise_conv2d_566/BiasAdd (49.40k/49.40k flops)\n",
      "  model_43/conv2d_609/BiasAdd (49.40k/49.40k flops)\n",
      "  model_43/batch_normalization_1172/FusedBatchNormV3 (47.79k/47.79k flops)\n",
      "  model_43/conv2d_611/BiasAdd (46.60k/46.60k flops)\n",
      "  model_43/depthwise_conv2d_568/BiasAdd (46.60k/46.60k flops)\n",
      "  model_43/depthwise_conv2d_562/BiasAdd (44.00k/44.00k flops)\n",
      "  model_43/depthwise_conv2d_567/BiasAdd (40.00k/40.00k flops)\n",
      "  model_43/conv2d_610/BiasAdd (40.00k/40.00k flops)\n",
      "  model_43/batch_normalization_1185/FusedBatchNormV3 (35.95k/35.95k flops)\n",
      "  model_43/conv2d_613/BiasAdd (30.60k/30.60k flops)\n",
      "  model_43/depthwise_conv2d_569/BiasAdd (28.40k/28.40k flops)\n",
      "  model_43/conv2d_612/BiasAdd (28.40k/28.40k flops)\n",
      "  model_43/depthwise_conv2d_565/BiasAdd (25.60k/25.60k flops)\n",
      "  model_43/conv2d_608/BiasAdd (25.60k/25.60k flops)\n",
      "  model_43/depthwise_conv2d_564/BiasAdd (23.20k/23.20k flops)\n",
      "  model_43/batch_normalization_1187/FusedBatchNormV3 (18.48k/18.48k flops)\n",
      "  model_43/batch_normalization_1184/FusedBatchNormV3 (17.14k/17.14k flops)\n",
      "  model_43/conv2d_614/BiasAdd (16.05k/16.05k flops)\n",
      "  model_43/batch_normalization_1186/FusedBatchNormV3 (15.41k/15.41k flops)\n",
      "  model_43/dense_43/MatMul (15.40k/15.40k flops)\n",
      "  model_43/depthwise_conv2d_570/BiasAdd (7.65k/7.65k flops)\n",
      "  model_43/conv2d_615/BiasAdd (6.93k/6.93k flops)\n",
      "  model_43/global_average_pooling2d_43/Mean (6.93k/6.93k flops)\n",
      "  model_43/depthwise_conv2d_571/BiasAdd (5.78k/5.78k flops)\n",
      "  model_43/dense_43/Softmax (50/50 flops)\n",
      "  model_43/dense_43/BiasAdd (10/10 flops)\n",
      "\n",
      "======================End of Report==========================\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "23.779556\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-30 13:40:19.667342: I tensorflow/core/grappler/devices.cc:66] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0\n",
      "2022-04-30 13:40:19.667456: I tensorflow/core/grappler/clusters/single_machine.cc:357] Starting new session\n",
      "2022-04-30 13:40:19.672059: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:1137] Optimization results for grappler item: graph_to_optimize\n",
      "  function_optimizer: function_optimizer did nothing. time = 0.006ms.\n",
      "  function_optimizer: function_optimizer did nothing. time = 0.001ms.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=========================Options=============================\n",
      "-max_depth                  10000\n",
      "-min_bytes                  0\n",
      "-min_peak_bytes             0\n",
      "-min_residual_bytes         0\n",
      "-min_output_bytes           0\n",
      "-min_micros                 0\n",
      "-min_accelerator_micros     0\n",
      "-min_cpu_micros             0\n",
      "-min_params                 0\n",
      "-min_float_ops              1\n",
      "-min_occurrence             0\n",
      "-step                       -1\n",
      "-order_by                   float_ops\n",
      "-account_type_regexes       .*\n",
      "-start_name_regexes         .*\n",
      "-trim_name_regexes          \n",
      "-show_name_regexes          .*\n",
      "-hide_name_regexes          \n",
      "-account_displayed_op_only  true\n",
      "-select                     float_ops\n",
      "-output                     stdout:\n",
      "\n",
      "==================Model Analysis Report======================\n",
      "\n",
      "Doc:\n",
      "scope: The nodes in the model graph are organized by their names, which is hierarchical like filesystem.\n",
      "flops: Number of float operations. Note: Please read the implementation for the math behind it.\n",
      "\n",
      "Profile:\n",
      "node name | # float_ops\n",
      "_TFProfRoot (--/413.21m flops)\n",
      "  model_44/conv2d_626/Conv2D (50.00m/50.00m flops)\n",
      "  model_44/conv2d_627/Conv2D (49.80m/49.80m flops)\n",
      "  model_44/conv2d_625/Conv2D (49.00m/49.00m flops)\n",
      "  model_44/conv2d_624/Conv2D (46.44m/46.44m flops)\n",
      "  model_44/conv2d_623/Conv2D (43.99m/43.99m flops)\n",
      "  model_44/conv2d_619/Conv2D (27.65m/27.65m flops)\n",
      "  model_44/conv2d_622/Conv2D (23.40m/23.40m flops)\n",
      "  model_44/conv2d_628/Conv2D (23.07m/23.07m flops)\n",
      "  model_44/conv2d_621/Conv2D (22.40m/22.40m flops)\n",
      "  model_44/conv2d_629/Conv2D (17.15m/17.15m flops)\n",
      "  model_44/conv2d_617/Conv2D (14.75m/14.75m flops)\n",
      "  model_44/conv2d_618/Conv2D (10.37m/10.37m flops)\n",
      "  model_44/conv2d_620/Conv2D (8.60m/8.60m flops)\n",
      "  model_44/conv2d_616/Conv2D (6.55m/6.55m flops)\n",
      "  model_44/depthwise_conv2d_572/depthwise (3.69m/3.69m flops)\n",
      "  model_44/depthwise_conv2d_574/depthwise (2.59m/2.59m flops)\n",
      "  model_44/depthwise_conv2d_573/depthwise (1.04m/1.04m flops)\n",
      "  model_44/depthwise_conv2d_582/depthwise (907.20k/907.20k flops)\n",
      "  model_44/depthwise_conv2d_581/depthwise (892.80k/892.80k flops)\n",
      "  model_44/depthwise_conv2d_580/depthwise (889.20k/889.20k flops)\n",
      "  model_44/depthwise_conv2d_579/depthwise (846.00k/846.00k flops)\n",
      "  model_44/depthwise_conv2d_578/depthwise (842.40k/842.40k flops)\n",
      "  model_44/depthwise_conv2d_576/depthwise (806.40k/806.40k flops)\n",
      "  model_44/depthwise_conv2d_575/depthwise (691.20k/691.20k flops)\n",
      "  model_44/batch_normalization_1190/FusedBatchNormV3 (461.02k/461.02k flops)\n",
      "  model_44/depthwise_conv2d_577/depthwise (450.00k/450.00k flops)\n",
      "  model_44/batch_normalization_1189/FusedBatchNormV3 (409.79k/409.79k flops)\n",
      "  model_44/batch_normalization_1188/FusedBatchNormV3 (409.79k/409.79k flops)\n",
      "  model_44/batch_normalization_1194/FusedBatchNormV3 (307.78k/307.78k flops)\n",
      "  model_44/batch_normalization_1192/FusedBatchNormV3 (288.54k/288.54k flops)\n",
      "  model_44/batch_normalization_1193/FusedBatchNormV3 (288.54k/288.54k flops)\n",
      "  model_44/conv2d_617/BiasAdd (230.40k/230.40k flops)\n",
      "  model_44/depthwise_conv2d_583/depthwise (222.30k/222.30k flops)\n",
      "  model_44/depthwise_conv2d_572/BiasAdd (204.80k/204.80k flops)\n",
      "  model_44/conv2d_616/BiasAdd (204.80k/204.80k flops)\n",
      "  model_44/batch_normalization_1198/FusedBatchNormV3 (201.50k/201.50k flops)\n",
      "  model_44/conv2d_619/BiasAdd (153.60k/153.60k flops)\n",
      "  model_44/depthwise_conv2d_584/depthwise (151.31k/151.31k flops)\n",
      "  model_44/conv2d_618/BiasAdd (144.00k/144.00k flops)\n",
      "  model_44/depthwise_conv2d_574/BiasAdd (144.00k/144.00k flops)\n",
      "  model_44/batch_normalization_1191/FusedBatchNormV3 (115.42k/115.42k flops)\n",
      "  model_44/batch_normalization_1208/FusedBatchNormV3 (103.82k/103.82k flops)\n",
      "  model_44/batch_normalization_1209/FusedBatchNormV3 (103.82k/103.82k flops)\n",
      "  model_44/batch_normalization_1207/FusedBatchNormV3 (102.18k/102.18k flops)\n",
      "  model_44/batch_normalization_1206/FusedBatchNormV3 (102.18k/102.18k flops)\n",
      "  model_44/batch_normalization_1205/FusedBatchNormV3 (101.76k/101.76k flops)\n",
      "  model_44/batch_normalization_1204/FusedBatchNormV3 (101.76k/101.76k flops)\n",
      "  model_44/batch_normalization_1210/FusedBatchNormV3 (101.76k/101.76k flops)\n",
      "  model_44/conv2d_621/BiasAdd (100.00k/100.00k flops)\n",
      "  model_44/batch_normalization_1203/FusedBatchNormV3 (96.82k/96.82k flops)\n",
      "  model_44/batch_normalization_1202/FusedBatchNormV3 (96.82k/96.82k flops)\n",
      "  model_44/batch_normalization_1200/FusedBatchNormV3 (96.41k/96.41k flops)\n",
      "  model_44/batch_normalization_1201/FusedBatchNormV3 (96.41k/96.41k flops)\n",
      "  model_44/batch_normalization_1197/FusedBatchNormV3 (90.27k/90.27k flops)\n",
      "  model_44/batch_normalization_1196/FusedBatchNormV3 (90.27k/90.27k flops)\n",
      "  model_44/batch_normalization_1195/FusedBatchNormV3 (77.38k/77.38k flops)\n",
      "  model_44/depthwise_conv2d_573/BiasAdd (57.60k/57.60k flops)\n",
      "  model_44/batch_normalization_1212/FusedBatchNormV3 (52.30k/52.30k flops)\n",
      "  model_44/batch_normalization_1199/FusedBatchNormV3 (51.50k/51.50k flops)\n",
      "  model_44/depthwise_conv2d_582/BiasAdd (50.40k/50.40k flops)\n",
      "  model_44/conv2d_626/BiasAdd (50.40k/50.40k flops)\n",
      "  model_44/conv2d_625/BiasAdd (49.60k/49.60k flops)\n",
      "  model_44/depthwise_conv2d_581/BiasAdd (49.60k/49.60k flops)\n",
      "  model_44/conv2d_627/BiasAdd (49.40k/49.40k flops)\n",
      "  model_44/conv2d_624/BiasAdd (49.40k/49.40k flops)\n",
      "  model_44/depthwise_conv2d_580/BiasAdd (49.40k/49.40k flops)\n",
      "  model_44/conv2d_623/BiasAdd (47.00k/47.00k flops)\n",
      "  model_44/depthwise_conv2d_579/BiasAdd (47.00k/47.00k flops)\n",
      "  model_44/conv2d_622/BiasAdd (46.80k/46.80k flops)\n",
      "  model_44/depthwise_conv2d_578/BiasAdd (46.80k/46.80k flops)\n",
      "  model_44/conv2d_620/BiasAdd (44.80k/44.80k flops)\n",
      "  model_44/depthwise_conv2d_576/BiasAdd (44.80k/44.80k flops)\n",
      "  model_44/depthwise_conv2d_575/BiasAdd (38.40k/38.40k flops)\n",
      "  model_44/batch_normalization_1211/FusedBatchNormV3 (27.66k/27.66k flops)\n",
      "  model_44/depthwise_conv2d_577/BiasAdd (25.00k/25.00k flops)\n",
      "  model_44/batch_normalization_1214/FusedBatchNormV3 (24.48k/24.48k flops)\n",
      "  model_44/conv2d_628/BiasAdd (23.35k/23.35k flops)\n",
      "  model_44/batch_normalization_1213/FusedBatchNormV3 (22.42k/22.42k flops)\n",
      "  model_44/dense_44/MatMul (20.40k/20.40k flops)\n",
      "  model_44/depthwise_conv2d_583/BiasAdd (12.35k/12.35k flops)\n",
      "  model_44/conv2d_629/BiasAdd (9.18k/9.18k flops)\n",
      "  model_44/global_average_pooling2d_44/Mean (9.18k/9.18k flops)\n",
      "  model_44/depthwise_conv2d_584/BiasAdd (8.41k/8.41k flops)\n",
      "  model_44/dense_44/Softmax (50/50 flops)\n",
      "  model_44/dense_44/BiasAdd (10/10 flops)\n",
      "\n",
      "======================End of Report==========================\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "23.822292\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-30 13:40:20.614321: I tensorflow/core/grappler/devices.cc:66] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0\n",
      "2022-04-30 13:40:20.614438: I tensorflow/core/grappler/clusters/single_machine.cc:357] Starting new session\n",
      "2022-04-30 13:40:20.618536: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:1137] Optimization results for grappler item: graph_to_optimize\n",
      "  function_optimizer: function_optimizer did nothing. time = 0.005ms.\n",
      "  function_optimizer: function_optimizer did nothing. time = 0.001ms.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=========================Options=============================\n",
      "-max_depth                  10000\n",
      "-min_bytes                  0\n",
      "-min_peak_bytes             0\n",
      "-min_residual_bytes         0\n",
      "-min_output_bytes           0\n",
      "-min_micros                 0\n",
      "-min_accelerator_micros     0\n",
      "-min_cpu_micros             0\n",
      "-min_params                 0\n",
      "-min_float_ops              1\n",
      "-min_occurrence             0\n",
      "-step                       -1\n",
      "-order_by                   float_ops\n",
      "-account_type_regexes       .*\n",
      "-start_name_regexes         .*\n",
      "-trim_name_regexes          \n",
      "-show_name_regexes          .*\n",
      "-hide_name_regexes          \n",
      "-account_displayed_op_only  true\n",
      "-select                     float_ops\n",
      "-output                     stdout:\n",
      "\n",
      "==================Model Analysis Report======================\n",
      "\n",
      "Doc:\n",
      "scope: The nodes in the model graph are organized by their names, which is hierarchical like filesystem.\n",
      "flops: Number of float operations. Note: Please read the implementation for the math behind it.\n",
      "\n",
      "Profile:\n",
      "node name | # float_ops\n",
      "_TFProfRoot (--/372.32m flops)\n",
      "  model_45/conv2d_638/Conv2D (49.00m/49.00m flops)\n",
      "  model_45/conv2d_639/Conv2D (46.26m/46.26m flops)\n",
      "  model_45/conv2d_637/Conv2D (39.36m/39.36m flops)\n",
      "  model_45/conv2d_640/Conv2D (39.25m/39.25m flops)\n",
      "  model_45/conv2d_641/Conv2D (39.25m/39.25m flops)\n",
      "  model_45/conv2d_635/Conv2D (27.60m/27.60m flops)\n",
      "  model_45/conv2d_633/Conv2D (25.10m/25.10m flops)\n",
      "  model_45/conv2d_631/Conv2D (18.02m/18.02m flops)\n",
      "  model_45/conv2d_636/Conv2D (17.56m/17.56m flops)\n",
      "  model_45/conv2d_642/Conv2D (14.08m/14.08m flops)\n",
      "  model_45/conv2d_634/Conv2D (13.06m/13.06m flops)\n",
      "  model_45/conv2d_632/Conv2D (10.42m/10.42m flops)\n",
      "  model_45/conv2d_643/Conv2D (7.04m/7.04m flops)\n",
      "  model_45/conv2d_630/Conv2D (6.55m/6.55m flops)\n",
      "  model_45/depthwise_conv2d_585/depthwise (3.69m/3.69m flops)\n",
      "  model_45/depthwise_conv2d_587/depthwise (2.13m/2.13m flops)\n",
      "  model_45/depthwise_conv2d_586/depthwise (1.27m/1.27m flops)\n",
      "  model_45/depthwise_conv2d_589/depthwise (1.11m/1.11m flops)\n",
      "  model_45/depthwise_conv2d_592/depthwise (903.60k/903.60k flops)\n",
      "  model_45/depthwise_conv2d_593/depthwise (878.40k/878.40k flops)\n",
      "  model_45/depthwise_conv2d_594/depthwise (853.20k/853.20k flops)\n",
      "  model_45/depthwise_conv2d_588/depthwise (763.20k/763.20k flops)\n",
      "  model_45/depthwise_conv2d_595/depthwise (745.20k/745.20k flops)\n",
      "  model_45/depthwise_conv2d_591/depthwise (705.60k/705.60k flops)\n",
      "  model_45/batch_normalization_1217/FusedBatchNormV3 (563.46k/563.46k flops)\n",
      "  model_45/batch_normalization_1216/FusedBatchNormV3 (409.79k/409.79k flops)\n",
      "  model_45/batch_normalization_1215/FusedBatchNormV3 (409.79k/409.79k flops)\n",
      "  model_45/depthwise_conv2d_590/depthwise (403.20k/403.20k flops)\n",
      "  model_45/batch_normalization_1221/FusedBatchNormV3 (339.84k/339.84k flops)\n",
      "  model_45/conv2d_631/BiasAdd (281.60k/281.60k flops)\n",
      "  model_45/batch_normalization_1219/FusedBatchNormV3 (237.24k/237.24k flops)\n",
      "  model_45/batch_normalization_1220/FusedBatchNormV3 (237.24k/237.24k flops)\n",
      "  model_45/depthwise_conv2d_596/depthwise (213.30k/213.30k flops)\n",
      "  model_45/conv2d_630/BiasAdd (204.80k/204.80k flops)\n",
      "  model_45/depthwise_conv2d_585/BiasAdd (204.80k/204.80k flops)\n",
      "  model_45/batch_normalization_1225/FusedBatchNormV3 (180.54k/180.54k flops)\n",
      "  model_45/conv2d_633/BiasAdd (169.60k/169.60k flops)\n",
      "  model_45/batch_normalization_1218/FusedBatchNormV3 (141.06k/141.06k flops)\n",
      "  model_45/batch_normalization_1223/FusedBatchNormV3 (124.12k/124.12k flops)\n",
      "  model_45/batch_normalization_1224/FusedBatchNormV3 (124.12k/124.12k flops)\n",
      "  model_45/conv2d_632/BiasAdd (118.40k/118.40k flops)\n",
      "  model_45/depthwise_conv2d_587/BiasAdd (118.40k/118.40k flops)\n",
      "  model_45/batch_normalization_1230/FusedBatchNormV3 (103.41k/103.41k flops)\n",
      "  model_45/batch_normalization_1229/FusedBatchNormV3 (103.41k/103.41k flops)\n",
      "  model_45/batch_normalization_1232/FusedBatchNormV3 (100.53k/100.53k flops)\n",
      "  model_45/batch_normalization_1231/FusedBatchNormV3 (100.53k/100.53k flops)\n",
      "  model_45/batch_normalization_1233/FusedBatchNormV3 (97.64k/97.64k flops)\n",
      "  model_45/batch_normalization_1234/FusedBatchNormV3 (97.64k/97.64k flops)\n",
      "  model_45/batch_normalization_1237/FusedBatchNormV3 (97.64k/97.64k flops)\n",
      "  model_45/depthwise_conv2d_597/depthwise (96.23k/96.23k flops)\n",
      "  model_45/conv2d_635/BiasAdd (89.60k/89.60k flops)\n",
      "  model_45/batch_normalization_1222/FusedBatchNormV3 (85.44k/85.44k flops)\n",
      "  model_45/batch_normalization_1236/FusedBatchNormV3 (85.28k/85.28k flops)\n",
      "  model_45/batch_normalization_1235/FusedBatchNormV3 (85.28k/85.28k flops)\n",
      "  model_45/batch_normalization_1227/FusedBatchNormV3 (80.75k/80.75k flops)\n",
      "  model_45/batch_normalization_1228/FusedBatchNormV3 (80.75k/80.75k flops)\n",
      "  model_45/depthwise_conv2d_586/BiasAdd (70.40k/70.40k flops)\n",
      "  model_45/conv2d_634/BiasAdd (61.60k/61.60k flops)\n",
      "  model_45/depthwise_conv2d_589/BiasAdd (61.60k/61.60k flops)\n",
      "  model_45/depthwise_conv2d_592/BiasAdd (50.20k/50.20k flops)\n",
      "  model_45/conv2d_637/BiasAdd (50.20k/50.20k flops)\n",
      "  model_45/depthwise_conv2d_593/BiasAdd (48.80k/48.80k flops)\n",
      "  model_45/conv2d_638/BiasAdd (48.80k/48.80k flops)\n",
      "  model_45/depthwise_conv2d_594/BiasAdd (47.40k/47.40k flops)\n",
      "  model_45/conv2d_641/BiasAdd (47.40k/47.40k flops)\n",
      "  model_45/conv2d_639/BiasAdd (47.40k/47.40k flops)\n",
      "  model_45/batch_normalization_1226/FusedBatchNormV3 (46.14k/46.14k flops)\n",
      "  model_45/depthwise_conv2d_588/BiasAdd (42.40k/42.40k flops)\n",
      "  model_45/conv2d_640/BiasAdd (41.40k/41.40k flops)\n",
      "  model_45/depthwise_conv2d_595/BiasAdd (41.40k/41.40k flops)\n",
      "  model_45/depthwise_conv2d_591/BiasAdd (39.20k/39.20k flops)\n",
      "  model_45/conv2d_636/BiasAdd (39.20k/39.20k flops)\n",
      "  model_45/batch_normalization_1239/FusedBatchNormV3 (33.26k/33.26k flops)\n",
      "  model_45/batch_normalization_1238/FusedBatchNormV3 (26.54k/26.54k flops)\n",
      "  model_45/depthwise_conv2d_590/BiasAdd (22.40k/22.40k flops)\n",
      "  model_45/batch_normalization_1241/FusedBatchNormV3 (15.79k/15.79k flops)\n",
      "  model_45/conv2d_642/BiasAdd (14.85k/14.85k flops)\n",
      "  model_45/batch_normalization_1240/FusedBatchNormV3 (14.26k/14.26k flops)\n",
      "  model_45/dense_45/MatMul (13.16k/13.16k flops)\n",
      "  model_45/depthwise_conv2d_596/BiasAdd (11.85k/11.85k flops)\n",
      "  model_45/global_average_pooling2d_45/Mean (5.92k/5.92k flops)\n",
      "  model_45/conv2d_643/BiasAdd (5.92k/5.92k flops)\n",
      "  model_45/depthwise_conv2d_597/BiasAdd (5.35k/5.35k flops)\n",
      "  model_45/dense_45/Softmax (50/50 flops)\n",
      "  model_45/dense_45/BiasAdd (10/10 flops)\n",
      "\n",
      "======================End of Report==========================\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "25.902676\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-30 13:40:21.632212: I tensorflow/core/grappler/devices.cc:66] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0\n",
      "2022-04-30 13:40:21.632329: I tensorflow/core/grappler/clusters/single_machine.cc:357] Starting new session\n",
      "2022-04-30 13:40:21.636894: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:1137] Optimization results for grappler item: graph_to_optimize\n",
      "  function_optimizer: function_optimizer did nothing. time = 0.006ms.\n",
      "  function_optimizer: function_optimizer did nothing. time = 0ms.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=========================Options=============================\n",
      "-max_depth                  10000\n",
      "-min_bytes                  0\n",
      "-min_peak_bytes             0\n",
      "-min_residual_bytes         0\n",
      "-min_output_bytes           0\n",
      "-min_micros                 0\n",
      "-min_accelerator_micros     0\n",
      "-min_cpu_micros             0\n",
      "-min_params                 0\n",
      "-min_float_ops              1\n",
      "-min_occurrence             0\n",
      "-step                       -1\n",
      "-order_by                   float_ops\n",
      "-account_type_regexes       .*\n",
      "-start_name_regexes         .*\n",
      "-trim_name_regexes          \n",
      "-show_name_regexes          .*\n",
      "-hide_name_regexes          \n",
      "-account_displayed_op_only  true\n",
      "-select                     float_ops\n",
      "-output                     stdout:\n",
      "\n",
      "==================Model Analysis Report======================\n",
      "\n",
      "Doc:\n",
      "scope: The nodes in the model graph are organized by their names, which is hierarchical like filesystem.\n",
      "flops: Number of float operations. Note: Please read the implementation for the math behind it.\n",
      "\n",
      "Profile:\n",
      "node name | # float_ops\n",
      "_TFProfRoot (--/342.80m flops)\n",
      "  model_46/conv2d_649/Conv2D (48.01m/48.01m flops)\n",
      "  model_46/conv2d_653/Conv2D (31.13m/31.13m flops)\n",
      "  model_46/conv2d_647/Conv2D (30.96m/30.96m flops)\n",
      "  model_46/conv2d_654/Conv2D (30.55m/30.55m flops)\n",
      "  model_46/conv2d_652/Conv2D (30.44m/30.44m flops)\n",
      "  model_46/conv2d_655/Conv2D (29.88m/29.88m flops)\n",
      "  model_46/conv2d_645/Conv2D (25.40m/25.40m flops)\n",
      "  model_46/conv2d_648/Conv2D (22.84m/22.84m flops)\n",
      "  model_46/conv2d_651/Conv2D (18.55m/18.55m flops)\n",
      "  model_46/conv2d_646/Conv2D (16.27m/16.27m flops)\n",
      "  model_46/conv2d_650/Conv2D (13.00m/13.00m flops)\n",
      "  model_46/conv2d_656/Conv2D (9.17m/9.17m flops)\n",
      "  model_46/conv2d_657/Conv2D (9.08m/9.08m flops)\n",
      "  model_46/conv2d_644/Conv2D (6.55m/6.55m flops)\n",
      "  model_46/depthwise_conv2d_598/depthwise (3.69m/3.69m flops)\n",
      "  model_46/depthwise_conv2d_600/depthwise (2.36m/2.36m flops)\n",
      "  model_46/depthwise_conv2d_599/depthwise (1.79m/1.79m flops)\n",
      "  model_46/depthwise_conv2d_602/depthwise (1.74m/1.74m flops)\n",
      "  model_46/depthwise_conv2d_601/depthwise (849.60k/849.60k flops)\n",
      "  model_46/batch_normalization_1244/FusedBatchNormV3 (793.97k/793.97k flops)\n",
      "  model_46/depthwise_conv2d_606/depthwise (774.00k/774.00k flops)\n",
      "  model_46/depthwise_conv2d_608/depthwise (759.60k/759.60k flops)\n",
      "  model_46/depthwise_conv2d_607/depthwise (651.60k/651.60k flops)\n",
      "  model_46/depthwise_conv2d_605/depthwise (637.20k/637.20k flops)\n",
      "  model_46/depthwise_conv2d_604/depthwise (471.60k/471.60k flops)\n",
      "  model_46/depthwise_conv2d_603/depthwise (446.40k/446.40k flops)\n",
      "  model_46/batch_normalization_1243/FusedBatchNormV3 (409.79k/409.79k flops)\n",
      "  model_46/batch_normalization_1242/FusedBatchNormV3 (409.79k/409.79k flops)\n",
      "  model_46/conv2d_645/BiasAdd (396.80k/396.80k flops)\n",
      "  model_46/batch_normalization_1248/FusedBatchNormV3 (378.31k/378.31k flops)\n",
      "  model_46/batch_normalization_1246/FusedBatchNormV3 (262.89k/262.89k flops)\n",
      "  model_46/batch_normalization_1247/FusedBatchNormV3 (262.89k/262.89k flops)\n",
      "  model_46/depthwise_conv2d_598/BiasAdd (204.80k/204.80k flops)\n",
      "  model_46/conv2d_644/BiasAdd (204.80k/204.80k flops)\n",
      "  model_46/batch_normalization_1252/FusedBatchNormV3 (199.89k/199.89k flops)\n",
      "  model_46/batch_normalization_1245/FusedBatchNormV3 (198.77k/198.77k flops)\n",
      "  model_46/batch_normalization_1251/FusedBatchNormV3 (195.05k/195.05k flops)\n",
      "  model_46/batch_normalization_1250/FusedBatchNormV3 (195.05k/195.05k flops)\n",
      "  model_46/conv2d_647/BiasAdd (188.80k/188.80k flops)\n",
      "  model_46/depthwise_conv2d_609/depthwise (159.30k/159.30k flops)\n",
      "  model_46/conv2d_646/BiasAdd (131.20k/131.20k flops)\n",
      "  model_46/depthwise_conv2d_600/BiasAdd (131.20k/131.20k flops)\n",
      "  model_46/conv2d_649/BiasAdd (99.20k/99.20k flops)\n",
      "  model_46/depthwise_conv2d_599/BiasAdd (99.20k/99.20k flops)\n",
      "  model_46/depthwise_conv2d_602/BiasAdd (96.80k/96.80k flops)\n",
      "  model_46/conv2d_648/BiasAdd (96.80k/96.80k flops)\n",
      "  model_46/batch_normalization_1249/FusedBatchNormV3 (95.11k/95.11k flops)\n",
      "  model_46/batch_normalization_1259/FusedBatchNormV3 (88.58k/88.58k flops)\n",
      "  model_46/batch_normalization_1258/FusedBatchNormV3 (88.58k/88.58k flops)\n",
      "  model_46/batch_normalization_1262/FusedBatchNormV3 (86.93k/86.93k flops)\n",
      "  model_46/batch_normalization_1263/FusedBatchNormV3 (86.93k/86.93k flops)\n",
      "  model_46/depthwise_conv2d_610/depthwise (83.92k/83.92k flops)\n",
      "  model_46/batch_normalization_1260/FusedBatchNormV3 (74.57k/74.57k flops)\n",
      "  model_46/batch_normalization_1261/FusedBatchNormV3 (74.57k/74.57k flops)\n",
      "  model_46/batch_normalization_1256/FusedBatchNormV3 (72.92k/72.92k flops)\n",
      "  model_46/batch_normalization_1257/FusedBatchNormV3 (72.92k/72.92k flops)\n",
      "  model_46/batch_normalization_1264/FusedBatchNormV3 (72.92k/72.92k flops)\n",
      "  model_46/batch_normalization_1255/FusedBatchNormV3 (53.97k/53.97k flops)\n",
      "  model_46/batch_normalization_1254/FusedBatchNormV3 (53.97k/53.97k flops)\n",
      "  model_46/batch_normalization_1253/FusedBatchNormV3 (51.09k/51.09k flops)\n",
      "  model_46/depthwise_conv2d_601/BiasAdd (47.20k/47.20k flops)\n",
      "  model_46/depthwise_conv2d_606/BiasAdd (43.00k/43.00k flops)\n",
      "  model_46/conv2d_652/BiasAdd (43.00k/43.00k flops)\n",
      "  model_46/depthwise_conv2d_608/BiasAdd (42.20k/42.20k flops)\n",
      "  model_46/conv2d_654/BiasAdd (42.20k/42.20k flops)\n",
      "  model_46/depthwise_conv2d_607/BiasAdd (36.20k/36.20k flops)\n",
      "  model_46/conv2d_653/BiasAdd (36.20k/36.20k flops)\n",
      "  model_46/conv2d_655/BiasAdd (35.40k/35.40k flops)\n",
      "  model_46/conv2d_651/BiasAdd (35.40k/35.40k flops)\n",
      "  model_46/depthwise_conv2d_605/BiasAdd (35.40k/35.40k flops)\n",
      "  model_46/batch_normalization_1266/FusedBatchNormV3 (29.01k/29.01k flops)\n",
      "  model_46/depthwise_conv2d_604/BiasAdd (26.20k/26.20k flops)\n",
      "  model_46/conv2d_650/BiasAdd (26.20k/26.20k flops)\n",
      "  model_46/depthwise_conv2d_603/BiasAdd (24.80k/24.80k flops)\n",
      "  model_46/batch_normalization_1268/FusedBatchNormV3 (23.38k/23.38k flops)\n",
      "  model_46/batch_normalization_1265/FusedBatchNormV3 (19.82k/19.82k flops)\n",
      "  model_46/dense_46/MatMul (19.48k/19.48k flops)\n",
      "  model_46/conv2d_656/BiasAdd (12.95k/12.95k flops)\n",
      "  model_46/batch_normalization_1267/FusedBatchNormV3 (12.43k/12.43k flops)\n",
      "  model_46/depthwise_conv2d_609/BiasAdd (8.85k/8.85k flops)\n",
      "  model_46/conv2d_657/BiasAdd (8.77k/8.77k flops)\n",
      "  model_46/global_average_pooling2d_46/Mean (8.77k/8.77k flops)\n",
      "  model_46/depthwise_conv2d_610/BiasAdd (4.66k/4.66k flops)\n",
      "  model_46/dense_46/Softmax (50/50 flops)\n",
      "  model_46/dense_46/BiasAdd (10/10 flops)\n",
      "\n",
      "======================End of Report==========================\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "23.123364\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-30 13:40:22.554307: I tensorflow/core/grappler/devices.cc:66] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0\n",
      "2022-04-30 13:40:22.554425: I tensorflow/core/grappler/clusters/single_machine.cc:357] Starting new session\n",
      "2022-04-30 13:40:22.558612: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:1137] Optimization results for grappler item: graph_to_optimize\n",
      "  function_optimizer: function_optimizer did nothing. time = 0.005ms.\n",
      "  function_optimizer: function_optimizer did nothing. time = 0.001ms.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=========================Options=============================\n",
      "-max_depth                  10000\n",
      "-min_bytes                  0\n",
      "-min_peak_bytes             0\n",
      "-min_residual_bytes         0\n",
      "-min_output_bytes           0\n",
      "-min_micros                 0\n",
      "-min_accelerator_micros     0\n",
      "-min_cpu_micros             0\n",
      "-min_params                 0\n",
      "-min_float_ops              1\n",
      "-min_occurrence             0\n",
      "-step                       -1\n",
      "-order_by                   float_ops\n",
      "-account_type_regexes       .*\n",
      "-start_name_regexes         .*\n",
      "-trim_name_regexes          \n",
      "-show_name_regexes          .*\n",
      "-hide_name_regexes          \n",
      "-account_displayed_op_only  true\n",
      "-select                     float_ops\n",
      "-output                     stdout:\n",
      "\n",
      "==================Model Analysis Report======================\n",
      "\n",
      "Doc:\n",
      "scope: The nodes in the model graph are organized by their names, which is hierarchical like filesystem.\n",
      "flops: Number of float operations. Note: Please read the implementation for the math behind it.\n",
      "\n",
      "Profile:\n",
      "node name | # float_ops\n",
      "_TFProfRoot (--/278.83m flops)\n",
      "  model_47/conv2d_666/Conv2D (32.59m/32.59m flops)\n",
      "  model_47/conv2d_665/Conv2D (30.16m/30.16m flops)\n",
      "  model_47/conv2d_669/Conv2D (29.77m/29.77m flops)\n",
      "  model_47/conv2d_668/Conv2D (25.73m/25.73m flops)\n",
      "  model_47/conv2d_661/Conv2D (24.22m/24.22m flops)\n",
      "  model_47/conv2d_659/Conv2D (23.76m/23.76m flops)\n",
      "  model_47/conv2d_667/Conv2D (22.15m/22.15m flops)\n",
      "  model_47/conv2d_660/Conv2D (15.96m/15.96m flops)\n",
      "  model_47/conv2d_663/Conv2D (11.79m/11.79m flops)\n",
      "  model_47/conv2d_670/Conv2D (11.50m/11.50m flops)\n",
      "  model_47/conv2d_671/Conv2D (9.97m/9.97m flops)\n",
      "  model_47/conv2d_664/Conv2D (7.99m/7.99m flops)\n",
      "  model_47/conv2d_662/Conv2D (7.74m/7.74m flops)\n",
      "  model_47/conv2d_658/Conv2D (6.55m/6.55m flops)\n",
      "  model_47/depthwise_conv2d_611/depthwise (3.69m/3.69m flops)\n",
      "  model_47/depthwise_conv2d_613/depthwise (2.48m/2.48m flops)\n",
      "  model_47/depthwise_conv2d_612/depthwise (1.67m/1.67m flops)\n",
      "  model_47/depthwise_conv2d_618/depthwise (910.80k/910.80k flops)\n",
      "  model_47/depthwise_conv2d_615/depthwise (792.00k/792.00k flops)\n",
      "  model_47/batch_normalization_1271/FusedBatchNormV3 (742.75k/742.75k flops)\n",
      "  model_47/depthwise_conv2d_621/depthwise (673.20k/673.20k flops)\n",
      "  model_47/depthwise_conv2d_614/depthwise (633.60k/633.60k flops)\n",
      "  model_47/depthwise_conv2d_620/depthwise (619.20k/619.20k flops)\n",
      "  model_47/depthwise_conv2d_619/depthwise (579.60k/579.60k flops)\n",
      "  model_47/depthwise_conv2d_617/depthwise (536.40k/536.40k flops)\n",
      "  model_47/batch_normalization_1270/FusedBatchNormV3 (409.79k/409.79k flops)\n",
      "  model_47/batch_normalization_1269/FusedBatchNormV3 (409.79k/409.79k flops)\n",
      "  model_47/conv2d_659/BiasAdd (371.20k/371.20k flops)\n",
      "  model_47/batch_normalization_1275/FusedBatchNormV3 (282.13k/282.13k flops)\n",
      "  model_47/batch_normalization_1274/FusedBatchNormV3 (275.72k/275.72k flops)\n",
      "  model_47/batch_normalization_1273/FusedBatchNormV3 (275.72k/275.72k flops)\n",
      "  model_47/depthwise_conv2d_616/depthwise (241.20k/241.20k flops)\n",
      "  model_47/conv2d_658/BiasAdd (204.80k/204.80k flops)\n",
      "  model_47/depthwise_conv2d_611/BiasAdd (204.80k/204.80k flops)\n",
      "  model_47/batch_normalization_1272/FusedBatchNormV3 (185.95k/185.95k flops)\n",
      "  model_47/depthwise_conv2d_622/depthwise (179.10k/179.10k flops)\n",
      "  model_47/conv2d_661/BiasAdd (140.80k/140.80k flops)\n",
      "  model_47/depthwise_conv2d_613/BiasAdd (137.60k/137.60k flops)\n",
      "  model_47/conv2d_660/BiasAdd (137.60k/137.60k flops)\n",
      "  model_47/batch_normalization_1279/FusedBatchNormV3 (108.00k/108.00k flops)\n",
      "  model_47/batch_normalization_1283/FusedBatchNormV3 (104.24k/104.24k flops)\n",
      "  model_47/batch_normalization_1284/FusedBatchNormV3 (104.24k/104.24k flops)\n",
      "  model_47/depthwise_conv2d_623/depthwise (93.64k/93.64k flops)\n",
      "  model_47/depthwise_conv2d_612/BiasAdd (92.80k/92.80k flops)\n",
      "  model_47/batch_normalization_1278/FusedBatchNormV3 (88.66k/88.66k flops)\n",
      "  model_47/batch_normalization_1277/FusedBatchNormV3 (88.66k/88.66k flops)\n",
      "  model_47/batch_normalization_1291/FusedBatchNormV3 (81.99k/81.99k flops)\n",
      "  model_47/batch_normalization_1289/FusedBatchNormV3 (77.04k/77.04k flops)\n",
      "  model_47/batch_normalization_1290/FusedBatchNormV3 (77.04k/77.04k flops)\n",
      "  model_47/batch_normalization_1276/FusedBatchNormV3 (70.93k/70.93k flops)\n",
      "  model_47/batch_normalization_1287/FusedBatchNormV3 (70.86k/70.86k flops)\n",
      "  model_47/batch_normalization_1288/FusedBatchNormV3 (70.86k/70.86k flops)\n",
      "  model_47/batch_normalization_1285/FusedBatchNormV3 (66.33k/66.33k flops)\n",
      "  model_47/batch_normalization_1286/FusedBatchNormV3 (66.33k/66.33k flops)\n",
      "  model_47/batch_normalization_1282/FusedBatchNormV3 (61.39k/61.39k flops)\n",
      "  model_47/batch_normalization_1281/FusedBatchNormV3 (61.39k/61.39k flops)\n",
      "  model_47/conv2d_663/BiasAdd (53.60k/53.60k flops)\n",
      "  model_47/conv2d_665/BiasAdd (50.60k/50.60k flops)\n",
      "  model_47/depthwise_conv2d_618/BiasAdd (50.60k/50.60k flops)\n",
      "  model_47/depthwise_conv2d_615/BiasAdd (44.00k/44.00k flops)\n",
      "  model_47/conv2d_662/BiasAdd (44.00k/44.00k flops)\n",
      "  model_47/conv2d_669/BiasAdd (39.80k/39.80k flops)\n",
      "  model_47/depthwise_conv2d_621/BiasAdd (37.40k/37.40k flops)\n",
      "  model_47/conv2d_668/BiasAdd (37.40k/37.40k flops)\n",
      "  model_47/depthwise_conv2d_614/BiasAdd (35.20k/35.20k flops)\n",
      "  model_47/depthwise_conv2d_620/BiasAdd (34.40k/34.40k flops)\n",
      "  model_47/conv2d_667/BiasAdd (34.40k/34.40k flops)\n",
      "  model_47/batch_normalization_1293/FusedBatchNormV3 (32.37k/32.37k flops)\n",
      "  model_47/depthwise_conv2d_619/BiasAdd (32.20k/32.20k flops)\n",
      "  model_47/conv2d_666/BiasAdd (32.20k/32.20k flops)\n",
      "  model_47/depthwise_conv2d_617/BiasAdd (29.80k/29.80k flops)\n",
      "  model_47/conv2d_664/BiasAdd (29.80k/29.80k flops)\n",
      "  model_47/batch_normalization_1280/FusedBatchNormV3 (27.60k/27.60k flops)\n",
      "  model_47/batch_normalization_1295/FusedBatchNormV3 (22.99k/22.99k flops)\n",
      "  model_47/batch_normalization_1292/FusedBatchNormV3 (22.29k/22.29k flops)\n",
      "  model_47/dense_47/MatMul (19.16k/19.16k flops)\n",
      "  model_47/conv2d_670/BiasAdd (14.45k/14.45k flops)\n",
      "  model_47/batch_normalization_1294/FusedBatchNormV3 (13.87k/13.87k flops)\n",
      "  model_47/depthwise_conv2d_616/BiasAdd (13.40k/13.40k flops)\n",
      "  model_47/depthwise_conv2d_622/BiasAdd (9.95k/9.95k flops)\n",
      "  model_47/global_average_pooling2d_47/Mean (8.62k/8.62k flops)\n",
      "  model_47/conv2d_671/BiasAdd (8.62k/8.62k flops)\n",
      "  model_47/depthwise_conv2d_623/BiasAdd (5.20k/5.20k flops)\n",
      "  model_47/dense_47/Softmax (50/50 flops)\n",
      "  model_47/dense_47/BiasAdd (10/10 flops)\n",
      "\n",
      "======================End of Report==========================\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "24.00618\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-30 13:40:23.579306: I tensorflow/core/grappler/devices.cc:66] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0\n",
      "2022-04-30 13:40:23.579433: I tensorflow/core/grappler/clusters/single_machine.cc:357] Starting new session\n",
      "2022-04-30 13:40:23.584284: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:1137] Optimization results for grappler item: graph_to_optimize\n",
      "  function_optimizer: function_optimizer did nothing. time = 0.006ms.\n",
      "  function_optimizer: function_optimizer did nothing. time = 0.001ms.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=========================Options=============================\n",
      "-max_depth                  10000\n",
      "-min_bytes                  0\n",
      "-min_peak_bytes             0\n",
      "-min_residual_bytes         0\n",
      "-min_output_bytes           0\n",
      "-min_micros                 0\n",
      "-min_accelerator_micros     0\n",
      "-min_cpu_micros             0\n",
      "-min_params                 0\n",
      "-min_float_ops              1\n",
      "-min_occurrence             0\n",
      "-step                       -1\n",
      "-order_by                   float_ops\n",
      "-account_type_regexes       .*\n",
      "-start_name_regexes         .*\n",
      "-trim_name_regexes          \n",
      "-show_name_regexes          .*\n",
      "-hide_name_regexes          \n",
      "-account_displayed_op_only  true\n",
      "-select                     float_ops\n",
      "-output                     stdout:\n",
      "\n",
      "==================Model Analysis Report======================\n",
      "\n",
      "Doc:\n",
      "scope: The nodes in the model graph are organized by their names, which is hierarchical like filesystem.\n",
      "flops: Number of float operations. Note: Please read the implementation for the math behind it.\n",
      "\n",
      "Profile:\n",
      "node name | # float_ops\n",
      "_TFProfRoot (--/365.18m flops)\n",
      "  model_48/conv2d_683/Conv2D (48.78m/48.78m flops)\n",
      "  model_48/conv2d_680/Conv2D (38.96m/38.96m flops)\n",
      "  model_48/conv2d_681/Conv2D (37.55m/37.55m flops)\n",
      "  model_48/conv2d_675/Conv2D (37.00m/37.00m flops)\n",
      "  model_48/conv2d_682/Conv2D (36.05m/36.05m flops)\n",
      "  model_48/conv2d_679/Conv2D (28.56m/28.56m flops)\n",
      "  model_48/conv2d_677/Conv2D (28.21m/28.21m flops)\n",
      "  model_48/conv2d_678/Conv2D (17.08m/17.08m flops)\n",
      "  model_48/conv2d_684/Conv2D (15.58m/15.58m flops)\n",
      "  model_48/conv2d_673/Conv2D (14.75m/14.75m flops)\n",
      "  model_48/conv2d_676/Conv2D (14.35m/14.35m flops)\n",
      "  model_48/conv2d_674/Conv2D (11.29m/11.29m flops)\n",
      "  model_48/conv2d_685/Conv2D (10.36m/10.36m flops)\n",
      "  model_48/conv2d_672/Conv2D (6.55m/6.55m flops)\n",
      "  model_48/depthwise_conv2d_624/depthwise (3.69m/3.69m flops)\n",
      "  model_48/depthwise_conv2d_626/depthwise (2.82m/2.82m flops)\n",
      "  model_48/depthwise_conv2d_628/depthwise (1.09m/1.09m flops)\n",
      "  model_48/depthwise_conv2d_625/depthwise (1.04m/1.04m flops)\n",
      "  model_48/depthwise_conv2d_632/depthwise (903.60k/903.60k flops)\n",
      "  model_48/depthwise_conv2d_634/depthwise (867.60k/867.60k flops)\n",
      "  model_48/depthwise_conv2d_627/depthwise (849.60k/849.60k flops)\n",
      "  model_48/depthwise_conv2d_631/depthwise (698.40k/698.40k flops)\n",
      "  model_48/depthwise_conv2d_633/depthwise (673.20k/673.20k flops)\n",
      "  model_48/depthwise_conv2d_630/depthwise (662.40k/662.40k flops)\n",
      "  model_48/batch_normalization_1298/FusedBatchNormV3 (461.02k/461.02k flops)\n",
      "  model_48/depthwise_conv2d_629/depthwise (417.60k/417.60k flops)\n",
      "  model_48/batch_normalization_1297/FusedBatchNormV3 (409.79k/409.79k flops)\n",
      "  model_48/batch_normalization_1296/FusedBatchNormV3 (409.79k/409.79k flops)\n",
      "  model_48/batch_normalization_1302/FusedBatchNormV3 (378.31k/378.31k flops)\n",
      "  model_48/batch_normalization_1300/FusedBatchNormV3 (314.19k/314.19k flops)\n",
      "  model_48/batch_normalization_1301/FusedBatchNormV3 (314.19k/314.19k flops)\n",
      "  model_48/conv2d_673/BiasAdd (230.40k/230.40k flops)\n",
      "  model_48/depthwise_conv2d_635/depthwise (227.70k/227.70k flops)\n",
      "  model_48/depthwise_conv2d_624/BiasAdd (204.80k/204.80k flops)\n",
      "  model_48/conv2d_672/BiasAdd (204.80k/204.80k flops)\n",
      "  model_48/conv2d_675/BiasAdd (188.80k/188.80k flops)\n",
      "  model_48/batch_normalization_1306/FusedBatchNormV3 (186.99k/186.99k flops)\n",
      "  model_48/conv2d_674/BiasAdd (156.80k/156.80k flops)\n",
      "  model_48/depthwise_conv2d_626/BiasAdd (156.80k/156.80k flops)\n",
      "  model_48/batch_normalization_1305/FusedBatchNormV3 (122.51k/122.51k flops)\n",
      "  model_48/batch_normalization_1304/FusedBatchNormV3 (122.51k/122.51k flops)\n",
      "  model_48/batch_normalization_1299/FusedBatchNormV3 (115.42k/115.42k flops)\n",
      "  model_48/batch_normalization_1318/FusedBatchNormV3 (104.24k/104.24k flops)\n",
      "  model_48/batch_normalization_1313/FusedBatchNormV3 (103.41k/103.41k flops)\n",
      "  model_48/batch_normalization_1312/FusedBatchNormV3 (103.41k/103.41k flops)\n",
      "  model_48/depthwise_conv2d_636/depthwise (99.79k/99.79k flops)\n",
      "  model_48/batch_normalization_1317/FusedBatchNormV3 (99.29k/99.29k flops)\n",
      "  model_48/batch_normalization_1316/FusedBatchNormV3 (99.29k/99.29k flops)\n",
      "  model_48/batch_normalization_1303/FusedBatchNormV3 (95.11k/95.11k flops)\n",
      "  model_48/conv2d_677/BiasAdd (92.80k/92.80k flops)\n",
      "  model_48/batch_normalization_1311/FusedBatchNormV3 (79.93k/79.93k flops)\n",
      "  model_48/batch_normalization_1310/FusedBatchNormV3 (79.93k/79.93k flops)\n",
      "  model_48/batch_normalization_1314/FusedBatchNormV3 (77.04k/77.04k flops)\n",
      "  model_48/batch_normalization_1315/FusedBatchNormV3 (77.04k/77.04k flops)\n",
      "  model_48/batch_normalization_1309/FusedBatchNormV3 (75.81k/75.81k flops)\n",
      "  model_48/batch_normalization_1308/FusedBatchNormV3 (75.81k/75.81k flops)\n",
      "  model_48/depthwise_conv2d_628/BiasAdd (60.80k/60.80k flops)\n",
      "  model_48/conv2d_676/BiasAdd (60.80k/60.80k flops)\n",
      "  model_48/depthwise_conv2d_625/BiasAdd (57.60k/57.60k flops)\n",
      "  model_48/conv2d_683/BiasAdd (50.60k/50.60k flops)\n",
      "  model_48/depthwise_conv2d_632/BiasAdd (50.20k/50.20k flops)\n",
      "  model_48/conv2d_680/BiasAdd (50.20k/50.20k flops)\n",
      "  model_48/depthwise_conv2d_634/BiasAdd (48.20k/48.20k flops)\n",
      "  model_48/conv2d_682/BiasAdd (48.20k/48.20k flops)\n",
      "  model_48/batch_normalization_1307/FusedBatchNormV3 (47.79k/47.79k flops)\n",
      "  model_48/depthwise_conv2d_627/BiasAdd (47.20k/47.20k flops)\n",
      "  model_48/depthwise_conv2d_631/BiasAdd (38.80k/38.80k flops)\n",
      "  model_48/conv2d_679/BiasAdd (38.80k/38.80k flops)\n",
      "  model_48/depthwise_conv2d_633/BiasAdd (37.40k/37.40k flops)\n",
      "  model_48/conv2d_681/BiasAdd (37.40k/37.40k flops)\n",
      "  model_48/depthwise_conv2d_630/BiasAdd (36.80k/36.80k flops)\n",
      "  model_48/conv2d_678/BiasAdd (36.80k/36.80k flops)\n",
      "  model_48/batch_normalization_1320/FusedBatchNormV3 (34.50k/34.50k flops)\n",
      "  model_48/batch_normalization_1319/FusedBatchNormV3 (28.34k/28.34k flops)\n",
      "  model_48/depthwise_conv2d_629/BiasAdd (23.20k/23.20k flops)\n",
      "  model_48/batch_normalization_1322/FusedBatchNormV3 (22.42k/22.42k flops)\n",
      "  model_48/dense_48/MatMul (18.68k/18.68k flops)\n",
      "  model_48/conv2d_684/BiasAdd (15.40k/15.40k flops)\n",
      "  model_48/batch_normalization_1321/FusedBatchNormV3 (14.78k/14.78k flops)\n",
      "  model_48/depthwise_conv2d_635/BiasAdd (12.65k/12.65k flops)\n",
      "  model_48/conv2d_685/BiasAdd (8.41k/8.41k flops)\n",
      "  model_48/global_average_pooling2d_48/Mean (8.41k/8.41k flops)\n",
      "  model_48/depthwise_conv2d_636/BiasAdd (5.54k/5.54k flops)\n",
      "  model_48/dense_48/Softmax (50/50 flops)\n",
      "  model_48/dense_48/BiasAdd (10/10 flops)\n",
      "\n",
      "======================End of Report==========================\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "20.740988\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-30 13:40:24.510841: I tensorflow/core/grappler/devices.cc:66] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0\n",
      "2022-04-30 13:40:24.510969: I tensorflow/core/grappler/clusters/single_machine.cc:357] Starting new session\n",
      "2022-04-30 13:40:24.515100: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:1137] Optimization results for grappler item: graph_to_optimize\n",
      "  function_optimizer: function_optimizer did nothing. time = 0.005ms.\n",
      "  function_optimizer: function_optimizer did nothing. time = 0ms.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=========================Options=============================\n",
      "-max_depth                  10000\n",
      "-min_bytes                  0\n",
      "-min_peak_bytes             0\n",
      "-min_residual_bytes         0\n",
      "-min_output_bytes           0\n",
      "-min_micros                 0\n",
      "-min_accelerator_micros     0\n",
      "-min_cpu_micros             0\n",
      "-min_params                 0\n",
      "-min_float_ops              1\n",
      "-min_occurrence             0\n",
      "-step                       -1\n",
      "-order_by                   float_ops\n",
      "-account_type_regexes       .*\n",
      "-start_name_regexes         .*\n",
      "-trim_name_regexes          \n",
      "-show_name_regexes          .*\n",
      "-hide_name_regexes          \n",
      "-account_displayed_op_only  true\n",
      "-select                     float_ops\n",
      "-output                     stdout:\n",
      "\n",
      "==================Model Analysis Report======================\n",
      "\n",
      "Doc:\n",
      "scope: The nodes in the model graph are organized by their names, which is hierarchical like filesystem.\n",
      "flops: Number of float operations. Note: Please read the implementation for the math behind it.\n",
      "\n",
      "Profile:\n",
      "node name | # float_ops\n",
      "_TFProfRoot (--/294.36m flops)\n",
      "  model_49/conv2d_695/Conv2D (44.04m/44.04m flops)\n",
      "  model_49/conv2d_696/Conv2D (39.88m/39.88m flops)\n",
      "  model_49/conv2d_697/Conv2D (36.98m/36.98m flops)\n",
      "  model_49/conv2d_694/Conv2D (36.23m/36.23m flops)\n",
      "  model_49/conv2d_693/Conv2D (28.56m/28.56m flops)\n",
      "  model_49/conv2d_689/Conv2D (17.08m/17.08m flops)\n",
      "  model_49/conv2d_687/Conv2D (15.56m/15.56m flops)\n",
      "  model_49/conv2d_698/Conv2D (11.41m/11.41m flops)\n",
      "  model_49/conv2d_691/Conv2D (10.19m/10.19m flops)\n",
      "  model_49/conv2d_692/Conv2D (9.10m/9.10m flops)\n",
      "  model_49/conv2d_690/Conv2D (7.21m/7.21m flops)\n",
      "  model_49/conv2d_699/Conv2D (7.12m/7.12m flops)\n",
      "  model_49/conv2d_688/Conv2D (7.05m/7.05m flops)\n",
      "  model_49/conv2d_686/Conv2D (6.55m/6.55m flops)\n",
      "  model_49/depthwise_conv2d_637/depthwise (3.69m/3.69m flops)\n",
      "  model_49/depthwise_conv2d_639/depthwise (1.67m/1.67m flops)\n",
      "  model_49/depthwise_conv2d_638/depthwise (1.09m/1.09m flops)\n",
      "  model_49/depthwise_conv2d_646/depthwise (892.80k/892.80k flops)\n",
      "  model_49/depthwise_conv2d_645/depthwise (799.20k/799.20k flops)\n",
      "  model_49/depthwise_conv2d_644/depthwise (734.40k/734.40k flops)\n",
      "  model_49/depthwise_conv2d_647/depthwise (723.60k/723.60k flops)\n",
      "  model_49/depthwise_conv2d_641/depthwise (705.60k/705.60k flops)\n",
      "  model_49/depthwise_conv2d_640/depthwise (662.40k/662.40k flops)\n",
      "  model_49/depthwise_conv2d_643/depthwise (630.00k/630.00k flops)\n",
      "  model_49/batch_normalization_1325/FusedBatchNormV3 (486.63k/486.63k flops)\n",
      "  model_49/batch_normalization_1324/FusedBatchNormV3 (409.79k/409.79k flops)\n",
      "  model_49/batch_normalization_1323/FusedBatchNormV3 (409.79k/409.79k flops)\n",
      "  model_49/batch_normalization_1329/FusedBatchNormV3 (294.95k/294.95k flops)\n",
      "  model_49/conv2d_687/BiasAdd (243.20k/243.20k flops)\n",
      "  model_49/depthwise_conv2d_642/depthwise (234.00k/234.00k flops)\n",
      "  model_49/depthwise_conv2d_648/depthwise (207.00k/207.00k flops)\n",
      "  model_49/conv2d_686/BiasAdd (204.80k/204.80k flops)\n",
      "  model_49/depthwise_conv2d_637/BiasAdd (204.80k/204.80k flops)\n",
      "  model_49/batch_normalization_1327/FusedBatchNormV3 (185.95k/185.95k flops)\n",
      "  model_49/batch_normalization_1328/FusedBatchNormV3 (185.95k/185.95k flops)\n",
      "  model_49/conv2d_689/BiasAdd (147.20k/147.20k flops)\n",
      "  model_49/batch_normalization_1326/FusedBatchNormV3 (121.83k/121.83k flops)\n",
      "  model_49/batch_normalization_1333/FusedBatchNormV3 (104.78k/104.78k flops)\n",
      "  model_49/batch_normalization_1342/FusedBatchNormV3 (102.18k/102.18k flops)\n",
      "  model_49/batch_normalization_1341/FusedBatchNormV3 (102.18k/102.18k flops)\n",
      "  model_49/batch_normalization_1345/FusedBatchNormV3 (94.76k/94.76k flops)\n",
      "  model_49/depthwise_conv2d_639/BiasAdd (92.80k/92.80k flops)\n",
      "  model_49/conv2d_688/BiasAdd (92.80k/92.80k flops)\n",
      "  model_49/batch_normalization_1340/FusedBatchNormV3 (91.46k/91.46k flops)\n",
      "  model_49/batch_normalization_1339/FusedBatchNormV3 (91.46k/91.46k flops)\n",
      "  model_49/batch_normalization_1337/FusedBatchNormV3 (84.05k/84.05k flops)\n",
      "  model_49/batch_normalization_1338/FusedBatchNormV3 (84.05k/84.05k flops)\n",
      "  model_49/batch_normalization_1344/FusedBatchNormV3 (82.81k/82.81k flops)\n",
      "  model_49/batch_normalization_1343/FusedBatchNormV3 (82.81k/82.81k flops)\n",
      "  model_49/depthwise_conv2d_649/depthwise (80.35k/80.35k flops)\n",
      "  model_49/batch_normalization_1331/FusedBatchNormV3 (78.99k/78.99k flops)\n",
      "  model_49/batch_normalization_1332/FusedBatchNormV3 (78.99k/78.99k flops)\n",
      "  model_49/batch_normalization_1330/FusedBatchNormV3 (74.15k/74.15k flops)\n",
      "  model_49/batch_normalization_1336/FusedBatchNormV3 (72.10k/72.10k flops)\n",
      "  model_49/batch_normalization_1335/FusedBatchNormV3 (72.10k/72.10k flops)\n",
      "  model_49/depthwise_conv2d_638/BiasAdd (60.80k/60.80k flops)\n",
      "  model_49/conv2d_691/BiasAdd (52.00k/52.00k flops)\n",
      "  model_49/conv2d_695/BiasAdd (49.60k/49.60k flops)\n",
      "  model_49/depthwise_conv2d_646/BiasAdd (49.60k/49.60k flops)\n",
      "  model_49/conv2d_697/BiasAdd (46.00k/46.00k flops)\n",
      "  model_49/depthwise_conv2d_645/BiasAdd (44.40k/44.40k flops)\n",
      "  model_49/conv2d_694/BiasAdd (44.40k/44.40k flops)\n",
      "  model_49/conv2d_693/BiasAdd (40.80k/40.80k flops)\n",
      "  model_49/depthwise_conv2d_644/BiasAdd (40.80k/40.80k flops)\n",
      "  model_49/depthwise_conv2d_647/BiasAdd (40.20k/40.20k flops)\n",
      "  model_49/conv2d_696/BiasAdd (40.20k/40.20k flops)\n",
      "  model_49/depthwise_conv2d_641/BiasAdd (39.20k/39.20k flops)\n",
      "  model_49/conv2d_690/BiasAdd (39.20k/39.20k flops)\n",
      "  model_49/depthwise_conv2d_640/BiasAdd (36.80k/36.80k flops)\n",
      "  model_49/conv2d_692/BiasAdd (35.00k/35.00k flops)\n",
      "  model_49/depthwise_conv2d_643/BiasAdd (35.00k/35.00k flops)\n",
      "  model_49/batch_normalization_1347/FusedBatchNormV3 (27.78k/27.78k flops)\n",
      "  model_49/batch_normalization_1334/FusedBatchNormV3 (26.78k/26.78k flops)\n",
      "  model_49/batch_normalization_1346/FusedBatchNormV3 (25.76k/25.76k flops)\n",
      "  model_49/batch_normalization_1349/FusedBatchNormV3 (19.15k/19.15k flops)\n",
      "  model_49/dense_49/MatMul (15.96k/15.96k flops)\n",
      "  model_49/depthwise_conv2d_642/BiasAdd (13.00k/13.00k flops)\n",
      "  model_49/conv2d_698/BiasAdd (12.40k/12.40k flops)\n",
      "  model_49/batch_normalization_1348/FusedBatchNormV3 (11.90k/11.90k flops)\n",
      "  model_49/depthwise_conv2d_648/BiasAdd (11.50k/11.50k flops)\n",
      "  model_49/global_average_pooling2d_49/Mean (7.18k/7.18k flops)\n",
      "  model_49/conv2d_699/BiasAdd (7.18k/7.18k flops)\n",
      "  model_49/depthwise_conv2d_649/BiasAdd (4.46k/4.46k flops)\n",
      "  model_49/dense_49/Softmax (50/50 flops)\n",
      "  model_49/dense_49/BiasAdd (10/10 flops)\n",
      "\n",
      "======================End of Report==========================\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "27.082852\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-30 13:40:25.439350: I tensorflow/core/grappler/devices.cc:66] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0\n",
      "2022-04-30 13:40:25.439467: I tensorflow/core/grappler/clusters/single_machine.cc:357] Starting new session\n",
      "2022-04-30 13:40:25.443485: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:1137] Optimization results for grappler item: graph_to_optimize\n",
      "  function_optimizer: function_optimizer did nothing. time = 0.005ms.\n",
      "  function_optimizer: function_optimizer did nothing. time = 0.001ms.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=========================Options=============================\n",
      "-max_depth                  10000\n",
      "-min_bytes                  0\n",
      "-min_peak_bytes             0\n",
      "-min_residual_bytes         0\n",
      "-min_output_bytes           0\n",
      "-min_micros                 0\n",
      "-min_accelerator_micros     0\n",
      "-min_cpu_micros             0\n",
      "-min_params                 0\n",
      "-min_float_ops              1\n",
      "-min_occurrence             0\n",
      "-step                       -1\n",
      "-order_by                   float_ops\n",
      "-account_type_regexes       .*\n",
      "-start_name_regexes         .*\n",
      "-trim_name_regexes          \n",
      "-show_name_regexes          .*\n",
      "-hide_name_regexes          \n",
      "-account_displayed_op_only  true\n",
      "-select                     float_ops\n",
      "-output                     stdout:\n",
      "\n",
      "==================Model Analysis Report======================\n",
      "\n",
      "Doc:\n",
      "scope: The nodes in the model graph are organized by their names, which is hierarchical like filesystem.\n",
      "flops: Number of float operations. Note: Please read the implementation for the math behind it.\n",
      "\n",
      "Profile:\n",
      "node name | # float_ops\n",
      "_TFProfRoot (--/481.17m flops)\n",
      "  model_50/conv2d_708/Conv2D (50.60m/50.60m flops)\n",
      "  model_50/conv2d_705/Conv2D (50.40m/50.40m flops)\n",
      "  model_50/conv2d_711/Conv2D (49.60m/49.60m flops)\n",
      "  model_50/conv2d_709/Conv2D (48.40m/48.40m flops)\n",
      "  model_50/conv2d_707/Conv2D (48.17m/48.17m flops)\n",
      "  model_50/conv2d_710/Conv2D (47.82m/47.82m flops)\n",
      "  model_50/conv2d_703/Conv2D (29.91m/29.91m flops)\n",
      "  model_50/conv2d_712/Conv2D (25.55m/25.55m flops)\n",
      "  model_50/conv2d_706/Conv2D (23.99m/23.99m flops)\n",
      "  model_50/conv2d_704/Conv2D (22.80m/22.80m flops)\n",
      "  model_50/conv2d_701/Conv2D (22.12m/22.12m flops)\n",
      "  model_50/conv2d_713/Conv2D (18.73m/18.73m flops)\n",
      "  model_50/conv2d_702/Conv2D (14.17m/14.17m flops)\n",
      "  model_50/conv2d_700/Conv2D (6.55m/6.55m flops)\n",
      "  model_50/depthwise_conv2d_650/depthwise (3.69m/3.69m flops)\n",
      "  model_50/depthwise_conv2d_652/depthwise (2.36m/2.36m flops)\n",
      "  model_50/depthwise_conv2d_654/depthwise (1.80m/1.80m flops)\n",
      "  model_50/depthwise_conv2d_651/depthwise (1.56m/1.56m flops)\n",
      "  model_50/depthwise_conv2d_657/depthwise (910.80k/910.80k flops)\n",
      "  model_50/depthwise_conv2d_658/depthwise (900.00k/900.00k flops)\n",
      "  model_50/depthwise_conv2d_660/depthwise (889.20k/889.20k flops)\n",
      "  model_50/depthwise_conv2d_659/depthwise (871.20k/871.20k flops)\n",
      "  model_50/depthwise_conv2d_656/depthwise (856.80k/856.80k flops)\n",
      "  model_50/depthwise_conv2d_653/depthwise (820.80k/820.80k flops)\n",
      "  model_50/batch_normalization_1352/FusedBatchNormV3 (691.52k/691.52k flops)\n",
      "  model_50/depthwise_conv2d_655/depthwise (453.60k/453.60k flops)\n",
      "  model_50/batch_normalization_1351/FusedBatchNormV3 (409.79k/409.79k flops)\n",
      "  model_50/batch_normalization_1350/FusedBatchNormV3 (409.79k/409.79k flops)\n",
      "  model_50/batch_normalization_1356/FusedBatchNormV3 (365.48k/365.48k flops)\n",
      "  model_50/conv2d_701/BiasAdd (345.60k/345.60k flops)\n",
      "  model_50/batch_normalization_1354/FusedBatchNormV3 (262.89k/262.89k flops)\n",
      "  model_50/batch_normalization_1355/FusedBatchNormV3 (262.89k/262.89k flops)\n",
      "  model_50/depthwise_conv2d_661/depthwise (225.90k/225.90k flops)\n",
      "  model_50/depthwise_conv2d_650/BiasAdd (204.80k/204.80k flops)\n",
      "  model_50/conv2d_700/BiasAdd (204.80k/204.80k flops)\n",
      "  model_50/batch_normalization_1360/FusedBatchNormV3 (203.11k/203.11k flops)\n",
      "  model_50/batch_normalization_1359/FusedBatchNormV3 (201.50k/201.50k flops)\n",
      "  model_50/batch_normalization_1358/FusedBatchNormV3 (201.50k/201.50k flops)\n",
      "  model_50/conv2d_703/BiasAdd (182.40k/182.40k flops)\n",
      "  model_50/batch_normalization_1353/FusedBatchNormV3 (173.12k/173.12k flops)\n",
      "  model_50/depthwise_conv2d_662/depthwise (164.92k/164.92k flops)\n",
      "  model_50/conv2d_702/BiasAdd (131.20k/131.20k flops)\n",
      "  model_50/depthwise_conv2d_652/BiasAdd (131.20k/131.20k flops)\n",
      "  model_50/batch_normalization_1365/FusedBatchNormV3 (104.24k/104.24k flops)\n",
      "  model_50/batch_normalization_1364/FusedBatchNormV3 (104.24k/104.24k flops)\n",
      "  model_50/batch_normalization_1372/FusedBatchNormV3 (103.41k/103.41k flops)\n",
      "  model_50/batch_normalization_1367/FusedBatchNormV3 (103.00k/103.00k flops)\n",
      "  model_50/batch_normalization_1366/FusedBatchNormV3 (103.00k/103.00k flops)\n",
      "  model_50/batch_normalization_1370/FusedBatchNormV3 (101.76k/101.76k flops)\n",
      "  model_50/batch_normalization_1371/FusedBatchNormV3 (101.76k/101.76k flops)\n",
      "  model_50/conv2d_705/BiasAdd (100.80k/100.80k flops)\n",
      "  model_50/depthwise_conv2d_654/BiasAdd (100.00k/100.00k flops)\n",
      "  model_50/conv2d_704/BiasAdd (100.00k/100.00k flops)\n",
      "  model_50/batch_normalization_1368/FusedBatchNormV3 (99.70k/99.70k flops)\n",
      "  model_50/batch_normalization_1369/FusedBatchNormV3 (99.70k/99.70k flops)\n",
      "  model_50/batch_normalization_1363/FusedBatchNormV3 (98.06k/98.06k flops)\n",
      "  model_50/batch_normalization_1362/FusedBatchNormV3 (98.06k/98.06k flops)\n",
      "  model_50/batch_normalization_1357/FusedBatchNormV3 (91.88k/91.88k flops)\n",
      "  model_50/depthwise_conv2d_651/BiasAdd (86.40k/86.40k flops)\n",
      "  model_50/batch_normalization_1374/FusedBatchNormV3 (57.01k/57.01k flops)\n",
      "  model_50/batch_normalization_1361/FusedBatchNormV3 (51.91k/51.91k flops)\n",
      "  model_50/depthwise_conv2d_657/BiasAdd (50.60k/50.60k flops)\n",
      "  model_50/conv2d_707/BiasAdd (50.60k/50.60k flops)\n",
      "  model_50/conv2d_711/BiasAdd (50.20k/50.20k flops)\n",
      "  model_50/depthwise_conv2d_658/BiasAdd (50.00k/50.00k flops)\n",
      "  model_50/conv2d_708/BiasAdd (50.00k/50.00k flops)\n",
      "  model_50/depthwise_conv2d_660/BiasAdd (49.40k/49.40k flops)\n",
      "  model_50/conv2d_710/BiasAdd (49.40k/49.40k flops)\n",
      "  model_50/conv2d_709/BiasAdd (48.40k/48.40k flops)\n",
      "  model_50/depthwise_conv2d_659/BiasAdd (48.40k/48.40k flops)\n",
      "  model_50/depthwise_conv2d_656/BiasAdd (47.60k/47.60k flops)\n",
      "  model_50/conv2d_706/BiasAdd (47.60k/47.60k flops)\n",
      "  model_50/depthwise_conv2d_653/BiasAdd (45.60k/45.60k flops)\n",
      "  model_50/batch_normalization_1373/FusedBatchNormV3 (28.11k/28.11k flops)\n",
      "  model_50/conv2d_712/BiasAdd (25.45k/25.45k flops)\n",
      "  model_50/depthwise_conv2d_655/BiasAdd (25.20k/25.20k flops)\n",
      "  model_50/batch_normalization_1376/FusedBatchNormV3 (24.53k/24.53k flops)\n",
      "  model_50/batch_normalization_1375/FusedBatchNormV3 (24.43k/24.43k flops)\n",
      "  model_50/dense_50/MatMul (20.44k/20.44k flops)\n",
      "  model_50/depthwise_conv2d_661/BiasAdd (12.55k/12.55k flops)\n",
      "  model_50/conv2d_713/BiasAdd (9.20k/9.20k flops)\n",
      "  model_50/global_average_pooling2d_50/Mean (9.20k/9.20k flops)\n",
      "  model_50/depthwise_conv2d_662/BiasAdd (9.16k/9.16k flops)\n",
      "  model_50/dense_50/Softmax (50/50 flops)\n",
      "  model_50/dense_50/BiasAdd (10/10 flops)\n",
      "\n",
      "======================End of Report==========================\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "39.902636\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-30 13:40:26.489306: I tensorflow/core/grappler/devices.cc:66] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0\n",
      "2022-04-30 13:40:26.489422: I tensorflow/core/grappler/clusters/single_machine.cc:357] Starting new session\n",
      "2022-04-30 13:40:26.493709: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:1137] Optimization results for grappler item: graph_to_optimize\n",
      "  function_optimizer: function_optimizer did nothing. time = 0.005ms.\n",
      "  function_optimizer: function_optimizer did nothing. time = 0.001ms.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=========================Options=============================\n",
      "-max_depth                  10000\n",
      "-min_bytes                  0\n",
      "-min_peak_bytes             0\n",
      "-min_residual_bytes         0\n",
      "-min_output_bytes           0\n",
      "-min_micros                 0\n",
      "-min_accelerator_micros     0\n",
      "-min_cpu_micros             0\n",
      "-min_params                 0\n",
      "-min_float_ops              1\n",
      "-min_occurrence             0\n",
      "-step                       -1\n",
      "-order_by                   float_ops\n",
      "-account_type_regexes       .*\n",
      "-start_name_regexes         .*\n",
      "-trim_name_regexes          \n",
      "-show_name_regexes          .*\n",
      "-hide_name_regexes          \n",
      "-account_displayed_op_only  true\n",
      "-select                     float_ops\n",
      "-output                     stdout:\n",
      "\n",
      "==================Model Analysis Report======================\n",
      "\n",
      "Doc:\n",
      "scope: The nodes in the model graph are organized by their names, which is hierarchical like filesystem.\n",
      "flops: Number of float operations. Note: Please read the implementation for the math behind it.\n",
      "\n",
      "Profile:\n",
      "node name | # float_ops\n",
      "_TFProfRoot (--/692.53m flops)\n",
      "  model_51/conv2d_722/Conv2D (72.57m/72.57m flops)\n",
      "  model_51/conv2d_717/Conv2D (70.83m/70.83m flops)\n",
      "  model_51/conv2d_723/Conv2D (69.99m/69.99m flops)\n",
      "  model_51/conv2d_721/Conv2D (69.08m/69.08m flops)\n",
      "  model_51/conv2d_724/Conv2D (68.87m/68.87m flops)\n",
      "  model_51/conv2d_725/Conv2D (68.02m/68.02m flops)\n",
      "  model_51/conv2d_719/Conv2D (62.01m/62.01m flops)\n",
      "  model_51/conv2d_718/Conv2D (33.68m/33.68m flops)\n",
      "  model_51/conv2d_726/Conv2D (33.04m/33.04m flops)\n",
      "  model_51/conv2d_720/Conv2D (31.67m/31.67m flops)\n",
      "  model_51/conv2d_715/Conv2D (27.13m/27.13m flops)\n",
      "  model_51/conv2d_716/Conv2D (25.86m/25.86m flops)\n",
      "  model_51/conv2d_727/Conv2D (16.86m/16.86m flops)\n",
      "  model_51/conv2d_714/Conv2D (9.44m/9.44m flops)\n",
      "  model_51/depthwise_conv2d_663/depthwise (5.31m/5.31m flops)\n",
      "  model_51/depthwise_conv2d_665/depthwise (5.06m/5.06m flops)\n",
      "  model_51/depthwise_conv2d_667/depthwise (2.41m/2.41m flops)\n",
      "  model_51/depthwise_conv2d_664/depthwise (1.91m/1.91m flops)\n",
      "  model_51/depthwise_conv2d_670/depthwise (1.31m/1.31m flops)\n",
      "  model_51/depthwise_conv2d_666/depthwise (1.31m/1.31m flops)\n",
      "  model_51/depthwise_conv2d_671/depthwise (1.29m/1.29m flops)\n",
      "  model_51/depthwise_conv2d_673/depthwise (1.27m/1.27m flops)\n",
      "  model_51/depthwise_conv2d_672/depthwise (1.26m/1.26m flops)\n",
      "  model_51/depthwise_conv2d_669/depthwise (1.23m/1.23m flops)\n",
      "  model_51/batch_normalization_1379/FusedBatchNormV3 (848.15k/848.15k flops)\n",
      "  model_51/depthwise_conv2d_668/depthwise (601.34k/601.34k flops)\n",
      "  model_51/batch_normalization_1378/FusedBatchNormV3 (590.02k/590.02k flops)\n",
      "  model_51/batch_normalization_1377/FusedBatchNormV3 (590.02k/590.02k flops)\n",
      "  model_51/batch_normalization_1383/FusedBatchNormV3 (581.36k/581.36k flops)\n",
      "  model_51/batch_normalization_1381/FusedBatchNormV3 (562.91k/562.91k flops)\n",
      "  model_51/batch_normalization_1382/FusedBatchNormV3 (562.91k/562.91k flops)\n",
      "  model_51/conv2d_715/BiasAdd (423.94k/423.94k flops)\n",
      "  model_51/depthwise_conv2d_674/depthwise (312.34k/312.34k flops)\n",
      "  model_51/depthwise_conv2d_663/BiasAdd (294.91k/294.91k flops)\n",
      "  model_51/conv2d_714/BiasAdd (294.91k/294.91k flops)\n",
      "  model_51/conv2d_717/BiasAdd (290.30k/290.30k flops)\n",
      "  model_51/conv2d_716/BiasAdd (281.09k/281.09k flops)\n",
      "  model_51/depthwise_conv2d_665/BiasAdd (281.09k/281.09k flops)\n",
      "  model_51/batch_normalization_1386/FusedBatchNormV3 (268.66k/268.66k flops)\n",
      "  model_51/batch_normalization_1387/FusedBatchNormV3 (268.66k/268.66k flops)\n",
      "  model_51/batch_normalization_1385/FusedBatchNormV3 (268.66k/268.66k flops)\n",
      "  model_51/batch_normalization_1380/FusedBatchNormV3 (212.24k/212.24k flops)\n",
      "  model_51/depthwise_conv2d_675/depthwise (154.22k/154.22k flops)\n",
      "  model_51/batch_normalization_1391/FusedBatchNormV3 (148.76k/148.76k flops)\n",
      "  model_51/batch_normalization_1392/FusedBatchNormV3 (148.76k/148.76k flops)\n",
      "  model_51/batch_normalization_1394/FusedBatchNormV3 (146.41k/146.41k flops)\n",
      "  model_51/batch_normalization_1393/FusedBatchNormV3 (146.41k/146.41k flops)\n",
      "  model_51/batch_normalization_1384/FusedBatchNormV3 (145.91k/145.91k flops)\n",
      "  model_51/batch_normalization_1398/FusedBatchNormV3 (144.06k/144.06k flops)\n",
      "  model_51/batch_normalization_1397/FusedBatchNormV3 (144.06k/144.06k flops)\n",
      "  model_51/batch_normalization_1396/FusedBatchNormV3 (143.47k/143.47k flops)\n",
      "  model_51/batch_normalization_1395/FusedBatchNormV3 (143.47k/143.47k flops)\n",
      "  model_51/batch_normalization_1399/FusedBatchNormV3 (141.71k/141.71k flops)\n",
      "  model_51/batch_normalization_1390/FusedBatchNormV3 (139.36k/139.36k flops)\n",
      "  model_51/batch_normalization_1389/FusedBatchNormV3 (139.36k/139.36k flops)\n",
      "  model_51/conv2d_719/BiasAdd (133.63k/133.63k flops)\n",
      "  model_51/conv2d_718/BiasAdd (133.63k/133.63k flops)\n",
      "  model_51/depthwise_conv2d_667/BiasAdd (133.63k/133.63k flops)\n",
      "  model_51/depthwise_conv2d_664/BiasAdd (105.98k/105.98k flops)\n",
      "  model_51/batch_normalization_1401/FusedBatchNormV3 (74.26k/74.26k flops)\n",
      "  model_51/conv2d_721/BiasAdd (72.86k/72.86k flops)\n",
      "  model_51/depthwise_conv2d_670/BiasAdd (72.86k/72.86k flops)\n",
      "  model_51/depthwise_conv2d_666/BiasAdd (72.58k/72.58k flops)\n",
      "  model_51/conv2d_722/BiasAdd (71.71k/71.71k flops)\n",
      "  model_51/depthwise_conv2d_671/BiasAdd (71.71k/71.71k flops)\n",
      "  model_51/depthwise_conv2d_673/BiasAdd (70.56k/70.56k flops)\n",
      "  model_51/conv2d_724/BiasAdd (70.56k/70.56k flops)\n",
      "  model_51/conv2d_723/BiasAdd (70.27k/70.27k flops)\n",
      "  model_51/depthwise_conv2d_672/BiasAdd (70.27k/70.27k flops)\n",
      "  model_51/conv2d_725/BiasAdd (69.41k/69.41k flops)\n",
      "  model_51/depthwise_conv2d_669/BiasAdd (68.26k/68.26k flops)\n",
      "  model_51/conv2d_720/BiasAdd (68.26k/68.26k flops)\n",
      "  model_51/batch_normalization_1388/FusedBatchNormV3 (68.21k/68.21k flops)\n",
      "  model_51/batch_normalization_1400/FusedBatchNormV3 (37.60k/37.60k flops)\n",
      "  model_51/conv2d_726/BiasAdd (34.27k/34.27k flops)\n",
      "  model_51/depthwise_conv2d_668/BiasAdd (33.41k/33.41k flops)\n",
      "  model_51/batch_normalization_1403/FusedBatchNormV3 (23.62k/23.62k flops)\n",
      "  model_51/batch_normalization_1402/FusedBatchNormV3 (22.85k/22.85k flops)\n",
      "  model_51/dense_51/MatMul (19.68k/19.68k flops)\n",
      "  model_51/depthwise_conv2d_674/BiasAdd (17.35k/17.35k flops)\n",
      "  model_51/conv2d_727/BiasAdd (8.86k/8.86k flops)\n",
      "  model_51/global_average_pooling2d_51/Mean (8.86k/8.86k flops)\n",
      "  model_51/depthwise_conv2d_675/BiasAdd (8.57k/8.57k flops)\n",
      "  model_51/dense_51/Softmax (50/50 flops)\n",
      "  model_51/dense_51/BiasAdd (10/10 flops)\n",
      "\n",
      "======================End of Report==========================\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "31.656484\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-30 13:40:27.446227: I tensorflow/core/grappler/devices.cc:66] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0\n",
      "2022-04-30 13:40:27.446341: I tensorflow/core/grappler/clusters/single_machine.cc:357] Starting new session\n",
      "2022-04-30 13:40:27.450417: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:1137] Optimization results for grappler item: graph_to_optimize\n",
      "  function_optimizer: function_optimizer did nothing. time = 0.005ms.\n",
      "  function_optimizer: function_optimizer did nothing. time = 0.001ms.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=========================Options=============================\n",
      "-max_depth                  10000\n",
      "-min_bytes                  0\n",
      "-min_peak_bytes             0\n",
      "-min_residual_bytes         0\n",
      "-min_output_bytes           0\n",
      "-min_micros                 0\n",
      "-min_accelerator_micros     0\n",
      "-min_cpu_micros             0\n",
      "-min_params                 0\n",
      "-min_float_ops              1\n",
      "-min_occurrence             0\n",
      "-step                       -1\n",
      "-order_by                   float_ops\n",
      "-account_type_regexes       .*\n",
      "-start_name_regexes         .*\n",
      "-trim_name_regexes          \n",
      "-show_name_regexes          .*\n",
      "-hide_name_regexes          \n",
      "-account_displayed_op_only  true\n",
      "-select                     float_ops\n",
      "-output                     stdout:\n",
      "\n",
      "==================Model Analysis Report======================\n",
      "\n",
      "Doc:\n",
      "scope: The nodes in the model graph are organized by their names, which is hierarchical like filesystem.\n",
      "flops: Number of float operations. Note: Please read the implementation for the math behind it.\n",
      "\n",
      "Profile:\n",
      "node name | # float_ops\n",
      "_TFProfRoot (--/551.88m flops)\n",
      "  model_52/conv2d_739/Conv2D (69.38m/69.38m flops)\n",
      "  model_52/conv2d_738/Conv2D (68.28m/68.28m flops)\n",
      "  model_52/conv2d_737/Conv2D (67.42m/67.42m flops)\n",
      "  model_52/conv2d_735/Conv2D (66.88m/66.88m flops)\n",
      "  model_52/conv2d_736/Conv2D (66.88m/66.88m flops)\n",
      "  model_52/conv2d_733/Conv2D (41.06m/41.06m flops)\n",
      "  model_52/conv2d_734/Conv2D (29.91m/29.91m flops)\n",
      "  model_52/conv2d_740/Conv2D (27.94m/27.94m flops)\n",
      "  model_52/conv2d_732/Conv2D (20.53m/20.53m flops)\n",
      "  model_52/conv2d_729/Conv2D (20.05m/20.05m flops)\n",
      "  model_52/conv2d_731/Conv2D (18.25m/18.25m flops)\n",
      "  model_52/conv2d_741/Conv2D (13.92m/13.92m flops)\n",
      "  model_52/conv2d_728/Conv2D (9.44m/9.44m flops)\n",
      "  model_52/conv2d_730/Conv2D (5.64m/5.64m flops)\n",
      "  model_52/depthwise_conv2d_676/depthwise (5.31m/5.31m flops)\n",
      "  model_52/depthwise_conv2d_680/depthwise (1.68m/1.68m flops)\n",
      "  model_52/depthwise_conv2d_678/depthwise (1.49m/1.49m flops)\n",
      "  model_52/depthwise_conv2d_677/depthwise (1.41m/1.41m flops)\n",
      "  model_52/depthwise_conv2d_685/depthwise (1.29m/1.29m flops)\n",
      "  model_52/depthwise_conv2d_683/depthwise (1.28m/1.28m flops)\n",
      "  model_52/depthwise_conv2d_686/depthwise (1.24m/1.24m flops)\n",
      "  model_52/depthwise_conv2d_682/depthwise (1.22m/1.22m flops)\n",
      "  model_52/depthwise_conv2d_684/depthwise (1.22m/1.22m flops)\n",
      "  model_52/depthwise_conv2d_679/depthwise (1.14m/1.14m flops)\n",
      "  model_52/batch_normalization_1406/FusedBatchNormV3 (626.89k/626.89k flops)\n",
      "  model_52/batch_normalization_1405/FusedBatchNormV3 (590.02k/590.02k flops)\n",
      "  model_52/batch_normalization_1404/FusedBatchNormV3 (590.02k/590.02k flops)\n",
      "  model_52/depthwise_conv2d_681/depthwise (570.24k/570.24k flops)\n",
      "  model_52/batch_normalization_1410/FusedBatchNormV3 (507.54k/507.54k flops)\n",
      "  model_52/depthwise_conv2d_687/depthwise (326.59k/326.59k flops)\n",
      "  model_52/conv2d_729/BiasAdd (313.34k/313.34k flops)\n",
      "  model_52/conv2d_728/BiasAdd (294.91k/294.91k flops)\n",
      "  model_52/depthwise_conv2d_676/BiasAdd (294.91k/294.91k flops)\n",
      "  model_52/batch_normalization_1414/FusedBatchNormV3 (254.76k/254.76k flops)\n",
      "  model_52/conv2d_731/BiasAdd (253.44k/253.44k flops)\n",
      "  model_52/batch_normalization_1413/FusedBatchNormV3 (187.60k/187.60k flops)\n",
      "  model_52/batch_normalization_1412/FusedBatchNormV3 (187.60k/187.60k flops)\n",
      "  model_52/batch_normalization_1409/FusedBatchNormV3 (166.10k/166.10k flops)\n",
      "  model_52/batch_normalization_1408/FusedBatchNormV3 (166.10k/166.10k flops)\n",
      "  model_52/batch_normalization_1407/FusedBatchNormV3 (156.88k/156.88k flops)\n",
      "  model_52/batch_normalization_1426/FusedBatchNormV3 (148.18k/148.18k flops)\n",
      "  model_52/batch_normalization_1422/FusedBatchNormV3 (145.82k/145.82k flops)\n",
      "  model_52/batch_normalization_1423/FusedBatchNormV3 (145.82k/145.82k flops)\n",
      "  model_52/batch_normalization_1419/FusedBatchNormV3 (144.65k/144.65k flops)\n",
      "  model_52/batch_normalization_1418/FusedBatchNormV3 (144.65k/144.65k flops)\n",
      "  model_52/batch_normalization_1424/FusedBatchNormV3 (140.53k/140.53k flops)\n",
      "  model_52/batch_normalization_1425/FusedBatchNormV3 (140.53k/140.53k flops)\n",
      "  model_52/batch_normalization_1421/FusedBatchNormV3 (138.77k/138.77k flops)\n",
      "  model_52/batch_normalization_1416/FusedBatchNormV3 (138.77k/138.77k flops)\n",
      "  model_52/batch_normalization_1420/FusedBatchNormV3 (138.77k/138.77k flops)\n",
      "  model_52/batch_normalization_1417/FusedBatchNormV3 (138.77k/138.77k flops)\n",
      "  model_52/batch_normalization_1411/FusedBatchNormV3 (127.38k/127.38k flops)\n",
      "  model_52/conv2d_733/BiasAdd (126.72k/126.72k flops)\n",
      "  model_52/depthwise_conv2d_688/depthwise (124.74k/124.74k flops)\n",
      "  model_52/depthwise_conv2d_680/BiasAdd (93.31k/93.31k flops)\n",
      "  model_52/conv2d_732/BiasAdd (93.31k/93.31k flops)\n",
      "  model_52/depthwise_conv2d_678/BiasAdd (82.94k/82.94k flops)\n",
      "  model_52/conv2d_730/BiasAdd (82.94k/82.94k flops)\n",
      "  model_52/depthwise_conv2d_677/BiasAdd (78.34k/78.34k flops)\n",
      "  model_52/conv2d_739/BiasAdd (72.58k/72.58k flops)\n",
      "  model_52/depthwise_conv2d_685/BiasAdd (71.42k/71.42k flops)\n",
      "  model_52/conv2d_737/BiasAdd (71.42k/71.42k flops)\n",
      "  model_52/conv2d_735/BiasAdd (70.85k/70.85k flops)\n",
      "  model_52/depthwise_conv2d_683/BiasAdd (70.85k/70.85k flops)\n",
      "  model_52/depthwise_conv2d_686/BiasAdd (68.83k/68.83k flops)\n",
      "  model_52/conv2d_738/BiasAdd (68.83k/68.83k flops)\n",
      "  model_52/conv2d_736/BiasAdd (67.97k/67.97k flops)\n",
      "  model_52/depthwise_conv2d_682/BiasAdd (67.97k/67.97k flops)\n",
      "  model_52/conv2d_734/BiasAdd (67.97k/67.97k flops)\n",
      "  model_52/depthwise_conv2d_684/BiasAdd (67.97k/67.97k flops)\n",
      "  model_52/batch_normalization_1415/FusedBatchNormV3 (64.68k/64.68k flops)\n",
      "  model_52/depthwise_conv2d_679/BiasAdd (63.36k/63.36k flops)\n",
      "  model_52/batch_normalization_1428/FusedBatchNormV3 (60.06k/60.06k flops)\n",
      "  model_52/batch_normalization_1427/FusedBatchNormV3 (39.31k/39.31k flops)\n",
      "  model_52/depthwise_conv2d_681/BiasAdd (31.68k/31.68k flops)\n",
      "  model_52/conv2d_740/BiasAdd (27.72k/27.72k flops)\n",
      "  model_52/batch_normalization_1430/FusedBatchNormV3 (24.10k/24.10k flops)\n",
      "  model_52/dense_52/MatMul (20.08k/20.08k flops)\n",
      "  model_52/batch_normalization_1429/FusedBatchNormV3 (18.48k/18.48k flops)\n",
      "  model_52/depthwise_conv2d_687/BiasAdd (18.14k/18.14k flops)\n",
      "  model_52/global_average_pooling2d_52/Mean (9.04k/9.04k flops)\n",
      "  model_52/conv2d_741/BiasAdd (9.04k/9.04k flops)\n",
      "  model_52/depthwise_conv2d_688/BiasAdd (6.93k/6.93k flops)\n",
      "  model_52/dense_52/Softmax (50/50 flops)\n",
      "  model_52/dense_52/BiasAdd (10/10 flops)\n",
      "\n",
      "======================End of Report==========================\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "36.195404\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-30 13:40:28.504469: I tensorflow/core/grappler/devices.cc:66] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0\n",
      "2022-04-30 13:40:28.504589: I tensorflow/core/grappler/clusters/single_machine.cc:357] Starting new session\n",
      "2022-04-30 13:40:28.509298: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:1137] Optimization results for grappler item: graph_to_optimize\n",
      "  function_optimizer: function_optimizer did nothing. time = 0.005ms.\n",
      "  function_optimizer: function_optimizer did nothing. time = 0.001ms.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=========================Options=============================\n",
      "-max_depth                  10000\n",
      "-min_bytes                  0\n",
      "-min_peak_bytes             0\n",
      "-min_residual_bytes         0\n",
      "-min_output_bytes           0\n",
      "-min_micros                 0\n",
      "-min_accelerator_micros     0\n",
      "-min_cpu_micros             0\n",
      "-min_params                 0\n",
      "-min_float_ops              1\n",
      "-min_occurrence             0\n",
      "-step                       -1\n",
      "-order_by                   float_ops\n",
      "-account_type_regexes       .*\n",
      "-start_name_regexes         .*\n",
      "-trim_name_regexes          \n",
      "-show_name_regexes          .*\n",
      "-hide_name_regexes          \n",
      "-account_displayed_op_only  true\n",
      "-select                     float_ops\n",
      "-output                     stdout:\n",
      "\n",
      "==================Model Analysis Report======================\n",
      "\n",
      "Doc:\n",
      "scope: The nodes in the model graph are organized by their names, which is hierarchical like filesystem.\n",
      "flops: Number of float operations. Note: Please read the implementation for the math behind it.\n",
      "\n",
      "Profile:\n",
      "node name | # float_ops\n",
      "_TFProfRoot (--/486.07m flops)\n",
      "  model_53/conv2d_747/Conv2D (62.03m/62.03m flops)\n",
      "  model_53/conv2d_750/Conv2D (53.18m/53.18m flops)\n",
      "  model_53/conv2d_745/Conv2D (50.69m/50.69m flops)\n",
      "  model_53/conv2d_752/Conv2D (44.51m/44.51m flops)\n",
      "  model_53/conv2d_751/Conv2D (40.06m/40.06m flops)\n",
      "  model_53/conv2d_753/Conv2D (36.56m/36.56m flops)\n",
      "  model_53/conv2d_749/Conv2D (35.45m/35.45m flops)\n",
      "  model_53/conv2d_743/Conv2D (29.49m/29.49m flops)\n",
      "  model_53/conv2d_746/Conv2D (26.86m/26.86m flops)\n",
      "  model_53/conv2d_744/Conv2D (23.04m/23.04m flops)\n",
      "  model_53/conv2d_748/Conv2D (20.19m/20.19m flops)\n",
      "  model_53/conv2d_754/Conv2D (14.15m/14.15m flops)\n",
      "  model_53/conv2d_755/Conv2D (10.46m/10.46m flops)\n",
      "  model_53/conv2d_742/Conv2D (9.44m/9.44m flops)\n",
      "  model_53/depthwise_conv2d_689/depthwise (5.31m/5.31m flops)\n",
      "  model_53/depthwise_conv2d_691/depthwise (4.15m/4.15m flops)\n",
      "  model_53/depthwise_conv2d_693/depthwise (2.20m/2.20m flops)\n",
      "  model_53/depthwise_conv2d_690/depthwise (2.07m/2.07m flops)\n",
      "  model_53/depthwise_conv2d_699/depthwise (1.19m/1.19m flops)\n",
      "  model_53/depthwise_conv2d_696/depthwise (1.16m/1.16m flops)\n",
      "  model_53/depthwise_conv2d_692/depthwise (1.14m/1.14m flops)\n",
      "  model_53/depthwise_conv2d_697/depthwise (1.07m/1.07m flops)\n",
      "  model_53/batch_normalization_1433/FusedBatchNormV3 (921.90k/921.90k flops)\n",
      "  model_53/depthwise_conv2d_698/depthwise (870.91k/870.91k flops)\n",
      "  model_53/depthwise_conv2d_695/depthwise (715.39k/715.39k flops)\n",
      "  model_53/depthwise_conv2d_694/depthwise (658.37k/658.37k flops)\n",
      "  model_53/batch_normalization_1432/FusedBatchNormV3 (590.02k/590.02k flops)\n",
      "  model_53/batch_normalization_1431/FusedBatchNormV3 (590.02k/590.02k flops)\n",
      "  model_53/batch_normalization_1437/FusedBatchNormV3 (507.54k/507.54k flops)\n",
      "  model_53/batch_normalization_1435/FusedBatchNormV3 (461.40k/461.40k flops)\n",
      "  model_53/batch_normalization_1436/FusedBatchNormV3 (461.40k/461.40k flops)\n",
      "  model_53/conv2d_743/BiasAdd (460.80k/460.80k flops)\n",
      "  model_53/conv2d_742/BiasAdd (294.91k/294.91k flops)\n",
      "  model_53/depthwise_conv2d_689/BiasAdd (294.91k/294.91k flops)\n",
      "  model_53/batch_normalization_1441/FusedBatchNormV3 (294.13k/294.13k flops)\n",
      "  model_53/conv2d_745/BiasAdd (253.44k/253.44k flops)\n",
      "  model_53/batch_normalization_1439/FusedBatchNormV3 (245.50k/245.50k flops)\n",
      "  model_53/batch_normalization_1440/FusedBatchNormV3 (245.50k/245.50k flops)\n",
      "  model_53/batch_normalization_1434/FusedBatchNormV3 (230.70k/230.70k flops)\n",
      "  model_53/depthwise_conv2d_691/BiasAdd (230.40k/230.40k flops)\n",
      "  model_53/conv2d_744/BiasAdd (230.40k/230.40k flops)\n",
      "  model_53/depthwise_conv2d_700/depthwise (178.85k/178.85k flops)\n",
      "  model_53/conv2d_747/BiasAdd (146.30k/146.30k flops)\n",
      "  model_53/batch_normalization_1451/FusedBatchNormV3 (135.24k/135.24k flops)\n",
      "  model_53/batch_normalization_1452/FusedBatchNormV3 (135.24k/135.24k flops)\n",
      "  model_53/batch_normalization_1446/FusedBatchNormV3 (131.12k/131.12k flops)\n",
      "  model_53/batch_normalization_1445/FusedBatchNormV3 (131.12k/131.12k flops)\n",
      "  model_53/batch_normalization_1438/FusedBatchNormV3 (127.38k/127.38k flops)\n",
      "  model_53/depthwise_conv2d_693/BiasAdd (122.11k/122.11k flops)\n",
      "  model_53/conv2d_746/BiasAdd (122.11k/122.11k flops)\n",
      "  model_53/batch_normalization_1448/FusedBatchNormV3 (121.72k/121.72k flops)\n",
      "  model_53/batch_normalization_1447/FusedBatchNormV3 (121.72k/121.72k flops)\n",
      "  model_53/depthwise_conv2d_701/depthwise (115.34k/115.34k flops)\n",
      "  model_53/depthwise_conv2d_690/BiasAdd (115.20k/115.20k flops)\n",
      "  model_53/batch_normalization_1449/FusedBatchNormV3 (98.78k/98.78k flops)\n",
      "  model_53/batch_normalization_1450/FusedBatchNormV3 (98.78k/98.78k flops)\n",
      "  model_53/batch_normalization_1444/FusedBatchNormV3 (81.14k/81.14k flops)\n",
      "  model_53/batch_normalization_1453/FusedBatchNormV3 (81.14k/81.14k flops)\n",
      "  model_53/batch_normalization_1443/FusedBatchNormV3 (81.14k/81.14k flops)\n",
      "  model_53/batch_normalization_1442/FusedBatchNormV3 (74.68k/74.68k flops)\n",
      "  model_53/depthwise_conv2d_699/BiasAdd (66.24k/66.24k flops)\n",
      "  model_53/conv2d_752/BiasAdd (66.24k/66.24k flops)\n",
      "  model_53/conv2d_749/BiasAdd (64.22k/64.22k flops)\n",
      "  model_53/depthwise_conv2d_696/BiasAdd (64.22k/64.22k flops)\n",
      "  model_53/depthwise_conv2d_692/BiasAdd (63.36k/63.36k flops)\n",
      "  model_53/conv2d_750/BiasAdd (59.62k/59.62k flops)\n",
      "  model_53/depthwise_conv2d_697/BiasAdd (59.62k/59.62k flops)\n",
      "  model_53/batch_normalization_1455/FusedBatchNormV3 (55.54k/55.54k flops)\n",
      "  model_53/depthwise_conv2d_698/BiasAdd (48.38k/48.38k flops)\n",
      "  model_53/conv2d_751/BiasAdd (48.38k/48.38k flops)\n",
      "  model_53/conv2d_753/BiasAdd (39.74k/39.74k flops)\n",
      "  model_53/depthwise_conv2d_695/BiasAdd (39.74k/39.74k flops)\n",
      "  model_53/conv2d_748/BiasAdd (39.74k/39.74k flops)\n",
      "  model_53/depthwise_conv2d_694/BiasAdd (36.58k/36.58k flops)\n",
      "  model_53/conv2d_754/BiasAdd (25.63k/25.63k flops)\n",
      "  model_53/batch_normalization_1454/FusedBatchNormV3 (21.53k/21.53k flops)\n",
      "  model_53/batch_normalization_1457/FusedBatchNormV3 (19.58k/19.58k flops)\n",
      "  model_53/batch_normalization_1456/FusedBatchNormV3 (17.09k/17.09k flops)\n",
      "  model_53/dense_53/MatMul (16.32k/16.32k flops)\n",
      "  model_53/depthwise_conv2d_700/BiasAdd (9.94k/9.94k flops)\n",
      "  model_53/conv2d_755/BiasAdd (7.34k/7.34k flops)\n",
      "  model_53/global_average_pooling2d_53/Mean (7.34k/7.34k flops)\n",
      "  model_53/depthwise_conv2d_701/BiasAdd (6.41k/6.41k flops)\n",
      "  model_53/dense_53/Softmax (50/50 flops)\n",
      "  model_53/dense_53/BiasAdd (10/10 flops)\n",
      "\n",
      "======================End of Report==========================\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "32.376796\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-30 13:40:29.430257: I tensorflow/core/grappler/devices.cc:66] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0\n",
      "2022-04-30 13:40:29.430373: I tensorflow/core/grappler/clusters/single_machine.cc:357] Starting new session\n",
      "2022-04-30 13:40:29.434538: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:1137] Optimization results for grappler item: graph_to_optimize\n",
      "  function_optimizer: function_optimizer did nothing. time = 0.004ms.\n",
      "  function_optimizer: function_optimizer did nothing. time = 0.001ms.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=========================Options=============================\n",
      "-max_depth                  10000\n",
      "-min_bytes                  0\n",
      "-min_peak_bytes             0\n",
      "-min_residual_bytes         0\n",
      "-min_output_bytes           0\n",
      "-min_micros                 0\n",
      "-min_accelerator_micros     0\n",
      "-min_cpu_micros             0\n",
      "-min_params                 0\n",
      "-min_float_ops              1\n",
      "-min_occurrence             0\n",
      "-step                       -1\n",
      "-order_by                   float_ops\n",
      "-account_type_regexes       .*\n",
      "-start_name_regexes         .*\n",
      "-trim_name_regexes          \n",
      "-show_name_regexes          .*\n",
      "-hide_name_regexes          \n",
      "-account_displayed_op_only  true\n",
      "-select                     float_ops\n",
      "-output                     stdout:\n",
      "\n",
      "==================Model Analysis Report======================\n",
      "\n",
      "Doc:\n",
      "scope: The nodes in the model graph are organized by their names, which is hierarchical like filesystem.\n",
      "flops: Number of float operations. Note: Please read the implementation for the math behind it.\n",
      "\n",
      "Profile:\n",
      "node name | # float_ops\n",
      "_TFProfRoot (--/362.54m flops)\n",
      "  model_54/conv2d_759/Conv2D (61.93m/61.93m flops)\n",
      "  model_54/conv2d_767/Conv2D (37.74m/37.74m flops)\n",
      "  model_54/conv2d_766/Conv2D (29.61m/29.61m flops)\n",
      "  model_54/conv2d_764/Conv2D (29.06m/29.06m flops)\n",
      "  model_54/conv2d_763/Conv2D (27.06m/27.06m flops)\n",
      "  model_54/conv2d_765/Conv2D (23.72m/23.72m flops)\n",
      "  model_54/conv2d_757/Conv2D (23.59m/23.59m flops)\n",
      "  model_54/conv2d_758/Conv2D (20.64m/20.64m flops)\n",
      "  model_54/conv2d_761/Conv2D (18.55m/18.55m flops)\n",
      "  model_54/conv2d_768/Conv2D (17.20m/17.20m flops)\n",
      "  model_54/conv2d_760/Conv2D (16.87m/16.87m flops)\n",
      "  model_54/conv2d_762/Conv2D (10.26m/10.26m flops)\n",
      "  model_54/conv2d_769/Conv2D (9.86m/9.86m flops)\n",
      "  model_54/conv2d_756/Conv2D (9.44m/9.44m flops)\n",
      "  model_54/depthwise_conv2d_702/depthwise (5.31m/5.31m flops)\n",
      "  model_54/depthwise_conv2d_704/depthwise (4.64m/4.64m flops)\n",
      "  model_54/depthwise_conv2d_703/depthwise (1.66m/1.66m flops)\n",
      "  model_54/depthwise_conv2d_706/depthwise (1.26m/1.26m flops)\n",
      "  model_54/depthwise_conv2d_705/depthwise (1.24m/1.24m flops)\n",
      "  model_54/depthwise_conv2d_712/depthwise (938.30k/938.30k flops)\n",
      "  model_54/depthwise_conv2d_709/depthwise (902.02k/902.02k flops)\n",
      "  model_54/depthwise_conv2d_710/depthwise (751.68k/751.68k flops)\n",
      "  model_54/batch_normalization_1460/FusedBatchNormV3 (737.52k/737.52k flops)\n",
      "  model_54/depthwise_conv2d_711/depthwise (736.13k/736.13k flops)\n",
      "  model_54/depthwise_conv2d_708/depthwise (699.84k/699.84k flops)\n",
      "  model_54/batch_normalization_1459/FusedBatchNormV3 (590.02k/590.02k flops)\n",
      "  model_54/batch_normalization_1458/FusedBatchNormV3 (590.02k/590.02k flops)\n",
      "  model_54/batch_normalization_1464/FusedBatchNormV3 (553.68k/553.68k flops)\n",
      "  model_54/batch_normalization_1462/FusedBatchNormV3 (516.77k/516.77k flops)\n",
      "  model_54/batch_normalization_1463/FusedBatchNormV3 (516.77k/516.77k flops)\n",
      "  model_54/conv2d_757/BiasAdd (368.64k/368.64k flops)\n",
      "  model_54/depthwise_conv2d_707/depthwise (342.14k/342.14k flops)\n",
      "  model_54/conv2d_756/BiasAdd (294.91k/294.91k flops)\n",
      "  model_54/depthwise_conv2d_702/BiasAdd (294.91k/294.91k flops)\n",
      "  model_54/conv2d_759/BiasAdd (276.48k/276.48k flops)\n",
      "  model_54/conv2d_758/BiasAdd (258.05k/258.05k flops)\n",
      "  model_54/depthwise_conv2d_704/BiasAdd (258.05k/258.05k flops)\n",
      "  model_54/depthwise_conv2d_713/depthwise (234.58k/234.58k flops)\n",
      "  model_54/batch_normalization_1461/FusedBatchNormV3 (184.56k/184.56k flops)\n",
      "  model_54/batch_normalization_1468/FusedBatchNormV3 (152.86k/152.86k flops)\n",
      "  model_54/batch_normalization_1467/FusedBatchNormV3 (141.28k/141.28k flops)\n",
      "  model_54/batch_normalization_1466/FusedBatchNormV3 (141.28k/141.28k flops)\n",
      "  model_54/batch_normalization_1465/FusedBatchNormV3 (138.96k/138.96k flops)\n",
      "  model_54/depthwise_conv2d_714/depthwise (106.92k/106.92k flops)\n",
      "  model_54/batch_normalization_1480/FusedBatchNormV3 (106.43k/106.43k flops)\n",
      "  model_54/batch_normalization_1478/FusedBatchNormV3 (106.43k/106.43k flops)\n",
      "  model_54/batch_normalization_1479/FusedBatchNormV3 (106.43k/106.43k flops)\n",
      "  model_54/batch_normalization_1473/FusedBatchNormV3 (102.31k/102.31k flops)\n",
      "  model_54/batch_normalization_1472/FusedBatchNormV3 (102.31k/102.31k flops)\n",
      "  model_54/depthwise_conv2d_703/BiasAdd (92.16k/92.16k flops)\n",
      "  model_54/batch_normalization_1475/FusedBatchNormV3 (85.26k/85.26k flops)\n",
      "  model_54/batch_normalization_1474/FusedBatchNormV3 (85.26k/85.26k flops)\n",
      "  model_54/batch_normalization_1476/FusedBatchNormV3 (83.50k/83.50k flops)\n",
      "  model_54/batch_normalization_1477/FusedBatchNormV3 (83.50k/83.50k flops)\n",
      "  model_54/batch_normalization_1471/FusedBatchNormV3 (79.38k/79.38k flops)\n",
      "  model_54/batch_normalization_1470/FusedBatchNormV3 (79.38k/79.38k flops)\n",
      "  model_54/conv2d_761/BiasAdd (76.03k/76.03k flops)\n",
      "  model_54/depthwise_conv2d_706/BiasAdd (70.27k/70.27k flops)\n",
      "  model_54/conv2d_760/BiasAdd (70.27k/70.27k flops)\n",
      "  model_54/depthwise_conv2d_705/BiasAdd (69.12k/69.12k flops)\n",
      "  model_54/depthwise_conv2d_712/BiasAdd (52.13k/52.13k flops)\n",
      "  model_54/conv2d_767/BiasAdd (52.13k/52.13k flops)\n",
      "  model_54/conv2d_766/BiasAdd (52.13k/52.13k flops)\n",
      "  model_54/batch_normalization_1482/FusedBatchNormV3 (51.48k/51.48k flops)\n",
      "  model_54/conv2d_763/BiasAdd (50.11k/50.11k flops)\n",
      "  model_54/depthwise_conv2d_709/BiasAdd (50.11k/50.11k flops)\n",
      "  model_54/conv2d_764/BiasAdd (41.76k/41.76k flops)\n",
      "  model_54/depthwise_conv2d_710/BiasAdd (41.76k/41.76k flops)\n",
      "  model_54/depthwise_conv2d_711/BiasAdd (40.90k/40.90k flops)\n",
      "  model_54/conv2d_765/BiasAdd (40.90k/40.90k flops)\n",
      "  model_54/depthwise_conv2d_708/BiasAdd (38.88k/38.88k flops)\n",
      "  model_54/conv2d_762/BiasAdd (38.88k/38.88k flops)\n",
      "  model_54/batch_normalization_1469/FusedBatchNormV3 (38.81k/38.81k flops)\n",
      "  model_54/batch_normalization_1481/FusedBatchNormV3 (28.24k/28.24k flops)\n",
      "  model_54/conv2d_768/BiasAdd (23.76k/23.76k flops)\n",
      "  model_54/batch_normalization_1484/FusedBatchNormV3 (19.92k/19.92k flops)\n",
      "  model_54/depthwise_conv2d_707/BiasAdd (19.01k/19.01k flops)\n",
      "  model_54/dense_54/MatMul (16.60k/16.60k flops)\n",
      "  model_54/batch_normalization_1483/FusedBatchNormV3 (15.84k/15.84k flops)\n",
      "  model_54/depthwise_conv2d_713/BiasAdd (13.03k/13.03k flops)\n",
      "  model_54/global_average_pooling2d_54/Mean (7.47k/7.47k flops)\n",
      "  model_54/conv2d_769/BiasAdd (7.47k/7.47k flops)\n",
      "  model_54/depthwise_conv2d_714/BiasAdd (5.94k/5.94k flops)\n",
      "  model_54/dense_54/Softmax (50/50 flops)\n",
      "  model_54/dense_54/BiasAdd (10/10 flops)\n",
      "\n",
      "======================End of Report==========================\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "34.993012\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-30 13:40:30.459864: I tensorflow/core/grappler/devices.cc:66] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0\n",
      "2022-04-30 13:40:30.459995: I tensorflow/core/grappler/clusters/single_machine.cc:357] Starting new session\n",
      "2022-04-30 13:40:30.464530: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:1137] Optimization results for grappler item: graph_to_optimize\n",
      "  function_optimizer: function_optimizer did nothing. time = 0.006ms.\n",
      "  function_optimizer: function_optimizer did nothing. time = 0.001ms.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=========================Options=============================\n",
      "-max_depth                  10000\n",
      "-min_bytes                  0\n",
      "-min_peak_bytes             0\n",
      "-min_residual_bytes         0\n",
      "-min_output_bytes           0\n",
      "-min_micros                 0\n",
      "-min_accelerator_micros     0\n",
      "-min_cpu_micros             0\n",
      "-min_params                 0\n",
      "-min_float_ops              1\n",
      "-min_occurrence             0\n",
      "-step                       -1\n",
      "-order_by                   float_ops\n",
      "-account_type_regexes       .*\n",
      "-start_name_regexes         .*\n",
      "-trim_name_regexes          \n",
      "-show_name_regexes          .*\n",
      "-hide_name_regexes          \n",
      "-account_displayed_op_only  true\n",
      "-select                     float_ops\n",
      "-output                     stdout:\n",
      "\n",
      "==================Model Analysis Report======================\n",
      "\n",
      "Doc:\n",
      "scope: The nodes in the model graph are organized by their names, which is hierarchical like filesystem.\n",
      "flops: Number of float operations. Note: Please read the implementation for the math behind it.\n",
      "\n",
      "Profile:\n",
      "node name | # float_ops\n",
      "_TFProfRoot (--/467.07m flops)\n",
      "  model_55/conv2d_773/Conv2D (73.16m/73.16m flops)\n",
      "  model_55/conv2d_779/Conv2D (51.66m/51.66m flops)\n",
      "  model_55/conv2d_780/Conv2D (49.75m/49.75m flops)\n",
      "  model_55/conv2d_775/Conv2D (42.65m/42.65m flops)\n",
      "  model_55/conv2d_778/Conv2D (40.71m/40.71m flops)\n",
      "  model_55/conv2d_781/Conv2D (35.84m/35.84m flops)\n",
      "  model_55/conv2d_777/Conv2D (34.50m/34.50m flops)\n",
      "  model_55/conv2d_774/Conv2D (25.84m/25.84m flops)\n",
      "  model_55/conv2d_771/Conv2D (20.05m/20.05m flops)\n",
      "  model_55/conv2d_772/Conv2D (19.74m/19.74m flops)\n",
      "  model_55/conv2d_776/Conv2D (19.29m/19.29m flops)\n",
      "  model_55/conv2d_782/Conv2D (10.13m/10.13m flops)\n",
      "  model_55/conv2d_770/Conv2D (9.44m/9.44m flops)\n",
      "  model_55/depthwise_conv2d_715/depthwise (5.31m/5.31m flops)\n",
      "  model_55/depthwise_conv2d_717/depthwise (5.23m/5.23m flops)\n",
      "  model_55/conv2d_783/Conv2D (4.62m/4.62m flops)\n",
      "  model_55/depthwise_conv2d_719/depthwise (1.85m/1.85m flops)\n",
      "  model_55/depthwise_conv2d_716/depthwise (1.41m/1.41m flops)\n",
      "  model_55/depthwise_conv2d_718/depthwise (1.31m/1.31m flops)\n",
      "  model_55/depthwise_conv2d_724/depthwise (1.22m/1.22m flops)\n",
      "  model_55/depthwise_conv2d_723/depthwise (984.96k/984.96k flops)\n",
      "  model_55/depthwise_conv2d_722/depthwise (964.22k/964.22k flops)\n",
      "  model_55/depthwise_conv2d_725/depthwise (948.67k/948.67k flops)\n",
      "  model_55/depthwise_conv2d_721/depthwise (834.62k/834.62k flops)\n",
      "  model_55/batch_normalization_1487/FusedBatchNormV3 (626.89k/626.89k flops)\n",
      "  model_55/batch_normalization_1486/FusedBatchNormV3 (590.02k/590.02k flops)\n",
      "  model_55/batch_normalization_1485/FusedBatchNormV3 (590.02k/590.02k flops)\n",
      "  model_55/batch_normalization_1489/FusedBatchNormV3 (581.36k/581.36k flops)\n",
      "  model_55/batch_normalization_1491/FusedBatchNormV3 (581.36k/581.36k flops)\n",
      "  model_55/batch_normalization_1490/FusedBatchNormV3 (581.36k/581.36k flops)\n",
      "  model_55/depthwise_conv2d_720/depthwise (539.14k/539.14k flops)\n",
      "  model_55/conv2d_771/BiasAdd (313.34k/313.34k flops)\n",
      "  model_55/conv2d_770/BiasAdd (294.91k/294.91k flops)\n",
      "  model_55/depthwise_conv2d_715/BiasAdd (294.91k/294.91k flops)\n",
      "  model_55/conv2d_773/BiasAdd (290.30k/290.30k flops)\n",
      "  model_55/depthwise_conv2d_717/BiasAdd (290.30k/290.30k flops)\n",
      "  model_55/conv2d_772/BiasAdd (290.30k/290.30k flops)\n",
      "  model_55/batch_normalization_1495/FusedBatchNormV3 (240.86k/240.86k flops)\n",
      "  model_55/depthwise_conv2d_726/depthwise (220.32k/220.32k flops)\n",
      "  model_55/batch_normalization_1494/FusedBatchNormV3 (206.12k/206.12k flops)\n",
      "  model_55/batch_normalization_1493/FusedBatchNormV3 (206.12k/206.12k flops)\n",
      "  model_55/batch_normalization_1488/FusedBatchNormV3 (156.88k/156.88k flops)\n",
      "  model_55/batch_normalization_1492/FusedBatchNormV3 (145.91k/145.91k flops)\n",
      "  model_55/batch_normalization_1504/FusedBatchNormV3 (138.77k/138.77k flops)\n",
      "  model_55/batch_normalization_1503/FusedBatchNormV3 (138.77k/138.77k flops)\n",
      "  model_55/conv2d_775/BiasAdd (119.81k/119.81k flops)\n",
      "  model_55/batch_normalization_1502/FusedBatchNormV3 (111.72k/111.72k flops)\n",
      "  model_55/batch_normalization_1501/FusedBatchNormV3 (111.72k/111.72k flops)\n",
      "  model_55/batch_normalization_1500/FusedBatchNormV3 (109.37k/109.37k flops)\n",
      "  model_55/batch_normalization_1499/FusedBatchNormV3 (109.37k/109.37k flops)\n",
      "  model_55/batch_normalization_1505/FusedBatchNormV3 (107.60k/107.60k flops)\n",
      "  model_55/batch_normalization_1506/FusedBatchNormV3 (107.60k/107.60k flops)\n",
      "  model_55/depthwise_conv2d_719/BiasAdd (102.53k/102.53k flops)\n",
      "  model_55/conv2d_774/BiasAdd (102.53k/102.53k flops)\n",
      "  model_55/batch_normalization_1507/FusedBatchNormV3 (99.96k/99.96k flops)\n",
      "  model_55/batch_normalization_1498/FusedBatchNormV3 (94.67k/94.67k flops)\n",
      "  model_55/batch_normalization_1497/FusedBatchNormV3 (94.67k/94.67k flops)\n",
      "  model_55/depthwise_conv2d_716/BiasAdd (78.34k/78.34k flops)\n",
      "  model_55/depthwise_conv2d_718/BiasAdd (72.58k/72.58k flops)\n",
      "  model_55/depthwise_conv2d_724/BiasAdd (67.97k/67.97k flops)\n",
      "  model_55/conv2d_779/BiasAdd (67.97k/67.97k flops)\n",
      "  model_55/depthwise_conv2d_727/depthwise (67.07k/67.07k flops)\n",
      "  model_55/batch_normalization_1496/FusedBatchNormV3 (61.15k/61.15k flops)\n",
      "  model_55/conv2d_778/BiasAdd (54.72k/54.72k flops)\n",
      "  model_55/depthwise_conv2d_723/BiasAdd (54.72k/54.72k flops)\n",
      "  model_55/conv2d_777/BiasAdd (53.57k/53.57k flops)\n",
      "  model_55/depthwise_conv2d_722/BiasAdd (53.57k/53.57k flops)\n",
      "  model_55/depthwise_conv2d_725/BiasAdd (52.70k/52.70k flops)\n",
      "  model_55/conv2d_780/BiasAdd (52.70k/52.70k flops)\n",
      "  model_55/conv2d_781/BiasAdd (48.96k/48.96k flops)\n",
      "  model_55/depthwise_conv2d_721/BiasAdd (46.37k/46.37k flops)\n",
      "  model_55/conv2d_776/BiasAdd (46.37k/46.37k flops)\n",
      "  model_55/batch_normalization_1509/FusedBatchNormV3 (32.29k/32.29k flops)\n",
      "  model_55/depthwise_conv2d_720/BiasAdd (29.95k/29.95k flops)\n",
      "  model_55/batch_normalization_1508/FusedBatchNormV3 (26.52k/26.52k flops)\n",
      "  model_55/conv2d_782/BiasAdd (14.90k/14.90k flops)\n",
      "  model_55/batch_normalization_1511/FusedBatchNormV3 (14.88k/14.88k flops)\n",
      "  model_55/dense_55/MatMul (12.40k/12.40k flops)\n",
      "  model_55/depthwise_conv2d_726/BiasAdd (12.24k/12.24k flops)\n",
      "  model_55/batch_normalization_1510/FusedBatchNormV3 (9.94k/9.94k flops)\n",
      "  model_55/global_average_pooling2d_55/Mean (5.58k/5.58k flops)\n",
      "  model_55/conv2d_783/BiasAdd (5.58k/5.58k flops)\n",
      "  model_55/depthwise_conv2d_727/BiasAdd (3.73k/3.73k flops)\n",
      "  model_55/dense_55/Softmax (50/50 flops)\n",
      "  model_55/dense_55/BiasAdd (10/10 flops)\n",
      "\n",
      "======================End of Report==========================\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "34.90318\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-30 13:40:31.372814: I tensorflow/core/grappler/devices.cc:66] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0\n",
      "2022-04-30 13:40:31.372932: I tensorflow/core/grappler/clusters/single_machine.cc:357] Starting new session\n",
      "2022-04-30 13:40:31.377025: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:1137] Optimization results for grappler item: graph_to_optimize\n",
      "  function_optimizer: function_optimizer did nothing. time = 0.006ms.\n",
      "  function_optimizer: function_optimizer did nothing. time = 0.001ms.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=========================Options=============================\n",
      "-max_depth                  10000\n",
      "-min_bytes                  0\n",
      "-min_peak_bytes             0\n",
      "-min_residual_bytes         0\n",
      "-min_output_bytes           0\n",
      "-min_micros                 0\n",
      "-min_accelerator_micros     0\n",
      "-min_cpu_micros             0\n",
      "-min_params                 0\n",
      "-min_float_ops              1\n",
      "-min_occurrence             0\n",
      "-step                       -1\n",
      "-order_by                   float_ops\n",
      "-account_type_regexes       .*\n",
      "-start_name_regexes         .*\n",
      "-trim_name_regexes          \n",
      "-show_name_regexes          .*\n",
      "-hide_name_regexes          \n",
      "-account_displayed_op_only  true\n",
      "-select                     float_ops\n",
      "-output                     stdout:\n",
      "\n",
      "==================Model Analysis Report======================\n",
      "\n",
      "Doc:\n",
      "scope: The nodes in the model graph are organized by their names, which is hierarchical like filesystem.\n",
      "flops: Number of float operations. Note: Please read the implementation for the math behind it.\n",
      "\n",
      "Profile:\n",
      "node name | # float_ops\n",
      "_TFProfRoot (--/527.31m flops)\n",
      "  model_56/conv2d_793/Conv2D (63.76m/63.76m flops)\n",
      "  model_56/conv2d_794/Conv2D (62.99m/62.99m flops)\n",
      "  model_56/conv2d_792/Conv2D (62.63m/62.63m flops)\n",
      "  model_56/conv2d_789/Conv2D (59.30m/59.30m flops)\n",
      "  model_56/conv2d_787/Conv2D (51.76m/51.76m flops)\n",
      "  model_56/conv2d_795/Conv2D (42.27m/42.27m flops)\n",
      "  model_56/conv2d_791/Conv2D (35.39m/35.39m flops)\n",
      "  model_56/conv2d_788/Conv2D (27.37m/27.37m flops)\n",
      "  model_56/conv2d_785/Conv2D (20.05m/20.05m flops)\n",
      "  model_56/conv2d_790/Conv2D (18.73m/18.73m flops)\n",
      "  model_56/conv2d_796/Conv2D (16.70m/16.70m flops)\n",
      "  model_56/conv2d_786/Conv2D (16.29m/16.29m flops)\n",
      "  model_56/conv2d_797/Conv2D (10.89m/10.89m flops)\n",
      "  model_56/conv2d_784/Conv2D (9.44m/9.44m flops)\n",
      "  model_56/depthwise_conv2d_728/depthwise (5.31m/5.31m flops)\n",
      "  model_56/depthwise_conv2d_730/depthwise (4.31m/4.31m flops)\n",
      "  model_56/depthwise_conv2d_732/depthwise (2.28m/2.28m flops)\n",
      "  model_56/depthwise_conv2d_729/depthwise (1.41m/1.41m flops)\n",
      "  model_56/depthwise_conv2d_736/depthwise (1.28m/1.28m flops)\n",
      "  model_56/depthwise_conv2d_738/depthwise (1.26m/1.26m flops)\n",
      "  model_56/depthwise_conv2d_737/depthwise (1.17m/1.17m flops)\n",
      "  model_56/depthwise_conv2d_735/depthwise (1.15m/1.15m flops)\n",
      "  model_56/depthwise_conv2d_731/depthwise (1.12m/1.12m flops)\n",
      "  model_56/depthwise_conv2d_734/depthwise (720.58k/720.58k flops)\n",
      "  model_56/batch_normalization_1514/FusedBatchNormV3 (626.89k/626.89k flops)\n",
      "  model_56/depthwise_conv2d_733/depthwise (606.53k/606.53k flops)\n",
      "  model_56/batch_normalization_1513/FusedBatchNormV3 (590.02k/590.02k flops)\n",
      "  model_56/batch_normalization_1512/FusedBatchNormV3 (590.02k/590.02k flops)\n",
      "  model_56/batch_normalization_1518/FusedBatchNormV3 (498.31k/498.31k flops)\n",
      "  model_56/batch_normalization_1516/FusedBatchNormV3 (479.86k/479.86k flops)\n",
      "  model_56/batch_normalization_1517/FusedBatchNormV3 (479.86k/479.86k flops)\n",
      "  model_56/conv2d_785/BiasAdd (313.34k/313.34k flops)\n",
      "  model_56/depthwise_conv2d_728/BiasAdd (294.91k/294.91k flops)\n",
      "  model_56/conv2d_784/BiasAdd (294.91k/294.91k flops)\n",
      "  model_56/batch_normalization_1522/FusedBatchNormV3 (270.97k/270.97k flops)\n",
      "  model_56/batch_normalization_1521/FusedBatchNormV3 (254.76k/254.76k flops)\n",
      "  model_56/batch_normalization_1520/FusedBatchNormV3 (254.76k/254.76k flops)\n",
      "  model_56/conv2d_787/BiasAdd (248.83k/248.83k flops)\n",
      "  model_56/depthwise_conv2d_730/BiasAdd (239.62k/239.62k flops)\n",
      "  model_56/conv2d_786/BiasAdd (239.62k/239.62k flops)\n",
      "  model_56/depthwise_conv2d_739/depthwise (195.70k/195.70k flops)\n",
      "  model_56/batch_normalization_1515/FusedBatchNormV3 (156.88k/156.88k flops)\n",
      "  model_56/batch_normalization_1529/FusedBatchNormV3 (144.65k/144.65k flops)\n",
      "  model_56/batch_normalization_1528/FusedBatchNormV3 (144.65k/144.65k flops)\n",
      "  model_56/batch_normalization_1533/FusedBatchNormV3 (142.88k/142.88k flops)\n",
      "  model_56/batch_normalization_1532/FusedBatchNormV3 (142.88k/142.88k flops)\n",
      "  model_56/conv2d_789/BiasAdd (134.78k/134.78k flops)\n",
      "  model_56/batch_normalization_1531/FusedBatchNormV3 (132.30k/132.30k flops)\n",
      "  model_56/batch_normalization_1530/FusedBatchNormV3 (132.30k/132.30k flops)\n",
      "  model_56/batch_normalization_1527/FusedBatchNormV3 (129.95k/129.95k flops)\n",
      "  model_56/batch_normalization_1526/FusedBatchNormV3 (129.95k/129.95k flops)\n",
      "  model_56/depthwise_conv2d_732/BiasAdd (126.72k/126.72k flops)\n",
      "  model_56/conv2d_788/BiasAdd (126.72k/126.72k flops)\n",
      "  model_56/batch_normalization_1519/FusedBatchNormV3 (125.06k/125.06k flops)\n",
      "  model_56/depthwise_conv2d_740/depthwise (124.42k/124.42k flops)\n",
      "  model_56/batch_normalization_1534/FusedBatchNormV3 (88.79k/88.79k flops)\n",
      "  model_56/batch_normalization_1525/FusedBatchNormV3 (81.73k/81.73k flops)\n",
      "  model_56/batch_normalization_1524/FusedBatchNormV3 (81.73k/81.73k flops)\n",
      "  model_56/depthwise_conv2d_729/BiasAdd (78.34k/78.34k flops)\n",
      "  model_56/conv2d_792/BiasAdd (70.85k/70.85k flops)\n",
      "  model_56/depthwise_conv2d_736/BiasAdd (70.85k/70.85k flops)\n",
      "  model_56/depthwise_conv2d_738/BiasAdd (69.98k/69.98k flops)\n",
      "  model_56/conv2d_794/BiasAdd (69.98k/69.98k flops)\n",
      "  model_56/batch_normalization_1523/FusedBatchNormV3 (68.80k/68.80k flops)\n",
      "  model_56/conv2d_793/BiasAdd (64.80k/64.80k flops)\n",
      "  model_56/depthwise_conv2d_737/BiasAdd (64.80k/64.80k flops)\n",
      "  model_56/conv2d_791/BiasAdd (63.65k/63.65k flops)\n",
      "  model_56/depthwise_conv2d_735/BiasAdd (63.65k/63.65k flops)\n",
      "  model_56/depthwise_conv2d_731/BiasAdd (62.21k/62.21k flops)\n",
      "  model_56/batch_normalization_1536/FusedBatchNormV3 (59.90k/59.90k flops)\n",
      "  model_56/conv2d_795/BiasAdd (43.49k/43.49k flops)\n",
      "  model_56/depthwise_conv2d_734/BiasAdd (40.03k/40.03k flops)\n",
      "  model_56/conv2d_790/BiasAdd (40.03k/40.03k flops)\n",
      "  model_56/depthwise_conv2d_733/BiasAdd (33.70k/33.70k flops)\n",
      "  model_56/conv2d_796/BiasAdd (27.65k/27.65k flops)\n",
      "  model_56/batch_normalization_1535/FusedBatchNormV3 (23.56k/23.56k flops)\n",
      "  model_56/batch_normalization_1538/FusedBatchNormV3 (18.91k/18.91k flops)\n",
      "  model_56/batch_normalization_1537/FusedBatchNormV3 (18.43k/18.43k flops)\n",
      "  model_56/dense_56/MatMul (15.76k/15.76k flops)\n",
      "  model_56/depthwise_conv2d_739/BiasAdd (10.87k/10.87k flops)\n",
      "  model_56/conv2d_797/BiasAdd (7.09k/7.09k flops)\n",
      "  model_56/global_average_pooling2d_56/Mean (7.09k/7.09k flops)\n",
      "  model_56/depthwise_conv2d_740/BiasAdd (6.91k/6.91k flops)\n",
      "  model_56/dense_56/Softmax (50/50 flops)\n",
      "  model_56/dense_56/BiasAdd (10/10 flops)\n",
      "\n",
      "======================End of Report==========================\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "33.785532\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-30 13:40:32.412333: I tensorflow/core/grappler/devices.cc:66] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0\n",
      "2022-04-30 13:40:32.412452: I tensorflow/core/grappler/clusters/single_machine.cc:357] Starting new session\n",
      "2022-04-30 13:40:32.417141: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:1137] Optimization results for grappler item: graph_to_optimize\n",
      "  function_optimizer: function_optimizer did nothing. time = 0.006ms.\n",
      "  function_optimizer: function_optimizer did nothing. time = 0.001ms.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=========================Options=============================\n",
      "-max_depth                  10000\n",
      "-min_bytes                  0\n",
      "-min_peak_bytes             0\n",
      "-min_residual_bytes         0\n",
      "-min_output_bytes           0\n",
      "-min_micros                 0\n",
      "-min_accelerator_micros     0\n",
      "-min_cpu_micros             0\n",
      "-min_params                 0\n",
      "-min_float_ops              1\n",
      "-min_occurrence             0\n",
      "-step                       -1\n",
      "-order_by                   float_ops\n",
      "-account_type_regexes       .*\n",
      "-start_name_regexes         .*\n",
      "-trim_name_regexes          \n",
      "-show_name_regexes          .*\n",
      "-hide_name_regexes          \n",
      "-account_displayed_op_only  true\n",
      "-select                     float_ops\n",
      "-output                     stdout:\n",
      "\n",
      "==================Model Analysis Report======================\n",
      "\n",
      "Doc:\n",
      "scope: The nodes in the model graph are organized by their names, which is hierarchical like filesystem.\n",
      "flops: Number of float operations. Note: Please read the implementation for the math behind it.\n",
      "\n",
      "Profile:\n",
      "node name | # float_ops\n",
      "_TFProfRoot (--/522.42m flops)\n",
      "  model_57/conv2d_807/Conv2D (66.08m/66.08m flops)\n",
      "  model_57/conv2d_806/Conv2D (63.33m/63.33m flops)\n",
      "  model_57/conv2d_808/Conv2D (54.14m/54.14m flops)\n",
      "  model_57/conv2d_803/Conv2D (54.08m/54.08m flops)\n",
      "  model_57/conv2d_805/Conv2D (51.89m/51.89m flops)\n",
      "  model_57/conv2d_809/Conv2D (45.60m/45.60m flops)\n",
      "  model_57/conv2d_799/Conv2D (31.85m/31.85m flops)\n",
      "  model_57/conv2d_810/Conv2D (28.65m/28.65m flops)\n",
      "  model_57/conv2d_804/Conv2D (27.18m/27.18m flops)\n",
      "  model_57/conv2d_811/Conv2D (17.43m/17.43m flops)\n",
      "  model_57/conv2d_801/Conv2D (16.57m/16.57m flops)\n",
      "  model_57/conv2d_800/Conv2D (14.43m/14.43m flops)\n",
      "  model_57/conv2d_802/Conv2D (13.86m/13.86m flops)\n",
      "  model_57/conv2d_798/Conv2D (9.44m/9.44m flops)\n",
      "  model_57/depthwise_conv2d_741/depthwise (5.31m/5.31m flops)\n",
      "  model_57/depthwise_conv2d_743/depthwise (2.41m/2.41m flops)\n",
      "  model_57/depthwise_conv2d_742/depthwise (2.24m/2.24m flops)\n",
      "  model_57/depthwise_conv2d_745/depthwise (2.01m/2.01m flops)\n",
      "  model_57/depthwise_conv2d_750/depthwise (1.25m/1.25m flops)\n",
      "  model_57/depthwise_conv2d_749/depthwise (1.23m/1.23m flops)\n",
      "  model_57/depthwise_conv2d_748/depthwise (1.20m/1.20m flops)\n",
      "  model_57/depthwise_conv2d_747/depthwise (1.01m/1.01m flops)\n",
      "  model_57/depthwise_conv2d_751/depthwise (1.01m/1.01m flops)\n",
      "  model_57/batch_normalization_1541/FusedBatchNormV3 (995.65k/995.65k flops)\n",
      "  model_57/depthwise_conv2d_744/depthwise (642.82k/642.82k flops)\n",
      "  model_57/depthwise_conv2d_746/depthwise (627.26k/627.26k flops)\n",
      "  model_57/batch_normalization_1540/FusedBatchNormV3 (590.02k/590.02k flops)\n",
      "  model_57/batch_normalization_1539/FusedBatchNormV3 (590.02k/590.02k flops)\n",
      "  model_57/conv2d_799/BiasAdd (497.66k/497.66k flops)\n",
      "  model_57/conv2d_798/BiasAdd (294.91k/294.91k flops)\n",
      "  model_57/depthwise_conv2d_741/BiasAdd (294.91k/294.91k flops)\n",
      "  model_57/batch_normalization_1545/FusedBatchNormV3 (286.07k/286.07k flops)\n",
      "  model_57/batch_normalization_1549/FusedBatchNormV3 (280.24k/280.24k flops)\n",
      "  model_57/batch_normalization_1544/FusedBatchNormV3 (267.61k/267.61k flops)\n",
      "  model_57/batch_normalization_1543/FusedBatchNormV3 (267.61k/267.61k flops)\n",
      "  model_57/depthwise_conv2d_752/depthwise (263.09k/263.09k flops)\n",
      "  model_57/batch_normalization_1542/FusedBatchNormV3 (249.16k/249.16k flops)\n",
      "  model_57/batch_normalization_1548/FusedBatchNormV3 (224.65k/224.65k flops)\n",
      "  model_57/batch_normalization_1547/FusedBatchNormV3 (224.65k/224.65k flops)\n",
      "  model_57/depthwise_conv2d_753/depthwise (158.76k/158.76k flops)\n",
      "  model_57/conv2d_801/BiasAdd (142.85k/142.85k flops)\n",
      "  model_57/batch_normalization_1558/FusedBatchNormV3 (141.71k/141.71k flops)\n",
      "  model_57/batch_normalization_1557/FusedBatchNormV3 (141.71k/141.71k flops)\n",
      "  model_57/batch_normalization_1555/FusedBatchNormV3 (139.94k/139.94k flops)\n",
      "  model_57/batch_normalization_1556/FusedBatchNormV3 (139.94k/139.94k flops)\n",
      "  model_57/conv2d_803/BiasAdd (139.39k/139.39k flops)\n",
      "  model_57/batch_normalization_1554/FusedBatchNormV3 (135.83k/135.83k flops)\n",
      "  model_57/batch_normalization_1553/FusedBatchNormV3 (135.83k/135.83k flops)\n",
      "  model_57/conv2d_800/BiasAdd (133.63k/133.63k flops)\n",
      "  model_57/depthwise_conv2d_743/BiasAdd (133.63k/133.63k flops)\n",
      "  model_57/depthwise_conv2d_742/BiasAdd (124.42k/124.42k flops)\n",
      "  model_57/batch_normalization_1561/FusedBatchNormV3 (119.36k/119.36k flops)\n",
      "  model_57/batch_normalization_1559/FusedBatchNormV3 (114.66k/114.66k flops)\n",
      "  model_57/batch_normalization_1552/FusedBatchNormV3 (114.66k/114.66k flops)\n",
      "  model_57/batch_normalization_1560/FusedBatchNormV3 (114.66k/114.66k flops)\n",
      "  model_57/batch_normalization_1551/FusedBatchNormV3 (114.66k/114.66k flops)\n",
      "  model_57/depthwise_conv2d_745/BiasAdd (111.74k/111.74k flops)\n",
      "  model_57/conv2d_802/BiasAdd (111.74k/111.74k flops)\n",
      "  model_57/batch_normalization_1563/FusedBatchNormV3 (76.44k/76.44k flops)\n",
      "  model_57/batch_normalization_1546/FusedBatchNormV3 (71.80k/71.80k flops)\n",
      "  model_57/batch_normalization_1550/FusedBatchNormV3 (71.15k/71.15k flops)\n",
      "  model_57/depthwise_conv2d_750/BiasAdd (69.41k/69.41k flops)\n",
      "  model_57/conv2d_807/BiasAdd (69.41k/69.41k flops)\n",
      "  model_57/depthwise_conv2d_749/BiasAdd (68.54k/68.54k flops)\n",
      "  model_57/conv2d_806/BiasAdd (68.54k/68.54k flops)\n",
      "  model_57/depthwise_conv2d_748/BiasAdd (66.53k/66.53k flops)\n",
      "  model_57/conv2d_805/BiasAdd (66.53k/66.53k flops)\n",
      "  model_57/conv2d_809/BiasAdd (58.46k/58.46k flops)\n",
      "  model_57/depthwise_conv2d_751/BiasAdd (56.16k/56.16k flops)\n",
      "  model_57/depthwise_conv2d_747/BiasAdd (56.16k/56.16k flops)\n",
      "  model_57/conv2d_808/BiasAdd (56.16k/56.16k flops)\n",
      "  model_57/conv2d_804/BiasAdd (56.16k/56.16k flops)\n",
      "  model_57/depthwise_conv2d_744/BiasAdd (35.71k/35.71k flops)\n",
      "  model_57/conv2d_810/BiasAdd (35.28k/35.28k flops)\n",
      "  model_57/depthwise_conv2d_746/BiasAdd (34.85k/34.85k flops)\n",
      "  model_57/batch_normalization_1562/FusedBatchNormV3 (31.67k/31.67k flops)\n",
      "  model_57/batch_normalization_1565/FusedBatchNormV3 (23.71k/23.71k flops)\n",
      "  model_57/batch_normalization_1564/FusedBatchNormV3 (23.52k/23.52k flops)\n",
      "  model_57/dense_57/MatMul (19.76k/19.76k flops)\n",
      "  model_57/depthwise_conv2d_752/BiasAdd (14.62k/14.62k flops)\n",
      "  model_57/conv2d_811/BiasAdd (8.89k/8.89k flops)\n",
      "  model_57/global_average_pooling2d_57/Mean (8.89k/8.89k flops)\n",
      "  model_57/depthwise_conv2d_753/BiasAdd (8.82k/8.82k flops)\n",
      "  model_57/dense_57/Softmax (50/50 flops)\n",
      "  model_57/dense_57/BiasAdd (10/10 flops)\n",
      "\n",
      "======================End of Report==========================\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "39.636148\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-30 13:40:33.355898: I tensorflow/core/grappler/devices.cc:66] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0\n",
      "2022-04-30 13:40:33.356012: I tensorflow/core/grappler/clusters/single_machine.cc:357] Starting new session\n",
      "2022-04-30 13:40:33.360189: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:1137] Optimization results for grappler item: graph_to_optimize\n",
      "  function_optimizer: function_optimizer did nothing. time = 0.005ms.\n",
      "  function_optimizer: function_optimizer did nothing. time = 0ms.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=========================Options=============================\n",
      "-max_depth                  10000\n",
      "-min_bytes                  0\n",
      "-min_peak_bytes             0\n",
      "-min_residual_bytes         0\n",
      "-min_output_bytes           0\n",
      "-min_micros                 0\n",
      "-min_accelerator_micros     0\n",
      "-min_cpu_micros             0\n",
      "-min_params                 0\n",
      "-min_float_ops              1\n",
      "-min_occurrence             0\n",
      "-step                       -1\n",
      "-order_by                   float_ops\n",
      "-account_type_regexes       .*\n",
      "-start_name_regexes         .*\n",
      "-trim_name_regexes          \n",
      "-show_name_regexes          .*\n",
      "-hide_name_regexes          \n",
      "-account_displayed_op_only  true\n",
      "-select                     float_ops\n",
      "-output                     stdout:\n",
      "\n",
      "==================Model Analysis Report======================\n",
      "\n",
      "Doc:\n",
      "scope: The nodes in the model graph are organized by their names, which is hierarchical like filesystem.\n",
      "flops: Number of float operations. Note: Please read the implementation for the math behind it.\n",
      "\n",
      "Profile:\n",
      "node name | # float_ops\n",
      "_TFProfRoot (--/703.90m flops)\n",
      "  model_58/conv2d_823/Conv2D (74.32m/74.32m flops)\n",
      "  model_58/conv2d_819/Conv2D (73.45m/73.45m flops)\n",
      "  model_58/conv2d_820/Conv2D (73.45m/73.45m flops)\n",
      "  model_58/conv2d_822/Conv2D (73.45m/73.45m flops)\n",
      "  model_58/conv2d_821/Conv2D (73.16m/73.16m flops)\n",
      "  model_58/conv2d_817/Conv2D (69.70m/69.70m flops)\n",
      "  model_58/conv2d_815/Conv2D (53.08m/53.08m flops)\n",
      "  model_58/conv2d_818/Conv2D (36.29m/36.29m flops)\n",
      "  model_58/conv2d_816/Conv2D (33.45m/33.45m flops)\n",
      "  model_58/conv2d_824/Conv2D (32.53m/32.53m flops)\n",
      "  model_58/conv2d_813/Conv2D (30.67m/30.67m flops)\n",
      "  model_58/conv2d_814/Conv2D (23.00m/23.00m flops)\n",
      "  model_58/conv2d_825/Conv2D (15.05m/15.05m flops)\n",
      "  model_58/conv2d_812/Conv2D (9.44m/9.44m flops)\n",
      "  model_58/depthwise_conv2d_754/depthwise (5.31m/5.31m flops)\n",
      "  model_58/depthwise_conv2d_756/depthwise (3.98m/3.98m flops)\n",
      "  model_58/depthwise_conv2d_758/depthwise (2.51m/2.51m flops)\n",
      "  model_58/depthwise_conv2d_755/depthwise (2.16m/2.16m flops)\n",
      "  model_58/depthwise_conv2d_761/depthwise (1.31m/1.31m flops)\n",
      "  model_58/depthwise_conv2d_764/depthwise (1.31m/1.31m flops)\n",
      "  model_58/depthwise_conv2d_760/depthwise (1.31m/1.31m flops)\n",
      "  model_58/depthwise_conv2d_762/depthwise (1.31m/1.31m flops)\n",
      "  model_58/depthwise_conv2d_763/depthwise (1.31m/1.31m flops)\n",
      "  model_58/depthwise_conv2d_757/depthwise (1.24m/1.24m flops)\n",
      "  model_58/batch_normalization_1568/FusedBatchNormV3 (958.78k/958.78k flops)\n",
      "  model_58/depthwise_conv2d_759/depthwise (648.00k/648.00k flops)\n",
      "  model_58/batch_normalization_1567/FusedBatchNormV3 (590.02k/590.02k flops)\n",
      "  model_58/batch_normalization_1566/FusedBatchNormV3 (590.02k/590.02k flops)\n",
      "  model_58/batch_normalization_1572/FusedBatchNormV3 (553.68k/553.68k flops)\n",
      "  model_58/conv2d_813/BiasAdd (479.23k/479.23k flops)\n",
      "  model_58/batch_normalization_1570/FusedBatchNormV3 (442.94k/442.94k flops)\n",
      "  model_58/batch_normalization_1571/FusedBatchNormV3 (442.94k/442.94k flops)\n",
      "  model_58/depthwise_conv2d_765/depthwise (330.48k/330.48k flops)\n",
      "  model_58/depthwise_conv2d_754/BiasAdd (294.91k/294.91k flops)\n",
      "  model_58/conv2d_812/BiasAdd (294.91k/294.91k flops)\n",
      "  model_58/batch_normalization_1576/FusedBatchNormV3 (289.50k/289.50k flops)\n",
      "  model_58/batch_normalization_1575/FusedBatchNormV3 (280.24k/280.24k flops)\n",
      "  model_58/batch_normalization_1574/FusedBatchNormV3 (280.24k/280.24k flops)\n",
      "  model_58/conv2d_815/BiasAdd (276.48k/276.48k flops)\n",
      "  model_58/batch_normalization_1569/FusedBatchNormV3 (239.93k/239.93k flops)\n",
      "  model_58/depthwise_conv2d_756/BiasAdd (221.18k/221.18k flops)\n",
      "  model_58/conv2d_814/BiasAdd (221.18k/221.18k flops)\n",
      "  model_58/batch_normalization_1588/FusedBatchNormV3 (149.94k/149.94k flops)\n",
      "  model_58/batch_normalization_1586/FusedBatchNormV3 (148.76k/148.76k flops)\n",
      "  model_58/batch_normalization_1587/FusedBatchNormV3 (148.76k/148.76k flops)\n",
      "  model_58/batch_normalization_1580/FusedBatchNormV3 (148.76k/148.76k flops)\n",
      "  model_58/batch_normalization_1581/FusedBatchNormV3 (148.76k/148.76k flops)\n",
      "  model_58/batch_normalization_1585/FusedBatchNormV3 (148.18k/148.18k flops)\n",
      "  model_58/batch_normalization_1578/FusedBatchNormV3 (148.18k/148.18k flops)\n",
      "  model_58/batch_normalization_1579/FusedBatchNormV3 (148.18k/148.18k flops)\n",
      "  model_58/batch_normalization_1582/FusedBatchNormV3 (148.18k/148.18k flops)\n",
      "  model_58/batch_normalization_1583/FusedBatchNormV3 (148.18k/148.18k flops)\n",
      "  model_58/batch_normalization_1584/FusedBatchNormV3 (148.18k/148.18k flops)\n",
      "  model_58/conv2d_817/BiasAdd (144.00k/144.00k flops)\n",
      "  model_58/depthwise_conv2d_766/depthwise (143.53k/143.53k flops)\n",
      "  model_58/depthwise_conv2d_758/BiasAdd (139.39k/139.39k flops)\n",
      "  model_58/conv2d_816/BiasAdd (139.39k/139.39k flops)\n",
      "  model_58/batch_normalization_1573/FusedBatchNormV3 (138.96k/138.96k flops)\n",
      "  model_58/depthwise_conv2d_755/BiasAdd (119.81k/119.81k flops)\n",
      "  model_58/batch_normalization_1577/FusedBatchNormV3 (73.50k/73.50k flops)\n",
      "  model_58/conv2d_823/BiasAdd (73.44k/73.44k flops)\n",
      "  model_58/depthwise_conv2d_761/BiasAdd (72.86k/72.86k flops)\n",
      "  model_58/depthwise_conv2d_764/BiasAdd (72.86k/72.86k flops)\n",
      "  model_58/conv2d_822/BiasAdd (72.86k/72.86k flops)\n",
      "  model_58/conv2d_819/BiasAdd (72.86k/72.86k flops)\n",
      "  model_58/conv2d_821/BiasAdd (72.58k/72.58k flops)\n",
      "  model_58/conv2d_820/BiasAdd (72.58k/72.58k flops)\n",
      "  model_58/depthwise_conv2d_760/BiasAdd (72.58k/72.58k flops)\n",
      "  model_58/conv2d_818/BiasAdd (72.58k/72.58k flops)\n",
      "  model_58/depthwise_conv2d_762/BiasAdd (72.58k/72.58k flops)\n",
      "  model_58/depthwise_conv2d_763/BiasAdd (72.58k/72.58k flops)\n",
      "  model_58/depthwise_conv2d_757/BiasAdd (69.12k/69.12k flops)\n",
      "  model_58/batch_normalization_1590/FusedBatchNormV3 (69.11k/69.11k flops)\n",
      "  model_58/batch_normalization_1589/FusedBatchNormV3 (39.78k/39.78k flops)\n",
      "  model_58/depthwise_conv2d_759/BiasAdd (36.00k/36.00k flops)\n",
      "  model_58/conv2d_824/BiasAdd (31.90k/31.90k flops)\n",
      "  model_58/batch_normalization_1592/FusedBatchNormV3 (22.66k/22.66k flops)\n",
      "  model_58/batch_normalization_1591/FusedBatchNormV3 (21.26k/21.26k flops)\n",
      "  model_58/dense_58/MatMul (18.88k/18.88k flops)\n",
      "  model_58/depthwise_conv2d_765/BiasAdd (18.36k/18.36k flops)\n",
      "  model_58/conv2d_825/BiasAdd (8.50k/8.50k flops)\n",
      "  model_58/global_average_pooling2d_58/Mean (8.50k/8.50k flops)\n",
      "  model_58/depthwise_conv2d_766/BiasAdd (7.97k/7.97k flops)\n",
      "  model_58/dense_58/Softmax (50/50 flops)\n",
      "  model_58/dense_58/BiasAdd (10/10 flops)\n",
      "\n",
      "======================End of Report==========================\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "32.364756\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-30 13:40:34.408640: I tensorflow/core/grappler/devices.cc:66] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0\n",
      "2022-04-30 13:40:34.408756: I tensorflow/core/grappler/clusters/single_machine.cc:357] Starting new session\n",
      "2022-04-30 13:40:34.413558: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:1137] Optimization results for grappler item: graph_to_optimize\n",
      "  function_optimizer: function_optimizer did nothing. time = 0.005ms.\n",
      "  function_optimizer: function_optimizer did nothing. time = 0.001ms.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=========================Options=============================\n",
      "-max_depth                  10000\n",
      "-min_bytes                  0\n",
      "-min_peak_bytes             0\n",
      "-min_residual_bytes         0\n",
      "-min_output_bytes           0\n",
      "-min_micros                 0\n",
      "-min_accelerator_micros     0\n",
      "-min_cpu_micros             0\n",
      "-min_params                 0\n",
      "-min_float_ops              1\n",
      "-min_occurrence             0\n",
      "-step                       -1\n",
      "-order_by                   float_ops\n",
      "-account_type_regexes       .*\n",
      "-start_name_regexes         .*\n",
      "-trim_name_regexes          \n",
      "-show_name_regexes          .*\n",
      "-hide_name_regexes          \n",
      "-account_displayed_op_only  true\n",
      "-select                     float_ops\n",
      "-output                     stdout:\n",
      "\n",
      "==================Model Analysis Report======================\n",
      "\n",
      "Doc:\n",
      "scope: The nodes in the model graph are organized by their names, which is hierarchical like filesystem.\n",
      "flops: Number of float operations. Note: Please read the implementation for the math behind it.\n",
      "\n",
      "Profile:\n",
      "node name | # float_ops\n",
      "_TFProfRoot (--/485.16m flops)\n",
      "  model_59/conv2d_835/Conv2D (56.73m/56.73m flops)\n",
      "  model_59/conv2d_834/Conv2D (56.21m/56.21m flops)\n",
      "  model_59/conv2d_836/Conv2D (55.74m/55.74m flops)\n",
      "  model_59/conv2d_837/Conv2D (55.48m/55.48m flops)\n",
      "  model_59/conv2d_833/Conv2D (52.76m/52.76m flops)\n",
      "  model_59/conv2d_829/Conv2D (36.38m/36.38m flops)\n",
      "  model_59/conv2d_831/Conv2D (31.74m/31.74m flops)\n",
      "  model_59/conv2d_832/Conv2D (20.46m/20.46m flops)\n",
      "  model_59/conv2d_838/Conv2D (20.25m/20.25m flops)\n",
      "  model_59/conv2d_827/Conv2D (20.05m/20.05m flops)\n",
      "  model_59/conv2d_830/Conv2D (17.98m/17.98m flops)\n",
      "  model_59/conv2d_828/Conv2D (13.16m/13.16m flops)\n",
      "  model_59/conv2d_839/Conv2D (11.21m/11.21m flops)\n",
      "  model_59/conv2d_826/Conv2D (9.44m/9.44m flops)\n",
      "  model_59/depthwise_conv2d_767/depthwise (5.31m/5.31m flops)\n",
      "  model_59/depthwise_conv2d_769/depthwise (3.48m/3.48m flops)\n",
      "  model_59/depthwise_conv2d_771/depthwise (1.72m/1.72m flops)\n",
      "  model_59/depthwise_conv2d_768/depthwise (1.41m/1.41m flops)\n",
      "  model_59/depthwise_conv2d_775/depthwise (1.18m/1.18m flops)\n",
      "  model_59/depthwise_conv2d_777/depthwise (1.16m/1.16m flops)\n",
      "  model_59/depthwise_conv2d_776/depthwise (1.12m/1.12m flops)\n",
      "  model_59/depthwise_conv2d_773/depthwise (1.11m/1.11m flops)\n",
      "  model_59/depthwise_conv2d_774/depthwise (1.11m/1.11m flops)\n",
      "  model_59/depthwise_conv2d_770/depthwise (974.59k/974.59k flops)\n",
      "  model_59/batch_normalization_1595/FusedBatchNormV3 (626.89k/626.89k flops)\n",
      "  model_59/batch_normalization_1594/FusedBatchNormV3 (590.02k/590.02k flops)\n",
      "  model_59/batch_normalization_1593/FusedBatchNormV3 (590.02k/590.02k flops)\n",
      "  model_59/batch_normalization_1599/FusedBatchNormV3 (433.72k/433.72k flops)\n",
      "  model_59/depthwise_conv2d_772/depthwise (430.27k/430.27k flops)\n",
      "  model_59/batch_normalization_1597/FusedBatchNormV3 (387.58k/387.58k flops)\n",
      "  model_59/batch_normalization_1598/FusedBatchNormV3 (387.58k/387.58k flops)\n",
      "  model_59/conv2d_827/BiasAdd (313.34k/313.34k flops)\n",
      "  model_59/conv2d_826/BiasAdd (294.91k/294.91k flops)\n",
      "  model_59/depthwise_conv2d_767/BiasAdd (294.91k/294.91k flops)\n",
      "  model_59/depthwise_conv2d_778/depthwise (278.64k/278.64k flops)\n",
      "  model_59/conv2d_829/BiasAdd (216.58k/216.58k flops)\n",
      "  model_59/depthwise_conv2d_769/BiasAdd (193.54k/193.54k flops)\n",
      "  model_59/conv2d_828/BiasAdd (193.54k/193.54k flops)\n",
      "  model_59/batch_normalization_1602/FusedBatchNormV3 (192.23k/192.23k flops)\n",
      "  model_59/batch_normalization_1603/FusedBatchNormV3 (192.23k/192.23k flops)\n",
      "  model_59/batch_normalization_1601/FusedBatchNormV3 (192.23k/192.23k flops)\n",
      "  model_59/batch_normalization_1596/FusedBatchNormV3 (156.88k/156.88k flops)\n",
      "  model_59/batch_normalization_1610/FusedBatchNormV3 (134.06k/134.06k flops)\n",
      "  model_59/batch_normalization_1609/FusedBatchNormV3 (134.06k/134.06k flops)\n",
      "  model_59/batch_normalization_1613/FusedBatchNormV3 (131.71k/131.71k flops)\n",
      "  model_59/batch_normalization_1614/FusedBatchNormV3 (131.71k/131.71k flops)\n",
      "  model_59/batch_normalization_1611/FusedBatchNormV3 (127.01k/127.01k flops)\n",
      "  model_59/batch_normalization_1612/FusedBatchNormV3 (127.01k/127.01k flops)\n",
      "  model_59/batch_normalization_1615/FusedBatchNormV3 (126.42k/126.42k flops)\n",
      "  model_59/batch_normalization_1608/FusedBatchNormV3 (125.83k/125.83k flops)\n",
      "  model_59/batch_normalization_1607/FusedBatchNormV3 (125.83k/125.83k flops)\n",
      "  model_59/batch_normalization_1606/FusedBatchNormV3 (125.83k/125.83k flops)\n",
      "  model_59/batch_normalization_1605/FusedBatchNormV3 (125.83k/125.83k flops)\n",
      "  model_59/batch_normalization_1600/FusedBatchNormV3 (108.85k/108.85k flops)\n",
      "  model_59/depthwise_conv2d_779/depthwise (105.95k/105.95k flops)\n",
      "  model_59/depthwise_conv2d_771/BiasAdd (95.62k/95.62k flops)\n",
      "  model_59/conv2d_831/BiasAdd (95.62k/95.62k flops)\n",
      "  model_59/conv2d_830/BiasAdd (95.62k/95.62k flops)\n",
      "  model_59/depthwise_conv2d_768/BiasAdd (78.34k/78.34k flops)\n",
      "  model_59/conv2d_834/BiasAdd (65.66k/65.66k flops)\n",
      "  model_59/depthwise_conv2d_775/BiasAdd (65.66k/65.66k flops)\n",
      "  model_59/depthwise_conv2d_777/BiasAdd (64.51k/64.51k flops)\n",
      "  model_59/conv2d_836/BiasAdd (64.51k/64.51k flops)\n",
      "  model_59/depthwise_conv2d_776/BiasAdd (62.21k/62.21k flops)\n",
      "  model_59/conv2d_835/BiasAdd (62.21k/62.21k flops)\n",
      "  model_59/conv2d_837/BiasAdd (61.92k/61.92k flops)\n",
      "  model_59/depthwise_conv2d_773/BiasAdd (61.63k/61.63k flops)\n",
      "  model_59/conv2d_833/BiasAdd (61.63k/61.63k flops)\n",
      "  model_59/depthwise_conv2d_774/BiasAdd (61.63k/61.63k flops)\n",
      "  model_59/conv2d_832/BiasAdd (61.63k/61.63k flops)\n",
      "  model_59/depthwise_conv2d_770/BiasAdd (54.14k/54.14k flops)\n",
      "  model_59/batch_normalization_1617/FusedBatchNormV3 (51.01k/51.01k flops)\n",
      "  model_59/batch_normalization_1604/FusedBatchNormV3 (48.80k/48.80k flops)\n",
      "  model_59/batch_normalization_1616/FusedBatchNormV3 (33.54k/33.54k flops)\n",
      "  model_59/depthwise_conv2d_772/BiasAdd (23.90k/23.90k flops)\n",
      "  model_59/conv2d_838/BiasAdd (23.54k/23.54k flops)\n",
      "  model_59/batch_normalization_1619/FusedBatchNormV3 (22.85k/22.85k flops)\n",
      "  model_59/dense_59/MatMul (19.04k/19.04k flops)\n",
      "  model_59/batch_normalization_1618/FusedBatchNormV3 (15.70k/15.70k flops)\n",
      "  model_59/depthwise_conv2d_778/BiasAdd (15.48k/15.48k flops)\n",
      "  model_59/global_average_pooling2d_59/Mean (8.57k/8.57k flops)\n",
      "  model_59/conv2d_839/BiasAdd (8.57k/8.57k flops)\n",
      "  model_59/depthwise_conv2d_779/BiasAdd (5.89k/5.89k flops)\n",
      "  model_59/dense_59/Softmax (50/50 flops)\n",
      "  model_59/dense_59/BiasAdd (10/10 flops)\n",
      "\n",
      "======================End of Report==========================\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "33.577316\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-30 13:40:35.335305: I tensorflow/core/grappler/devices.cc:66] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0\n",
      "2022-04-30 13:40:35.335422: I tensorflow/core/grappler/clusters/single_machine.cc:357] Starting new session\n",
      "2022-04-30 13:40:35.339575: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:1137] Optimization results for grappler item: graph_to_optimize\n",
      "  function_optimizer: function_optimizer did nothing. time = 0.005ms.\n",
      "  function_optimizer: function_optimizer did nothing. time = 0.001ms.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=========================Options=============================\n",
      "-max_depth                  10000\n",
      "-min_bytes                  0\n",
      "-min_peak_bytes             0\n",
      "-min_residual_bytes         0\n",
      "-min_output_bytes           0\n",
      "-min_micros                 0\n",
      "-min_accelerator_micros     0\n",
      "-min_cpu_micros             0\n",
      "-min_params                 0\n",
      "-min_float_ops              1\n",
      "-min_occurrence             0\n",
      "-step                       -1\n",
      "-order_by                   float_ops\n",
      "-account_type_regexes       .*\n",
      "-start_name_regexes         .*\n",
      "-trim_name_regexes          \n",
      "-show_name_regexes          .*\n",
      "-hide_name_regexes          \n",
      "-account_displayed_op_only  true\n",
      "-select                     float_ops\n",
      "-output                     stdout:\n",
      "\n",
      "==================Model Analysis Report======================\n",
      "\n",
      "Doc:\n",
      "scope: The nodes in the model graph are organized by their names, which is hierarchical like filesystem.\n",
      "flops: Number of float operations. Note: Please read the implementation for the math behind it.\n",
      "\n",
      "Profile:\n",
      "node name | # float_ops\n",
      "_TFProfRoot (--/417.80m flops)\n",
      "  model_60/conv2d_850/Conv2D (46.76m/46.76m flops)\n",
      "  model_60/conv2d_848/Conv2D (43.42m/43.42m flops)\n",
      "  model_60/conv2d_849/Conv2D (43.42m/43.42m flops)\n",
      "  model_60/conv2d_847/Conv2D (41.10m/41.10m flops)\n",
      "  model_60/conv2d_843/Conv2D (38.04m/38.04m flops)\n",
      "  model_60/conv2d_851/Conv2D (35.64m/35.64m flops)\n",
      "  model_60/conv2d_841/Conv2D (33.03m/33.03m flops)\n",
      "  model_60/conv2d_842/Conv2D (22.19m/22.19m flops)\n",
      "  model_60/conv2d_852/Conv2D (20.61m/20.61m flops)\n",
      "  model_60/conv2d_845/Conv2D (17.97m/17.97m flops)\n",
      "  model_60/conv2d_853/Conv2D (13.37m/13.37m flops)\n",
      "  model_60/conv2d_844/Conv2D (13.27m/13.27m flops)\n",
      "  model_60/conv2d_846/Conv2D (11.98m/11.98m flops)\n",
      "  model_60/conv2d_840/Conv2D (9.44m/9.44m flops)\n",
      "  model_60/depthwise_conv2d_780/depthwise (5.31m/5.31m flops)\n",
      "  model_60/depthwise_conv2d_782/depthwise (3.57m/3.57m flops)\n",
      "  model_60/depthwise_conv2d_781/depthwise (2.32m/2.32m flops)\n",
      "  model_60/depthwise_conv2d_784/depthwise (1.24m/1.24m flops)\n",
      "  model_60/depthwise_conv2d_787/depthwise (1.16m/1.16m flops)\n",
      "  model_60/depthwise_conv2d_789/depthwise (1.16m/1.16m flops)\n",
      "  model_60/batch_normalization_1622/FusedBatchNormV3 (1.03m/1.03m flops)\n",
      "  model_60/depthwise_conv2d_783/depthwise (995.33k/995.33k flops)\n",
      "  model_60/depthwise_conv2d_790/depthwise (943.49k/943.49k flops)\n",
      "  model_60/depthwise_conv2d_788/depthwise (876.10k/876.10k flops)\n",
      "  model_60/depthwise_conv2d_786/depthwise (829.44k/829.44k flops)\n",
      "  model_60/batch_normalization_1621/FusedBatchNormV3 (590.02k/590.02k flops)\n",
      "  model_60/batch_normalization_1620/FusedBatchNormV3 (590.02k/590.02k flops)\n",
      "  model_60/conv2d_841/BiasAdd (516.10k/516.10k flops)\n",
      "  model_60/batch_normalization_1626/FusedBatchNormV3 (442.94k/442.94k flops)\n",
      "  model_60/batch_normalization_1624/FusedBatchNormV3 (396.80k/396.80k flops)\n",
      "  model_60/batch_normalization_1625/FusedBatchNormV3 (396.80k/396.80k flops)\n",
      "  model_60/depthwise_conv2d_785/depthwise (336.96k/336.96k flops)\n",
      "  model_60/conv2d_840/BiasAdd (294.91k/294.91k flops)\n",
      "  model_60/depthwise_conv2d_780/BiasAdd (294.91k/294.91k flops)\n",
      "  model_60/batch_normalization_1623/FusedBatchNormV3 (258.38k/258.38k flops)\n",
      "  model_60/conv2d_843/BiasAdd (221.18k/221.18k flops)\n",
      "  model_60/depthwise_conv2d_791/depthwise (220.32k/220.32k flops)\n",
      "  model_60/conv2d_842/BiasAdd (198.14k/198.14k flops)\n",
      "  model_60/depthwise_conv2d_782/BiasAdd (198.14k/198.14k flops)\n",
      "  model_60/batch_normalization_1630/FusedBatchNormV3 (150.54k/150.54k flops)\n",
      "  model_60/batch_normalization_1628/FusedBatchNormV3 (138.96k/138.96k flops)\n",
      "  model_60/batch_normalization_1629/FusedBatchNormV3 (138.96k/138.96k flops)\n",
      "  model_60/depthwise_conv2d_792/depthwise (136.40k/136.40k flops)\n",
      "  model_60/batch_normalization_1639/FusedBatchNormV3 (131.12k/131.12k flops)\n",
      "  model_60/batch_normalization_1638/FusedBatchNormV3 (131.12k/131.12k flops)\n",
      "  model_60/batch_normalization_1635/FusedBatchNormV3 (131.12k/131.12k flops)\n",
      "  model_60/batch_normalization_1634/FusedBatchNormV3 (131.12k/131.12k flops)\n",
      "  model_60/depthwise_conv2d_781/BiasAdd (129.02k/129.02k flops)\n",
      "  model_60/batch_normalization_1627/FusedBatchNormV3 (111.17k/111.17k flops)\n",
      "  model_60/batch_normalization_1641/FusedBatchNormV3 (107.02k/107.02k flops)\n",
      "  model_60/batch_normalization_1640/FusedBatchNormV3 (107.02k/107.02k flops)\n",
      "  model_60/batch_normalization_1642/FusedBatchNormV3 (99.96k/99.96k flops)\n",
      "  model_60/batch_normalization_1636/FusedBatchNormV3 (99.37k/99.37k flops)\n",
      "  model_60/batch_normalization_1637/FusedBatchNormV3 (99.37k/99.37k flops)\n",
      "  model_60/batch_normalization_1633/FusedBatchNormV3 (94.08k/94.08k flops)\n",
      "  model_60/batch_normalization_1632/FusedBatchNormV3 (94.08k/94.08k flops)\n",
      "  model_60/conv2d_845/BiasAdd (74.88k/74.88k flops)\n",
      "  model_60/depthwise_conv2d_784/BiasAdd (69.12k/69.12k flops)\n",
      "  model_60/conv2d_844/BiasAdd (69.12k/69.12k flops)\n",
      "  model_60/batch_normalization_1644/FusedBatchNormV3 (65.68k/65.68k flops)\n",
      "  model_60/depthwise_conv2d_787/BiasAdd (64.22k/64.22k flops)\n",
      "  model_60/depthwise_conv2d_789/BiasAdd (64.22k/64.22k flops)\n",
      "  model_60/conv2d_847/BiasAdd (64.22k/64.22k flops)\n",
      "  model_60/conv2d_849/BiasAdd (64.22k/64.22k flops)\n",
      "  model_60/depthwise_conv2d_783/BiasAdd (55.30k/55.30k flops)\n",
      "  model_60/depthwise_conv2d_790/BiasAdd (52.42k/52.42k flops)\n",
      "  model_60/conv2d_850/BiasAdd (52.42k/52.42k flops)\n",
      "  model_60/conv2d_851/BiasAdd (48.96k/48.96k flops)\n",
      "  model_60/conv2d_848/BiasAdd (48.67k/48.67k flops)\n",
      "  model_60/depthwise_conv2d_788/BiasAdd (48.67k/48.67k flops)\n",
      "  model_60/depthwise_conv2d_786/BiasAdd (46.08k/46.08k flops)\n",
      "  model_60/conv2d_846/BiasAdd (46.08k/46.08k flops)\n",
      "  model_60/batch_normalization_1631/FusedBatchNormV3 (38.22k/38.22k flops)\n",
      "  model_60/conv2d_852/BiasAdd (30.31k/30.31k flops)\n",
      "  model_60/batch_normalization_1643/FusedBatchNormV3 (26.52k/26.52k flops)\n",
      "  model_60/batch_normalization_1646/FusedBatchNormV3 (21.17k/21.17k flops)\n",
      "  model_60/batch_normalization_1645/FusedBatchNormV3 (20.21k/20.21k flops)\n",
      "  model_60/depthwise_conv2d_785/BiasAdd (18.72k/18.72k flops)\n",
      "  model_60/dense_60/MatMul (17.64k/17.64k flops)\n",
      "  model_60/depthwise_conv2d_791/BiasAdd (12.24k/12.24k flops)\n",
      "  model_60/global_average_pooling2d_60/Mean (7.94k/7.94k flops)\n",
      "  model_60/conv2d_853/BiasAdd (7.94k/7.94k flops)\n",
      "  model_60/depthwise_conv2d_792/BiasAdd (7.58k/7.58k flops)\n",
      "  model_60/dense_60/Softmax (50/50 flops)\n",
      "  model_60/dense_60/BiasAdd (10/10 flops)\n",
      "\n",
      "======================End of Report==========================\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "47.365428\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-30 13:40:36.362121: I tensorflow/core/grappler/devices.cc:66] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0\n",
      "2022-04-30 13:40:36.362236: I tensorflow/core/grappler/clusters/single_machine.cc:357] Starting new session\n",
      "2022-04-30 13:40:36.367109: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:1137] Optimization results for grappler item: graph_to_optimize\n",
      "  function_optimizer: function_optimizer did nothing. time = 0.006ms.\n",
      "  function_optimizer: function_optimizer did nothing. time = 0.001ms.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=========================Options=============================\n",
      "-max_depth                  10000\n",
      "-min_bytes                  0\n",
      "-min_peak_bytes             0\n",
      "-min_residual_bytes         0\n",
      "-min_output_bytes           0\n",
      "-min_micros                 0\n",
      "-min_accelerator_micros     0\n",
      "-min_cpu_micros             0\n",
      "-min_params                 0\n",
      "-min_float_ops              1\n",
      "-min_occurrence             0\n",
      "-step                       -1\n",
      "-order_by                   float_ops\n",
      "-account_type_regexes       .*\n",
      "-start_name_regexes         .*\n",
      "-trim_name_regexes          \n",
      "-show_name_regexes          .*\n",
      "-hide_name_regexes          \n",
      "-account_displayed_op_only  true\n",
      "-select                     float_ops\n",
      "-output                     stdout:\n",
      "\n",
      "==================Model Analysis Report======================\n",
      "\n",
      "Doc:\n",
      "scope: The nodes in the model graph are organized by their names, which is hierarchical like filesystem.\n",
      "flops: Number of float operations. Note: Please read the implementation for the math behind it.\n",
      "\n",
      "Profile:\n",
      "node name | # float_ops\n",
      "_TFProfRoot (--/613.01m flops)\n",
      "  model_61/conv2d_862/Conv2D (75.95m/75.95m flops)\n",
      "  model_61/conv2d_865/Conv2D (62.21m/62.21m flops)\n",
      "  model_61/conv2d_857/Conv2D (57.80m/57.80m flops)\n",
      "  model_61/conv2d_863/Conv2D (55.83m/55.83m flops)\n",
      "  model_61/conv2d_859/Conv2D (55.66m/55.66m flops)\n",
      "  model_61/conv2d_861/Conv2D (51.00m/51.00m flops)\n",
      "  model_61/conv2d_864/Conv2D (44.77m/44.77m flops)\n",
      "  model_61/conv2d_855/Conv2D (41.75m/41.75m flops)\n",
      "  model_61/conv2d_856/Conv2D (31.31m/31.31m flops)\n",
      "  model_61/conv2d_860/Conv2D (27.24m/27.24m flops)\n",
      "  model_61/conv2d_866/Conv2D (22.67m/22.67m flops)\n",
      "  model_61/conv2d_858/Conv2D (21.37m/21.37m flops)\n",
      "  model_61/conv2d_867/Conv2D (13.82m/13.82m flops)\n",
      "  model_61/conv2d_854/Conv2D (12.85m/12.85m flops)\n",
      "  model_61/depthwise_conv2d_793/depthwise (7.23m/7.23m flops)\n",
      "  model_61/depthwise_conv2d_795/depthwise (5.42m/5.42m flops)\n",
      "  model_61/depthwise_conv2d_794/depthwise (2.94m/2.94m flops)\n",
      "  model_61/depthwise_conv2d_797/depthwise (2.00m/2.00m flops)\n",
      "  model_61/depthwise_conv2d_800/depthwise (1.65m/1.65m flops)\n",
      "  model_61/depthwise_conv2d_801/depthwise (1.46m/1.46m flops)\n",
      "  model_61/depthwise_conv2d_796/depthwise (1.35m/1.35m flops)\n",
      "  model_61/batch_normalization_1649/FusedBatchNormV3 (1.30m/1.30m flops)\n",
      "  model_61/depthwise_conv2d_802/depthwise (1.21m/1.21m flops)\n",
      "  model_61/depthwise_conv2d_803/depthwise (1.17m/1.17m flops)\n",
      "  model_61/depthwise_conv2d_799/depthwise (980.78k/980.78k flops)\n",
      "  model_61/depthwise_conv2d_798/depthwise (882.00k/882.00k flops)\n",
      "  model_61/batch_normalization_1648/FusedBatchNormV3 (803.01k/803.01k flops)\n",
      "  model_61/batch_normalization_1647/FusedBatchNormV3 (803.01k/803.01k flops)\n",
      "  model_61/conv2d_855/BiasAdd (652.29k/652.29k flops)\n",
      "  model_61/batch_normalization_1651/FusedBatchNormV3 (602.69k/602.69k flops)\n",
      "  model_61/batch_normalization_1652/FusedBatchNormV3 (602.69k/602.69k flops)\n",
      "  model_61/batch_normalization_1653/FusedBatchNormV3 (602.69k/602.69k flops)\n",
      "  model_61/depthwise_conv2d_804/depthwise (421.60k/421.60k flops)\n",
      "  model_61/conv2d_854/BiasAdd (401.41k/401.41k flops)\n",
      "  model_61/depthwise_conv2d_793/BiasAdd (401.41k/401.41k flops)\n",
      "  model_61/batch_normalization_1657/FusedBatchNormV3 (393.50k/393.50k flops)\n",
      "  model_61/batch_normalization_1650/FusedBatchNormV3 (326.46k/326.46k flops)\n",
      "  model_61/conv2d_856/BiasAdd (301.06k/301.06k flops)\n",
      "  model_61/conv2d_857/BiasAdd (301.06k/301.06k flops)\n",
      "  model_61/depthwise_conv2d_795/BiasAdd (301.06k/301.06k flops)\n",
      "  model_61/batch_normalization_1655/FusedBatchNormV3 (223.51k/223.51k flops)\n",
      "  model_61/batch_normalization_1656/FusedBatchNormV3 (223.51k/223.51k flops)\n",
      "  model_61/conv2d_859/BiasAdd (196.00k/196.00k flops)\n",
      "  model_61/batch_normalization_1669/FusedBatchNormV3 (190.24k/190.24k flops)\n",
      "  model_61/batch_normalization_1661/FusedBatchNormV3 (186.26k/186.26k flops)\n",
      "  model_61/batch_normalization_1662/FusedBatchNormV3 (186.26k/186.26k flops)\n",
      "  model_61/batch_normalization_1664/FusedBatchNormV3 (164.77k/164.77k flops)\n",
      "  model_61/batch_normalization_1663/FusedBatchNormV3 (164.77k/164.77k flops)\n",
      "  model_61/depthwise_conv2d_794/BiasAdd (163.07k/163.07k flops)\n",
      "  model_61/batch_normalization_1654/FusedBatchNormV3 (151.10k/151.10k flops)\n",
      "  model_61/depthwise_conv2d_805/depthwise (139.39k/139.39k flops)\n",
      "  model_61/batch_normalization_1666/FusedBatchNormV3 (136.91k/136.91k flops)\n",
      "  model_61/batch_normalization_1665/FusedBatchNormV3 (136.91k/136.91k flops)\n",
      "  model_61/batch_normalization_1668/FusedBatchNormV3 (132.14k/132.14k flops)\n",
      "  model_61/batch_normalization_1667/FusedBatchNormV3 (132.14k/132.14k flops)\n",
      "  model_61/conv2d_858/BiasAdd (111.33k/111.33k flops)\n",
      "  model_61/depthwise_conv2d_797/BiasAdd (111.33k/111.33k flops)\n",
      "  model_61/batch_normalization_1660/FusedBatchNormV3 (110.64k/110.64k flops)\n",
      "  model_61/batch_normalization_1659/FusedBatchNormV3 (110.64k/110.64k flops)\n",
      "  model_61/batch_normalization_1658/FusedBatchNormV3 (99.50k/99.50k flops)\n",
      "  model_61/conv2d_865/BiasAdd (93.69k/93.69k flops)\n",
      "  model_61/conv2d_861/BiasAdd (91.73k/91.73k flops)\n",
      "  model_61/depthwise_conv2d_800/BiasAdd (91.73k/91.73k flops)\n",
      "  model_61/conv2d_862/BiasAdd (81.14k/81.14k flops)\n",
      "  model_61/depthwise_conv2d_801/BiasAdd (81.14k/81.14k flops)\n",
      "  model_61/depthwise_conv2d_796/BiasAdd (75.26k/75.26k flops)\n",
      "  model_61/conv2d_863/BiasAdd (67.42k/67.42k flops)\n",
      "  model_61/depthwise_conv2d_802/BiasAdd (67.42k/67.42k flops)\n",
      "  model_61/conv2d_864/BiasAdd (65.07k/65.07k flops)\n",
      "  model_61/depthwise_conv2d_803/BiasAdd (65.07k/65.07k flops)\n",
      "  model_61/conv2d_860/BiasAdd (54.49k/54.49k flops)\n",
      "  model_61/depthwise_conv2d_799/BiasAdd (54.49k/54.49k flops)\n",
      "  model_61/batch_normalization_1671/FusedBatchNormV3 (50.34k/50.34k flops)\n",
      "  model_61/batch_normalization_1670/FusedBatchNormV3 (49.71k/49.71k flops)\n",
      "  model_61/depthwise_conv2d_798/BiasAdd (49.00k/49.00k flops)\n",
      "  model_61/batch_normalization_1673/FusedBatchNormV3 (33.90k/33.90k flops)\n",
      "  model_61/conv2d_866/BiasAdd (23.72k/23.72k flops)\n",
      "  model_61/depthwise_conv2d_804/BiasAdd (23.42k/23.42k flops)\n",
      "  model_61/batch_normalization_1672/FusedBatchNormV3 (18.39k/18.39k flops)\n",
      "  model_61/dense_61/MatMul (17.84k/17.84k flops)\n",
      "  model_61/conv2d_867/BiasAdd (14.27k/14.27k flops)\n",
      "  model_61/global_average_pooling2d_61/Mean (14.27k/14.27k flops)\n",
      "  model_61/depthwise_conv2d_805/BiasAdd (7.74k/7.74k flops)\n",
      "  model_61/dense_61/Softmax (50/50 flops)\n",
      "  model_61/dense_61/BiasAdd (10/10 flops)\n",
      "\n",
      "======================End of Report==========================\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "47.053604\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-30 13:40:37.285637: I tensorflow/core/grappler/devices.cc:66] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0\n",
      "2022-04-30 13:40:37.285756: I tensorflow/core/grappler/clusters/single_machine.cc:357] Starting new session\n",
      "2022-04-30 13:40:37.290036: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:1137] Optimization results for grappler item: graph_to_optimize\n",
      "  function_optimizer: function_optimizer did nothing. time = 0.005ms.\n",
      "  function_optimizer: function_optimizer did nothing. time = 0.001ms.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=========================Options=============================\n",
      "-max_depth                  10000\n",
      "-min_bytes                  0\n",
      "-min_peak_bytes             0\n",
      "-min_residual_bytes         0\n",
      "-min_output_bytes           0\n",
      "-min_micros                 0\n",
      "-min_accelerator_micros     0\n",
      "-min_cpu_micros             0\n",
      "-min_params                 0\n",
      "-min_float_ops              1\n",
      "-min_occurrence             0\n",
      "-step                       -1\n",
      "-order_by                   float_ops\n",
      "-account_type_regexes       .*\n",
      "-start_name_regexes         .*\n",
      "-trim_name_regexes          \n",
      "-show_name_regexes          .*\n",
      "-hide_name_regexes          \n",
      "-account_displayed_op_only  true\n",
      "-select                     float_ops\n",
      "-output                     stdout:\n",
      "\n",
      "==================Model Analysis Report======================\n",
      "\n",
      "Doc:\n",
      "scope: The nodes in the model graph are organized by their names, which is hierarchical like filesystem.\n",
      "flops: Number of float operations. Note: Please read the implementation for the math behind it.\n",
      "\n",
      "Profile:\n",
      "node name | # float_ops\n",
      "_TFProfRoot (--/642.74m flops)\n",
      "  model_62/conv2d_871/Conv2D (75.79m/75.79m flops)\n",
      "  model_62/conv2d_876/Conv2D (68.75m/68.75m flops)\n",
      "  model_62/conv2d_877/Conv2D (62.66m/62.66m flops)\n",
      "  model_62/conv2d_879/Conv2D (60.18m/60.18m flops)\n",
      "  model_62/conv2d_878/Conv2D (58.60m/58.60m flops)\n",
      "  model_62/conv2d_875/Conv2D (56.34m/56.34m flops)\n",
      "  model_62/conv2d_873/Conv2D (45.64m/45.64m flops)\n",
      "  model_62/conv2d_869/Conv2D (33.72m/33.72m flops)\n",
      "  model_62/conv2d_874/Conv2D (29.70m/29.70m flops)\n",
      "  model_62/conv2d_870/Conv2D (27.92m/27.92m flops)\n",
      "  model_62/conv2d_880/Conv2D (27.04m/27.04m flops)\n",
      "  model_62/conv2d_872/Conv2D (24.31m/24.31m flops)\n",
      "  model_62/conv2d_881/Conv2D (20.07m/20.07m flops)\n",
      "  model_62/conv2d_868/Conv2D (12.85m/12.85m flops)\n",
      "  model_62/depthwise_conv2d_806/depthwise (7.23m/7.23m flops)\n",
      "  model_62/depthwise_conv2d_808/depthwise (5.98m/5.98m flops)\n",
      "  model_62/depthwise_conv2d_807/depthwise (2.37m/2.37m flops)\n",
      "  model_62/depthwise_conv2d_810/depthwise (1.92m/1.92m flops)\n",
      "  model_62/depthwise_conv2d_809/depthwise (1.61m/1.61m flops)\n",
      "  model_62/depthwise_conv2d_814/depthwise (1.52m/1.52m flops)\n",
      "  model_62/depthwise_conv2d_813/depthwise (1.43m/1.43m flops)\n",
      "  model_62/depthwise_conv2d_816/depthwise (1.43m/1.43m flops)\n",
      "  model_62/depthwise_conv2d_815/depthwise (1.31m/1.31m flops)\n",
      "  model_62/depthwise_conv2d_812/depthwise (1.25m/1.25m flops)\n",
      "  model_62/batch_normalization_1676/FusedBatchNormV3 (1.05m/1.05m flops)\n",
      "  model_62/batch_normalization_1675/FusedBatchNormV3 (803.01k/803.01k flops)\n",
      "  model_62/batch_normalization_1674/FusedBatchNormV3 (803.01k/803.01k flops)\n",
      "  model_62/depthwise_conv2d_811/depthwise (754.99k/754.99k flops)\n",
      "  model_62/batch_normalization_1680/FusedBatchNormV3 (715.69k/715.69k flops)\n",
      "  model_62/batch_normalization_1678/FusedBatchNormV3 (665.47k/665.47k flops)\n",
      "  model_62/batch_normalization_1679/FusedBatchNormV3 (665.47k/665.47k flops)\n",
      "  model_62/conv2d_869/BiasAdd (526.85k/526.85k flops)\n",
      "  model_62/conv2d_868/BiasAdd (401.41k/401.41k flops)\n",
      "  model_62/depthwise_conv2d_806/BiasAdd (401.41k/401.41k flops)\n",
      "  model_62/conv2d_871/BiasAdd (357.50k/357.50k flops)\n",
      "  model_62/batch_normalization_1684/FusedBatchNormV3 (336.84k/336.84k flops)\n",
      "  model_62/depthwise_conv2d_817/depthwise (335.16k/335.16k flops)\n",
      "  model_62/conv2d_870/BiasAdd (332.42k/332.42k flops)\n",
      "  model_62/depthwise_conv2d_808/BiasAdd (332.42k/332.42k flops)\n",
      "  model_62/batch_normalization_1677/FusedBatchNormV3 (263.68k/263.68k flops)\n",
      "  model_62/batch_normalization_1683/FusedBatchNormV3 (214.06k/214.06k flops)\n",
      "  model_62/batch_normalization_1682/FusedBatchNormV3 (214.06k/214.06k flops)\n",
      "  model_62/depthwise_conv2d_818/depthwise (209.09k/209.09k flops)\n",
      "  model_62/batch_normalization_1681/FusedBatchNormV3 (179.44k/179.44k flops)\n",
      "  model_62/batch_normalization_1690/FusedBatchNormV3 (171.94k/171.94k flops)\n",
      "  model_62/batch_normalization_1691/FusedBatchNormV3 (171.94k/171.94k flops)\n",
      "  model_62/conv2d_873/BiasAdd (167.78k/167.78k flops)\n",
      "  model_62/batch_normalization_1689/FusedBatchNormV3 (161.59k/161.59k flops)\n",
      "  model_62/batch_normalization_1688/FusedBatchNormV3 (161.59k/161.59k flops)\n",
      "  model_62/batch_normalization_1694/FusedBatchNormV3 (160.79k/160.79k flops)\n",
      "  model_62/batch_normalization_1695/FusedBatchNormV3 (160.79k/160.79k flops)\n",
      "  model_62/batch_normalization_1696/FusedBatchNormV3 (151.24k/151.24k flops)\n",
      "  model_62/batch_normalization_1692/FusedBatchNormV3 (147.26k/147.26k flops)\n",
      "  model_62/batch_normalization_1693/FusedBatchNormV3 (147.26k/147.26k flops)\n",
      "  model_62/batch_normalization_1687/FusedBatchNormV3 (140.89k/140.89k flops)\n",
      "  model_62/batch_normalization_1686/FusedBatchNormV3 (140.89k/140.89k flops)\n",
      "  model_62/depthwise_conv2d_807/BiasAdd (131.71k/131.71k flops)\n",
      "  model_62/conv2d_872/BiasAdd (106.62k/106.62k flops)\n",
      "  model_62/depthwise_conv2d_810/BiasAdd (106.62k/106.62k flops)\n",
      "  model_62/depthwise_conv2d_809/BiasAdd (89.38k/89.38k flops)\n",
      "  model_62/batch_normalization_1685/FusedBatchNormV3 (85.17k/85.17k flops)\n",
      "  model_62/conv2d_876/BiasAdd (84.67k/84.67k flops)\n",
      "  model_62/depthwise_conv2d_814/BiasAdd (84.67k/84.67k flops)\n",
      "  model_62/depthwise_conv2d_813/BiasAdd (79.58k/79.58k flops)\n",
      "  model_62/conv2d_875/BiasAdd (79.58k/79.58k flops)\n",
      "  model_62/depthwise_conv2d_816/BiasAdd (79.18k/79.18k flops)\n",
      "  model_62/conv2d_878/BiasAdd (79.18k/79.18k flops)\n",
      "  model_62/batch_normalization_1698/FusedBatchNormV3 (75.50k/75.50k flops)\n",
      "  model_62/conv2d_879/BiasAdd (74.48k/74.48k flops)\n",
      "  model_62/depthwise_conv2d_815/BiasAdd (72.52k/72.52k flops)\n",
      "  model_62/conv2d_877/BiasAdd (72.52k/72.52k flops)\n",
      "  model_62/depthwise_conv2d_812/BiasAdd (69.38k/69.38k flops)\n",
      "  model_62/conv2d_874/BiasAdd (69.38k/69.38k flops)\n",
      "  model_62/depthwise_conv2d_811/BiasAdd (41.94k/41.94k flops)\n",
      "  model_62/batch_normalization_1697/FusedBatchNormV3 (39.52k/39.52k flops)\n",
      "  model_62/conv2d_880/BiasAdd (35.57k/35.57k flops)\n",
      "  model_62/batch_normalization_1700/FusedBatchNormV3 (32.83k/32.83k flops)\n",
      "  model_62/batch_normalization_1699/FusedBatchNormV3 (27.59k/27.59k flops)\n",
      "  model_62/depthwise_conv2d_817/BiasAdd (18.62k/18.62k flops)\n",
      "  model_62/dense_62/MatMul (17.28k/17.28k flops)\n",
      "  model_62/global_average_pooling2d_62/Mean (13.82k/13.82k flops)\n",
      "  model_62/conv2d_881/BiasAdd (13.82k/13.82k flops)\n",
      "  model_62/depthwise_conv2d_818/BiasAdd (11.62k/11.62k flops)\n",
      "  model_62/dense_62/Softmax (50/50 flops)\n",
      "  model_62/dense_62/BiasAdd (10/10 flops)\n",
      "\n",
      "======================End of Report==========================\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "45.048716\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-30 13:40:38.310477: I tensorflow/core/grappler/devices.cc:66] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0\n",
      "2022-04-30 13:40:38.310593: I tensorflow/core/grappler/clusters/single_machine.cc:357] Starting new session\n",
      "2022-04-30 13:40:38.315462: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:1137] Optimization results for grappler item: graph_to_optimize\n",
      "  function_optimizer: function_optimizer did nothing. time = 0.006ms.\n",
      "  function_optimizer: function_optimizer did nothing. time = 0.001ms.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=========================Options=============================\n",
      "-max_depth                  10000\n",
      "-min_bytes                  0\n",
      "-min_peak_bytes             0\n",
      "-min_residual_bytes         0\n",
      "-min_output_bytes           0\n",
      "-min_micros                 0\n",
      "-min_accelerator_micros     0\n",
      "-min_cpu_micros             0\n",
      "-min_params                 0\n",
      "-min_float_ops              1\n",
      "-min_occurrence             0\n",
      "-step                       -1\n",
      "-order_by                   float_ops\n",
      "-account_type_regexes       .*\n",
      "-start_name_regexes         .*\n",
      "-trim_name_regexes          \n",
      "-show_name_regexes          .*\n",
      "-hide_name_regexes          \n",
      "-account_displayed_op_only  true\n",
      "-select                     float_ops\n",
      "-output                     stdout:\n",
      "\n",
      "==================Model Analysis Report======================\n",
      "\n",
      "Doc:\n",
      "scope: The nodes in the model graph are organized by their names, which is hierarchical like filesystem.\n",
      "flops: Number of float operations. Note: Please read the implementation for the math behind it.\n",
      "\n",
      "Profile:\n",
      "node name | # float_ops\n",
      "_TFProfRoot (--/684.00m flops)\n",
      "  model_63/conv2d_892/Conv2D (92.51m/92.51m flops)\n",
      "  model_63/conv2d_891/Conv2D (91.03m/91.03m flops)\n",
      "  model_63/conv2d_890/Conv2D (84.09m/84.09m flops)\n",
      "  model_63/conv2d_893/Conv2D (83.50m/83.50m flops)\n",
      "  model_63/conv2d_889/Conv2D (71.10m/71.10m flops)\n",
      "  model_63/conv2d_883/Conv2D (43.35m/43.35m flops)\n",
      "  model_63/conv2d_885/Conv2D (30.11m/30.11m flops)\n",
      "  model_63/conv2d_887/Conv2D (29.55m/29.55m flops)\n",
      "  model_63/conv2d_894/Conv2D (28.31m/28.31m flops)\n",
      "  model_63/conv2d_888/Conv2D (24.79m/24.79m flops)\n",
      "  model_63/conv2d_884/Conv2D (20.32m/20.32m flops)\n",
      "  model_63/conv2d_895/Conv2D (19.79m/19.79m flops)\n",
      "  model_63/conv2d_886/Conv2D (15.55m/15.55m flops)\n",
      "  model_63/conv2d_882/Conv2D (12.85m/12.85m flops)\n",
      "  model_63/depthwise_conv2d_819/depthwise (7.23m/7.23m flops)\n",
      "  model_63/depthwise_conv2d_821/depthwise (3.39m/3.39m flops)\n",
      "  model_63/depthwise_conv2d_820/depthwise (3.05m/3.05m flops)\n",
      "  model_63/depthwise_conv2d_829/depthwise (1.76m/1.76m flops)\n",
      "  model_63/depthwise_conv2d_823/depthwise (1.75m/1.75m flops)\n",
      "  model_63/depthwise_conv2d_827/depthwise (1.74m/1.74m flops)\n",
      "  model_63/depthwise_conv2d_828/depthwise (1.67m/1.67m flops)\n",
      "  model_63/depthwise_conv2d_826/depthwise (1.54m/1.54m flops)\n",
      "  model_63/depthwise_conv2d_825/depthwise (1.47m/1.47m flops)\n",
      "  model_63/batch_normalization_1703/FusedBatchNormV3 (1.36m/1.36m flops)\n",
      "  model_63/depthwise_conv2d_822/depthwise (1.13m/1.13m flops)\n",
      "  model_63/batch_normalization_1702/FusedBatchNormV3 (803.01k/803.01k flops)\n",
      "  model_63/batch_normalization_1701/FusedBatchNormV3 (803.01k/803.01k flops)\n",
      "  model_63/conv2d_883/BiasAdd (677.38k/677.38k flops)\n",
      "  model_63/depthwise_conv2d_824/depthwise (536.26k/536.26k flops)\n",
      "  model_63/batch_normalization_1707/FusedBatchNormV3 (502.24k/502.24k flops)\n",
      "  model_63/conv2d_882/BiasAdd (401.41k/401.41k flops)\n",
      "  model_63/depthwise_conv2d_819/BiasAdd (401.41k/401.41k flops)\n",
      "  model_63/batch_normalization_1706/FusedBatchNormV3 (376.68k/376.68k flops)\n",
      "  model_63/batch_normalization_1705/FusedBatchNormV3 (376.68k/376.68k flops)\n",
      "  model_63/depthwise_conv2d_830/depthwise (375.73k/375.73k flops)\n",
      "  model_63/batch_normalization_1704/FusedBatchNormV3 (339.01k/339.01k flops)\n",
      "  model_63/conv2d_885/BiasAdd (250.88k/250.88k flops)\n",
      "  model_63/batch_normalization_1711/FusedBatchNormV3 (239.25k/239.25k flops)\n",
      "  model_63/batch_normalization_1722/FusedBatchNormV3 (199.00k/199.00k flops)\n",
      "  model_63/batch_normalization_1721/FusedBatchNormV3 (199.00k/199.00k flops)\n",
      "  model_63/batch_normalization_1718/FusedBatchNormV3 (195.82k/195.82k flops)\n",
      "  model_63/batch_normalization_1717/FusedBatchNormV3 (195.82k/195.82k flops)\n",
      "  model_63/depthwise_conv2d_831/depthwise (195.26k/195.26k flops)\n",
      "  model_63/batch_normalization_1709/FusedBatchNormV3 (195.18k/195.18k flops)\n",
      "  model_63/batch_normalization_1710/FusedBatchNormV3 (195.18k/195.18k flops)\n",
      "  model_63/depthwise_conv2d_821/BiasAdd (188.16k/188.16k flops)\n",
      "  model_63/conv2d_884/BiasAdd (188.16k/188.16k flops)\n",
      "  model_63/batch_normalization_1720/FusedBatchNormV3 (187.86k/187.86k flops)\n",
      "  model_63/batch_normalization_1719/FusedBatchNormV3 (187.86k/187.86k flops)\n",
      "  model_63/batch_normalization_1715/FusedBatchNormV3 (173.53k/173.53k flops)\n",
      "  model_63/batch_normalization_1716/FusedBatchNormV3 (173.53k/173.53k flops)\n",
      "  model_63/batch_normalization_1723/FusedBatchNormV3 (169.55k/169.55k flops)\n",
      "  model_63/depthwise_conv2d_820/BiasAdd (169.34k/169.34k flops)\n",
      "  model_63/batch_normalization_1714/FusedBatchNormV3 (165.57k/165.57k flops)\n",
      "  model_63/batch_normalization_1713/FusedBatchNormV3 (165.57k/165.57k flops)\n",
      "  model_63/batch_normalization_1708/FusedBatchNormV3 (125.92k/125.92k flops)\n",
      "  model_63/conv2d_887/BiasAdd (119.17k/119.17k flops)\n",
      "  model_63/depthwise_conv2d_829/BiasAdd (98.00k/98.00k flops)\n",
      "  model_63/conv2d_892/BiasAdd (98.00k/98.00k flops)\n",
      "  model_63/conv2d_886/BiasAdd (97.22k/97.22k flops)\n",
      "  model_63/depthwise_conv2d_823/BiasAdd (97.22k/97.22k flops)\n",
      "  model_63/depthwise_conv2d_827/BiasAdd (96.43k/96.43k flops)\n",
      "  model_63/conv2d_890/BiasAdd (96.43k/96.43k flops)\n",
      "  model_63/conv2d_891/BiasAdd (92.51k/92.51k flops)\n",
      "  model_63/depthwise_conv2d_828/BiasAdd (92.51k/92.51k flops)\n",
      "  model_63/conv2d_889/BiasAdd (85.46k/85.46k flops)\n",
      "  model_63/depthwise_conv2d_826/BiasAdd (85.46k/85.46k flops)\n",
      "  model_63/conv2d_893/BiasAdd (83.50k/83.50k flops)\n",
      "  model_63/conv2d_888/BiasAdd (81.54k/81.54k flops)\n",
      "  model_63/depthwise_conv2d_825/BiasAdd (81.54k/81.54k flops)\n",
      "  model_63/batch_normalization_1725/FusedBatchNormV3 (70.51k/70.51k flops)\n",
      "  model_63/depthwise_conv2d_822/BiasAdd (62.72k/62.72k flops)\n",
      "  model_63/batch_normalization_1712/FusedBatchNormV3 (60.50k/60.50k flops)\n",
      "  model_63/batch_normalization_1724/FusedBatchNormV3 (44.30k/44.30k flops)\n",
      "  model_63/batch_normalization_1727/FusedBatchNormV3 (34.66k/34.66k flops)\n",
      "  model_63/conv2d_894/BiasAdd (33.22k/33.22k flops)\n",
      "  model_63/depthwise_conv2d_824/BiasAdd (29.79k/29.79k flops)\n",
      "  model_63/batch_normalization_1726/FusedBatchNormV3 (25.76k/25.76k flops)\n",
      "  model_63/depthwise_conv2d_830/BiasAdd (20.87k/20.87k flops)\n",
      "  model_63/dense_63/MatMul (18.24k/18.24k flops)\n",
      "  model_63/global_average_pooling2d_63/Mean (14.59k/14.59k flops)\n",
      "  model_63/conv2d_895/BiasAdd (14.59k/14.59k flops)\n",
      "  model_63/depthwise_conv2d_831/BiasAdd (10.85k/10.85k flops)\n",
      "  model_63/dense_63/Softmax (50/50 flops)\n",
      "  model_63/dense_63/BiasAdd (10/10 flops)\n",
      "\n",
      "======================End of Report==========================\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "49.56306\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-30 13:40:39.260125: I tensorflow/core/grappler/devices.cc:66] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0\n",
      "2022-04-30 13:40:39.260220: I tensorflow/core/grappler/clusters/single_machine.cc:357] Starting new session\n",
      "2022-04-30 13:40:39.264534: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:1137] Optimization results for grappler item: graph_to_optimize\n",
      "  function_optimizer: function_optimizer did nothing. time = 0.005ms.\n",
      "  function_optimizer: function_optimizer did nothing. time = 0.001ms.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=========================Options=============================\n",
      "-max_depth                  10000\n",
      "-min_bytes                  0\n",
      "-min_peak_bytes             0\n",
      "-min_residual_bytes         0\n",
      "-min_output_bytes           0\n",
      "-min_micros                 0\n",
      "-min_accelerator_micros     0\n",
      "-min_cpu_micros             0\n",
      "-min_params                 0\n",
      "-min_float_ops              1\n",
      "-min_occurrence             0\n",
      "-step                       -1\n",
      "-order_by                   float_ops\n",
      "-account_type_regexes       .*\n",
      "-start_name_regexes         .*\n",
      "-trim_name_regexes          \n",
      "-show_name_regexes          .*\n",
      "-hide_name_regexes          \n",
      "-account_displayed_op_only  true\n",
      "-select                     float_ops\n",
      "-output                     stdout:\n",
      "\n",
      "==================Model Analysis Report======================\n",
      "\n",
      "Doc:\n",
      "scope: The nodes in the model graph are organized by their names, which is hierarchical like filesystem.\n",
      "flops: Number of float operations. Note: Please read the implementation for the math behind it.\n",
      "\n",
      "Profile:\n",
      "node name | # float_ops\n",
      "_TFProfRoot (--/716.64m flops)\n",
      "  model_64/conv2d_901/Conv2D (96.38m/96.38m flops)\n",
      "  model_64/conv2d_899/Conv2D (81.41m/81.41m flops)\n",
      "  model_64/conv2d_906/Conv2D (67.46m/67.46m flops)\n",
      "  model_64/conv2d_904/Conv2D (63.92m/63.92m flops)\n",
      "  model_64/conv2d_905/Conv2D (62.46m/62.46m flops)\n",
      "  model_64/conv2d_903/Conv2D (61.19m/61.19m flops)\n",
      "  model_64/conv2d_907/Conv2D (60.18m/60.18m flops)\n",
      "  model_64/conv2d_900/Conv2D (44.78m/44.78m flops)\n",
      "  model_64/conv2d_902/Conv2D (35.65m/35.65m flops)\n",
      "  model_64/conv2d_897/Conv2D (32.11m/32.11m flops)\n",
      "  model_64/conv2d_898/Conv2D (27.60m/27.60m flops)\n",
      "  model_64/conv2d_908/Conv2D (17.28m/17.28m flops)\n",
      "  model_64/conv2d_896/Conv2D (12.85m/12.85m flops)\n",
      "  model_64/conv2d_909/Conv2D (11.73m/11.73m flops)\n",
      "  model_64/depthwise_conv2d_832/depthwise (7.23m/7.23m flops)\n",
      "  model_64/depthwise_conv2d_834/depthwise (6.21m/6.21m flops)\n",
      "  model_64/depthwise_conv2d_836/depthwise (3.42m/3.42m flops)\n",
      "  model_64/depthwise_conv2d_833/depthwise (2.26m/2.26m flops)\n",
      "  model_64/depthwise_conv2d_835/depthwise (1.67m/1.67m flops)\n",
      "  model_64/depthwise_conv2d_839/depthwise (1.54m/1.54m flops)\n",
      "  model_64/depthwise_conv2d_841/depthwise (1.50m/1.50m flops)\n",
      "  model_64/depthwise_conv2d_842/depthwise (1.43m/1.43m flops)\n",
      "  model_64/depthwise_conv2d_840/depthwise (1.32m/1.32m flops)\n",
      "  model_64/depthwise_conv2d_838/depthwise (1.26m/1.26m flops)\n",
      "  model_64/batch_normalization_1730/FusedBatchNormV3 (1.00m/1.00m flops)\n",
      "  model_64/depthwise_conv2d_837/depthwise (896.11k/896.11k flops)\n",
      "  model_64/batch_normalization_1729/FusedBatchNormV3 (803.01k/803.01k flops)\n",
      "  model_64/batch_normalization_1728/FusedBatchNormV3 (803.01k/803.01k flops)\n",
      "  model_64/batch_normalization_1734/FusedBatchNormV3 (740.80k/740.80k flops)\n",
      "  model_64/batch_normalization_1732/FusedBatchNormV3 (690.58k/690.58k flops)\n",
      "  model_64/batch_normalization_1733/FusedBatchNormV3 (690.58k/690.58k flops)\n",
      "  model_64/conv2d_897/BiasAdd (501.76k/501.76k flops)\n",
      "  model_64/depthwise_conv2d_832/BiasAdd (401.41k/401.41k flops)\n",
      "  model_64/conv2d_896/BiasAdd (401.41k/401.41k flops)\n",
      "  model_64/batch_normalization_1738/FusedBatchNormV3 (399.80k/399.80k flops)\n",
      "  model_64/batch_normalization_1737/FusedBatchNormV3 (380.91k/380.91k flops)\n",
      "  model_64/batch_normalization_1736/FusedBatchNormV3 (380.91k/380.91k flops)\n",
      "  model_64/conv2d_899/BiasAdd (370.05k/370.05k flops)\n",
      "  model_64/depthwise_conv2d_834/BiasAdd (344.96k/344.96k flops)\n",
      "  model_64/conv2d_898/BiasAdd (344.96k/344.96k flops)\n",
      "  model_64/depthwise_conv2d_843/depthwise (335.16k/335.16k flops)\n",
      "  model_64/batch_normalization_1731/FusedBatchNormV3 (251.12k/251.12k flops)\n",
      "  model_64/conv2d_901/BiasAdd (199.14k/199.14k flops)\n",
      "  model_64/conv2d_900/BiasAdd (189.73k/189.73k flops)\n",
      "  model_64/depthwise_conv2d_836/BiasAdd (189.73k/189.73k flops)\n",
      "  model_64/batch_normalization_1735/FusedBatchNormV3 (185.73k/185.73k flops)\n",
      "  model_64/batch_normalization_1743/FusedBatchNormV3 (173.53k/173.53k flops)\n",
      "  model_64/batch_normalization_1742/FusedBatchNormV3 (173.53k/173.53k flops)\n",
      "  model_64/batch_normalization_1746/FusedBatchNormV3 (169.55k/169.55k flops)\n",
      "  model_64/batch_normalization_1747/FusedBatchNormV3 (169.55k/169.55k flops)\n",
      "  model_64/batch_normalization_1748/FusedBatchNormV3 (160.79k/160.79k flops)\n",
      "  model_64/batch_normalization_1749/FusedBatchNormV3 (160.79k/160.79k flops)\n",
      "  model_64/batch_normalization_1750/FusedBatchNormV3 (151.24k/151.24k flops)\n",
      "  model_64/batch_normalization_1745/FusedBatchNormV3 (148.85k/148.85k flops)\n",
      "  model_64/batch_normalization_1744/FusedBatchNormV3 (148.85k/148.85k flops)\n",
      "  model_64/batch_normalization_1741/FusedBatchNormV3 (142.48k/142.48k flops)\n",
      "  model_64/batch_normalization_1740/FusedBatchNormV3 (142.48k/142.48k flops)\n",
      "  model_64/depthwise_conv2d_844/depthwise (133.63k/133.63k flops)\n",
      "  model_64/depthwise_conv2d_833/BiasAdd (125.44k/125.44k flops)\n",
      "  model_64/batch_normalization_1739/FusedBatchNormV3 (101.09k/101.09k flops)\n",
      "  model_64/depthwise_conv2d_835/BiasAdd (92.51k/92.51k flops)\n",
      "  model_64/depthwise_conv2d_839/BiasAdd (85.46k/85.46k flops)\n",
      "  model_64/conv2d_903/BiasAdd (85.46k/85.46k flops)\n",
      "  model_64/depthwise_conv2d_841/BiasAdd (83.50k/83.50k flops)\n",
      "  model_64/conv2d_905/BiasAdd (83.50k/83.50k flops)\n",
      "  model_64/depthwise_conv2d_842/BiasAdd (79.18k/79.18k flops)\n",
      "  model_64/conv2d_906/BiasAdd (79.18k/79.18k flops)\n",
      "  model_64/conv2d_907/BiasAdd (74.48k/74.48k flops)\n",
      "  model_64/conv2d_904/BiasAdd (73.30k/73.30k flops)\n",
      "  model_64/depthwise_conv2d_840/BiasAdd (73.30k/73.30k flops)\n",
      "  model_64/depthwise_conv2d_838/BiasAdd (70.17k/70.17k flops)\n",
      "  model_64/conv2d_902/BiasAdd (70.17k/70.17k flops)\n",
      "  model_64/depthwise_conv2d_837/BiasAdd (49.78k/49.78k flops)\n",
      "  model_64/batch_normalization_1752/FusedBatchNormV3 (48.26k/48.26k flops)\n",
      "  model_64/batch_normalization_1751/FusedBatchNormV3 (39.52k/39.52k flops)\n",
      "  model_64/batch_normalization_1754/FusedBatchNormV3 (30.02k/30.02k flops)\n",
      "  model_64/conv2d_908/BiasAdd (22.74k/22.74k flops)\n",
      "  model_64/depthwise_conv2d_843/BiasAdd (18.62k/18.62k flops)\n",
      "  model_64/batch_normalization_1753/FusedBatchNormV3 (17.63k/17.63k flops)\n",
      "  model_64/dense_64/MatMul (15.80k/15.80k flops)\n",
      "  model_64/conv2d_909/BiasAdd (12.64k/12.64k flops)\n",
      "  model_64/global_average_pooling2d_64/Mean (12.64k/12.64k flops)\n",
      "  model_64/depthwise_conv2d_844/BiasAdd (7.42k/7.42k flops)\n",
      "  model_64/dense_64/Softmax (50/50 flops)\n",
      "  model_64/dense_64/BiasAdd (10/10 flops)\n",
      "\n",
      "======================End of Report==========================\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "39.647828\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-30 13:40:40.176501: I tensorflow/core/grappler/devices.cc:66] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0\n",
      "2022-04-30 13:40:40.176617: I tensorflow/core/grappler/clusters/single_machine.cc:357] Starting new session\n",
      "2022-04-30 13:40:40.180686: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:1137] Optimization results for grappler item: graph_to_optimize\n",
      "  function_optimizer: function_optimizer did nothing. time = 0.004ms.\n",
      "  function_optimizer: function_optimizer did nothing. time = 0.001ms.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=========================Options=============================\n",
      "-max_depth                  10000\n",
      "-min_bytes                  0\n",
      "-min_peak_bytes             0\n",
      "-min_residual_bytes         0\n",
      "-min_output_bytes           0\n",
      "-min_micros                 0\n",
      "-min_accelerator_micros     0\n",
      "-min_cpu_micros             0\n",
      "-min_params                 0\n",
      "-min_float_ops              1\n",
      "-min_occurrence             0\n",
      "-step                       -1\n",
      "-order_by                   float_ops\n",
      "-account_type_regexes       .*\n",
      "-start_name_regexes         .*\n",
      "-trim_name_regexes          \n",
      "-show_name_regexes          .*\n",
      "-hide_name_regexes          \n",
      "-account_displayed_op_only  true\n",
      "-select                     float_ops\n",
      "-output                     stdout:\n",
      "\n",
      "==================Model Analysis Report======================\n",
      "\n",
      "Doc:\n",
      "scope: The nodes in the model graph are organized by their names, which is hierarchical like filesystem.\n",
      "flops: Number of float operations. Note: Please read the implementation for the math behind it.\n",
      "\n",
      "Profile:\n",
      "node name | # float_ops\n",
      "_TFProfRoot (--/466.71m flops)\n",
      "  model_65/conv2d_918/Conv2D (54.94m/54.94m flops)\n",
      "  model_65/conv2d_919/Conv2D (53.57m/53.57m flops)\n",
      "  model_65/conv2d_920/Conv2D (48.19m/48.19m flops)\n",
      "  model_65/conv2d_921/Conv2D (44.17m/44.17m flops)\n",
      "  model_65/conv2d_911/Conv2D (36.93m/36.93m flops)\n",
      "  model_65/conv2d_917/Conv2D (30.86m/30.86m flops)\n",
      "  model_65/conv2d_923/Conv2D (29.37m/29.37m flops)\n",
      "  model_65/conv2d_915/Conv2D (27.10m/27.10m flops)\n",
      "  model_65/conv2d_922/Conv2D (26.63m/26.63m flops)\n",
      "  model_65/conv2d_913/Conv2D (24.84m/24.84m flops)\n",
      "  model_65/conv2d_916/Conv2D (17.36m/17.36m flops)\n",
      "  model_65/conv2d_912/Conv2D (17.31m/17.31m flops)\n",
      "  model_65/conv2d_910/Conv2D (12.85m/12.85m flops)\n",
      "  model_65/conv2d_914/Conv2D (9.93m/9.93m flops)\n",
      "  model_65/depthwise_conv2d_845/depthwise (7.23m/7.23m flops)\n",
      "  model_65/depthwise_conv2d_847/depthwise (3.39m/3.39m flops)\n",
      "  model_65/depthwise_conv2d_846/depthwise (2.60m/2.60m flops)\n",
      "  model_65/depthwise_conv2d_853/depthwise (1.55m/1.55m flops)\n",
      "  model_65/depthwise_conv2d_855/depthwise (1.39m/1.39m flops)\n",
      "  model_65/depthwise_conv2d_849/depthwise (1.35m/1.35m flops)\n",
      "  model_65/batch_normalization_1757/FusedBatchNormV3 (1.15m/1.15m flops)\n",
      "  model_65/depthwise_conv2d_852/depthwise (1.13m/1.13m flops)\n",
      "  model_65/depthwise_conv2d_854/depthwise (1.10m/1.10m flops)\n",
      "  model_65/depthwise_conv2d_848/depthwise (931.39k/931.39k flops)\n",
      "  model_65/depthwise_conv2d_851/depthwise (867.89k/867.89k flops)\n",
      "  model_65/batch_normalization_1756/FusedBatchNormV3 (803.01k/803.01k flops)\n",
      "  model_65/batch_normalization_1755/FusedBatchNormV3 (803.01k/803.01k flops)\n",
      "  model_65/depthwise_conv2d_850/depthwise (635.04k/635.04k flops)\n",
      "  model_65/conv2d_911/BiasAdd (577.02k/577.02k flops)\n",
      "  model_65/batch_normalization_1761/FusedBatchNormV3 (414.35k/414.35k flops)\n",
      "  model_65/conv2d_910/BiasAdd (401.41k/401.41k flops)\n",
      "  model_65/depthwise_conv2d_845/BiasAdd (401.41k/401.41k flops)\n",
      "  model_65/batch_normalization_1759/FusedBatchNormV3 (376.68k/376.68k flops)\n",
      "  model_65/batch_normalization_1760/FusedBatchNormV3 (376.68k/376.68k flops)\n",
      "  model_65/batch_normalization_1758/FusedBatchNormV3 (288.79k/288.79k flops)\n",
      "  model_65/batch_normalization_1765/FusedBatchNormV3 (283.32k/283.32k flops)\n",
      "  model_65/depthwise_conv2d_857/depthwise (273.60k/273.60k flops)\n",
      "  model_65/depthwise_conv2d_856/depthwise (252.25k/252.25k flops)\n",
      "  model_65/conv2d_913/BiasAdd (206.98k/206.98k flops)\n",
      "  model_65/conv2d_912/BiasAdd (188.16k/188.16k flops)\n",
      "  model_65/depthwise_conv2d_847/BiasAdd (188.16k/188.16k flops)\n",
      "  model_65/batch_normalization_1772/FusedBatchNormV3 (174.32k/174.32k flops)\n",
      "  model_65/batch_normalization_1771/FusedBatchNormV3 (174.32k/174.32k flops)\n",
      "  model_65/batch_normalization_1776/FusedBatchNormV3 (156.81k/156.81k flops)\n",
      "  model_65/batch_normalization_1775/FusedBatchNormV3 (156.81k/156.81k flops)\n",
      "  model_65/batch_normalization_1764/FusedBatchNormV3 (151.10k/151.10k flops)\n",
      "  model_65/batch_normalization_1763/FusedBatchNormV3 (151.10k/151.10k flops)\n",
      "  model_65/depthwise_conv2d_846/BiasAdd (144.26k/144.26k flops)\n",
      "  model_65/conv2d_915/BiasAdd (141.12k/141.12k flops)\n",
      "  model_65/batch_normalization_1769/FusedBatchNormV3 (127.36k/127.36k flops)\n",
      "  model_65/batch_normalization_1770/FusedBatchNormV3 (127.36k/127.36k flops)\n",
      "  model_65/batch_normalization_1773/FusedBatchNormV3 (124.18k/124.18k flops)\n",
      "  model_65/batch_normalization_1774/FusedBatchNormV3 (124.18k/124.18k flops)\n",
      "  model_65/batch_normalization_1777/FusedBatchNormV3 (113.83k/113.83k flops)\n",
      "  model_65/batch_normalization_1762/FusedBatchNormV3 (103.88k/103.88k flops)\n",
      "  model_65/batch_normalization_1779/FusedBatchNormV3 (98.80k/98.80k flops)\n",
      "  model_65/batch_normalization_1768/FusedBatchNormV3 (97.91k/97.91k flops)\n",
      "  model_65/batch_normalization_1767/FusedBatchNormV3 (97.91k/97.91k flops)\n",
      "  model_65/depthwise_conv2d_853/BiasAdd (85.85k/85.85k flops)\n",
      "  model_65/conv2d_918/BiasAdd (85.85k/85.85k flops)\n",
      "  model_65/depthwise_conv2d_855/BiasAdd (77.22k/77.22k flops)\n",
      "  model_65/conv2d_920/BiasAdd (77.22k/77.22k flops)\n",
      "  model_65/depthwise_conv2d_849/BiasAdd (75.26k/75.26k flops)\n",
      "  model_65/conv2d_914/BiasAdd (75.26k/75.26k flops)\n",
      "  model_65/batch_normalization_1766/FusedBatchNormV3 (71.64k/71.64k flops)\n",
      "  model_65/conv2d_917/BiasAdd (62.72k/62.72k flops)\n",
      "  model_65/depthwise_conv2d_852/BiasAdd (62.72k/62.72k flops)\n",
      "  model_65/depthwise_conv2d_854/BiasAdd (61.15k/61.15k flops)\n",
      "  model_65/conv2d_919/BiasAdd (61.15k/61.15k flops)\n",
      "  model_65/conv2d_921/BiasAdd (56.06k/56.06k flops)\n",
      "  model_65/depthwise_conv2d_848/BiasAdd (51.74k/51.74k flops)\n",
      "  model_65/depthwise_conv2d_851/BiasAdd (48.22k/48.22k flops)\n",
      "  model_65/conv2d_916/BiasAdd (48.22k/48.22k flops)\n",
      "  model_65/conv2d_922/BiasAdd (46.55k/46.55k flops)\n",
      "  model_65/batch_normalization_1781/FusedBatchNormV3 (36.71k/36.71k flops)\n",
      "  model_65/batch_normalization_1780/FusedBatchNormV3 (36.10k/36.10k flops)\n",
      "  model_65/depthwise_conv2d_850/BiasAdd (35.28k/35.28k flops)\n",
      "  model_65/batch_normalization_1778/FusedBatchNormV3 (29.74k/29.74k flops)\n",
      "  model_65/dense_65/MatMul (19.32k/19.32k flops)\n",
      "  model_65/global_average_pooling2d_65/Mean (15.46k/15.46k flops)\n",
      "  model_65/conv2d_923/BiasAdd (15.46k/15.46k flops)\n",
      "  model_65/depthwise_conv2d_857/BiasAdd (15.20k/15.20k flops)\n",
      "  model_65/depthwise_conv2d_856/BiasAdd (14.01k/14.01k flops)\n",
      "  model_65/dense_65/Softmax (50/50 flops)\n",
      "  model_65/dense_65/BiasAdd (10/10 flops)\n",
      "\n",
      "======================End of Report==========================\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "46.523172\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-30 13:40:41.205252: I tensorflow/core/grappler/devices.cc:66] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0\n",
      "2022-04-30 13:40:41.205367: I tensorflow/core/grappler/clusters/single_machine.cc:357] Starting new session\n",
      "2022-04-30 13:40:41.209883: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:1137] Optimization results for grappler item: graph_to_optimize\n",
      "  function_optimizer: function_optimizer did nothing. time = 0.006ms.\n",
      "  function_optimizer: function_optimizer did nothing. time = 0.001ms.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=========================Options=============================\n",
      "-max_depth                  10000\n",
      "-min_bytes                  0\n",
      "-min_peak_bytes             0\n",
      "-min_residual_bytes         0\n",
      "-min_output_bytes           0\n",
      "-min_micros                 0\n",
      "-min_accelerator_micros     0\n",
      "-min_cpu_micros             0\n",
      "-min_params                 0\n",
      "-min_float_ops              1\n",
      "-min_occurrence             0\n",
      "-step                       -1\n",
      "-order_by                   float_ops\n",
      "-account_type_regexes       .*\n",
      "-start_name_regexes         .*\n",
      "-trim_name_regexes          \n",
      "-show_name_regexes          .*\n",
      "-hide_name_regexes          \n",
      "-account_displayed_op_only  true\n",
      "-select                     float_ops\n",
      "-output                     stdout:\n",
      "\n",
      "==================Model Analysis Report======================\n",
      "\n",
      "Doc:\n",
      "scope: The nodes in the model graph are organized by their names, which is hierarchical like filesystem.\n",
      "flops: Number of float operations. Note: Please read the implementation for the math behind it.\n",
      "\n",
      "Profile:\n",
      "node name | # float_ops\n",
      "_TFProfRoot (--/673.86m flops)\n",
      "  model_66/conv2d_933/Conv2D (68.75m/68.75m flops)\n",
      "  model_66/conv2d_934/Conv2D (68.75m/68.75m flops)\n",
      "  model_66/conv2d_935/Conv2D (68.75m/68.75m flops)\n",
      "  model_66/conv2d_929/Conv2D (68.30m/68.30m flops)\n",
      "  model_66/conv2d_932/Conv2D (66.72m/66.72m flops)\n",
      "  model_66/conv2d_931/Conv2D (58.69m/58.69m flops)\n",
      "  model_66/conv2d_927/Conv2D (51.18m/51.18m flops)\n",
      "  model_66/conv2d_928/Conv2D (37.26m/37.26m flops)\n",
      "  model_66/conv2d_925/Conv2D (35.32m/35.32m flops)\n",
      "  model_66/conv2d_930/Conv2D (32.77m/32.77m flops)\n",
      "  model_66/conv2d_936/Conv2D (29.44m/29.44m flops)\n",
      "  model_66/conv2d_926/Conv2D (18.77m/18.77m flops)\n",
      "  model_66/conv2d_937/Conv2D (18.00m/18.00m flops)\n",
      "  model_66/conv2d_924/Conv2D (12.85m/12.85m flops)\n",
      "  model_66/depthwise_conv2d_858/depthwise (7.23m/7.23m flops)\n",
      "  model_66/depthwise_conv2d_860/depthwise (3.84m/3.84m flops)\n",
      "  model_66/depthwise_conv2d_862/depthwise (2.79m/2.79m flops)\n",
      "  model_66/depthwise_conv2d_859/depthwise (2.48m/2.48m flops)\n",
      "  model_66/depthwise_conv2d_861/depthwise (1.69m/1.69m flops)\n",
      "  model_66/depthwise_conv2d_866/depthwise (1.52m/1.52m flops)\n",
      "  model_66/depthwise_conv2d_868/depthwise (1.52m/1.52m flops)\n",
      "  model_66/depthwise_conv2d_867/depthwise (1.43m/1.43m flops)\n",
      "  model_66/depthwise_conv2d_865/depthwise (1.39m/1.39m flops)\n",
      "  model_66/depthwise_conv2d_864/depthwise (1.34m/1.34m flops)\n",
      "  model_66/batch_normalization_1784/FusedBatchNormV3 (1.10m/1.10m flops)\n",
      "  model_66/batch_normalization_1783/FusedBatchNormV3 (803.01k/803.01k flops)\n",
      "  model_66/batch_normalization_1782/FusedBatchNormV3 (803.01k/803.01k flops)\n",
      "  model_66/depthwise_conv2d_863/depthwise (776.16k/776.16k flops)\n",
      "  model_66/batch_normalization_1788/FusedBatchNormV3 (753.36k/753.36k flops)\n",
      "  model_66/conv2d_925/BiasAdd (551.94k/551.94k flops)\n",
      "  model_66/batch_normalization_1786/FusedBatchNormV3 (426.90k/426.90k flops)\n",
      "  model_66/batch_normalization_1787/FusedBatchNormV3 (426.90k/426.90k flops)\n",
      "  model_66/conv2d_924/BiasAdd (401.41k/401.41k flops)\n",
      "  model_66/depthwise_conv2d_858/BiasAdd (401.41k/401.41k flops)\n",
      "  model_66/conv2d_927/BiasAdd (376.32k/376.32k flops)\n",
      "  model_66/depthwise_conv2d_869/depthwise (358.09k/358.09k flops)\n",
      "  model_66/batch_normalization_1792/FusedBatchNormV3 (346.28k/346.28k flops)\n",
      "  model_66/batch_normalization_1790/FusedBatchNormV3 (311.65k/311.65k flops)\n",
      "  model_66/batch_normalization_1791/FusedBatchNormV3 (311.65k/311.65k flops)\n",
      "  model_66/batch_normalization_1785/FusedBatchNormV3 (276.23k/276.23k flops)\n",
      "  model_66/conv2d_926/BiasAdd (213.25k/213.25k flops)\n",
      "  model_66/depthwise_conv2d_860/BiasAdd (213.25k/213.25k flops)\n",
      "  model_66/depthwise_conv2d_870/depthwise (213.12k/213.12k flops)\n",
      "  model_66/batch_normalization_1789/FusedBatchNormV3 (188.88k/188.88k flops)\n",
      "  model_66/conv2d_929/BiasAdd (172.48k/172.48k flops)\n",
      "  model_66/batch_normalization_1799/FusedBatchNormV3 (171.94k/171.94k flops)\n",
      "  model_66/batch_normalization_1803/FusedBatchNormV3 (171.94k/171.94k flops)\n",
      "  model_66/batch_normalization_1798/FusedBatchNormV3 (171.94k/171.94k flops)\n",
      "  model_66/batch_normalization_1802/FusedBatchNormV3 (171.94k/171.94k flops)\n",
      "  model_66/batch_normalization_1801/FusedBatchNormV3 (161.59k/161.59k flops)\n",
      "  model_66/batch_normalization_1804/FusedBatchNormV3 (161.59k/161.59k flops)\n",
      "  model_66/batch_normalization_1800/FusedBatchNormV3 (161.59k/161.59k flops)\n",
      "  model_66/batch_normalization_1796/FusedBatchNormV3 (156.81k/156.81k flops)\n",
      "  model_66/batch_normalization_1797/FusedBatchNormV3 (156.81k/156.81k flops)\n",
      "  model_66/depthwise_conv2d_862/BiasAdd (155.23k/155.23k flops)\n",
      "  model_66/conv2d_928/BiasAdd (155.23k/155.23k flops)\n",
      "  model_66/batch_normalization_1795/FusedBatchNormV3 (151.24k/151.24k flops)\n",
      "  model_66/batch_normalization_1794/FusedBatchNormV3 (151.24k/151.24k flops)\n",
      "  model_66/depthwise_conv2d_859/BiasAdd (137.98k/137.98k flops)\n",
      "  model_66/depthwise_conv2d_861/BiasAdd (94.08k/94.08k flops)\n",
      "  model_66/batch_normalization_1793/FusedBatchNormV3 (87.56k/87.56k flops)\n",
      "  model_66/depthwise_conv2d_868/BiasAdd (84.67k/84.67k flops)\n",
      "  model_66/depthwise_conv2d_866/BiasAdd (84.67k/84.67k flops)\n",
      "  model_66/conv2d_934/BiasAdd (84.67k/84.67k flops)\n",
      "  model_66/conv2d_932/BiasAdd (84.67k/84.67k flops)\n",
      "  model_66/depthwise_conv2d_867/BiasAdd (79.58k/79.58k flops)\n",
      "  model_66/conv2d_935/BiasAdd (79.58k/79.58k flops)\n",
      "  model_66/conv2d_933/BiasAdd (79.58k/79.58k flops)\n",
      "  model_66/conv2d_931/BiasAdd (77.22k/77.22k flops)\n",
      "  model_66/depthwise_conv2d_865/BiasAdd (77.22k/77.22k flops)\n",
      "  model_66/batch_normalization_1806/FusedBatchNormV3 (76.96k/76.96k flops)\n",
      "  model_66/depthwise_conv2d_864/BiasAdd (74.48k/74.48k flops)\n",
      "  model_66/conv2d_930/BiasAdd (74.48k/74.48k flops)\n",
      "  model_66/depthwise_conv2d_863/BiasAdd (43.12k/43.12k flops)\n",
      "  model_66/batch_normalization_1805/FusedBatchNormV3 (42.22k/42.22k flops)\n",
      "  model_66/conv2d_936/BiasAdd (36.26k/36.26k flops)\n",
      "  model_66/batch_normalization_1808/FusedBatchNormV3 (28.88k/28.88k flops)\n",
      "  model_66/batch_normalization_1807/FusedBatchNormV3 (28.12k/28.12k flops)\n",
      "  model_66/depthwise_conv2d_869/BiasAdd (19.89k/19.89k flops)\n",
      "  model_66/dense_66/MatMul (15.20k/15.20k flops)\n",
      "  model_66/global_average_pooling2d_66/Mean (12.16k/12.16k flops)\n",
      "  model_66/conv2d_937/BiasAdd (12.16k/12.16k flops)\n",
      "  model_66/depthwise_conv2d_870/BiasAdd (11.84k/11.84k flops)\n",
      "  model_66/dense_66/Softmax (50/50 flops)\n",
      "  model_66/dense_66/BiasAdd (10/10 flops)\n",
      "\n",
      "======================End of Report==========================\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "50.004188\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-30 13:40:42.132342: I tensorflow/core/grappler/devices.cc:66] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0\n",
      "2022-04-30 13:40:42.132460: I tensorflow/core/grappler/clusters/single_machine.cc:357] Starting new session\n",
      "2022-04-30 13:40:42.136555: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:1137] Optimization results for grappler item: graph_to_optimize\n",
      "  function_optimizer: function_optimizer did nothing. time = 0.005ms.\n",
      "  function_optimizer: function_optimizer did nothing. time = 0.001ms.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=========================Options=============================\n",
      "-max_depth                  10000\n",
      "-min_bytes                  0\n",
      "-min_peak_bytes             0\n",
      "-min_residual_bytes         0\n",
      "-min_output_bytes           0\n",
      "-min_micros                 0\n",
      "-min_accelerator_micros     0\n",
      "-min_cpu_micros             0\n",
      "-min_params                 0\n",
      "-min_float_ops              1\n",
      "-min_occurrence             0\n",
      "-step                       -1\n",
      "-order_by                   float_ops\n",
      "-account_type_regexes       .*\n",
      "-start_name_regexes         .*\n",
      "-trim_name_regexes          \n",
      "-show_name_regexes          .*\n",
      "-hide_name_regexes          \n",
      "-account_displayed_op_only  true\n",
      "-select                     float_ops\n",
      "-output                     stdout:\n",
      "\n",
      "==================Model Analysis Report======================\n",
      "\n",
      "Doc:\n",
      "scope: The nodes in the model graph are organized by their names, which is hierarchical like filesystem.\n",
      "flops: Number of float operations. Note: Please read the implementation for the math behind it.\n",
      "\n",
      "Profile:\n",
      "node name | # float_ops\n",
      "_TFProfRoot (--/719.58m flops)\n",
      "  model_67/conv2d_943/Conv2D (88.76m/88.76m flops)\n",
      "  model_67/conv2d_949/Conv2D (87.69m/87.69m flops)\n",
      "  model_67/conv2d_948/Conv2D (75.70m/75.70m flops)\n",
      "  model_67/conv2d_941/Conv2D (56.45m/56.45m flops)\n",
      "  model_67/conv2d_946/Conv2D (48.13m/48.13m flops)\n",
      "  model_67/conv2d_947/Conv2D (47.19m/47.19m flops)\n",
      "  model_67/conv2d_950/Conv2D (46.78m/46.78m flops)\n",
      "  model_67/conv2d_939/Conv2D (44.96m/44.96m flops)\n",
      "  model_67/conv2d_945/Conv2D (43.28m/43.28m flops)\n",
      "  model_67/conv2d_942/Conv2D (36.38m/36.38m flops)\n",
      "  model_67/conv2d_951/Conv2D (33.29m/33.29m flops)\n",
      "  model_67/conv2d_940/Conv2D (31.61m/31.61m flops)\n",
      "  model_67/conv2d_944/Conv2D (25.63m/25.63m flops)\n",
      "  model_67/conv2d_938/Conv2D (12.85m/12.85m flops)\n",
      "  model_67/depthwise_conv2d_871/depthwise (7.23m/7.23m flops)\n",
      "  model_67/depthwise_conv2d_873/depthwise (5.08m/5.08m flops)\n",
      "  model_67/depthwise_conv2d_875/depthwise (3.27m/3.27m flops)\n",
      "  model_67/depthwise_conv2d_872/depthwise (3.16m/3.16m flops)\n",
      "  model_67/depthwise_conv2d_881/depthwise (1.69m/1.69m flops)\n",
      "  model_67/depthwise_conv2d_878/depthwise (1.45m/1.45m flops)\n",
      "  model_67/depthwise_conv2d_880/depthwise (1.43m/1.43m flops)\n",
      "  model_67/depthwise_conv2d_874/depthwise (1.41m/1.41m flops)\n",
      "  model_67/batch_normalization_1811/FusedBatchNormV3 (1.41m/1.41m flops)\n",
      "  model_67/depthwise_conv2d_879/depthwise (1.05m/1.05m flops)\n",
      "  model_67/depthwise_conv2d_877/depthwise (945.50k/945.50k flops)\n",
      "  model_67/depthwise_conv2d_876/depthwise (860.83k/860.83k flops)\n",
      "  model_67/batch_normalization_1810/FusedBatchNormV3 (803.01k/803.01k flops)\n",
      "  model_67/batch_normalization_1809/FusedBatchNormV3 (803.01k/803.01k flops)\n",
      "  model_67/conv2d_939/BiasAdd (702.46k/702.46k flops)\n",
      "  model_67/batch_normalization_1815/FusedBatchNormV3 (627.80k/627.80k flops)\n",
      "  model_67/batch_normalization_1813/FusedBatchNormV3 (565.02k/565.02k flops)\n",
      "  model_67/batch_normalization_1814/FusedBatchNormV3 (565.02k/565.02k flops)\n",
      "  model_67/depthwise_conv2d_882/depthwise (412.78k/412.78k flops)\n",
      "  model_67/depthwise_conv2d_871/BiasAdd (401.41k/401.41k flops)\n",
      "  model_67/conv2d_938/BiasAdd (401.41k/401.41k flops)\n",
      "  model_67/batch_normalization_1819/FusedBatchNormV3 (384.06k/384.06k flops)\n",
      "  model_67/batch_normalization_1817/FusedBatchNormV3 (365.17k/365.17k flops)\n",
      "  model_67/batch_normalization_1818/FusedBatchNormV3 (365.17k/365.17k flops)\n",
      "  model_67/batch_normalization_1812/FusedBatchNormV3 (351.57k/351.57k flops)\n",
      "  model_67/conv2d_941/BiasAdd (313.60k/313.60k flops)\n",
      "  model_67/depthwise_conv2d_883/depthwise (293.76k/293.76k flops)\n",
      "  model_67/conv2d_940/BiasAdd (282.24k/282.24k flops)\n",
      "  model_67/depthwise_conv2d_873/BiasAdd (282.24k/282.24k flops)\n",
      "  model_67/conv2d_943/BiasAdd (191.30k/191.30k flops)\n",
      "  model_67/batch_normalization_1830/FusedBatchNormV3 (190.24k/190.24k flops)\n",
      "  model_67/batch_normalization_1829/FusedBatchNormV3 (190.24k/190.24k flops)\n",
      "  model_67/batch_normalization_1831/FusedBatchNormV3 (186.26k/186.26k flops)\n",
      "  model_67/conv2d_942/BiasAdd (181.89k/181.89k flops)\n",
      "  model_67/depthwise_conv2d_875/BiasAdd (181.89k/181.89k flops)\n",
      "  model_67/depthwise_conv2d_872/BiasAdd (175.62k/175.62k flops)\n",
      "  model_67/batch_normalization_1824/FusedBatchNormV3 (163.98k/163.98k flops)\n",
      "  model_67/batch_normalization_1823/FusedBatchNormV3 (163.98k/163.98k flops)\n",
      "  model_67/batch_normalization_1828/FusedBatchNormV3 (160.79k/160.79k flops)\n",
      "  model_67/batch_normalization_1827/FusedBatchNormV3 (160.79k/160.79k flops)\n",
      "  model_67/batch_normalization_1816/FusedBatchNormV3 (157.40k/157.40k flops)\n",
      "  model_67/batch_normalization_1826/FusedBatchNormV3 (118.60k/118.60k flops)\n",
      "  model_67/batch_normalization_1825/FusedBatchNormV3 (118.60k/118.60k flops)\n",
      "  model_67/batch_normalization_1822/FusedBatchNormV3 (106.66k/106.66k flops)\n",
      "  model_67/batch_normalization_1821/FusedBatchNormV3 (106.66k/106.66k flops)\n",
      "  model_67/batch_normalization_1833/FusedBatchNormV3 (106.08k/106.08k flops)\n",
      "  model_67/batch_normalization_1820/FusedBatchNormV3 (97.11k/97.11k flops)\n",
      "  model_67/depthwise_conv2d_881/BiasAdd (93.69k/93.69k flops)\n",
      "  model_67/conv2d_948/BiasAdd (93.69k/93.69k flops)\n",
      "  model_67/conv2d_949/BiasAdd (91.73k/91.73k flops)\n",
      "  model_67/depthwise_conv2d_878/BiasAdd (80.75k/80.75k flops)\n",
      "  model_67/conv2d_945/BiasAdd (80.75k/80.75k flops)\n",
      "  model_67/conv2d_947/BiasAdd (79.18k/79.18k flops)\n",
      "  model_67/depthwise_conv2d_880/BiasAdd (79.18k/79.18k flops)\n",
      "  model_67/depthwise_conv2d_874/BiasAdd (78.40k/78.40k flops)\n",
      "  model_67/conv2d_946/BiasAdd (58.41k/58.41k flops)\n",
      "  model_67/depthwise_conv2d_879/BiasAdd (58.41k/58.41k flops)\n",
      "  model_67/depthwise_conv2d_877/BiasAdd (52.53k/52.53k flops)\n",
      "  model_67/conv2d_944/BiasAdd (52.53k/52.53k flops)\n",
      "  model_67/conv2d_950/BiasAdd (49.98k/49.98k flops)\n",
      "  model_67/batch_normalization_1832/FusedBatchNormV3 (48.67k/48.67k flops)\n",
      "  model_67/depthwise_conv2d_876/BiasAdd (47.82k/47.82k flops)\n",
      "  model_67/batch_normalization_1835/FusedBatchNormV3 (38.76k/38.76k flops)\n",
      "  model_67/batch_normalization_1834/FusedBatchNormV3 (38.76k/38.76k flops)\n",
      "  model_67/depthwise_conv2d_882/BiasAdd (22.93k/22.93k flops)\n",
      "  model_67/dense_67/MatMul (20.40k/20.40k flops)\n",
      "  model_67/depthwise_conv2d_883/BiasAdd (16.32k/16.32k flops)\n",
      "  model_67/conv2d_951/BiasAdd (16.32k/16.32k flops)\n",
      "  model_67/global_average_pooling2d_67/Mean (16.32k/16.32k flops)\n",
      "  model_67/dense_67/Softmax (50/50 flops)\n",
      "  model_67/dense_67/BiasAdd (10/10 flops)\n",
      "\n",
      "======================End of Report==========================\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "48.1995\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-30 13:40:43.184758: I tensorflow/core/grappler/devices.cc:66] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0\n",
      "2022-04-30 13:40:43.184875: I tensorflow/core/grappler/clusters/single_machine.cc:357] Starting new session\n",
      "2022-04-30 13:40:43.189564: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:1137] Optimization results for grappler item: graph_to_optimize\n",
      "  function_optimizer: function_optimizer did nothing. time = 0.006ms.\n",
      "  function_optimizer: function_optimizer did nothing. time = 0.001ms.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=========================Options=============================\n",
      "-max_depth                  10000\n",
      "-min_bytes                  0\n",
      "-min_peak_bytes             0\n",
      "-min_residual_bytes         0\n",
      "-min_output_bytes           0\n",
      "-min_micros                 0\n",
      "-min_accelerator_micros     0\n",
      "-min_cpu_micros             0\n",
      "-min_params                 0\n",
      "-min_float_ops              1\n",
      "-min_occurrence             0\n",
      "-step                       -1\n",
      "-order_by                   float_ops\n",
      "-account_type_regexes       .*\n",
      "-start_name_regexes         .*\n",
      "-trim_name_regexes          \n",
      "-show_name_regexes          .*\n",
      "-hide_name_regexes          \n",
      "-account_displayed_op_only  true\n",
      "-select                     float_ops\n",
      "-output                     stdout:\n",
      "\n",
      "==================Model Analysis Report======================\n",
      "\n",
      "Doc:\n",
      "scope: The nodes in the model graph are organized by their names, which is hierarchical like filesystem.\n",
      "flops: Number of float operations. Note: Please read the implementation for the math behind it.\n",
      "\n",
      "Profile:\n",
      "node name | # float_ops\n",
      "_TFProfRoot (--/767.31m flops)\n",
      "  model_68/conv2d_962/Conv2D (88.91m/88.91m flops)\n",
      "  model_68/conv2d_963/Conv2D (87.72m/87.72m flops)\n",
      "  model_68/conv2d_961/Conv2D (82.20m/82.20m flops)\n",
      "  model_68/conv2d_960/Conv2D (80.38m/80.38m flops)\n",
      "  model_68/conv2d_959/Conv2D (74.51m/74.51m flops)\n",
      "  model_68/conv2d_957/Conv2D (70.40m/70.40m flops)\n",
      "  model_68/conv2d_955/Conv2D (53.94m/53.94m flops)\n",
      "  model_68/conv2d_958/Conv2D (41.32m/41.32m flops)\n",
      "  model_68/conv2d_953/Conv2D (35.32m/35.32m flops)\n",
      "  model_68/conv2d_964/Conv2D (30.72m/30.72m flops)\n",
      "  model_68/conv2d_956/Conv2D (28.85m/28.85m flops)\n",
      "  model_68/conv2d_954/Conv2D (23.73m/23.73m flops)\n",
      "  model_68/conv2d_965/Conv2D (16.22m/16.22m flops)\n",
      "  model_68/conv2d_952/Conv2D (12.85m/12.85m flops)\n",
      "  model_68/depthwise_conv2d_884/depthwise (7.23m/7.23m flops)\n",
      "  model_68/depthwise_conv2d_886/depthwise (4.85m/4.85m flops)\n",
      "  model_68/depthwise_conv2d_888/depthwise (2.60m/2.60m flops)\n",
      "  model_68/depthwise_conv2d_885/depthwise (2.48m/2.48m flops)\n",
      "  model_68/depthwise_conv2d_894/depthwise (1.78m/1.78m flops)\n",
      "  model_68/depthwise_conv2d_892/depthwise (1.64m/1.64m flops)\n",
      "  model_68/depthwise_conv2d_893/depthwise (1.59m/1.59m flops)\n",
      "  model_68/depthwise_conv2d_891/depthwise (1.55m/1.55m flops)\n",
      "  model_68/depthwise_conv2d_890/depthwise (1.52m/1.52m flops)\n",
      "  model_68/depthwise_conv2d_887/depthwise (1.41m/1.41m flops)\n",
      "  model_68/batch_normalization_1838/FusedBatchNormV3 (1.10m/1.10m flops)\n",
      "  model_68/depthwise_conv2d_889/depthwise (860.83k/860.83k flops)\n",
      "  model_68/batch_normalization_1837/FusedBatchNormV3 (803.01k/803.01k flops)\n",
      "  model_68/batch_normalization_1836/FusedBatchNormV3 (803.01k/803.01k flops)\n",
      "  model_68/batch_normalization_1842/FusedBatchNormV3 (627.80k/627.80k flops)\n",
      "  model_68/conv2d_953/BiasAdd (551.94k/551.94k flops)\n",
      "  model_68/batch_normalization_1840/FusedBatchNormV3 (539.91k/539.91k flops)\n",
      "  model_68/batch_normalization_1841/FusedBatchNormV3 (539.91k/539.91k flops)\n",
      "  model_68/depthwise_conv2d_884/BiasAdd (401.41k/401.41k flops)\n",
      "  model_68/conv2d_952/BiasAdd (401.41k/401.41k flops)\n",
      "  model_68/depthwise_conv2d_895/depthwise (391.61k/391.61k flops)\n",
      "  model_68/batch_normalization_1846/FusedBatchNormV3 (384.06k/384.06k flops)\n",
      "  model_68/conv2d_955/BiasAdd (313.60k/313.60k flops)\n",
      "  model_68/batch_normalization_1844/FusedBatchNormV3 (289.62k/289.62k flops)\n",
      "  model_68/batch_normalization_1845/FusedBatchNormV3 (289.62k/289.62k flops)\n",
      "  model_68/batch_normalization_1839/FusedBatchNormV3 (276.23k/276.23k flops)\n",
      "  model_68/conv2d_954/BiasAdd (269.70k/269.70k flops)\n",
      "  model_68/depthwise_conv2d_886/BiasAdd (269.70k/269.70k flops)\n",
      "  model_68/depthwise_conv2d_896/depthwise (203.33k/203.33k flops)\n",
      "  model_68/batch_normalization_1857/FusedBatchNormV3 (200.59k/200.59k flops)\n",
      "  model_68/batch_normalization_1856/FusedBatchNormV3 (200.59k/200.59k flops)\n",
      "  model_68/conv2d_957/BiasAdd (191.30k/191.30k flops)\n",
      "  model_68/batch_normalization_1853/FusedBatchNormV3 (185.47k/185.47k flops)\n",
      "  model_68/batch_normalization_1852/FusedBatchNormV3 (185.47k/185.47k flops)\n",
      "  model_68/batch_normalization_1854/FusedBatchNormV3 (179.10k/179.10k flops)\n",
      "  model_68/batch_normalization_1855/FusedBatchNormV3 (179.10k/179.10k flops)\n",
      "  model_68/batch_normalization_1858/FusedBatchNormV3 (176.71k/176.71k flops)\n",
      "  model_68/batch_normalization_1851/FusedBatchNormV3 (175.12k/175.12k flops)\n",
      "  model_68/batch_normalization_1850/FusedBatchNormV3 (175.12k/175.12k flops)\n",
      "  model_68/batch_normalization_1849/FusedBatchNormV3 (171.94k/171.94k flops)\n",
      "  model_68/batch_normalization_1848/FusedBatchNormV3 (171.94k/171.94k flops)\n",
      "  model_68/batch_normalization_1843/FusedBatchNormV3 (157.40k/157.40k flops)\n",
      "  model_68/conv2d_956/BiasAdd (144.26k/144.26k flops)\n",
      "  model_68/depthwise_conv2d_888/BiasAdd (144.26k/144.26k flops)\n",
      "  model_68/depthwise_conv2d_885/BiasAdd (137.98k/137.98k flops)\n",
      "  model_68/conv2d_962/BiasAdd (98.78k/98.78k flops)\n",
      "  model_68/depthwise_conv2d_894/BiasAdd (98.78k/98.78k flops)\n",
      "  model_68/batch_normalization_1847/FusedBatchNormV3 (97.11k/97.11k flops)\n",
      "  model_68/conv2d_960/BiasAdd (91.34k/91.34k flops)\n",
      "  model_68/depthwise_conv2d_892/BiasAdd (91.34k/91.34k flops)\n",
      "  model_68/conv2d_961/BiasAdd (88.20k/88.20k flops)\n",
      "  model_68/depthwise_conv2d_893/BiasAdd (88.20k/88.20k flops)\n",
      "  model_68/conv2d_963/BiasAdd (87.02k/87.02k flops)\n",
      "  model_68/depthwise_conv2d_891/BiasAdd (86.24k/86.24k flops)\n",
      "  model_68/conv2d_959/BiasAdd (86.24k/86.24k flops)\n",
      "  model_68/depthwise_conv2d_890/BiasAdd (84.67k/84.67k flops)\n",
      "  model_68/conv2d_958/BiasAdd (84.67k/84.67k flops)\n",
      "  model_68/depthwise_conv2d_887/BiasAdd (78.40k/78.40k flops)\n",
      "  model_68/batch_normalization_1860/FusedBatchNormV3 (73.42k/73.42k flops)\n",
      "  model_68/depthwise_conv2d_889/BiasAdd (47.82k/47.82k flops)\n",
      "  model_68/batch_normalization_1859/FusedBatchNormV3 (46.18k/46.18k flops)\n",
      "  model_68/conv2d_964/BiasAdd (34.59k/34.59k flops)\n",
      "  model_68/batch_normalization_1862/FusedBatchNormV3 (27.28k/27.28k flops)\n",
      "  model_68/batch_normalization_1861/FusedBatchNormV3 (26.83k/26.83k flops)\n",
      "  model_68/depthwise_conv2d_895/BiasAdd (21.76k/21.76k flops)\n",
      "  model_68/dense_68/MatMul (14.36k/14.36k flops)\n",
      "  model_68/conv2d_965/BiasAdd (11.49k/11.49k flops)\n",
      "  model_68/global_average_pooling2d_68/Mean (11.49k/11.49k flops)\n",
      "  model_68/depthwise_conv2d_896/BiasAdd (11.30k/11.30k flops)\n",
      "  model_68/dense_68/Softmax (50/50 flops)\n",
      "  model_68/dense_68/BiasAdd (10/10 flops)\n",
      "\n",
      "======================End of Report==========================\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "47.88814\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-30 13:40:44.114089: I tensorflow/core/grappler/devices.cc:66] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0\n",
      "2022-04-30 13:40:44.114207: I tensorflow/core/grappler/clusters/single_machine.cc:357] Starting new session\n",
      "2022-04-30 13:40:44.118369: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:1137] Optimization results for grappler item: graph_to_optimize\n",
      "  function_optimizer: function_optimizer did nothing. time = 0.005ms.\n",
      "  function_optimizer: function_optimizer did nothing. time = 0.001ms.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=========================Options=============================\n",
      "-max_depth                  10000\n",
      "-min_bytes                  0\n",
      "-min_peak_bytes             0\n",
      "-min_residual_bytes         0\n",
      "-min_output_bytes           0\n",
      "-min_micros                 0\n",
      "-min_accelerator_micros     0\n",
      "-min_cpu_micros             0\n",
      "-min_params                 0\n",
      "-min_float_ops              1\n",
      "-min_occurrence             0\n",
      "-step                       -1\n",
      "-order_by                   float_ops\n",
      "-account_type_regexes       .*\n",
      "-start_name_regexes         .*\n",
      "-trim_name_regexes          \n",
      "-show_name_regexes          .*\n",
      "-hide_name_regexes          \n",
      "-account_displayed_op_only  true\n",
      "-select                     float_ops\n",
      "-output                     stdout:\n",
      "\n",
      "==================Model Analysis Report======================\n",
      "\n",
      "Doc:\n",
      "scope: The nodes in the model graph are organized by their names, which is hierarchical like filesystem.\n",
      "flops: Number of float operations. Note: Please read the implementation for the math behind it.\n",
      "\n",
      "Profile:\n",
      "node name | # float_ops\n",
      "_TFProfRoot (--/795.01m flops)\n",
      "  model_69/conv2d_976/Conv2D (94.83m/94.83m flops)\n",
      "  model_69/conv2d_975/Conv2D (89.19m/89.19m flops)\n",
      "  model_69/conv2d_974/Conv2D (86.59m/86.59m flops)\n",
      "  model_69/conv2d_977/Conv2D (86.14m/86.14m flops)\n",
      "  model_69/conv2d_973/Conv2D (74.90m/74.90m flops)\n",
      "  model_69/conv2d_971/Conv2D (73.83m/73.83m flops)\n",
      "  model_69/conv2d_969/Conv2D (63.82m/63.82m flops)\n",
      "  model_69/conv2d_970/Conv2D (35.90m/35.90m flops)\n",
      "  model_69/conv2d_972/Conv2D (35.04m/35.04m flops)\n",
      "  model_69/conv2d_978/Conv2D (31.36m/31.36m flops)\n",
      "  model_69/conv2d_967/Conv2D (27.30m/27.30m flops)\n",
      "  model_69/conv2d_979/Conv2D (22.03m/22.03m flops)\n",
      "  model_69/conv2d_968/Conv2D (20.47m/20.47m flops)\n",
      "  model_69/conv2d_966/Conv2D (12.85m/12.85m flops)\n",
      "  model_69/depthwise_conv2d_897/depthwise (7.23m/7.23m flops)\n",
      "  model_69/depthwise_conv2d_899/depthwise (5.42m/5.42m flops)\n",
      "  model_69/depthwise_conv2d_901/depthwise (3.05m/3.05m flops)\n",
      "  model_69/depthwise_conv2d_898/depthwise (1.92m/1.92m flops)\n",
      "  model_69/depthwise_conv2d_907/depthwise (1.78m/1.78m flops)\n",
      "  model_69/depthwise_conv2d_906/depthwise (1.69m/1.69m flops)\n",
      "  model_69/depthwise_conv2d_905/depthwise (1.67m/1.67m flops)\n",
      "  model_69/depthwise_conv2d_904/depthwise (1.64m/1.64m flops)\n",
      "  model_69/depthwise_conv2d_900/depthwise (1.50m/1.50m flops)\n",
      "  model_69/depthwise_conv2d_903/depthwise (1.45m/1.45m flops)\n",
      "  model_69/batch_normalization_1865/FusedBatchNormV3 (853.20k/853.20k flops)\n",
      "  model_69/batch_normalization_1864/FusedBatchNormV3 (803.01k/803.01k flops)\n",
      "  model_69/batch_normalization_1863/FusedBatchNormV3 (803.01k/803.01k flops)\n",
      "  model_69/depthwise_conv2d_902/depthwise (769.10k/769.10k flops)\n",
      "  model_69/batch_normalization_1869/FusedBatchNormV3 (665.47k/665.47k flops)\n",
      "  model_69/batch_normalization_1867/FusedBatchNormV3 (602.69k/602.69k flops)\n",
      "  model_69/batch_normalization_1868/FusedBatchNormV3 (602.69k/602.69k flops)\n",
      "  model_69/conv2d_967/BiasAdd (426.50k/426.50k flops)\n",
      "  model_69/conv2d_966/BiasAdd (401.41k/401.41k flops)\n",
      "  model_69/depthwise_conv2d_897/BiasAdd (401.41k/401.41k flops)\n",
      "  model_69/depthwise_conv2d_908/depthwise (384.55k/384.55k flops)\n",
      "  model_69/batch_normalization_1873/FusedBatchNormV3 (343.13k/343.13k flops)\n",
      "  model_69/batch_normalization_1872/FusedBatchNormV3 (339.98k/339.98k flops)\n",
      "  model_69/batch_normalization_1871/FusedBatchNormV3 (339.98k/339.98k flops)\n",
      "  model_69/conv2d_969/BiasAdd (332.42k/332.42k flops)\n",
      "  model_69/depthwise_conv2d_899/BiasAdd (301.06k/301.06k flops)\n",
      "  model_69/conv2d_968/BiasAdd (301.06k/301.06k flops)\n",
      "  model_69/batch_normalization_1866/FusedBatchNormV3 (213.45k/213.45k flops)\n",
      "  model_69/depthwise_conv2d_909/depthwise (211.39k/211.39k flops)\n",
      "  model_69/batch_normalization_1884/FusedBatchNormV3 (200.59k/200.59k flops)\n",
      "  model_69/batch_normalization_1883/FusedBatchNormV3 (200.59k/200.59k flops)\n",
      "  model_69/batch_normalization_1881/FusedBatchNormV3 (191.04k/191.04k flops)\n",
      "  model_69/batch_normalization_1882/FusedBatchNormV3 (191.04k/191.04k flops)\n",
      "  model_69/batch_normalization_1880/FusedBatchNormV3 (188.65k/188.65k flops)\n",
      "  model_69/batch_normalization_1879/FusedBatchNormV3 (188.65k/188.65k flops)\n",
      "  model_69/batch_normalization_1878/FusedBatchNormV3 (185.47k/185.47k flops)\n",
      "  model_69/batch_normalization_1877/FusedBatchNormV3 (185.47k/185.47k flops)\n",
      "  model_69/batch_normalization_1885/FusedBatchNormV3 (173.53k/173.53k flops)\n",
      "  model_69/conv2d_971/BiasAdd (170.91k/170.91k flops)\n",
      "  model_69/depthwise_conv2d_901/BiasAdd (169.34k/169.34k flops)\n",
      "  model_69/conv2d_970/BiasAdd (169.34k/169.34k flops)\n",
      "  model_69/batch_normalization_1870/FusedBatchNormV3 (166.84k/166.84k flops)\n",
      "  model_69/batch_normalization_1875/FusedBatchNormV3 (163.18k/163.18k flops)\n",
      "  model_69/batch_normalization_1876/FusedBatchNormV3 (163.18k/163.18k flops)\n",
      "  model_69/depthwise_conv2d_898/BiasAdd (106.62k/106.62k flops)\n",
      "  model_69/depthwise_conv2d_907/BiasAdd (98.78k/98.78k flops)\n",
      "  model_69/conv2d_976/BiasAdd (98.78k/98.78k flops)\n",
      "  model_69/depthwise_conv2d_906/BiasAdd (94.08k/94.08k flops)\n",
      "  model_69/conv2d_975/BiasAdd (94.08k/94.08k flops)\n",
      "  model_69/conv2d_974/BiasAdd (92.90k/92.90k flops)\n",
      "  model_69/depthwise_conv2d_905/BiasAdd (92.90k/92.90k flops)\n",
      "  model_69/conv2d_973/BiasAdd (91.34k/91.34k flops)\n",
      "  model_69/depthwise_conv2d_904/BiasAdd (91.34k/91.34k flops)\n",
      "  model_69/batch_normalization_1874/FusedBatchNormV3 (86.76k/86.76k flops)\n",
      "  model_69/conv2d_977/BiasAdd (85.46k/85.46k flops)\n",
      "  model_69/depthwise_conv2d_900/BiasAdd (83.10k/83.10k flops)\n",
      "  model_69/depthwise_conv2d_903/BiasAdd (80.36k/80.36k flops)\n",
      "  model_69/conv2d_972/BiasAdd (80.36k/80.36k flops)\n",
      "  model_69/batch_normalization_1887/FusedBatchNormV3 (76.34k/76.34k flops)\n",
      "  model_69/batch_normalization_1886/FusedBatchNormV3 (45.34k/45.34k flops)\n",
      "  model_69/depthwise_conv2d_902/BiasAdd (42.73k/42.73k flops)\n",
      "  model_69/conv2d_978/BiasAdd (35.97k/35.97k flops)\n",
      "  model_69/batch_normalization_1889/FusedBatchNormV3 (35.64k/35.64k flops)\n",
      "  model_69/batch_normalization_1888/FusedBatchNormV3 (27.89k/27.89k flops)\n",
      "  model_69/depthwise_conv2d_908/BiasAdd (21.36k/21.36k flops)\n",
      "  model_69/dense_69/MatMul (18.76k/18.76k flops)\n",
      "  model_69/global_average_pooling2d_69/Mean (15.01k/15.01k flops)\n",
      "  model_69/conv2d_979/BiasAdd (15.01k/15.01k flops)\n",
      "  model_69/depthwise_conv2d_909/BiasAdd (11.74k/11.74k flops)\n",
      "  model_69/dense_69/Softmax (50/50 flops)\n",
      "  model_69/dense_69/BiasAdd (10/10 flops)\n",
      "\n",
      "======================End of Report==========================\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "53.00954\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-30 13:40:45.152374: I tensorflow/core/grappler/devices.cc:66] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0\n",
      "2022-04-30 13:40:45.152490: I tensorflow/core/grappler/clusters/single_machine.cc:357] Starting new session\n",
      "2022-04-30 13:40:45.157130: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:1137] Optimization results for grappler item: graph_to_optimize\n",
      "  function_optimizer: function_optimizer did nothing. time = 0.006ms.\n",
      "  function_optimizer: function_optimizer did nothing. time = 0.001ms.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=========================Options=============================\n",
      "-max_depth                  10000\n",
      "-min_bytes                  0\n",
      "-min_peak_bytes             0\n",
      "-min_residual_bytes         0\n",
      "-min_output_bytes           0\n",
      "-min_micros                 0\n",
      "-min_accelerator_micros     0\n",
      "-min_cpu_micros             0\n",
      "-min_params                 0\n",
      "-min_float_ops              1\n",
      "-min_occurrence             0\n",
      "-step                       -1\n",
      "-order_by                   float_ops\n",
      "-account_type_regexes       .*\n",
      "-start_name_regexes         .*\n",
      "-trim_name_regexes          \n",
      "-show_name_regexes          .*\n",
      "-hide_name_regexes          \n",
      "-account_displayed_op_only  true\n",
      "-select                     float_ops\n",
      "-output                     stdout:\n",
      "\n",
      "==================Model Analysis Report======================\n",
      "\n",
      "Doc:\n",
      "scope: The nodes in the model graph are organized by their names, which is hierarchical like filesystem.\n",
      "flops: Number of float operations. Note: Please read the implementation for the math behind it.\n",
      "\n",
      "Profile:\n",
      "node name | # float_ops\n",
      "_TFProfRoot (--/869.75m flops)\n",
      "  model_70/conv2d_983/Conv2D (99.57m/99.57m flops)\n",
      "  model_70/conv2d_989/Conv2D (97.99m/97.99m flops)\n",
      "  model_70/conv2d_990/Conv2D (94.42m/94.42m flops)\n",
      "  model_70/conv2d_988/Conv2D (93.34m/93.34m flops)\n",
      "  model_70/conv2d_985/Conv2D (89.56m/89.56m flops)\n",
      "  model_70/conv2d_991/Conv2D (75.01m/75.01m flops)\n",
      "  model_70/conv2d_987/Conv2D (64.24m/64.24m flops)\n",
      "  model_70/conv2d_984/Conv2D (47.02m/47.02m flops)\n",
      "  model_70/conv2d_981/Conv2D (33.72m/33.72m flops)\n",
      "  model_70/conv2d_982/Conv2D (33.19m/33.19m flops)\n",
      "  model_70/conv2d_986/Conv2D (31.99m/31.99m flops)\n",
      "  model_70/conv2d_992/Conv2D (29.70m/29.70m flops)\n",
      "  model_70/conv2d_993/Conv2D (22.44m/22.44m flops)\n",
      "  model_70/conv2d_980/Conv2D (12.85m/12.85m flops)\n",
      "  model_70/depthwise_conv2d_910/depthwise (7.23m/7.23m flops)\n",
      "  model_70/depthwise_conv2d_912/depthwise (7.11m/7.11m flops)\n",
      "  model_70/depthwise_conv2d_914/depthwise (3.36m/3.36m flops)\n",
      "  model_70/depthwise_conv2d_911/depthwise (2.37m/2.37m flops)\n",
      "  model_70/depthwise_conv2d_919/depthwise (1.79m/1.79m flops)\n",
      "  model_70/depthwise_conv2d_913/depthwise (1.78m/1.78m flops)\n",
      "  model_70/depthwise_conv2d_918/depthwise (1.74m/1.74m flops)\n",
      "  model_70/depthwise_conv2d_917/depthwise (1.70m/1.70m flops)\n",
      "  model_70/depthwise_conv2d_920/depthwise (1.68m/1.68m flops)\n",
      "  model_70/depthwise_conv2d_916/depthwise (1.20m/1.20m flops)\n",
      "  model_70/batch_normalization_1892/FusedBatchNormV3 (1.05m/1.05m flops)\n",
      "  model_70/depthwise_conv2d_915/depthwise (846.72k/846.72k flops)\n",
      "  model_70/batch_normalization_1891/FusedBatchNormV3 (803.01k/803.01k flops)\n",
      "  model_70/batch_normalization_1890/FusedBatchNormV3 (803.01k/803.01k flops)\n",
      "  model_70/batch_normalization_1894/FusedBatchNormV3 (791.03k/791.03k flops)\n",
      "  model_70/batch_normalization_1895/FusedBatchNormV3 (791.03k/791.03k flops)\n",
      "  model_70/batch_normalization_1896/FusedBatchNormV3 (791.03k/791.03k flops)\n",
      "  model_70/conv2d_981/BiasAdd (526.85k/526.85k flops)\n",
      "  model_70/depthwise_conv2d_910/BiasAdd (401.41k/401.41k flops)\n",
      "  model_70/conv2d_980/BiasAdd (401.41k/401.41k flops)\n",
      "  model_70/conv2d_982/BiasAdd (395.14k/395.14k flops)\n",
      "  model_70/conv2d_983/BiasAdd (395.14k/395.14k flops)\n",
      "  model_70/depthwise_conv2d_912/BiasAdd (395.14k/395.14k flops)\n",
      "  model_70/batch_normalization_1900/FusedBatchNormV3 (377.76k/377.76k flops)\n",
      "  model_70/batch_normalization_1898/FusedBatchNormV3 (374.61k/374.61k flops)\n",
      "  model_70/batch_normalization_1899/FusedBatchNormV3 (374.61k/374.61k flops)\n",
      "  model_70/depthwise_conv2d_921/depthwise (354.56k/354.56k flops)\n",
      "  model_70/batch_normalization_1893/FusedBatchNormV3 (263.68k/263.68k flops)\n",
      "  model_70/depthwise_conv2d_922/depthwise (217.15k/217.15k flops)\n",
      "  model_70/batch_normalization_1908/FusedBatchNormV3 (201.39k/201.39k flops)\n",
      "  model_70/batch_normalization_1909/FusedBatchNormV3 (201.39k/201.39k flops)\n",
      "  model_70/batch_normalization_1897/FusedBatchNormV3 (198.32k/198.32k flops)\n",
      "  model_70/batch_normalization_1907/FusedBatchNormV3 (196.61k/196.61k flops)\n",
      "  model_70/batch_normalization_1906/FusedBatchNormV3 (196.61k/196.61k flops)\n",
      "  model_70/batch_normalization_1905/FusedBatchNormV3 (191.84k/191.84k flops)\n",
      "  model_70/batch_normalization_1904/FusedBatchNormV3 (191.84k/191.84k flops)\n",
      "  model_70/batch_normalization_1911/FusedBatchNormV3 (189.45k/189.45k flops)\n",
      "  model_70/batch_normalization_1910/FusedBatchNormV3 (189.45k/189.45k flops)\n",
      "  model_70/conv2d_985/BiasAdd (188.16k/188.16k flops)\n",
      "  model_70/conv2d_984/BiasAdd (186.59k/186.59k flops)\n",
      "  model_70/depthwise_conv2d_914/BiasAdd (186.59k/186.59k flops)\n",
      "  model_70/batch_normalization_1912/FusedBatchNormV3 (160.00k/160.00k flops)\n",
      "  model_70/batch_normalization_1903/FusedBatchNormV3 (135.32k/135.32k flops)\n",
      "  model_70/batch_normalization_1902/FusedBatchNormV3 (135.32k/135.32k flops)\n",
      "  model_70/depthwise_conv2d_911/BiasAdd (131.71k/131.71k flops)\n",
      "  model_70/depthwise_conv2d_919/BiasAdd (99.18k/99.18k flops)\n",
      "  model_70/conv2d_989/BiasAdd (99.18k/99.18k flops)\n",
      "  model_70/depthwise_conv2d_913/BiasAdd (98.78k/98.78k flops)\n",
      "  model_70/depthwise_conv2d_918/BiasAdd (96.82k/96.82k flops)\n",
      "  model_70/conv2d_988/BiasAdd (96.82k/96.82k flops)\n",
      "  model_70/batch_normalization_1901/FusedBatchNormV3 (95.52k/95.52k flops)\n",
      "  model_70/conv2d_987/BiasAdd (94.47k/94.47k flops)\n",
      "  model_70/depthwise_conv2d_917/BiasAdd (94.47k/94.47k flops)\n",
      "  model_70/conv2d_990/BiasAdd (93.30k/93.30k flops)\n",
      "  model_70/depthwise_conv2d_920/BiasAdd (93.30k/93.30k flops)\n",
      "  model_70/conv2d_991/BiasAdd (78.79k/78.79k flops)\n",
      "  model_70/batch_normalization_1914/FusedBatchNormV3 (78.42k/78.42k flops)\n",
      "  model_70/conv2d_986/BiasAdd (66.64k/66.64k flops)\n",
      "  model_70/depthwise_conv2d_916/BiasAdd (66.64k/66.64k flops)\n",
      "  model_70/depthwise_conv2d_915/BiasAdd (47.04k/47.04k flops)\n",
      "  model_70/batch_normalization_1913/FusedBatchNormV3 (41.81k/41.81k flops)\n",
      "  model_70/conv2d_992/BiasAdd (36.95k/36.95k flops)\n",
      "  model_70/batch_normalization_1916/FusedBatchNormV3 (35.34k/35.34k flops)\n",
      "  model_70/batch_normalization_1915/FusedBatchNormV3 (28.65k/28.65k flops)\n",
      "  model_70/depthwise_conv2d_921/BiasAdd (19.70k/19.70k flops)\n",
      "  model_70/dense_70/MatMul (18.60k/18.60k flops)\n",
      "  model_70/conv2d_993/BiasAdd (14.88k/14.88k flops)\n",
      "  model_70/global_average_pooling2d_70/Mean (14.88k/14.88k flops)\n",
      "  model_70/depthwise_conv2d_922/BiasAdd (12.06k/12.06k flops)\n",
      "  model_70/dense_70/Softmax (50/50 flops)\n",
      "  model_70/dense_70/BiasAdd (10/10 flops)\n",
      "\n",
      "======================End of Report==========================\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "53.698452\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-30 13:40:46.090131: I tensorflow/core/grappler/devices.cc:66] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0\n",
      "2022-04-30 13:40:46.090248: I tensorflow/core/grappler/clusters/single_machine.cc:357] Starting new session\n",
      "2022-04-30 13:40:46.094360: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:1137] Optimization results for grappler item: graph_to_optimize\n",
      "  function_optimizer: function_optimizer did nothing. time = 0.005ms.\n",
      "  function_optimizer: function_optimizer did nothing. time = 0.001ms.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=========================Options=============================\n",
      "-max_depth                  10000\n",
      "-min_bytes                  0\n",
      "-min_peak_bytes             0\n",
      "-min_residual_bytes         0\n",
      "-min_output_bytes           0\n",
      "-min_micros                 0\n",
      "-min_accelerator_micros     0\n",
      "-min_cpu_micros             0\n",
      "-min_params                 0\n",
      "-min_float_ops              1\n",
      "-min_occurrence             0\n",
      "-step                       -1\n",
      "-order_by                   float_ops\n",
      "-account_type_regexes       .*\n",
      "-start_name_regexes         .*\n",
      "-trim_name_regexes          \n",
      "-show_name_regexes          .*\n",
      "-hide_name_regexes          \n",
      "-account_displayed_op_only  true\n",
      "-select                     float_ops\n",
      "-output                     stdout:\n",
      "\n",
      "==================Model Analysis Report======================\n",
      "\n",
      "Doc:\n",
      "scope: The nodes in the model graph are organized by their names, which is hierarchical like filesystem.\n",
      "flops: Number of float operations. Note: Please read the implementation for the math behind it.\n",
      "\n",
      "Profile:\n",
      "node name | # float_ops\n",
      "_TFProfRoot (--/693.71m flops)\n",
      "  model_71/conv2d_1003/Conv2D (100.69m/100.69m flops)\n",
      "  model_71/conv2d_999/Conv2D (97.20m/97.20m flops)\n",
      "  model_71/conv2d_1002/Conv2D (80.64m/80.64m flops)\n",
      "  model_71/conv2d_1004/Conv2D (70.44m/70.44m flops)\n",
      "  model_71/conv2d_1005/Conv2D (51.74m/51.74m flops)\n",
      "  model_71/conv2d_1001/Conv2D (42.92m/42.92m flops)\n",
      "  model_71/conv2d_995/Conv2D (41.94m/41.94m flops)\n",
      "  model_71/conv2d_997/Conv2D (31.20m/31.20m flops)\n",
      "  model_71/conv2d_998/Conv2D (29.25m/29.25m flops)\n",
      "  model_71/conv2d_1000/Conv2D (28.70m/28.70m flops)\n",
      "  model_71/conv2d_1006/Conv2D (22.30m/22.30m flops)\n",
      "  model_71/conv2d_996/Conv2D (18.35m/18.35m flops)\n",
      "  model_71/conv2d_994/Conv2D (16.78m/16.78m flops)\n",
      "  model_71/conv2d_1007/Conv2D (16.58m/16.58m flops)\n",
      "  model_71/depthwise_conv2d_923/depthwise (9.44m/9.44m flops)\n",
      "  model_71/depthwise_conv2d_925/depthwise (4.13m/4.13m flops)\n",
      "  model_71/depthwise_conv2d_927/depthwise (3.87m/3.87m flops)\n",
      "  model_71/depthwise_conv2d_924/depthwise (2.95m/2.95m flops)\n",
      "  model_71/depthwise_conv2d_931/depthwise (2.15m/2.15m flops)\n",
      "  model_71/depthwise_conv2d_932/depthwise (1.94m/1.94m flops)\n",
      "  model_71/depthwise_conv2d_930/depthwise (1.56m/1.56m flops)\n",
      "  model_71/depthwise_conv2d_933/depthwise (1.50m/1.50m flops)\n",
      "  model_71/batch_normalization_1919/FusedBatchNormV3 (1.31m/1.31m flops)\n",
      "  model_71/depthwise_conv2d_926/depthwise (1.25m/1.25m flops)\n",
      "  model_71/depthwise_conv2d_929/depthwise (1.14m/1.14m flops)\n",
      "  model_71/batch_normalization_1918/FusedBatchNormV3 (1.05m/1.05m flops)\n",
      "  model_71/batch_normalization_1917/FusedBatchNormV3 (1.05m/1.05m flops)\n",
      "  model_71/depthwise_conv2d_928/depthwise (1.04m/1.04m flops)\n",
      "  model_71/conv2d_995/BiasAdd (655.36k/655.36k flops)\n",
      "  model_71/batch_normalization_1923/FusedBatchNormV3 (557.46k/557.46k flops)\n",
      "  model_71/depthwise_conv2d_923/BiasAdd (524.29k/524.29k flops)\n",
      "  model_71/conv2d_994/BiasAdd (524.29k/524.29k flops)\n",
      "  model_71/batch_normalization_1927/FusedBatchNormV3 (464.20k/464.20k flops)\n",
      "  model_71/batch_normalization_1922/FusedBatchNormV3 (459.09k/459.09k flops)\n",
      "  model_71/batch_normalization_1921/FusedBatchNormV3 (459.09k/459.09k flops)\n",
      "  model_71/batch_normalization_1925/FusedBatchNormV3 (431.34k/431.34k flops)\n",
      "  model_71/batch_normalization_1926/FusedBatchNormV3 (431.34k/431.34k flops)\n",
      "  model_71/depthwise_conv2d_934/depthwise (357.12k/357.12k flops)\n",
      "  model_71/batch_normalization_1920/FusedBatchNormV3 (327.92k/327.92k flops)\n",
      "  model_71/conv2d_997/BiasAdd (278.53k/278.53k flops)\n",
      "  model_71/batch_normalization_1933/FusedBatchNormV3 (241.39k/241.39k flops)\n",
      "  model_71/batch_normalization_1934/FusedBatchNormV3 (241.39k/241.39k flops)\n",
      "  model_71/conv2d_999/BiasAdd (231.42k/231.42k flops)\n",
      "  model_71/depthwise_conv2d_925/BiasAdd (229.38k/229.38k flops)\n",
      "  model_71/conv2d_996/BiasAdd (229.38k/229.38k flops)\n",
      "  model_71/batch_normalization_1935/FusedBatchNormV3 (218.60k/218.60k flops)\n",
      "  model_71/batch_normalization_1936/FusedBatchNormV3 (218.60k/218.60k flops)\n",
      "  model_71/conv2d_998/BiasAdd (215.04k/215.04k flops)\n",
      "  model_71/depthwise_conv2d_927/BiasAdd (215.04k/215.04k flops)\n",
      "  model_71/batch_normalization_1932/FusedBatchNormV3 (175.08k/175.08k flops)\n",
      "  model_71/batch_normalization_1931/FusedBatchNormV3 (175.08k/175.08k flops)\n",
      "  model_71/batch_normalization_1937/FusedBatchNormV3 (168.87k/168.87k flops)\n",
      "  model_71/batch_normalization_1938/FusedBatchNormV3 (168.87k/168.87k flops)\n",
      "  model_71/depthwise_conv2d_924/BiasAdd (163.84k/163.84k flops)\n",
      "  model_71/depthwise_conv2d_935/depthwise (161.86k/161.86k flops)\n",
      "  model_71/batch_normalization_1939/FusedBatchNormV3 (160.58k/160.58k flops)\n",
      "  model_71/batch_normalization_1924/FusedBatchNormV3 (139.67k/139.67k flops)\n",
      "  model_71/batch_normalization_1930/FusedBatchNormV3 (128.46k/128.46k flops)\n",
      "  model_71/batch_normalization_1929/FusedBatchNormV3 (128.46k/128.46k flops)\n",
      "  model_71/conv2d_1002/BiasAdd (119.30k/119.30k flops)\n",
      "  model_71/depthwise_conv2d_931/BiasAdd (119.30k/119.30k flops)\n",
      "  model_71/batch_normalization_1928/FusedBatchNormV3 (117.07k/117.07k flops)\n",
      "  model_71/depthwise_conv2d_932/BiasAdd (108.03k/108.03k flops)\n",
      "  model_71/conv2d_1003/BiasAdd (108.03k/108.03k flops)\n",
      "  model_71/conv2d_1001/BiasAdd (86.53k/86.53k flops)\n",
      "  model_71/depthwise_conv2d_930/BiasAdd (86.53k/86.53k flops)\n",
      "  model_71/conv2d_1004/BiasAdd (83.46k/83.46k flops)\n",
      "  model_71/depthwise_conv2d_933/BiasAdd (83.46k/83.46k flops)\n",
      "  model_71/conv2d_1005/BiasAdd (79.36k/79.36k flops)\n",
      "  model_71/batch_normalization_1941/FusedBatchNormV3 (75.31k/75.31k flops)\n",
      "  model_71/depthwise_conv2d_926/BiasAdd (69.63k/69.63k flops)\n",
      "  model_71/conv2d_1000/BiasAdd (63.49k/63.49k flops)\n",
      "  model_71/depthwise_conv2d_929/BiasAdd (63.49k/63.49k flops)\n",
      "  model_71/depthwise_conv2d_928/BiasAdd (57.86k/57.86k flops)\n",
      "  model_71/batch_normalization_1940/FusedBatchNormV3 (41.54k/41.54k flops)\n",
      "  model_71/conv2d_1006/BiasAdd (35.97k/35.97k flops)\n",
      "  model_71/batch_normalization_1943/FusedBatchNormV3 (35.04k/35.04k flops)\n",
      "  model_71/batch_normalization_1942/FusedBatchNormV3 (21.36k/21.36k flops)\n",
      "  model_71/depthwise_conv2d_934/BiasAdd (19.84k/19.84k flops)\n",
      "  model_71/dense_71/MatMul (18.44k/18.44k flops)\n",
      "  model_71/global_average_pooling2d_71/Mean (14.75k/14.75k flops)\n",
      "  model_71/conv2d_1007/BiasAdd (14.75k/14.75k flops)\n",
      "  model_71/depthwise_conv2d_935/BiasAdd (8.99k/8.99k flops)\n",
      "  model_71/dense_71/Softmax (50/50 flops)\n",
      "  model_71/dense_71/BiasAdd (10/10 flops)\n",
      "\n",
      "======================End of Report==========================\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "63.838068\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-30 13:40:47.120154: I tensorflow/core/grappler/devices.cc:66] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0\n",
      "2022-04-30 13:40:47.120276: I tensorflow/core/grappler/clusters/single_machine.cc:357] Starting new session\n",
      "2022-04-30 13:40:47.124857: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:1137] Optimization results for grappler item: graph_to_optimize\n",
      "  function_optimizer: function_optimizer did nothing. time = 0.005ms.\n",
      "  function_optimizer: function_optimizer did nothing. time = 0.001ms.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=========================Options=============================\n",
      "-max_depth                  10000\n",
      "-min_bytes                  0\n",
      "-min_peak_bytes             0\n",
      "-min_residual_bytes         0\n",
      "-min_output_bytes           0\n",
      "-min_micros                 0\n",
      "-min_accelerator_micros     0\n",
      "-min_cpu_micros             0\n",
      "-min_params                 0\n",
      "-min_float_ops              1\n",
      "-min_occurrence             0\n",
      "-step                       -1\n",
      "-order_by                   float_ops\n",
      "-account_type_regexes       .*\n",
      "-start_name_regexes         .*\n",
      "-trim_name_regexes          \n",
      "-show_name_regexes          .*\n",
      "-hide_name_regexes          \n",
      "-account_displayed_op_only  true\n",
      "-select                     float_ops\n",
      "-output                     stdout:\n",
      "\n",
      "==================Model Analysis Report======================\n",
      "\n",
      "Doc:\n",
      "scope: The nodes in the model graph are organized by their names, which is hierarchical like filesystem.\n",
      "flops: Number of float operations. Note: Please read the implementation for the math behind it.\n",
      "\n",
      "Profile:\n",
      "node name | # float_ops\n",
      "_TFProfRoot (--/957.06m flops)\n",
      "  model_72/conv2d_1019/Conv2D (119.81m/119.81m flops)\n",
      "  model_72/conv2d_1018/Conv2D (115.97m/115.97m flops)\n",
      "  model_72/conv2d_1016/Conv2D (107.86m/107.86m flops)\n",
      "  model_72/conv2d_1015/Conv2D (104.25m/104.25m flops)\n",
      "  model_72/conv2d_1017/Conv2D (103.58m/103.58m flops)\n",
      "  model_72/conv2d_1011/Conv2D (67.83m/67.83m flops)\n",
      "  model_72/conv2d_1009/Conv2D (60.82m/60.82m flops)\n",
      "  model_72/conv2d_1013/Conv2D (45.71m/45.71m flops)\n",
      "  model_72/conv2d_1010/Conv2D (42.76m/42.76m flops)\n",
      "  model_72/conv2d_1020/Conv2D (40.83m/40.83m flops)\n",
      "  model_72/conv2d_1014/Conv2D (38.47m/38.47m flops)\n",
      "  model_72/conv2d_1012/Conv2D (22.61m/22.61m flops)\n",
      "  model_72/conv2d_1021/Conv2D (17.35m/17.35m flops)\n",
      "  model_72/conv2d_1008/Conv2D (16.78m/16.78m flops)\n",
      "  model_72/depthwise_conv2d_936/depthwise (9.44m/9.44m flops)\n",
      "  model_72/depthwise_conv2d_938/depthwise (6.64m/6.64m flops)\n",
      "  model_72/depthwise_conv2d_937/depthwise (4.28m/4.28m flops)\n",
      "  model_72/depthwise_conv2d_943/depthwise (2.32m/2.32m flops)\n",
      "  model_72/depthwise_conv2d_945/depthwise (2.23m/2.23m flops)\n",
      "  model_72/depthwise_conv2d_940/depthwise (2.21m/2.21m flops)\n",
      "  model_72/depthwise_conv2d_946/depthwise (2.16m/2.16m flops)\n",
      "  model_72/depthwise_conv2d_944/depthwise (1.93m/1.93m flops)\n",
      "  model_72/batch_normalization_1946/FusedBatchNormV3 (1.90m/1.90m flops)\n",
      "  model_72/depthwise_conv2d_942/depthwise (1.86m/1.86m flops)\n",
      "  model_72/depthwise_conv2d_939/depthwise (1.70m/1.70m flops)\n",
      "  model_72/batch_normalization_1945/FusedBatchNormV3 (1.05m/1.05m flops)\n",
      "  model_72/batch_normalization_1944/FusedBatchNormV3 (1.05m/1.05m flops)\n",
      "  model_72/conv2d_1009/BiasAdd (950.27k/950.27k flops)\n",
      "  model_72/depthwise_conv2d_941/depthwise (857.09k/857.09k flops)\n",
      "  model_72/batch_normalization_1950/FusedBatchNormV3 (754.22k/754.22k flops)\n",
      "  model_72/batch_normalization_1948/FusedBatchNormV3 (737.82k/737.82k flops)\n",
      "  model_72/batch_normalization_1949/FusedBatchNormV3 (737.82k/737.82k flops)\n",
      "  model_72/depthwise_conv2d_947/depthwise (576.00k/576.00k flops)\n",
      "  model_72/conv2d_1008/BiasAdd (524.29k/524.29k flops)\n",
      "  model_72/depthwise_conv2d_936/BiasAdd (524.29k/524.29k flops)\n",
      "  model_72/batch_normalization_1947/FusedBatchNormV3 (475.48k/475.48k flops)\n",
      "  model_72/batch_normalization_1954/FusedBatchNormV3 (382.04k/382.04k flops)\n",
      "  model_72/conv2d_1011/BiasAdd (376.83k/376.83k flops)\n",
      "  model_72/conv2d_1010/BiasAdd (368.64k/368.64k flops)\n",
      "  model_72/depthwise_conv2d_938/BiasAdd (368.64k/368.64k flops)\n",
      "  model_72/batch_normalization_1958/FusedBatchNormV3 (261.07k/261.07k flops)\n",
      "  model_72/batch_normalization_1959/FusedBatchNormV3 (261.07k/261.07k flops)\n",
      "  model_72/batch_normalization_1966/FusedBatchNormV3 (259.00k/259.00k flops)\n",
      "  model_72/batch_normalization_1963/FusedBatchNormV3 (250.71k/250.71k flops)\n",
      "  model_72/batch_normalization_1962/FusedBatchNormV3 (250.71k/250.71k flops)\n",
      "  model_72/batch_normalization_1953/FusedBatchNormV3 (246.48k/246.48k flops)\n",
      "  model_72/batch_normalization_1952/FusedBatchNormV3 (246.48k/246.48k flops)\n",
      "  model_72/batch_normalization_1965/FusedBatchNormV3 (242.42k/242.42k flops)\n",
      "  model_72/batch_normalization_1964/FusedBatchNormV3 (242.42k/242.42k flops)\n",
      "  model_72/depthwise_conv2d_937/BiasAdd (237.57k/237.57k flops)\n",
      "  model_72/batch_normalization_1960/FusedBatchNormV3 (216.52k/216.52k flops)\n",
      "  model_72/batch_normalization_1961/FusedBatchNormV3 (216.52k/216.52k flops)\n",
      "  model_72/batch_normalization_1957/FusedBatchNormV3 (209.27k/209.27k flops)\n",
      "  model_72/batch_normalization_1956/FusedBatchNormV3 (209.27k/209.27k flops)\n",
      "  model_72/conv2d_1013/BiasAdd (190.46k/190.46k flops)\n",
      "  model_72/batch_normalization_1951/FusedBatchNormV3 (188.97k/188.97k flops)\n",
      "  model_72/depthwise_conv2d_948/depthwise (183.74k/183.74k flops)\n",
      "  model_72/conv2d_1015/BiasAdd (129.02k/129.02k flops)\n",
      "  model_72/depthwise_conv2d_943/BiasAdd (129.02k/129.02k flops)\n",
      "  model_72/conv2d_1019/BiasAdd (128.00k/128.00k flops)\n",
      "  model_72/depthwise_conv2d_945/BiasAdd (123.90k/123.90k flops)\n",
      "  model_72/conv2d_1017/BiasAdd (123.90k/123.90k flops)\n",
      "  model_72/depthwise_conv2d_940/BiasAdd (122.88k/122.88k flops)\n",
      "  model_72/conv2d_1012/BiasAdd (122.88k/122.88k flops)\n",
      "  model_72/depthwise_conv2d_946/BiasAdd (119.81k/119.81k flops)\n",
      "  model_72/conv2d_1018/BiasAdd (119.81k/119.81k flops)\n",
      "  model_72/conv2d_1016/BiasAdd (107.01k/107.01k flops)\n",
      "  model_72/depthwise_conv2d_944/BiasAdd (107.01k/107.01k flops)\n",
      "  model_72/depthwise_conv2d_942/BiasAdd (103.42k/103.42k flops)\n",
      "  model_72/conv2d_1014/BiasAdd (103.42k/103.42k flops)\n",
      "  model_72/batch_normalization_1955/FusedBatchNormV3 (96.35k/96.35k flops)\n",
      "  model_72/depthwise_conv2d_939/BiasAdd (94.21k/94.21k flops)\n",
      "  model_72/batch_normalization_1968/FusedBatchNormV3 (85.49k/85.49k flops)\n",
      "  model_72/batch_normalization_1967/FusedBatchNormV3 (67.00k/67.00k flops)\n",
      "  model_72/depthwise_conv2d_941/BiasAdd (47.62k/47.62k flops)\n",
      "  model_72/conv2d_1020/BiasAdd (40.83k/40.83k flops)\n",
      "  model_72/batch_normalization_1970/FusedBatchNormV3 (32.30k/32.30k flops)\n",
      "  model_72/depthwise_conv2d_947/BiasAdd (32.00k/32.00k flops)\n",
      "  model_72/batch_normalization_1969/FusedBatchNormV3 (24.24k/24.24k flops)\n",
      "  model_72/dense_72/MatMul (17.00k/17.00k flops)\n",
      "  model_72/global_average_pooling2d_72/Mean (13.60k/13.60k flops)\n",
      "  model_72/conv2d_1021/BiasAdd (13.60k/13.60k flops)\n",
      "  model_72/depthwise_conv2d_948/BiasAdd (10.21k/10.21k flops)\n",
      "  model_72/dense_72/Softmax (50/50 flops)\n",
      "  model_72/dense_72/BiasAdd (10/10 flops)\n",
      "\n",
      "======================End of Report==========================\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "59.569908\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-30 13:40:48.051517: I tensorflow/core/grappler/devices.cc:66] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0\n",
      "2022-04-30 13:40:48.051633: I tensorflow/core/grappler/clusters/single_machine.cc:357] Starting new session\n",
      "2022-04-30 13:40:48.055851: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:1137] Optimization results for grappler item: graph_to_optimize\n",
      "  function_optimizer: function_optimizer did nothing. time = 0.005ms.\n",
      "  function_optimizer: function_optimizer did nothing. time = 0.001ms.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=========================Options=============================\n",
      "-max_depth                  10000\n",
      "-min_bytes                  0\n",
      "-min_peak_bytes             0\n",
      "-min_residual_bytes         0\n",
      "-min_output_bytes           0\n",
      "-min_micros                 0\n",
      "-min_accelerator_micros     0\n",
      "-min_cpu_micros             0\n",
      "-min_params                 0\n",
      "-min_float_ops              1\n",
      "-min_occurrence             0\n",
      "-step                       -1\n",
      "-order_by                   float_ops\n",
      "-account_type_regexes       .*\n",
      "-start_name_regexes         .*\n",
      "-trim_name_regexes          \n",
      "-show_name_regexes          .*\n",
      "-hide_name_regexes          \n",
      "-account_displayed_op_only  true\n",
      "-select                     float_ops\n",
      "-output                     stdout:\n",
      "\n",
      "==================Model Analysis Report======================\n",
      "\n",
      "Doc:\n",
      "scope: The nodes in the model graph are organized by their names, which is hierarchical like filesystem.\n",
      "flops: Number of float operations. Note: Please read the implementation for the math behind it.\n",
      "\n",
      "Profile:\n",
      "node name | # float_ops\n",
      "_TFProfRoot (--/732.28m flops)\n",
      "  model_73/conv2d_1027/Conv2D (96.34m/96.34m flops)\n",
      "  model_73/conv2d_1033/Conv2D (66.93m/66.93m flops)\n",
      "  model_73/conv2d_1030/Conv2D (65.03m/65.03m flops)\n",
      "  model_73/conv2d_1023/Conv2D (58.72m/58.72m flops)\n",
      "  model_73/conv2d_1031/Conv2D (56.51m/56.51m flops)\n",
      "  model_73/conv2d_1032/Conv2D (51.43m/51.43m flops)\n",
      "  model_73/conv2d_1029/Conv2D (50.23m/50.23m flops)\n",
      "  model_73/conv2d_1025/Conv2D (47.19m/47.19m flops)\n",
      "  model_73/conv2d_1034/Conv2D (45.43m/45.43m flops)\n",
      "  model_73/conv2d_1026/Conv2D (34.41m/34.41m flops)\n",
      "  model_73/conv2d_1028/Conv2D (33.49m/33.49m flops)\n",
      "  model_73/conv2d_1024/Conv2D (33.03m/33.03m flops)\n",
      "  model_73/conv2d_1035/Conv2D (28.27m/28.27m flops)\n",
      "  model_73/conv2d_1022/Conv2D (16.78m/16.78m flops)\n",
      "  model_73/depthwise_conv2d_949/depthwise (9.44m/9.44m flops)\n",
      "  model_73/depthwise_conv2d_951/depthwise (5.31m/5.31m flops)\n",
      "  model_73/depthwise_conv2d_950/depthwise (4.13m/4.13m flops)\n",
      "  model_73/depthwise_conv2d_953/depthwise (3.87m/3.87m flops)\n",
      "  model_73/batch_normalization_1973/FusedBatchNormV3 (1.84m/1.84m flops)\n",
      "  model_73/depthwise_conv2d_957/depthwise (1.74m/1.74m flops)\n",
      "  model_73/depthwise_conv2d_959/depthwise (1.59m/1.59m flops)\n",
      "  model_73/depthwise_conv2d_956/depthwise (1.55m/1.55m flops)\n",
      "  model_73/depthwise_conv2d_952/depthwise (1.47m/1.47m flops)\n",
      "  model_73/depthwise_conv2d_955/depthwise (1.35m/1.35m flops)\n",
      "  model_73/depthwise_conv2d_958/depthwise (1.35m/1.35m flops)\n",
      "  model_73/batch_normalization_1972/FusedBatchNormV3 (1.05m/1.05m flops)\n",
      "  model_73/batch_normalization_1971/FusedBatchNormV3 (1.05m/1.05m flops)\n",
      "  model_73/depthwise_conv2d_954/depthwise (1.03m/1.03m flops)\n",
      "  model_73/conv2d_1023/BiasAdd (917.50k/917.50k flops)\n",
      "  model_73/batch_normalization_1977/FusedBatchNormV3 (655.84k/655.84k flops)\n",
      "  model_73/batch_normalization_1975/FusedBatchNormV3 (590.26k/590.26k flops)\n",
      "  model_73/batch_normalization_1976/FusedBatchNormV3 (590.26k/590.26k flops)\n",
      "  model_73/conv2d_1022/BiasAdd (524.29k/524.29k flops)\n",
      "  model_73/depthwise_conv2d_949/BiasAdd (524.29k/524.29k flops)\n",
      "  model_73/batch_normalization_1981/FusedBatchNormV3 (460.10k/460.10k flops)\n",
      "  model_73/batch_normalization_1974/FusedBatchNormV3 (459.09k/459.09k flops)\n",
      "  model_73/depthwise_conv2d_960/depthwise (437.76k/437.76k flops)\n",
      "  model_73/batch_normalization_1979/FusedBatchNormV3 (431.34k/431.34k flops)\n",
      "  model_73/batch_normalization_1980/FusedBatchNormV3 (431.34k/431.34k flops)\n",
      "  model_73/conv2d_1025/BiasAdd (327.68k/327.68k flops)\n",
      "  model_73/conv2d_1024/BiasAdd (294.91k/294.91k flops)\n",
      "  model_73/depthwise_conv2d_951/BiasAdd (294.91k/294.91k flops)\n",
      "  model_73/depthwise_conv2d_961/depthwise (268.99k/268.99k flops)\n",
      "  model_73/depthwise_conv2d_950/BiasAdd (229.38k/229.38k flops)\n",
      "  model_73/conv2d_1027/BiasAdd (229.38k/229.38k flops)\n",
      "  model_73/depthwise_conv2d_953/BiasAdd (215.04k/215.04k flops)\n",
      "  model_73/conv2d_1026/BiasAdd (215.04k/215.04k flops)\n",
      "  model_73/batch_normalization_1993/FusedBatchNormV3 (196.84k/196.84k flops)\n",
      "  model_73/batch_normalization_1988/FusedBatchNormV3 (195.80k/195.80k flops)\n",
      "  model_73/batch_normalization_1987/FusedBatchNormV3 (195.80k/195.80k flops)\n",
      "  model_73/batch_normalization_1991/FusedBatchNormV3 (178.19k/178.19k flops)\n",
      "  model_73/batch_normalization_1992/FusedBatchNormV3 (178.19k/178.19k flops)\n",
      "  model_73/batch_normalization_1986/FusedBatchNormV3 (174.05k/174.05k flops)\n",
      "  model_73/batch_normalization_1985/FusedBatchNormV3 (174.05k/174.05k flops)\n",
      "  model_73/batch_normalization_1978/FusedBatchNormV3 (164.32k/164.32k flops)\n",
      "  model_73/batch_normalization_1984/FusedBatchNormV3 (151.26k/151.26k flops)\n",
      "  model_73/batch_normalization_1983/FusedBatchNormV3 (151.26k/151.26k flops)\n",
      "  model_73/batch_normalization_1989/FusedBatchNormV3 (151.26k/151.26k flops)\n",
      "  model_73/batch_normalization_1990/FusedBatchNormV3 (151.26k/151.26k flops)\n",
      "  model_73/batch_normalization_1995/FusedBatchNormV3 (125.16k/125.16k flops)\n",
      "  model_73/batch_normalization_1982/FusedBatchNormV3 (116.03k/116.03k flops)\n",
      "  model_73/conv2d_1033/BiasAdd (97.28k/97.28k flops)\n",
      "  model_73/conv2d_1030/BiasAdd (96.77k/96.77k flops)\n",
      "  model_73/depthwise_conv2d_957/BiasAdd (96.77k/96.77k flops)\n",
      "  model_73/depthwise_conv2d_959/BiasAdd (88.06k/88.06k flops)\n",
      "  model_73/conv2d_1032/BiasAdd (88.06k/88.06k flops)\n",
      "  model_73/depthwise_conv2d_956/BiasAdd (86.02k/86.02k flops)\n",
      "  model_73/conv2d_1029/BiasAdd (86.02k/86.02k flops)\n",
      "  model_73/depthwise_conv2d_952/BiasAdd (81.92k/81.92k flops)\n",
      "  model_73/depthwise_conv2d_958/BiasAdd (74.75k/74.75k flops)\n",
      "  model_73/depthwise_conv2d_955/BiasAdd (74.75k/74.75k flops)\n",
      "  model_73/conv2d_1031/BiasAdd (74.75k/74.75k flops)\n",
      "  model_73/conv2d_1028/BiasAdd (74.75k/74.75k flops)\n",
      "  model_73/conv2d_1034/BiasAdd (59.78k/59.78k flops)\n",
      "  model_73/depthwise_conv2d_954/BiasAdd (57.34k/57.34k flops)\n",
      "  model_73/batch_normalization_1994/FusedBatchNormV3 (50.92k/50.92k flops)\n",
      "  model_73/batch_normalization_1997/FusedBatchNormV3 (35.95k/35.95k flops)\n",
      "  model_73/batch_normalization_1996/FusedBatchNormV3 (35.49k/35.49k flops)\n",
      "  model_73/depthwise_conv2d_960/BiasAdd (24.32k/24.32k flops)\n",
      "  model_73/dense_73/MatMul (18.92k/18.92k flops)\n",
      "  model_73/global_average_pooling2d_73/Mean (15.14k/15.14k flops)\n",
      "  model_73/conv2d_1035/BiasAdd (15.14k/15.14k flops)\n",
      "  model_73/depthwise_conv2d_961/BiasAdd (14.94k/14.94k flops)\n",
      "  model_73/dense_73/Softmax (50/50 flops)\n",
      "  model_73/dense_73/BiasAdd (10/10 flops)\n",
      "\n",
      "======================End of Report==========================\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "60.177916\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-30 13:40:49.087133: I tensorflow/core/grappler/devices.cc:66] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0\n",
      "2022-04-30 13:40:49.087246: I tensorflow/core/grappler/clusters/single_machine.cc:357] Starting new session\n",
      "2022-04-30 13:40:49.091991: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:1137] Optimization results for grappler item: graph_to_optimize\n",
      "  function_optimizer: function_optimizer did nothing. time = 0.006ms.\n",
      "  function_optimizer: function_optimizer did nothing. time = 0ms.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=========================Options=============================\n",
      "-max_depth                  10000\n",
      "-min_bytes                  0\n",
      "-min_peak_bytes             0\n",
      "-min_residual_bytes         0\n",
      "-min_output_bytes           0\n",
      "-min_micros                 0\n",
      "-min_accelerator_micros     0\n",
      "-min_cpu_micros             0\n",
      "-min_params                 0\n",
      "-min_float_ops              1\n",
      "-min_occurrence             0\n",
      "-step                       -1\n",
      "-order_by                   float_ops\n",
      "-account_type_regexes       .*\n",
      "-start_name_regexes         .*\n",
      "-trim_name_regexes          \n",
      "-show_name_regexes          .*\n",
      "-hide_name_regexes          \n",
      "-account_displayed_op_only  true\n",
      "-select                     float_ops\n",
      "-output                     stdout:\n",
      "\n",
      "==================Model Analysis Report======================\n",
      "\n",
      "Doc:\n",
      "scope: The nodes in the model graph are organized by their names, which is hierarchical like filesystem.\n",
      "flops: Number of float operations. Note: Please read the implementation for the math behind it.\n",
      "\n",
      "Profile:\n",
      "node name | # float_ops\n",
      "_TFProfRoot (--/920.81m flops)\n",
      "  model_74/conv2d_1045/Conv2D (122.90m/122.90m flops)\n",
      "  model_74/conv2d_1046/Conv2D (111.17m/111.17m flops)\n",
      "  model_74/conv2d_1044/Conv2D (102.66m/102.66m flops)\n",
      "  model_74/conv2d_1047/Conv2D (93.31m/93.31m flops)\n",
      "  model_74/conv2d_1043/Conv2D (88.60m/88.60m flops)\n",
      "  model_74/conv2d_1039/Conv2D (72.09m/72.09m flops)\n",
      "  model_74/conv2d_1041/Conv2D (53.23m/53.23m flops)\n",
      "  model_74/conv2d_1042/Conv2D (48.56m/48.56m flops)\n",
      "  model_74/conv2d_1037/Conv2D (44.04m/44.04m flops)\n",
      "  model_74/conv2d_1048/Conv2D (42.16m/42.16m flops)\n",
      "  model_74/conv2d_1038/Conv2D (27.53m/27.53m flops)\n",
      "  model_74/conv2d_1040/Conv2D (25.68m/25.68m flops)\n",
      "  model_74/conv2d_1049/Conv2D (22.29m/22.29m flops)\n",
      "  model_74/conv2d_1036/Conv2D (16.78m/16.78m flops)\n",
      "  model_74/depthwise_conv2d_962/depthwise (9.44m/9.44m flops)\n",
      "  model_74/depthwise_conv2d_964/depthwise (5.90m/5.90m flops)\n",
      "  model_74/depthwise_conv2d_963/depthwise (3.10m/3.10m flops)\n",
      "  model_74/depthwise_conv2d_971/depthwise (2.29m/2.29m flops)\n",
      "  model_74/depthwise_conv2d_970/depthwise (2.22m/2.22m flops)\n",
      "  model_74/depthwise_conv2d_966/depthwise (2.10m/2.10m flops)\n",
      "  model_74/depthwise_conv2d_965/depthwise (2.03m/2.03m flops)\n",
      "  model_74/depthwise_conv2d_972/depthwise (2.01m/2.01m flops)\n",
      "  model_74/depthwise_conv2d_968/depthwise (1.92m/1.92m flops)\n",
      "  model_74/depthwise_conv2d_969/depthwise (1.92m/1.92m flops)\n",
      "  model_74/batch_normalization_2000/FusedBatchNormV3 (1.38m/1.38m flops)\n",
      "  model_74/depthwise_conv2d_967/depthwise (1.05m/1.05m flops)\n",
      "  model_74/batch_normalization_1999/FusedBatchNormV3 (1.05m/1.05m flops)\n",
      "  model_74/batch_normalization_1998/FusedBatchNormV3 (1.05m/1.05m flops)\n",
      "  model_74/batch_normalization_2004/FusedBatchNormV3 (901.78k/901.78k flops)\n",
      "  model_74/conv2d_1037/BiasAdd (688.13k/688.13k flops)\n",
      "  model_74/batch_normalization_2002/FusedBatchNormV3 (655.84k/655.84k flops)\n",
      "  model_74/batch_normalization_2003/FusedBatchNormV3 (655.84k/655.84k flops)\n",
      "  model_74/depthwise_conv2d_962/BiasAdd (524.29k/524.29k flops)\n",
      "  model_74/conv2d_1036/BiasAdd (524.29k/524.29k flops)\n",
      "  model_74/depthwise_conv2d_973/depthwise (481.54k/481.54k flops)\n",
      "  model_74/batch_normalization_2008/FusedBatchNormV3 (468.31k/468.31k flops)\n",
      "  model_74/conv2d_1039/BiasAdd (450.56k/450.56k flops)\n",
      "  model_74/batch_normalization_2001/FusedBatchNormV3 (344.32k/344.32k flops)\n",
      "  model_74/conv2d_1038/BiasAdd (327.68k/327.68k flops)\n",
      "  model_74/depthwise_conv2d_964/BiasAdd (327.68k/327.68k flops)\n",
      "  model_74/batch_normalization_2016/FusedBatchNormV3 (257.96k/257.96k flops)\n",
      "  model_74/batch_normalization_2017/FusedBatchNormV3 (257.96k/257.96k flops)\n",
      "  model_74/batch_normalization_2014/FusedBatchNormV3 (249.68k/249.68k flops)\n",
      "  model_74/batch_normalization_2015/FusedBatchNormV3 (249.68k/249.68k flops)\n",
      "  model_74/batch_normalization_2007/FusedBatchNormV3 (234.16k/234.16k flops)\n",
      "  model_74/batch_normalization_2006/FusedBatchNormV3 (234.16k/234.16k flops)\n",
      "  model_74/conv2d_1041/BiasAdd (233.47k/233.47k flops)\n",
      "  model_74/depthwise_conv2d_974/depthwise (226.94k/226.94k flops)\n",
      "  model_74/batch_normalization_2005/FusedBatchNormV3 (225.94k/225.94k flops)\n",
      "  model_74/batch_normalization_2019/FusedBatchNormV3 (225.85k/225.85k flops)\n",
      "  model_74/batch_normalization_2018/FusedBatchNormV3 (225.85k/225.85k flops)\n",
      "  model_74/batch_normalization_2020/FusedBatchNormV3 (216.52k/216.52k flops)\n",
      "  model_74/batch_normalization_2013/FusedBatchNormV3 (215.49k/215.49k flops)\n",
      "  model_74/batch_normalization_2012/FusedBatchNormV3 (215.49k/215.49k flops)\n",
      "  model_74/batch_normalization_2011/FusedBatchNormV3 (215.49k/215.49k flops)\n",
      "  model_74/batch_normalization_2010/FusedBatchNormV3 (215.49k/215.49k flops)\n",
      "  model_74/depthwise_conv2d_963/BiasAdd (172.03k/172.03k flops)\n",
      "  model_74/depthwise_conv2d_971/BiasAdd (127.49k/127.49k flops)\n",
      "  model_74/conv2d_1045/BiasAdd (127.49k/127.49k flops)\n",
      "  model_74/conv2d_1044/BiasAdd (123.39k/123.39k flops)\n",
      "  model_74/depthwise_conv2d_970/BiasAdd (123.39k/123.39k flops)\n",
      "  model_74/batch_normalization_2009/FusedBatchNormV3 (118.10k/118.10k flops)\n",
      "  model_74/conv2d_1040/BiasAdd (116.74k/116.74k flops)\n",
      "  model_74/depthwise_conv2d_966/BiasAdd (116.74k/116.74k flops)\n",
      "  model_74/depthwise_conv2d_965/BiasAdd (112.64k/112.64k flops)\n",
      "  model_74/depthwise_conv2d_972/BiasAdd (111.62k/111.62k flops)\n",
      "  model_74/conv2d_1046/BiasAdd (111.62k/111.62k flops)\n",
      "  model_74/conv2d_1047/BiasAdd (107.01k/107.01k flops)\n",
      "  model_74/conv2d_1042/BiasAdd (106.50k/106.50k flops)\n",
      "  model_74/depthwise_conv2d_968/BiasAdd (106.50k/106.50k flops)\n",
      "  model_74/conv2d_1043/BiasAdd (106.50k/106.50k flops)\n",
      "  model_74/depthwise_conv2d_969/BiasAdd (106.50k/106.50k flops)\n",
      "  model_74/batch_normalization_2022/FusedBatchNormV3 (105.59k/105.59k flops)\n",
      "  model_74/depthwise_conv2d_967/BiasAdd (58.37k/58.37k flops)\n",
      "  model_74/batch_normalization_2021/FusedBatchNormV3 (56.01k/56.01k flops)\n",
      "  model_74/conv2d_1048/BiasAdd (50.43k/50.43k flops)\n",
      "  model_74/batch_normalization_2024/FusedBatchNormV3 (33.59k/33.59k flops)\n",
      "  model_74/batch_normalization_2023/FusedBatchNormV3 (29.94k/29.94k flops)\n",
      "  model_74/depthwise_conv2d_973/BiasAdd (26.75k/26.75k flops)\n",
      "  model_74/dense_74/MatMul (17.68k/17.68k flops)\n",
      "  model_74/conv2d_1049/BiasAdd (14.14k/14.14k flops)\n",
      "  model_74/global_average_pooling2d_74/Mean (14.14k/14.14k flops)\n",
      "  model_74/depthwise_conv2d_974/BiasAdd (12.61k/12.61k flops)\n",
      "  model_74/dense_74/Softmax (50/50 flops)\n",
      "  model_74/dense_74/BiasAdd (10/10 flops)\n",
      "\n",
      "======================End of Report==========================\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "70.34118\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-30 13:40:50.030766: I tensorflow/core/grappler/devices.cc:66] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0\n",
      "2022-04-30 13:40:50.030887: I tensorflow/core/grappler/clusters/single_machine.cc:357] Starting new session\n",
      "2022-04-30 13:40:50.035099: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:1137] Optimization results for grappler item: graph_to_optimize\n",
      "  function_optimizer: function_optimizer did nothing. time = 0.005ms.\n",
      "  function_optimizer: function_optimizer did nothing. time = 0.001ms.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=========================Options=============================\n",
      "-max_depth                  10000\n",
      "-min_bytes                  0\n",
      "-min_peak_bytes             0\n",
      "-min_residual_bytes         0\n",
      "-min_output_bytes           0\n",
      "-min_micros                 0\n",
      "-min_accelerator_micros     0\n",
      "-min_cpu_micros             0\n",
      "-min_params                 0\n",
      "-min_float_ops              1\n",
      "-min_occurrence             0\n",
      "-step                       -1\n",
      "-order_by                   float_ops\n",
      "-account_type_regexes       .*\n",
      "-start_name_regexes         .*\n",
      "-trim_name_regexes          \n",
      "-show_name_regexes          .*\n",
      "-hide_name_regexes          \n",
      "-account_displayed_op_only  true\n",
      "-select                     float_ops\n",
      "-output                     stdout:\n",
      "\n",
      "==================Model Analysis Report======================\n",
      "\n",
      "Doc:\n",
      "scope: The nodes in the model graph are organized by their names, which is hierarchical like filesystem.\n",
      "flops: Number of float operations. Note: Please read the implementation for the math behind it.\n",
      "\n",
      "Profile:\n",
      "node name | # float_ops\n",
      "_TFProfRoot (--/1.21b flops)\n",
      "  model_75/conv2d_1061/Conv2D (132.13m/132.13m flops)\n",
      "  model_75/conv2d_1060/Conv2D (130.57m/130.57m flops)\n",
      "  model_75/conv2d_1058/Conv2D (124.90m/124.90m flops)\n",
      "  model_75/conv2d_1059/Conv2D (124.40m/124.40m flops)\n",
      "  model_75/conv2d_1057/Conv2D (124.38m/124.38m flops)\n",
      "  model_75/conv2d_1055/Conv2D (112.51m/112.51m flops)\n",
      "  model_75/conv2d_1053/Conv2D (109.71m/109.71m flops)\n",
      "  model_75/conv2d_1056/Conv2D (62.19m/62.19m flops)\n",
      "  model_75/conv2d_1054/Conv2D (55.36m/55.36m flops)\n",
      "  model_75/conv2d_1051/Conv2D (52.43m/52.43m flops)\n",
      "  model_75/conv2d_1052/Conv2D (44.24m/44.24m flops)\n",
      "  model_75/conv2d_1062/Conv2D (42.66m/42.66m flops)\n",
      "  model_75/conv2d_1063/Conv2D (20.24m/20.24m flops)\n",
      "  model_75/conv2d_1050/Conv2D (16.78m/16.78m flops)\n",
      "  model_75/depthwise_conv2d_975/depthwise (9.44m/9.44m flops)\n",
      "  model_75/depthwise_conv2d_977/depthwise (7.96m/7.96m flops)\n",
      "  model_75/depthwise_conv2d_979/depthwise (4.02m/4.02m flops)\n",
      "  model_75/depthwise_conv2d_976/depthwise (3.69m/3.69m flops)\n",
      "  model_75/depthwise_conv2d_985/depthwise (2.34m/2.34m flops)\n",
      "  model_75/depthwise_conv2d_982/depthwise (2.32m/2.32m flops)\n",
      "  model_75/depthwise_conv2d_984/depthwise (2.31m/2.31m flops)\n",
      "  model_75/depthwise_conv2d_978/depthwise (2.29m/2.29m flops)\n",
      "  model_75/depthwise_conv2d_983/depthwise (2.23m/2.23m flops)\n",
      "  model_75/depthwise_conv2d_981/depthwise (2.22m/2.22m flops)\n",
      "  model_75/batch_normalization_2027/FusedBatchNormV3 (1.64m/1.64m flops)\n",
      "  model_75/depthwise_conv2d_980/depthwise (1.16m/1.16m flops)\n",
      "  model_75/batch_normalization_2026/FusedBatchNormV3 (1.05m/1.05m flops)\n",
      "  model_75/batch_normalization_2025/FusedBatchNormV3 (1.05m/1.05m flops)\n",
      "  model_75/batch_normalization_2031/FusedBatchNormV3 (1.02m/1.02m flops)\n",
      "  model_75/batch_normalization_2029/FusedBatchNormV3 (885.38k/885.38k flops)\n",
      "  model_75/batch_normalization_2030/FusedBatchNormV3 (885.38k/885.38k flops)\n",
      "  model_75/conv2d_1051/BiasAdd (819.20k/819.20k flops)\n",
      "  model_75/depthwise_conv2d_986/depthwise (585.22k/585.22k flops)\n",
      "  model_75/depthwise_conv2d_975/BiasAdd (524.29k/524.29k flops)\n",
      "  model_75/conv2d_1050/BiasAdd (524.29k/524.29k flops)\n",
      "  model_75/batch_normalization_2035/FusedBatchNormV3 (517.61k/517.61k flops)\n",
      "  model_75/conv2d_1053/BiasAdd (507.90k/507.90k flops)\n",
      "  model_75/batch_normalization_2034/FusedBatchNormV3 (447.77k/447.77k flops)\n",
      "  model_75/batch_normalization_2033/FusedBatchNormV3 (447.77k/447.77k flops)\n",
      "  model_75/conv2d_1052/BiasAdd (442.37k/442.37k flops)\n",
      "  model_75/depthwise_conv2d_977/BiasAdd (442.37k/442.37k flops)\n",
      "  model_75/batch_normalization_2028/FusedBatchNormV3 (409.90k/409.90k flops)\n",
      "  model_75/batch_normalization_2047/FusedBatchNormV3 (263.14k/263.14k flops)\n",
      "  model_75/batch_normalization_2045/FusedBatchNormV3 (263.14k/263.14k flops)\n",
      "  model_75/batch_normalization_2046/FusedBatchNormV3 (263.14k/263.14k flops)\n",
      "  model_75/batch_normalization_2040/FusedBatchNormV3 (261.07k/261.07k flops)\n",
      "  model_75/batch_normalization_2039/FusedBatchNormV3 (261.07k/261.07k flops)\n",
      "  model_75/batch_normalization_2044/FusedBatchNormV3 (260.04k/260.04k flops)\n",
      "  model_75/batch_normalization_2043/FusedBatchNormV3 (260.04k/260.04k flops)\n",
      "  model_75/conv2d_1055/BiasAdd (258.05k/258.05k flops)\n",
      "  model_75/batch_normalization_2032/FusedBatchNormV3 (254.70k/254.70k flops)\n",
      "  model_75/batch_normalization_2042/FusedBatchNormV3 (250.71k/250.71k flops)\n",
      "  model_75/batch_normalization_2041/FusedBatchNormV3 (250.71k/250.71k flops)\n",
      "  model_75/batch_normalization_2038/FusedBatchNormV3 (249.68k/249.68k flops)\n",
      "  model_75/batch_normalization_2037/FusedBatchNormV3 (249.68k/249.68k flops)\n",
      "  model_75/depthwise_conv2d_979/BiasAdd (223.23k/223.23k flops)\n",
      "  model_75/conv2d_1054/BiasAdd (223.23k/223.23k flops)\n",
      "  model_75/depthwise_conv2d_976/BiasAdd (204.80k/204.80k flops)\n",
      "  model_75/depthwise_conv2d_987/depthwise (188.93k/188.93k flops)\n",
      "  model_75/batch_normalization_2036/FusedBatchNormV3 (130.54k/130.54k flops)\n",
      "  model_75/depthwise_conv2d_985/BiasAdd (130.05k/130.05k flops)\n",
      "  model_75/conv2d_1061/BiasAdd (130.05k/130.05k flops)\n",
      "  model_75/conv2d_1060/BiasAdd (130.05k/130.05k flops)\n",
      "  model_75/depthwise_conv2d_982/BiasAdd (129.02k/129.02k flops)\n",
      "  model_75/conv2d_1057/BiasAdd (129.02k/129.02k flops)\n",
      "  model_75/depthwise_conv2d_984/BiasAdd (128.51k/128.51k flops)\n",
      "  model_75/conv2d_1059/BiasAdd (128.51k/128.51k flops)\n",
      "  model_75/depthwise_conv2d_978/BiasAdd (126.98k/126.98k flops)\n",
      "  model_75/conv2d_1058/BiasAdd (123.90k/123.90k flops)\n",
      "  model_75/depthwise_conv2d_983/BiasAdd (123.90k/123.90k flops)\n",
      "  model_75/depthwise_conv2d_981/BiasAdd (123.39k/123.39k flops)\n",
      "  model_75/conv2d_1056/BiasAdd (123.39k/123.39k flops)\n",
      "  model_75/batch_normalization_2049/FusedBatchNormV3 (87.90k/87.90k flops)\n",
      "  model_75/batch_normalization_2048/FusedBatchNormV3 (68.07k/68.07k flops)\n",
      "  model_75/depthwise_conv2d_980/BiasAdd (64.51k/64.51k flops)\n",
      "  model_75/conv2d_1062/BiasAdd (41.98k/41.98k flops)\n",
      "  model_75/batch_normalization_2051/FusedBatchNormV3 (36.63k/36.63k flops)\n",
      "  model_75/depthwise_conv2d_986/BiasAdd (32.51k/32.51k flops)\n",
      "  model_75/batch_normalization_2050/FusedBatchNormV3 (24.93k/24.93k flops)\n",
      "  model_75/dense_75/MatMul (19.28k/19.28k flops)\n",
      "  model_75/conv2d_1063/BiasAdd (15.42k/15.42k flops)\n",
      "  model_75/global_average_pooling2d_75/Mean (15.42k/15.42k flops)\n",
      "  model_75/depthwise_conv2d_987/BiasAdd (10.50k/10.50k flops)\n",
      "  model_75/dense_75/Softmax (50/50 flops)\n",
      "  model_75/dense_75/BiasAdd (10/10 flops)\n",
      "\n",
      "======================End of Report==========================\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "52.57782\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-30 13:40:51.047024: I tensorflow/core/grappler/devices.cc:66] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0\n",
      "2022-04-30 13:40:51.047151: I tensorflow/core/grappler/clusters/single_machine.cc:357] Starting new session\n",
      "2022-04-30 13:40:51.051962: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:1137] Optimization results for grappler item: graph_to_optimize\n",
      "  function_optimizer: function_optimizer did nothing. time = 0.005ms.\n",
      "  function_optimizer: function_optimizer did nothing. time = 0.001ms.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=========================Options=============================\n",
      "-max_depth                  10000\n",
      "-min_bytes                  0\n",
      "-min_peak_bytes             0\n",
      "-min_residual_bytes         0\n",
      "-min_output_bytes           0\n",
      "-min_micros                 0\n",
      "-min_accelerator_micros     0\n",
      "-min_cpu_micros             0\n",
      "-min_params                 0\n",
      "-min_float_ops              1\n",
      "-min_occurrence             0\n",
      "-step                       -1\n",
      "-order_by                   float_ops\n",
      "-account_type_regexes       .*\n",
      "-start_name_regexes         .*\n",
      "-trim_name_regexes          \n",
      "-show_name_regexes          .*\n",
      "-hide_name_regexes          \n",
      "-account_displayed_op_only  true\n",
      "-select                     float_ops\n",
      "-output                     stdout:\n",
      "\n",
      "==================Model Analysis Report======================\n",
      "\n",
      "Doc:\n",
      "scope: The nodes in the model graph are organized by their names, which is hierarchical like filesystem.\n",
      "flops: Number of float operations. Note: Please read the implementation for the math behind it.\n",
      "\n",
      "Profile:\n",
      "node name | # float_ops\n",
      "_TFProfRoot (--/721.85m flops)\n",
      "  model_76/conv2d_1075/Conv2D (97.30m/97.30m flops)\n",
      "  model_76/conv2d_1072/Conv2D (95.05m/95.05m flops)\n",
      "  model_76/conv2d_1073/Conv2D (93.10m/93.10m flops)\n",
      "  model_76/conv2d_1074/Conv2D (86.84m/86.84m flops)\n",
      "  model_76/conv2d_1071/Conv2D (71.09m/71.09m flops)\n",
      "  model_76/conv2d_1065/Conv2D (46.14m/46.14m flops)\n",
      "  model_76/conv2d_1069/Conv2D (42.47m/42.47m flops)\n",
      "  model_76/conv2d_1070/Conv2D (29.53m/29.53m flops)\n",
      "  model_76/conv2d_1076/Conv2D (27.94m/27.94m flops)\n",
      "  model_76/conv2d_1067/Conv2D (24.71m/24.71m flops)\n",
      "  model_76/conv2d_1066/Conv2D (18.74m/18.74m flops)\n",
      "  model_76/conv2d_1064/Conv2D (16.78m/16.78m flops)\n",
      "  model_76/conv2d_1068/Conv2D (15.20m/15.20m flops)\n",
      "  model_76/conv2d_1077/Conv2D (12.99m/12.99m flops)\n",
      "  model_76/depthwise_conv2d_988/depthwise (9.44m/9.44m flops)\n",
      "  model_76/depthwise_conv2d_990/depthwise (3.83m/3.83m flops)\n",
      "  model_76/depthwise_conv2d_989/depthwise (3.24m/3.24m flops)\n",
      "  model_76/depthwise_conv2d_992/depthwise (2.36m/2.36m flops)\n",
      "  model_76/depthwise_conv2d_996/depthwise (2.19m/2.19m flops)\n",
      "  model_76/depthwise_conv2d_998/depthwise (2.05m/2.05m flops)\n",
      "  model_76/depthwise_conv2d_995/depthwise (1.80m/1.80m flops)\n",
      "  model_76/depthwise_conv2d_997/depthwise (1.76m/1.76m flops)\n",
      "  model_76/depthwise_conv2d_994/depthwise (1.64m/1.64m flops)\n",
      "  model_76/batch_normalization_2054/FusedBatchNormV3 (1.44m/1.44m flops)\n",
      "  model_76/depthwise_conv2d_991/depthwise (1.07m/1.07m flops)\n",
      "  model_76/batch_normalization_2053/FusedBatchNormV3 (1.05m/1.05m flops)\n",
      "  model_76/batch_normalization_2052/FusedBatchNormV3 (1.05m/1.05m flops)\n",
      "  model_76/depthwise_conv2d_993/depthwise (746.50k/746.50k flops)\n",
      "  model_76/conv2d_1065/BiasAdd (720.90k/720.90k flops)\n",
      "  model_76/conv2d_1064/BiasAdd (524.29k/524.29k flops)\n",
      "  model_76/depthwise_conv2d_988/BiasAdd (524.29k/524.29k flops)\n",
      "  model_76/depthwise_conv2d_999/depthwise (493.06k/493.06k flops)\n",
      "  model_76/batch_normalization_2058/FusedBatchNormV3 (475.48k/475.48k flops)\n",
      "  model_76/batch_normalization_2056/FusedBatchNormV3 (426.30k/426.30k flops)\n",
      "  model_76/batch_normalization_2057/FusedBatchNormV3 (426.30k/426.30k flops)\n",
      "  model_76/batch_normalization_2055/FusedBatchNormV3 (360.71k/360.71k flops)\n",
      "  model_76/batch_normalization_2062/FusedBatchNormV3 (332.75k/332.75k flops)\n",
      "  model_76/batch_normalization_2061/FusedBatchNormV3 (262.91k/262.91k flops)\n",
      "  model_76/batch_normalization_2060/FusedBatchNormV3 (262.91k/262.91k flops)\n",
      "  model_76/batch_normalization_2069/FusedBatchNormV3 (246.57k/246.57k flops)\n",
      "  model_76/batch_normalization_2068/FusedBatchNormV3 (246.57k/246.57k flops)\n",
      "  model_76/conv2d_1067/BiasAdd (237.57k/237.57k flops)\n",
      "  model_76/batch_normalization_2072/FusedBatchNormV3 (229.99k/229.99k flops)\n",
      "  model_76/batch_normalization_2073/FusedBatchNormV3 (229.99k/229.99k flops)\n",
      "  model_76/batch_normalization_2074/FusedBatchNormV3 (221.70k/221.70k flops)\n",
      "  model_76/conv2d_1066/BiasAdd (212.99k/212.99k flops)\n",
      "  model_76/depthwise_conv2d_990/BiasAdd (212.99k/212.99k flops)\n",
      "  model_76/batch_normalization_2067/FusedBatchNormV3 (202.02k/202.02k flops)\n",
      "  model_76/batch_normalization_2066/FusedBatchNormV3 (202.02k/202.02k flops)\n",
      "  model_76/batch_normalization_2070/FusedBatchNormV3 (197.88k/197.88k flops)\n",
      "  model_76/batch_normalization_2071/FusedBatchNormV3 (197.88k/197.88k flops)\n",
      "  model_76/batch_normalization_2065/FusedBatchNormV3 (184.41k/184.41k flops)\n",
      "  model_76/batch_normalization_2064/FusedBatchNormV3 (184.41k/184.41k flops)\n",
      "  model_76/depthwise_conv2d_989/BiasAdd (180.22k/180.22k flops)\n",
      "  model_76/conv2d_1069/BiasAdd (165.89k/165.89k flops)\n",
      "  model_76/depthwise_conv2d_1000/depthwise (146.88k/146.88k flops)\n",
      "  model_76/depthwise_conv2d_992/BiasAdd (131.07k/131.07k flops)\n",
      "  model_76/conv2d_1068/BiasAdd (131.07k/131.07k flops)\n",
      "  model_76/conv2d_1072/BiasAdd (121.86k/121.86k flops)\n",
      "  model_76/depthwise_conv2d_996/BiasAdd (121.86k/121.86k flops)\n",
      "  model_76/batch_normalization_2059/FusedBatchNormV3 (119.13k/119.13k flops)\n",
      "  model_76/depthwise_conv2d_998/BiasAdd (113.66k/113.66k flops)\n",
      "  model_76/conv2d_1074/BiasAdd (113.66k/113.66k flops)\n",
      "  model_76/conv2d_1075/BiasAdd (109.57k/109.57k flops)\n",
      "  model_76/conv2d_1071/BiasAdd (99.84k/99.84k flops)\n",
      "  model_76/depthwise_conv2d_995/BiasAdd (99.84k/99.84k flops)\n",
      "  model_76/depthwise_conv2d_997/BiasAdd (97.79k/97.79k flops)\n",
      "  model_76/conv2d_1073/BiasAdd (97.79k/97.79k flops)\n",
      "  model_76/depthwise_conv2d_994/BiasAdd (91.14k/91.14k flops)\n",
      "  model_76/conv2d_1070/BiasAdd (91.14k/91.14k flops)\n",
      "  model_76/batch_normalization_2063/FusedBatchNormV3 (83.92k/83.92k flops)\n",
      "  model_76/batch_normalization_2076/FusedBatchNormV3 (68.34k/68.34k flops)\n",
      "  model_76/depthwise_conv2d_991/BiasAdd (59.39k/59.39k flops)\n",
      "  model_76/batch_normalization_2075/FusedBatchNormV3 (57.35k/57.35k flops)\n",
      "  model_76/depthwise_conv2d_993/BiasAdd (41.47k/41.47k flops)\n",
      "  model_76/conv2d_1076/BiasAdd (32.64k/32.64k flops)\n",
      "  model_76/batch_normalization_2078/FusedBatchNormV3 (30.25k/30.25k flops)\n",
      "  model_76/depthwise_conv2d_999/BiasAdd (27.39k/27.39k flops)\n",
      "  model_76/batch_normalization_2077/FusedBatchNormV3 (19.38k/19.38k flops)\n",
      "  model_76/dense_76/MatMul (15.92k/15.92k flops)\n",
      "  model_76/global_average_pooling2d_76/Mean (12.74k/12.74k flops)\n",
      "  model_76/conv2d_1077/BiasAdd (12.74k/12.74k flops)\n",
      "  model_76/depthwise_conv2d_1000/BiasAdd (8.16k/8.16k flops)\n",
      "  model_76/dense_76/Softmax (50/50 flops)\n",
      "  model_76/dense_76/BiasAdd (10/10 flops)\n",
      "\n",
      "======================End of Report==========================\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "58.931668\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-30 13:40:51.971638: I tensorflow/core/grappler/devices.cc:66] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0\n",
      "2022-04-30 13:40:51.971754: I tensorflow/core/grappler/clusters/single_machine.cc:357] Starting new session\n",
      "2022-04-30 13:40:51.976047: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:1137] Optimization results for grappler item: graph_to_optimize\n",
      "  function_optimizer: function_optimizer did nothing. time = 0.005ms.\n",
      "  function_optimizer: function_optimizer did nothing. time = 0ms.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=========================Options=============================\n",
      "-max_depth                  10000\n",
      "-min_bytes                  0\n",
      "-min_peak_bytes             0\n",
      "-min_residual_bytes         0\n",
      "-min_output_bytes           0\n",
      "-min_micros                 0\n",
      "-min_accelerator_micros     0\n",
      "-min_cpu_micros             0\n",
      "-min_params                 0\n",
      "-min_float_ops              1\n",
      "-min_occurrence             0\n",
      "-step                       -1\n",
      "-order_by                   float_ops\n",
      "-account_type_regexes       .*\n",
      "-start_name_regexes         .*\n",
      "-trim_name_regexes          \n",
      "-show_name_regexes          .*\n",
      "-hide_name_regexes          \n",
      "-account_displayed_op_only  true\n",
      "-select                     float_ops\n",
      "-output                     stdout:\n",
      "\n",
      "==================Model Analysis Report======================\n",
      "\n",
      "Doc:\n",
      "scope: The nodes in the model graph are organized by their names, which is hierarchical like filesystem.\n",
      "flops: Number of float operations. Note: Please read the implementation for the math behind it.\n",
      "\n",
      "Profile:\n",
      "node name | # float_ops\n",
      "_TFProfRoot (--/908.99m flops)\n",
      "  model_77/conv2d_1089/Conv2D (116.17m/116.17m flops)\n",
      "  model_77/conv2d_1088/Conv2D (102.75m/102.75m flops)\n",
      "  model_77/conv2d_1083/Conv2D (99.75m/99.75m flops)\n",
      "  model_77/conv2d_1087/Conv2D (98.21m/98.21m flops)\n",
      "  model_77/conv2d_1086/Conv2D (78.30m/78.30m flops)\n",
      "  model_77/conv2d_1081/Conv2D (72.22m/72.22m flops)\n",
      "  model_77/conv2d_1085/Conv2D (60.90m/60.90m flops)\n",
      "  model_77/conv2d_1090/Conv2D (48.96m/48.96m flops)\n",
      "  model_77/conv2d_1082/Conv2D (47.04m/47.04m flops)\n",
      "  model_77/conv2d_1084/Conv2D (42.32m/42.32m flops)\n",
      "  model_77/conv2d_1079/Conv2D (33.55m/33.55m flops)\n",
      "  model_77/conv2d_1091/Conv2D (22.87m/22.87m flops)\n",
      "  model_77/conv2d_1080/Conv2D (19.92m/19.92m flops)\n",
      "  model_77/conv2d_1078/Conv2D (16.78m/16.78m flops)\n",
      "  model_77/depthwise_conv2d_1001/depthwise (9.44m/9.44m flops)\n",
      "  model_77/depthwise_conv2d_1003/depthwise (5.60m/5.60m flops)\n",
      "  model_77/depthwise_conv2d_1005/depthwise (3.65m/3.65m flops)\n",
      "  model_77/depthwise_conv2d_1002/depthwise (2.36m/2.36m flops)\n",
      "  model_77/depthwise_conv2d_1004/depthwise (2.14m/2.14m flops)\n",
      "  model_77/depthwise_conv2d_1011/depthwise (2.08m/2.08m flops)\n",
      "  model_77/depthwise_conv2d_1010/depthwise (2.05m/2.05m flops)\n",
      "  model_77/depthwise_conv2d_1009/depthwise (1.99m/1.99m flops)\n",
      "  model_77/depthwise_conv2d_1008/depthwise (1.63m/1.63m flops)\n",
      "  model_77/depthwise_conv2d_1007/depthwise (1.55m/1.55m flops)\n",
      "  model_77/depthwise_conv2d_1006/depthwise (1.13m/1.13m flops)\n",
      "  model_77/batch_normalization_2080/FusedBatchNormV3 (1.05m/1.05m flops)\n",
      "  model_77/batch_normalization_2081/FusedBatchNormV3 (1.05m/1.05m flops)\n",
      "  model_77/batch_normalization_2079/FusedBatchNormV3 (1.05m/1.05m flops)\n",
      "  model_77/batch_normalization_2085/FusedBatchNormV3 (950.97k/950.97k flops)\n",
      "  model_77/batch_normalization_2083/FusedBatchNormV3 (623.05k/623.05k flops)\n",
      "  model_77/batch_normalization_2084/FusedBatchNormV3 (623.05k/623.05k flops)\n",
      "  model_77/depthwise_conv2d_1012/depthwise (578.30k/578.30k flops)\n",
      "  model_77/conv2d_1078/BiasAdd (524.29k/524.29k flops)\n",
      "  model_77/depthwise_conv2d_1001/BiasAdd (524.29k/524.29k flops)\n",
      "  model_77/conv2d_1079/BiasAdd (524.29k/524.29k flops)\n",
      "  model_77/batch_normalization_2089/FusedBatchNormV3 (505.28k/505.28k flops)\n",
      "  model_77/conv2d_1081/BiasAdd (475.14k/475.14k flops)\n",
      "  model_77/batch_normalization_2088/FusedBatchNormV3 (406.69k/406.69k flops)\n",
      "  model_77/batch_normalization_2087/FusedBatchNormV3 (406.69k/406.69k flops)\n",
      "  model_77/conv2d_1080/BiasAdd (311.30k/311.30k flops)\n",
      "  model_77/depthwise_conv2d_1003/BiasAdd (311.30k/311.30k flops)\n",
      "  model_77/batch_normalization_2082/FusedBatchNormV3 (262.34k/262.34k flops)\n",
      "  model_77/batch_normalization_2101/FusedBatchNormV3 (260.04k/260.04k flops)\n",
      "  model_77/conv2d_1083/BiasAdd (251.90k/251.90k flops)\n",
      "  model_77/batch_normalization_2086/FusedBatchNormV3 (238.26k/238.26k flops)\n",
      "  model_77/batch_normalization_2099/FusedBatchNormV3 (234.14k/234.14k flops)\n",
      "  model_77/batch_normalization_2100/FusedBatchNormV3 (234.14k/234.14k flops)\n",
      "  model_77/batch_normalization_2097/FusedBatchNormV3 (229.99k/229.99k flops)\n",
      "  model_77/batch_normalization_2098/FusedBatchNormV3 (229.99k/229.99k flops)\n",
      "  model_77/batch_normalization_2096/FusedBatchNormV3 (223.78k/223.78k flops)\n",
      "  model_77/batch_normalization_2095/FusedBatchNormV3 (223.78k/223.78k flops)\n",
      "  model_77/depthwise_conv2d_1013/depthwise (219.46k/219.46k flops)\n",
      "  model_77/depthwise_conv2d_1005/BiasAdd (202.75k/202.75k flops)\n",
      "  model_77/conv2d_1082/BiasAdd (202.75k/202.75k flops)\n",
      "  model_77/batch_normalization_2093/FusedBatchNormV3 (183.37k/183.37k flops)\n",
      "  model_77/batch_normalization_2094/FusedBatchNormV3 (183.37k/183.37k flops)\n",
      "  model_77/batch_normalization_2091/FusedBatchNormV3 (174.05k/174.05k flops)\n",
      "  model_77/batch_normalization_2092/FusedBatchNormV3 (174.05k/174.05k flops)\n",
      "  model_77/depthwise_conv2d_1002/BiasAdd (131.07k/131.07k flops)\n",
      "  model_77/conv2d_1089/BiasAdd (128.51k/128.51k flops)\n",
      "  model_77/batch_normalization_2090/FusedBatchNormV3 (127.43k/127.43k flops)\n",
      "  model_77/depthwise_conv2d_1004/BiasAdd (118.78k/118.78k flops)\n",
      "  model_77/depthwise_conv2d_1011/BiasAdd (115.71k/115.71k flops)\n",
      "  model_77/conv2d_1088/BiasAdd (115.71k/115.71k flops)\n",
      "  model_77/depthwise_conv2d_1010/BiasAdd (113.66k/113.66k flops)\n",
      "  model_77/conv2d_1087/BiasAdd (113.66k/113.66k flops)\n",
      "  model_77/conv2d_1086/BiasAdd (110.59k/110.59k flops)\n",
      "  model_77/depthwise_conv2d_1009/BiasAdd (110.59k/110.59k flops)\n",
      "  model_77/batch_normalization_2103/FusedBatchNormV3 (102.11k/102.11k flops)\n",
      "  model_77/conv2d_1085/BiasAdd (90.62k/90.62k flops)\n",
      "  model_77/depthwise_conv2d_1008/BiasAdd (90.62k/90.62k flops)\n",
      "  model_77/depthwise_conv2d_1007/BiasAdd (86.02k/86.02k flops)\n",
      "  model_77/conv2d_1084/BiasAdd (86.02k/86.02k flops)\n",
      "  model_77/batch_normalization_2102/FusedBatchNormV3 (67.27k/67.27k flops)\n",
      "  model_77/depthwise_conv2d_1006/BiasAdd (62.98k/62.98k flops)\n",
      "  model_77/conv2d_1090/BiasAdd (48.77k/48.77k flops)\n",
      "  model_77/batch_normalization_2105/FusedBatchNormV3 (35.64k/35.64k flops)\n",
      "  model_77/depthwise_conv2d_1012/BiasAdd (32.13k/32.13k flops)\n",
      "  model_77/batch_normalization_2104/FusedBatchNormV3 (28.96k/28.96k flops)\n",
      "  model_77/dense_77/MatMul (18.76k/18.76k flops)\n",
      "  model_77/global_average_pooling2d_77/Mean (15.01k/15.01k flops)\n",
      "  model_77/conv2d_1091/BiasAdd (15.01k/15.01k flops)\n",
      "  model_77/depthwise_conv2d_1013/BiasAdd (12.19k/12.19k flops)\n",
      "  model_77/dense_77/Softmax (50/50 flops)\n",
      "  model_77/dense_77/BiasAdd (10/10 flops)\n",
      "\n",
      "======================End of Report==========================\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "64.006492\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-30 13:40:53.006357: I tensorflow/core/grappler/devices.cc:66] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0\n",
      "2022-04-30 13:40:53.006475: I tensorflow/core/grappler/clusters/single_machine.cc:357] Starting new session\n",
      "2022-04-30 13:40:53.011344: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:1137] Optimization results for grappler item: graph_to_optimize\n",
      "  function_optimizer: function_optimizer did nothing. time = 0.006ms.\n",
      "  function_optimizer: function_optimizer did nothing. time = 0.001ms.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=========================Options=============================\n",
      "-max_depth                  10000\n",
      "-min_bytes                  0\n",
      "-min_peak_bytes             0\n",
      "-min_residual_bytes         0\n",
      "-min_output_bytes           0\n",
      "-min_micros                 0\n",
      "-min_accelerator_micros     0\n",
      "-min_cpu_micros             0\n",
      "-min_params                 0\n",
      "-min_float_ops              1\n",
      "-min_occurrence             0\n",
      "-step                       -1\n",
      "-order_by                   float_ops\n",
      "-account_type_regexes       .*\n",
      "-start_name_regexes         .*\n",
      "-trim_name_regexes          \n",
      "-show_name_regexes          .*\n",
      "-hide_name_regexes          \n",
      "-account_displayed_op_only  true\n",
      "-select                     float_ops\n",
      "-output                     stdout:\n",
      "\n",
      "==================Model Analysis Report======================\n",
      "\n",
      "Doc:\n",
      "scope: The nodes in the model graph are organized by their names, which is hierarchical like filesystem.\n",
      "flops: Number of float operations. Note: Please read the implementation for the math behind it.\n",
      "\n",
      "Profile:\n",
      "node name | # float_ops\n",
      "_TFProfRoot (--/961.23m flops)\n",
      "  model_78/conv2d_1103/Conv2D (114.12m/114.12m flops)\n",
      "  model_78/conv2d_1102/Conv2D (95.93m/95.93m flops)\n",
      "  model_78/conv2d_1095/Conv2D (89.95m/89.95m flops)\n",
      "  model_78/conv2d_1097/Conv2D (89.14m/89.14m flops)\n",
      "  model_78/conv2d_1101/Conv2D (86.43m/86.43m flops)\n",
      "  model_78/conv2d_1099/Conv2D (85.61m/85.61m flops)\n",
      "  model_78/conv2d_1100/Conv2D (85.61m/85.61m flops)\n",
      "  model_78/conv2d_1093/Conv2D (48.23m/48.23m flops)\n",
      "  model_78/conv2d_1098/Conv2D (47.92m/47.92m flops)\n",
      "  model_78/conv2d_1096/Conv2D (46.47m/46.47m flops)\n",
      "  model_78/conv2d_1104/Conv2D (45.62m/45.62m flops)\n",
      "  model_78/conv2d_1094/Conv2D (33.91m/33.91m flops)\n",
      "  model_78/conv2d_1105/Conv2D (22.81m/22.81m flops)\n",
      "  model_78/conv2d_1092/Conv2D (16.78m/16.78m flops)\n",
      "  model_78/depthwise_conv2d_1014/depthwise (9.44m/9.44m flops)\n",
      "  model_78/depthwise_conv2d_1016/depthwise (6.64m/6.64m flops)\n",
      "  model_78/depthwise_conv2d_1018/depthwise (3.43m/3.43m flops)\n",
      "  model_78/depthwise_conv2d_1015/depthwise (3.39m/3.39m flops)\n",
      "  model_78/depthwise_conv2d_1017/depthwise (2.25m/2.25m flops)\n",
      "  model_78/depthwise_conv2d_1024/depthwise (2.05m/2.05m flops)\n",
      "  model_78/depthwise_conv2d_1023/depthwise (1.94m/1.94m flops)\n",
      "  model_78/depthwise_conv2d_1021/depthwise (1.93m/1.93m flops)\n",
      "  model_78/depthwise_conv2d_1020/depthwise (1.84m/1.84m flops)\n",
      "  model_78/depthwise_conv2d_1022/depthwise (1.84m/1.84m flops)\n",
      "  model_78/batch_normalization_2108/FusedBatchNormV3 (1.51m/1.51m flops)\n",
      "  model_78/depthwise_conv2d_1019/depthwise (1.08m/1.08m flops)\n",
      "  model_78/batch_normalization_2107/FusedBatchNormV3 (1.05m/1.05m flops)\n",
      "  model_78/batch_normalization_2106/FusedBatchNormV3 (1.05m/1.05m flops)\n",
      "  model_78/batch_normalization_2112/FusedBatchNormV3 (1.00m/1.00m flops)\n",
      "  model_78/conv2d_1093/BiasAdd (753.66k/753.66k flops)\n",
      "  model_78/batch_normalization_2111/FusedBatchNormV3 (737.82k/737.82k flops)\n",
      "  model_78/batch_normalization_2110/FusedBatchNormV3 (737.82k/737.82k flops)\n",
      "  model_78/depthwise_conv2d_1025/depthwise (578.30k/578.30k flops)\n",
      "  model_78/conv2d_1092/BiasAdd (524.29k/524.29k flops)\n",
      "  model_78/depthwise_conv2d_1014/BiasAdd (524.29k/524.29k flops)\n",
      "  model_78/conv2d_1095/BiasAdd (499.71k/499.71k flops)\n",
      "  model_78/batch_normalization_2116/FusedBatchNormV3 (480.64k/480.64k flops)\n",
      "  model_78/batch_normalization_2114/FusedBatchNormV3 (382.04k/382.04k flops)\n",
      "  model_78/batch_normalization_2115/FusedBatchNormV3 (382.04k/382.04k flops)\n",
      "  model_78/batch_normalization_2109/FusedBatchNormV3 (377.11k/377.11k flops)\n",
      "  model_78/conv2d_1094/BiasAdd (368.64k/368.64k flops)\n",
      "  model_78/depthwise_conv2d_1016/BiasAdd (368.64k/368.64k flops)\n",
      "  model_78/batch_normalization_2128/FusedBatchNormV3 (260.04k/260.04k flops)\n",
      "  model_78/batch_normalization_2113/FusedBatchNormV3 (250.59k/250.59k flops)\n",
      "  model_78/conv2d_1097/BiasAdd (239.62k/239.62k flops)\n",
      "  model_78/batch_normalization_2127/FusedBatchNormV3 (229.99k/229.99k flops)\n",
      "  model_78/batch_normalization_2126/FusedBatchNormV3 (229.99k/229.99k flops)\n",
      "  model_78/batch_normalization_2124/FusedBatchNormV3 (218.60k/218.60k flops)\n",
      "  model_78/batch_normalization_2125/FusedBatchNormV3 (218.60k/218.60k flops)\n",
      "  model_78/batch_normalization_2121/FusedBatchNormV3 (216.52k/216.52k flops)\n",
      "  model_78/batch_normalization_2120/FusedBatchNormV3 (216.52k/216.52k flops)\n",
      "  model_78/batch_normalization_2122/FusedBatchNormV3 (207.20k/207.20k flops)\n",
      "  model_78/batch_normalization_2118/FusedBatchNormV3 (207.20k/207.20k flops)\n",
      "  model_78/batch_normalization_2123/FusedBatchNormV3 (207.20k/207.20k flops)\n",
      "  model_78/batch_normalization_2119/FusedBatchNormV3 (207.20k/207.20k flops)\n",
      "  model_78/depthwise_conv2d_1026/depthwise (204.48k/204.48k flops)\n",
      "  model_78/conv2d_1096/BiasAdd (190.46k/190.46k flops)\n",
      "  model_78/depthwise_conv2d_1018/BiasAdd (190.46k/190.46k flops)\n",
      "  model_78/depthwise_conv2d_1015/BiasAdd (188.42k/188.42k flops)\n",
      "  model_78/conv2d_1103/BiasAdd (128.51k/128.51k flops)\n",
      "  model_78/depthwise_conv2d_1017/BiasAdd (124.93k/124.93k flops)\n",
      "  model_78/batch_normalization_2117/FusedBatchNormV3 (121.21k/121.21k flops)\n",
      "  model_78/depthwise_conv2d_1024/BiasAdd (113.66k/113.66k flops)\n",
      "  model_78/conv2d_1102/BiasAdd (113.66k/113.66k flops)\n",
      "  model_78/conv2d_1101/BiasAdd (108.03k/108.03k flops)\n",
      "  model_78/depthwise_conv2d_1023/BiasAdd (108.03k/108.03k flops)\n",
      "  model_78/conv2d_1099/BiasAdd (107.01k/107.01k flops)\n",
      "  model_78/depthwise_conv2d_1021/BiasAdd (107.01k/107.01k flops)\n",
      "  model_78/conv2d_1100/BiasAdd (102.40k/102.40k flops)\n",
      "  model_78/conv2d_1098/BiasAdd (102.40k/102.40k flops)\n",
      "  model_78/depthwise_conv2d_1020/BiasAdd (102.40k/102.40k flops)\n",
      "  model_78/depthwise_conv2d_1022/BiasAdd (102.40k/102.40k flops)\n",
      "  model_78/batch_normalization_2130/FusedBatchNormV3 (95.14k/95.14k flops)\n",
      "  model_78/batch_normalization_2129/FusedBatchNormV3 (67.27k/67.27k flops)\n",
      "  model_78/depthwise_conv2d_1019/BiasAdd (59.90k/59.90k flops)\n",
      "  model_78/conv2d_1104/BiasAdd (45.44k/45.44k flops)\n",
      "  model_78/batch_normalization_2132/FusedBatchNormV3 (38.15k/38.15k flops)\n",
      "  model_78/depthwise_conv2d_1025/BiasAdd (32.13k/32.13k flops)\n",
      "  model_78/batch_normalization_2131/FusedBatchNormV3 (26.98k/26.98k flops)\n",
      "  model_78/dense_78/MatMul (20.08k/20.08k flops)\n",
      "  model_78/conv2d_1105/BiasAdd (16.06k/16.06k flops)\n",
      "  model_78/global_average_pooling2d_78/Mean (16.06k/16.06k flops)\n",
      "  model_78/depthwise_conv2d_1026/BiasAdd (11.36k/11.36k flops)\n",
      "  model_78/dense_78/Softmax (50/50 flops)\n",
      "  model_78/dense_78/BiasAdd (10/10 flops)\n",
      "\n",
      "======================End of Report==========================\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "65.918292\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-30 13:40:53.945054: I tensorflow/core/grappler/devices.cc:66] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0\n",
      "2022-04-30 13:40:53.945169: I tensorflow/core/grappler/clusters/single_machine.cc:357] Starting new session\n",
      "2022-04-30 13:40:53.949410: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:1137] Optimization results for grappler item: graph_to_optimize\n",
      "  function_optimizer: function_optimizer did nothing. time = 0.005ms.\n",
      "  function_optimizer: function_optimizer did nothing. time = 0ms.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=========================Options=============================\n",
      "-max_depth                  10000\n",
      "-min_bytes                  0\n",
      "-min_peak_bytes             0\n",
      "-min_residual_bytes         0\n",
      "-min_output_bytes           0\n",
      "-min_micros                 0\n",
      "-min_accelerator_micros     0\n",
      "-min_cpu_micros             0\n",
      "-min_params                 0\n",
      "-min_float_ops              1\n",
      "-min_occurrence             0\n",
      "-step                       -1\n",
      "-order_by                   float_ops\n",
      "-account_type_regexes       .*\n",
      "-start_name_regexes         .*\n",
      "-trim_name_regexes          \n",
      "-show_name_regexes          .*\n",
      "-hide_name_regexes          \n",
      "-account_displayed_op_only  true\n",
      "-select                     float_ops\n",
      "-output                     stdout:\n",
      "\n",
      "==================Model Analysis Report======================\n",
      "\n",
      "Doc:\n",
      "scope: The nodes in the model graph are organized by their names, which is hierarchical like filesystem.\n",
      "flops: Number of float operations. Note: Please read the implementation for the math behind it.\n",
      "\n",
      "Profile:\n",
      "node name | # float_ops\n",
      "_TFProfRoot (--/958.20m flops)\n",
      "  model_79/conv2d_1117/Conv2D (106.30m/106.30m flops)\n",
      "  model_79/conv2d_1109/Conv2D (105.64m/105.64m flops)\n",
      "  model_79/conv2d_1114/Conv2D (88.60m/88.60m flops)\n",
      "  model_79/conv2d_1111/Conv2D (87.00m/87.00m flops)\n",
      "  model_79/conv2d_1116/Conv2D (85.56m/85.56m flops)\n",
      "  model_79/conv2d_1113/Conv2D (82.66m/82.66m flops)\n",
      "  model_79/conv2d_1115/Conv2D (78.67m/78.67m flops)\n",
      "  model_79/conv2d_1107/Conv2D (52.43m/52.43m flops)\n",
      "  model_79/conv2d_1118/Conv2D (47.36m/47.36m flops)\n",
      "  model_79/conv2d_1110/Conv2D (45.71m/45.71m flops)\n",
      "  model_79/conv2d_1112/Conv2D (43.74m/43.74m flops)\n",
      "  model_79/conv2d_1108/Conv2D (42.60m/42.60m flops)\n",
      "  model_79/conv2d_1119/Conv2D (21.03m/21.03m flops)\n",
      "  model_79/conv2d_1106/Conv2D (16.78m/16.78m flops)\n",
      "  model_79/depthwise_conv2d_1027/depthwise (9.44m/9.44m flops)\n",
      "  model_79/depthwise_conv2d_1029/depthwise (7.67m/7.67m flops)\n",
      "  model_79/depthwise_conv2d_1028/depthwise (3.69m/3.69m flops)\n",
      "  model_79/depthwise_conv2d_1031/depthwise (3.32m/3.32m flops)\n",
      "  model_79/depthwise_conv2d_1030/depthwise (2.29m/2.29m flops)\n",
      "  model_79/depthwise_conv2d_1034/depthwise (2.06m/2.06m flops)\n",
      "  model_79/depthwise_conv2d_1037/depthwise (1.94m/1.94m flops)\n",
      "  model_79/depthwise_conv2d_1036/depthwise (1.82m/1.82m flops)\n",
      "  model_79/depthwise_conv2d_1035/depthwise (1.79m/1.79m flops)\n",
      "  model_79/depthwise_conv2d_1033/depthwise (1.67m/1.67m flops)\n",
      "  model_79/batch_normalization_2135/FusedBatchNormV3 (1.64m/1.64m flops)\n",
      "  model_79/depthwise_conv2d_1032/depthwise (1.09m/1.09m flops)\n",
      "  model_79/batch_normalization_2134/FusedBatchNormV3 (1.05m/1.05m flops)\n",
      "  model_79/batch_normalization_2133/FusedBatchNormV3 (1.05m/1.05m flops)\n",
      "  model_79/batch_normalization_2139/FusedBatchNormV3 (1.02m/1.02m flops)\n",
      "  model_79/batch_normalization_2137/FusedBatchNormV3 (852.59k/852.59k flops)\n",
      "  model_79/batch_normalization_2138/FusedBatchNormV3 (852.59k/852.59k flops)\n",
      "  model_79/conv2d_1107/BiasAdd (819.20k/819.20k flops)\n",
      "  model_79/depthwise_conv2d_1038/depthwise (566.78k/566.78k flops)\n",
      "  model_79/conv2d_1106/BiasAdd (524.29k/524.29k flops)\n",
      "  model_79/depthwise_conv2d_1027/BiasAdd (524.29k/524.29k flops)\n",
      "  model_79/conv2d_1109/BiasAdd (507.90k/507.90k flops)\n",
      "  model_79/batch_normalization_2143/FusedBatchNormV3 (484.74k/484.74k flops)\n",
      "  model_79/conv2d_1108/BiasAdd (425.98k/425.98k flops)\n",
      "  model_79/depthwise_conv2d_1029/BiasAdd (425.98k/425.98k flops)\n",
      "  model_79/batch_normalization_2136/FusedBatchNormV3 (409.90k/409.90k flops)\n",
      "  model_79/batch_normalization_2141/FusedBatchNormV3 (369.72k/369.72k flops)\n",
      "  model_79/batch_normalization_2142/FusedBatchNormV3 (369.72k/369.72k flops)\n",
      "  model_79/batch_normalization_2155/FusedBatchNormV3 (254.86k/254.86k flops)\n",
      "  model_79/batch_normalization_2140/FusedBatchNormV3 (254.70k/254.70k flops)\n",
      "  model_79/conv2d_1111/BiasAdd (241.66k/241.66k flops)\n",
      "  model_79/batch_normalization_2147/FusedBatchNormV3 (231.03k/231.03k flops)\n",
      "  model_79/batch_normalization_2148/FusedBatchNormV3 (231.03k/231.03k flops)\n",
      "  model_79/batch_normalization_2153/FusedBatchNormV3 (218.60k/218.60k flops)\n",
      "  model_79/batch_normalization_2154/FusedBatchNormV3 (218.60k/218.60k flops)\n",
      "  model_79/depthwise_conv2d_1039/depthwise (216.58k/216.58k flops)\n",
      "  model_79/batch_normalization_2152/FusedBatchNormV3 (205.13k/205.13k flops)\n",
      "  model_79/batch_normalization_2151/FusedBatchNormV3 (205.13k/205.13k flops)\n",
      "  model_79/depthwise_conv2d_1028/BiasAdd (204.80k/204.80k flops)\n",
      "  model_79/batch_normalization_2149/FusedBatchNormV3 (200.98k/200.98k flops)\n",
      "  model_79/batch_normalization_2150/FusedBatchNormV3 (200.98k/200.98k flops)\n",
      "  model_79/batch_normalization_2146/FusedBatchNormV3 (187.52k/187.52k flops)\n",
      "  model_79/batch_normalization_2145/FusedBatchNormV3 (187.52k/187.52k flops)\n",
      "  model_79/conv2d_1110/BiasAdd (184.32k/184.32k flops)\n",
      "  model_79/depthwise_conv2d_1031/BiasAdd (184.32k/184.32k flops)\n",
      "  model_79/depthwise_conv2d_1030/BiasAdd (126.98k/126.98k flops)\n",
      "  model_79/conv2d_1117/BiasAdd (125.95k/125.95k flops)\n",
      "  model_79/batch_normalization_2144/FusedBatchNormV3 (122.25k/122.25k flops)\n",
      "  model_79/depthwise_conv2d_1034/BiasAdd (114.18k/114.18k flops)\n",
      "  model_79/conv2d_1113/BiasAdd (114.18k/114.18k flops)\n",
      "  model_79/conv2d_1116/BiasAdd (108.03k/108.03k flops)\n",
      "  model_79/depthwise_conv2d_1037/BiasAdd (108.03k/108.03k flops)\n",
      "  model_79/conv2d_1115/BiasAdd (101.38k/101.38k flops)\n",
      "  model_79/depthwise_conv2d_1036/BiasAdd (101.38k/101.38k flops)\n",
      "  model_79/batch_normalization_2157/FusedBatchNormV3 (100.77k/100.77k flops)\n",
      "  model_79/conv2d_1114/BiasAdd (99.33k/99.33k flops)\n",
      "  model_79/depthwise_conv2d_1035/BiasAdd (99.33k/99.33k flops)\n",
      "  model_79/conv2d_1112/BiasAdd (92.67k/92.67k flops)\n",
      "  model_79/depthwise_conv2d_1033/BiasAdd (92.67k/92.67k flops)\n",
      "  model_79/batch_normalization_2156/FusedBatchNormV3 (65.93k/65.93k flops)\n",
      "  model_79/depthwise_conv2d_1032/BiasAdd (60.42k/60.42k flops)\n",
      "  model_79/conv2d_1118/BiasAdd (48.13k/48.13k flops)\n",
      "  model_79/batch_normalization_2159/FusedBatchNormV3 (33.21k/33.21k flops)\n",
      "  model_79/depthwise_conv2d_1038/BiasAdd (31.49k/31.49k flops)\n",
      "  model_79/batch_normalization_2158/FusedBatchNormV3 (28.58k/28.58k flops)\n",
      "  model_79/dense_79/MatMul (17.48k/17.48k flops)\n",
      "  model_79/conv2d_1119/BiasAdd (13.98k/13.98k flops)\n",
      "  model_79/global_average_pooling2d_79/Mean (13.98k/13.98k flops)\n",
      "  model_79/depthwise_conv2d_1039/BiasAdd (12.03k/12.03k flops)\n",
      "  model_79/dense_79/Softmax (50/50 flops)\n",
      "  model_79/dense_79/BiasAdd (10/10 flops)\n",
      "\n",
      "======================End of Report==========================\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "47.778484\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-30 13:40:54.869042: I tensorflow/core/grappler/devices.cc:66] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0\n",
      "2022-04-30 13:40:54.869154: I tensorflow/core/grappler/clusters/single_machine.cc:357] Starting new session\n",
      "2022-04-30 13:40:54.873246: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:1137] Optimization results for grappler item: graph_to_optimize\n",
      "  function_optimizer: function_optimizer did nothing. time = 0.004ms.\n",
      "  function_optimizer: function_optimizer did nothing. time = 0.001ms.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=========================Options=============================\n",
      "-max_depth                  10000\n",
      "-min_bytes                  0\n",
      "-min_peak_bytes             0\n",
      "-min_residual_bytes         0\n",
      "-min_output_bytes           0\n",
      "-min_micros                 0\n",
      "-min_accelerator_micros     0\n",
      "-min_cpu_micros             0\n",
      "-min_params                 0\n",
      "-min_float_ops              1\n",
      "-min_occurrence             0\n",
      "-step                       -1\n",
      "-order_by                   float_ops\n",
      "-account_type_regexes       .*\n",
      "-start_name_regexes         .*\n",
      "-trim_name_regexes          \n",
      "-show_name_regexes          .*\n",
      "-hide_name_regexes          \n",
      "-account_displayed_op_only  true\n",
      "-select                     float_ops\n",
      "-output                     stdout:\n",
      "\n",
      "==================Model Analysis Report======================\n",
      "\n",
      "Doc:\n",
      "scope: The nodes in the model graph are organized by their names, which is hierarchical like filesystem.\n",
      "flops: Number of float operations. Note: Please read the implementation for the math behind it.\n",
      "\n",
      "Profile:\n",
      "node name | # float_ops\n",
      "_TFProfRoot (--/463.88m flops)\n",
      "  model_80/conv2d_1121/Conv2D (48.23m/48.23m flops)\n",
      "  model_80/conv2d_1128/Conv2D (47.16m/47.16m flops)\n",
      "  model_80/conv2d_1127/Conv2D (43.43m/43.43m flops)\n",
      "  model_80/conv2d_1132/Conv2D (41.99m/41.99m flops)\n",
      "  model_80/conv2d_1131/Conv2D (39.52m/39.52m flops)\n",
      "  model_80/conv2d_1129/Conv2D (39.09m/39.09m flops)\n",
      "  model_80/conv2d_1130/Conv2D (37.16m/37.16m flops)\n",
      "  model_80/conv2d_1123/Conv2D (26.74m/26.74m flops)\n",
      "  model_80/conv2d_1133/Conv2D (25.12m/25.12m flops)\n",
      "  model_80/conv2d_1125/Conv2D (19.22m/19.22m flops)\n",
      "  model_80/conv2d_1122/Conv2D (18.09m/18.09m flops)\n",
      "  model_80/conv2d_1120/Conv2D (16.78m/16.78m flops)\n",
      "  model_80/conv2d_1126/Conv2D (13.14m/13.14m flops)\n",
      "  model_80/conv2d_1124/Conv2D (9.47m/9.47m flops)\n",
      "  model_80/depthwise_conv2d_1040/depthwise (9.44m/9.44m flops)\n",
      "  model_80/depthwise_conv2d_1042/depthwise (3.54m/3.54m flops)\n",
      "  model_80/depthwise_conv2d_1041/depthwise (3.39m/3.39m flops)\n",
      "  model_80/depthwise_conv2d_1047/depthwise (2.10m/2.10m flops)\n",
      "  model_80/depthwise_conv2d_1049/depthwise (1.74m/1.74m flops)\n",
      "  model_80/batch_normalization_2162/FusedBatchNormV3 (1.51m/1.51m flops)\n",
      "  model_80/depthwise_conv2d_1043/depthwise (1.25m/1.25m flops)\n",
      "  model_80/depthwise_conv2d_1044/depthwise (1.25m/1.25m flops)\n",
      "  model_80/batch_normalization_2161/FusedBatchNormV3 (1.05m/1.05m flops)\n",
      "  model_80/batch_normalization_2160/FusedBatchNormV3 (1.05m/1.05m flops)\n",
      "  model_80/depthwise_conv2d_1048/depthwise (930.82k/930.82k flops)\n",
      "  model_80/depthwise_conv2d_1050/depthwise (884.74k/884.74k flops)\n",
      "  model_80/depthwise_conv2d_1046/depthwise (857.09k/857.09k flops)\n",
      "  model_80/conv2d_1121/BiasAdd (753.66k/753.66k flops)\n",
      "  model_80/depthwise_conv2d_1045/depthwise (635.90k/635.90k flops)\n",
      "  model_80/batch_normalization_2166/FusedBatchNormV3 (557.46k/557.46k flops)\n",
      "  model_80/conv2d_1120/BiasAdd (524.29k/524.29k flops)\n",
      "  model_80/depthwise_conv2d_1040/BiasAdd (524.29k/524.29k flops)\n",
      "  model_80/depthwise_conv2d_1051/depthwise (463.10k/463.10k flops)\n",
      "  model_80/batch_normalization_2164/FusedBatchNormV3 (393.50k/393.50k flops)\n",
      "  model_80/batch_normalization_2165/FusedBatchNormV3 (393.50k/393.50k flops)\n",
      "  model_80/batch_normalization_2163/FusedBatchNormV3 (377.11k/377.11k flops)\n",
      "  model_80/batch_normalization_2170/FusedBatchNormV3 (283.45k/283.45k flops)\n",
      "  model_80/conv2d_1123/BiasAdd (278.53k/278.53k flops)\n",
      "  model_80/batch_normalization_2175/FusedBatchNormV3 (236.21k/236.21k flops)\n",
      "  model_80/batch_normalization_2174/FusedBatchNormV3 (236.21k/236.21k flops)\n",
      "  model_80/depthwise_conv2d_1052/depthwise (235.01k/235.01k flops)\n",
      "  model_80/batch_normalization_2182/FusedBatchNormV3 (208.24k/208.24k flops)\n",
      "  model_80/depthwise_conv2d_1042/BiasAdd (196.61k/196.61k flops)\n",
      "  model_80/conv2d_1122/BiasAdd (196.61k/196.61k flops)\n",
      "  model_80/batch_normalization_2178/FusedBatchNormV3 (195.80k/195.80k flops)\n",
      "  model_80/batch_normalization_2179/FusedBatchNormV3 (195.80k/195.80k flops)\n",
      "  model_80/depthwise_conv2d_1041/BiasAdd (188.42k/188.42k flops)\n",
      "  model_80/conv2d_1125/BiasAdd (141.31k/141.31k flops)\n",
      "  model_80/batch_normalization_2169/FusedBatchNormV3 (139.67k/139.67k flops)\n",
      "  model_80/batch_normalization_2168/FusedBatchNormV3 (139.67k/139.67k flops)\n",
      "  model_80/batch_normalization_2167/FusedBatchNormV3 (139.67k/139.67k flops)\n",
      "  model_80/conv2d_1127/BiasAdd (116.74k/116.74k flops)\n",
      "  model_80/depthwise_conv2d_1047/BiasAdd (116.74k/116.74k flops)\n",
      "  model_80/batch_normalization_2184/FusedBatchNormV3 (109.34k/109.34k flops)\n",
      "  model_80/batch_normalization_2177/FusedBatchNormV3 (104.64k/104.64k flops)\n",
      "  model_80/batch_normalization_2176/FusedBatchNormV3 (104.64k/104.64k flops)\n",
      "  model_80/conv2d_1131/BiasAdd (102.91k/102.91k flops)\n",
      "  model_80/batch_normalization_2181/FusedBatchNormV3 (99.46k/99.46k flops)\n",
      "  model_80/batch_normalization_2180/FusedBatchNormV3 (99.46k/99.46k flops)\n",
      "  model_80/depthwise_conv2d_1049/BiasAdd (96.77k/96.77k flops)\n",
      "  model_80/conv2d_1129/BiasAdd (96.77k/96.77k flops)\n",
      "  model_80/batch_normalization_2172/FusedBatchNormV3 (96.35k/96.35k flops)\n",
      "  model_80/batch_normalization_2173/FusedBatchNormV3 (96.35k/96.35k flops)\n",
      "  model_80/batch_normalization_2171/FusedBatchNormV3 (71.48k/71.48k flops)\n",
      "  model_80/depthwise_conv2d_1044/BiasAdd (69.63k/69.63k flops)\n",
      "  model_80/conv2d_1124/BiasAdd (69.63k/69.63k flops)\n",
      "  model_80/depthwise_conv2d_1043/BiasAdd (69.63k/69.63k flops)\n",
      "  model_80/batch_normalization_2183/FusedBatchNormV3 (53.87k/53.87k flops)\n",
      "  model_80/conv2d_1132/BiasAdd (52.22k/52.22k flops)\n",
      "  model_80/conv2d_1128/BiasAdd (51.71k/51.71k flops)\n",
      "  model_80/depthwise_conv2d_1048/BiasAdd (51.71k/51.71k flops)\n",
      "  model_80/conv2d_1130/BiasAdd (49.15k/49.15k flops)\n",
      "  model_80/depthwise_conv2d_1050/BiasAdd (49.15k/49.15k flops)\n",
      "  model_80/depthwise_conv2d_1046/BiasAdd (47.62k/47.62k flops)\n",
      "  model_80/conv2d_1126/BiasAdd (47.62k/47.62k flops)\n",
      "  model_80/batch_normalization_2186/FusedBatchNormV3 (36.56k/36.56k flops)\n",
      "  model_80/depthwise_conv2d_1045/BiasAdd (35.33k/35.33k flops)\n",
      "  model_80/batch_normalization_2185/FusedBatchNormV3 (31.01k/31.01k flops)\n",
      "  model_80/depthwise_conv2d_1051/BiasAdd (25.73k/25.73k flops)\n",
      "  model_80/dense_80/MatMul (19.24k/19.24k flops)\n",
      "  model_80/conv2d_1133/BiasAdd (15.39k/15.39k flops)\n",
      "  model_80/global_average_pooling2d_80/Mean (15.39k/15.39k flops)\n",
      "  model_80/depthwise_conv2d_1052/BiasAdd (13.06k/13.06k flops)\n",
      "  model_80/dense_80/Softmax (50/50 flops)\n",
      "  model_80/dense_80/BiasAdd (10/10 flops)\n",
      "\n",
      "======================End of Report==========================\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "75.350028\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-30 13:40:55.895950: I tensorflow/core/grappler/devices.cc:66] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0\n",
      "2022-04-30 13:40:55.896077: I tensorflow/core/grappler/clusters/single_machine.cc:357] Starting new session\n",
      "2022-04-30 13:40:55.900439: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:1137] Optimization results for grappler item: graph_to_optimize\n",
      "  function_optimizer: function_optimizer did nothing. time = 0.006ms.\n",
      "  function_optimizer: function_optimizer did nothing. time = 0ms.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=========================Options=============================\n",
      "-max_depth                  10000\n",
      "-min_bytes                  0\n",
      "-min_peak_bytes             0\n",
      "-min_residual_bytes         0\n",
      "-min_output_bytes           0\n",
      "-min_micros                 0\n",
      "-min_accelerator_micros     0\n",
      "-min_cpu_micros             0\n",
      "-min_params                 0\n",
      "-min_float_ops              1\n",
      "-min_occurrence             0\n",
      "-step                       -1\n",
      "-order_by                   float_ops\n",
      "-account_type_regexes       .*\n",
      "-start_name_regexes         .*\n",
      "-trim_name_regexes          \n",
      "-show_name_regexes          .*\n",
      "-hide_name_regexes          \n",
      "-account_displayed_op_only  true\n",
      "-select                     float_ops\n",
      "-output                     stdout:\n",
      "\n",
      "==================Model Analysis Report======================\n",
      "\n",
      "Doc:\n",
      "scope: The nodes in the model graph are organized by their names, which is hierarchical like filesystem.\n",
      "flops: Number of float operations. Note: Please read the implementation for the math behind it.\n",
      "\n",
      "Profile:\n",
      "node name | # float_ops\n",
      "_TFProfRoot (--/1.14b flops)\n",
      "  model_81/conv2d_1144/Conv2D (132.30m/132.30m flops)\n",
      "  model_81/conv2d_1143/Conv2D (129.29m/129.29m flops)\n",
      "  model_81/conv2d_1145/Conv2D (120.89m/120.89m flops)\n",
      "  model_81/conv2d_1142/Conv2D (108.11m/108.11m flops)\n",
      "  model_81/conv2d_1141/Conv2D (97.55m/97.55m flops)\n",
      "  model_81/conv2d_1139/Conv2D (91.35m/91.35m flops)\n",
      "  model_81/conv2d_1137/Conv2D (87.38m/87.38m flops)\n",
      "  model_81/conv2d_1146/Conv2D (61.27m/61.27m flops)\n",
      "  model_81/conv2d_1135/Conv2D (50.43m/50.43m flops)\n",
      "  model_81/conv2d_1140/Conv2D (49.78m/49.78m flops)\n",
      "  model_81/conv2d_1138/Conv2D (45.21m/45.21m flops)\n",
      "  model_81/conv2d_1147/Conv2D (43.53m/43.53m flops)\n",
      "  model_81/conv2d_1136/Conv2D (33.88m/33.88m flops)\n",
      "  model_81/conv2d_1134/Conv2D (21.23m/21.23m flops)\n",
      "  model_81/depthwise_conv2d_1053/depthwise (11.94m/11.94m flops)\n",
      "  model_81/depthwise_conv2d_1055/depthwise (8.02m/8.02m flops)\n",
      "  model_81/depthwise_conv2d_1057/depthwise (4.15m/4.15m flops)\n",
      "  model_81/depthwise_conv2d_1054/depthwise (3.55m/3.55m flops)\n",
      "  model_81/depthwise_conv2d_1062/depthwise (2.71m/2.71m flops)\n",
      "  model_81/depthwise_conv2d_1063/depthwise (2.57m/2.57m flops)\n",
      "  model_81/depthwise_conv2d_1061/depthwise (2.51m/2.51m flops)\n",
      "  model_81/depthwise_conv2d_1056/depthwise (2.29m/2.29m flops)\n",
      "  model_81/depthwise_conv2d_1059/depthwise (2.26m/2.26m flops)\n",
      "  model_81/depthwise_conv2d_1060/depthwise (2.26m/2.26m flops)\n",
      "  model_81/batch_normalization_2189/FusedBatchNormV3 (1.58m/1.58m flops)\n",
      "  model_81/batch_normalization_2188/FusedBatchNormV3 (1.33m/1.33m flops)\n",
      "  model_81/batch_normalization_2187/FusedBatchNormV3 (1.33m/1.33m flops)\n",
      "  model_81/depthwise_conv2d_1058/depthwise (1.15m/1.15m flops)\n",
      "  model_81/batch_normalization_2193/FusedBatchNormV3 (1.02m/1.02m flops)\n",
      "  model_81/batch_normalization_2191/FusedBatchNormV3 (892.16k/892.16k flops)\n",
      "  model_81/batch_normalization_2192/FusedBatchNormV3 (892.16k/892.16k flops)\n",
      "  model_81/conv2d_1135/BiasAdd (787.97k/787.97k flops)\n",
      "  model_81/conv2d_1134/BiasAdd (663.55k/663.55k flops)\n",
      "  model_81/depthwise_conv2d_1053/BiasAdd (663.55k/663.55k flops)\n",
      "  model_81/depthwise_conv2d_1064/depthwise (618.19k/618.19k flops)\n",
      "  model_81/batch_normalization_2197/FusedBatchNormV3 (514.40k/514.40k flops)\n",
      "  model_81/conv2d_1137/BiasAdd (508.03k/508.03k flops)\n",
      "  model_81/batch_normalization_2195/FusedBatchNormV3 (462.44k/462.44k flops)\n",
      "  model_81/batch_normalization_2196/FusedBatchNormV3 (462.44k/462.44k flops)\n",
      "  model_81/conv2d_1136/BiasAdd (445.82k/445.82k flops)\n",
      "  model_81/depthwise_conv2d_1055/BiasAdd (445.82k/445.82k flops)\n",
      "  model_81/depthwise_conv2d_1065/depthwise (401.40k/401.40k flops)\n",
      "  model_81/batch_normalization_2190/FusedBatchNormV3 (394.21k/394.21k flops)\n",
      "  model_81/batch_normalization_2206/FusedBatchNormV3 (303.46k/303.46k flops)\n",
      "  model_81/batch_normalization_2205/FusedBatchNormV3 (303.46k/303.46k flops)\n",
      "  model_81/batch_normalization_2208/FusedBatchNormV3 (287.76k/287.76k flops)\n",
      "  model_81/batch_normalization_2207/FusedBatchNormV3 (287.76k/287.76k flops)\n",
      "  model_81/batch_normalization_2203/FusedBatchNormV3 (281.22k/281.22k flops)\n",
      "  model_81/batch_normalization_2204/FusedBatchNormV3 (281.22k/281.22k flops)\n",
      "  model_81/batch_normalization_2209/FusedBatchNormV3 (277.30k/277.30k flops)\n",
      "  model_81/conv2d_1139/BiasAdd (256.61k/256.61k flops)\n",
      "  model_81/batch_normalization_2194/FusedBatchNormV3 (254.60k/254.60k flops)\n",
      "  model_81/batch_normalization_2202/FusedBatchNormV3 (253.75k/253.75k flops)\n",
      "  model_81/batch_normalization_2201/FusedBatchNormV3 (253.75k/253.75k flops)\n",
      "  model_81/batch_normalization_2200/FusedBatchNormV3 (253.75k/253.75k flops)\n",
      "  model_81/batch_normalization_2199/FusedBatchNormV3 (253.75k/253.75k flops)\n",
      "  model_81/conv2d_1138/BiasAdd (230.69k/230.69k flops)\n",
      "  model_81/depthwise_conv2d_1057/BiasAdd (230.69k/230.69k flops)\n",
      "  model_81/depthwise_conv2d_1054/BiasAdd (196.99k/196.99k flops)\n",
      "  model_81/depthwise_conv2d_1062/BiasAdd (150.34k/150.34k flops)\n",
      "  model_81/conv2d_1143/BiasAdd (150.34k/150.34k flops)\n",
      "  model_81/batch_normalization_2211/FusedBatchNormV3 (149.86k/149.86k flops)\n",
      "  model_81/depthwise_conv2d_1063/BiasAdd (142.56k/142.56k flops)\n",
      "  model_81/conv2d_1144/BiasAdd (142.56k/142.56k flops)\n",
      "  model_81/depthwise_conv2d_1061/BiasAdd (139.32k/139.32k flops)\n",
      "  model_81/conv2d_1142/BiasAdd (139.32k/139.32k flops)\n",
      "  model_81/conv2d_1145/BiasAdd (137.38k/137.38k flops)\n",
      "  model_81/batch_normalization_2198/FusedBatchNormV3 (129.49k/129.49k flops)\n",
      "  model_81/depthwise_conv2d_1056/BiasAdd (127.01k/127.01k flops)\n",
      "  model_81/depthwise_conv2d_1059/BiasAdd (125.71k/125.71k flops)\n",
      "  model_81/conv2d_1140/BiasAdd (125.71k/125.71k flops)\n",
      "  model_81/depthwise_conv2d_1060/BiasAdd (125.71k/125.71k flops)\n",
      "  model_81/conv2d_1141/BiasAdd (125.71k/125.71k flops)\n",
      "  model_81/conv2d_1146/BiasAdd (72.25k/72.25k flops)\n",
      "  model_81/batch_normalization_2210/FusedBatchNormV3 (71.23k/71.23k flops)\n",
      "  model_81/depthwise_conv2d_1058/BiasAdd (64.15k/64.15k flops)\n",
      "  model_81/batch_normalization_2213/FusedBatchNormV3 (54.66k/54.66k flops)\n",
      "  model_81/batch_normalization_2212/FusedBatchNormV3 (49.95k/49.95k flops)\n",
      "  model_81/depthwise_conv2d_1064/BiasAdd (34.34k/34.34k flops)\n",
      "  model_81/global_average_pooling2d_81/Mean (24.40k/24.40k flops)\n",
      "  model_81/conv2d_1147/BiasAdd (24.40k/24.40k flops)\n",
      "  model_81/depthwise_conv2d_1065/BiasAdd (22.30k/22.30k flops)\n",
      "  model_81/dense_81/MatMul (19.52k/19.52k flops)\n",
      "  model_81/dense_81/Softmax (50/50 flops)\n",
      "  model_81/dense_81/BiasAdd (10/10 flops)\n",
      "\n",
      "======================End of Report==========================\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "79.316172\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-30 13:40:56.827789: I tensorflow/core/grappler/devices.cc:66] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0\n",
      "2022-04-30 13:40:56.827903: I tensorflow/core/grappler/clusters/single_machine.cc:357] Starting new session\n",
      "2022-04-30 13:40:56.831984: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:1137] Optimization results for grappler item: graph_to_optimize\n",
      "  function_optimizer: function_optimizer did nothing. time = 0.005ms.\n",
      "  function_optimizer: function_optimizer did nothing. time = 0ms.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=========================Options=============================\n",
      "-max_depth                  10000\n",
      "-min_bytes                  0\n",
      "-min_peak_bytes             0\n",
      "-min_residual_bytes         0\n",
      "-min_output_bytes           0\n",
      "-min_micros                 0\n",
      "-min_accelerator_micros     0\n",
      "-min_cpu_micros             0\n",
      "-min_params                 0\n",
      "-min_float_ops              1\n",
      "-min_occurrence             0\n",
      "-step                       -1\n",
      "-order_by                   float_ops\n",
      "-account_type_regexes       .*\n",
      "-start_name_regexes         .*\n",
      "-trim_name_regexes          \n",
      "-show_name_regexes          .*\n",
      "-hide_name_regexes          \n",
      "-account_displayed_op_only  true\n",
      "-select                     float_ops\n",
      "-output                     stdout:\n",
      "\n",
      "==================Model Analysis Report======================\n",
      "\n",
      "Doc:\n",
      "scope: The nodes in the model graph are organized by their names, which is hierarchical like filesystem.\n",
      "flops: Number of float operations. Note: Please read the implementation for the math behind it.\n",
      "\n",
      "Profile:\n",
      "node name | # float_ops\n",
      "_TFProfRoot (--/1.31b flops)\n",
      "  model_82/conv2d_1158/Conv2D (158.14m/158.14m flops)\n",
      "  model_82/conv2d_1159/Conv2D (154.93m/154.93m flops)\n",
      "  model_82/conv2d_1157/Conv2D (153.65m/153.65m flops)\n",
      "  model_82/conv2d_1156/Conv2D (145.57m/145.57m flops)\n",
      "  model_82/conv2d_1155/Conv2D (131.62m/131.62m flops)\n",
      "  model_82/conv2d_1151/Conv2D (93.56m/93.56m flops)\n",
      "  model_82/conv2d_1160/Conv2D (77.31m/77.31m flops)\n",
      "  model_82/conv2d_1153/Conv2D (68.84m/68.84m flops)\n",
      "  model_82/conv2d_1149/Conv2D (58.39m/58.39m flops)\n",
      "  model_82/conv2d_1161/Conv2D (49.60m/49.60m flops)\n",
      "  model_82/conv2d_1154/Conv2D (46.68m/46.68m flops)\n",
      "  model_82/conv2d_1150/Conv2D (42.88m/42.88m flops)\n",
      "  model_82/conv2d_1152/Conv2D (39.81m/39.81m flops)\n",
      "  model_82/conv2d_1148/Conv2D (21.23m/21.23m flops)\n",
      "  model_82/depthwise_conv2d_1066/depthwise (11.94m/11.94m flops)\n",
      "  model_82/depthwise_conv2d_1068/depthwise (8.77m/8.77m flops)\n",
      "  model_82/depthwise_conv2d_1067/depthwise (4.11m/4.11m flops)\n",
      "  model_82/depthwise_conv2d_1070/depthwise (3.73m/3.73m flops)\n",
      "  model_82/depthwise_conv2d_1075/depthwise (2.88m/2.88m flops)\n",
      "  model_82/depthwise_conv2d_1076/depthwise (2.88m/2.88m flops)\n",
      "  model_82/depthwise_conv2d_1074/depthwise (2.80m/2.80m flops)\n",
      "  model_82/depthwise_conv2d_1073/depthwise (2.73m/2.73m flops)\n",
      "  model_82/depthwise_conv2d_1072/depthwise (2.53m/2.53m flops)\n",
      "  model_82/depthwise_conv2d_1069/depthwise (2.24m/2.24m flops)\n",
      "  model_82/batch_normalization_2216/FusedBatchNormV3 (1.83m/1.83m flops)\n",
      "  model_82/batch_normalization_2215/FusedBatchNormV3 (1.33m/1.33m flops)\n",
      "  model_82/batch_normalization_2214/FusedBatchNormV3 (1.33m/1.33m flops)\n",
      "  model_82/batch_normalization_2220/FusedBatchNormV3 (995.90k/995.90k flops)\n",
      "  model_82/batch_normalization_2218/FusedBatchNormV3 (975.16k/975.16k flops)\n",
      "  model_82/batch_normalization_2219/FusedBatchNormV3 (975.16k/975.16k flops)\n",
      "  model_82/depthwise_conv2d_1071/depthwise (968.11k/968.11k flops)\n",
      "  model_82/conv2d_1149/BiasAdd (912.38k/912.38k flops)\n",
      "  model_82/depthwise_conv2d_1077/depthwise (705.67k/705.67k flops)\n",
      "  model_82/conv2d_1148/BiasAdd (663.55k/663.55k flops)\n",
      "  model_82/depthwise_conv2d_1066/BiasAdd (663.55k/663.55k flops)\n",
      "  model_82/conv2d_1151/BiasAdd (497.66k/497.66k flops)\n",
      "  model_82/depthwise_conv2d_1068/BiasAdd (487.30k/487.30k flops)\n",
      "  model_82/conv2d_1150/BiasAdd (487.30k/487.30k flops)\n",
      "  model_82/batch_normalization_2217/FusedBatchNormV3 (456.46k/456.46k flops)\n",
      "  model_82/depthwise_conv2d_1078/depthwise (443.70k/443.70k flops)\n",
      "  model_82/batch_normalization_2224/FusedBatchNormV3 (431.27k/431.27k flops)\n",
      "  model_82/batch_normalization_2222/FusedBatchNormV3 (415.68k/415.68k flops)\n",
      "  model_82/batch_normalization_2223/FusedBatchNormV3 (415.68k/415.68k flops)\n",
      "  model_82/batch_normalization_2232/FusedBatchNormV3 (323.08k/323.08k flops)\n",
      "  model_82/batch_normalization_2233/FusedBatchNormV3 (323.08k/323.08k flops)\n",
      "  model_82/batch_normalization_2234/FusedBatchNormV3 (323.08k/323.08k flops)\n",
      "  model_82/batch_normalization_2235/FusedBatchNormV3 (323.08k/323.08k flops)\n",
      "  model_82/batch_normalization_2236/FusedBatchNormV3 (316.54k/316.54k flops)\n",
      "  model_82/batch_normalization_2231/FusedBatchNormV3 (313.92k/313.92k flops)\n",
      "  model_82/batch_normalization_2230/FusedBatchNormV3 (313.92k/313.92k flops)\n",
      "  model_82/batch_normalization_2229/FusedBatchNormV3 (306.07k/306.07k flops)\n",
      "  model_82/batch_normalization_2228/FusedBatchNormV3 (306.07k/306.07k flops)\n",
      "  model_82/batch_normalization_2227/FusedBatchNormV3 (283.84k/283.84k flops)\n",
      "  model_82/batch_normalization_2226/FusedBatchNormV3 (283.84k/283.84k flops)\n",
      "  model_82/batch_normalization_2221/FusedBatchNormV3 (249.41k/249.41k flops)\n",
      "  model_82/depthwise_conv2d_1067/BiasAdd (228.10k/228.10k flops)\n",
      "  model_82/conv2d_1153/BiasAdd (215.14k/215.14k flops)\n",
      "  model_82/depthwise_conv2d_1070/BiasAdd (207.36k/207.36k flops)\n",
      "  model_82/conv2d_1152/BiasAdd (207.36k/207.36k flops)\n",
      "  model_82/batch_normalization_2238/FusedBatchNormV3 (165.65k/165.65k flops)\n",
      "  model_82/depthwise_conv2d_1076/BiasAdd (160.06k/160.06k flops)\n",
      "  model_82/depthwise_conv2d_1075/BiasAdd (160.06k/160.06k flops)\n",
      "  model_82/conv2d_1158/BiasAdd (160.06k/160.06k flops)\n",
      "  model_82/conv2d_1157/BiasAdd (160.06k/160.06k flops)\n",
      "  model_82/conv2d_1159/BiasAdd (156.82k/156.82k flops)\n",
      "  model_82/conv2d_1156/BiasAdd (155.52k/155.52k flops)\n",
      "  model_82/depthwise_conv2d_1074/BiasAdd (155.52k/155.52k flops)\n",
      "  model_82/conv2d_1155/BiasAdd (151.63k/151.63k flops)\n",
      "  model_82/depthwise_conv2d_1073/BiasAdd (151.63k/151.63k flops)\n",
      "  model_82/conv2d_1154/BiasAdd (140.62k/140.62k flops)\n",
      "  model_82/depthwise_conv2d_1072/BiasAdd (140.62k/140.62k flops)\n",
      "  model_82/depthwise_conv2d_1069/BiasAdd (124.42k/124.42k flops)\n",
      "  model_82/batch_normalization_2225/FusedBatchNormV3 (108.56k/108.56k flops)\n",
      "  model_82/batch_normalization_2237/FusedBatchNormV3 (81.31k/81.31k flops)\n",
      "  model_82/conv2d_1160/BiasAdd (79.87k/79.87k flops)\n",
      "  model_82/batch_normalization_2240/FusedBatchNormV3 (56.34k/56.34k flops)\n",
      "  model_82/batch_normalization_2239/FusedBatchNormV3 (55.22k/55.22k flops)\n",
      "  model_82/depthwise_conv2d_1071/BiasAdd (53.78k/53.78k flops)\n",
      "  model_82/depthwise_conv2d_1077/BiasAdd (39.20k/39.20k flops)\n",
      "  model_82/global_average_pooling2d_82/Mean (25.15k/25.15k flops)\n",
      "  model_82/conv2d_1161/BiasAdd (25.15k/25.15k flops)\n",
      "  model_82/depthwise_conv2d_1078/BiasAdd (24.65k/24.65k flops)\n",
      "  model_82/dense_82/MatMul (20.12k/20.12k flops)\n",
      "  model_82/dense_82/Softmax (50/50 flops)\n",
      "  model_82/dense_82/BiasAdd (10/10 flops)\n",
      "\n",
      "======================End of Report==========================\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "75.004372\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-30 13:40:57.877811: I tensorflow/core/grappler/devices.cc:66] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0\n",
      "2022-04-30 13:40:57.877928: I tensorflow/core/grappler/clusters/single_machine.cc:357] Starting new session\n",
      "2022-04-30 13:40:57.882682: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:1137] Optimization results for grappler item: graph_to_optimize\n",
      "  function_optimizer: function_optimizer did nothing. time = 0.005ms.\n",
      "  function_optimizer: function_optimizer did nothing. time = 0.001ms.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=========================Options=============================\n",
      "-max_depth                  10000\n",
      "-min_bytes                  0\n",
      "-min_peak_bytes             0\n",
      "-min_residual_bytes         0\n",
      "-min_output_bytes           0\n",
      "-min_micros                 0\n",
      "-min_accelerator_micros     0\n",
      "-min_cpu_micros             0\n",
      "-min_params                 0\n",
      "-min_float_ops              1\n",
      "-min_occurrence             0\n",
      "-step                       -1\n",
      "-order_by                   float_ops\n",
      "-account_type_regexes       .*\n",
      "-start_name_regexes         .*\n",
      "-trim_name_regexes          \n",
      "-show_name_regexes          .*\n",
      "-hide_name_regexes          \n",
      "-account_displayed_op_only  true\n",
      "-select                     float_ops\n",
      "-output                     stdout:\n",
      "\n",
      "==================Model Analysis Report======================\n",
      "\n",
      "Doc:\n",
      "scope: The nodes in the model graph are organized by their names, which is hierarchical like filesystem.\n",
      "flops: Number of float operations. Note: Please read the implementation for the math behind it.\n",
      "\n",
      "Profile:\n",
      "node name | # float_ops\n",
      "_TFProfRoot (--/963.39m flops)\n",
      "  model_83/conv2d_1165/Conv2D (141.67m/141.67m flops)\n",
      "  model_83/conv2d_1170/Conv2D (117.81m/117.81m flops)\n",
      "  model_83/conv2d_1172/Conv2D (104.92m/104.92m flops)\n",
      "  model_83/conv2d_1171/Conv2D (96.34m/96.34m flops)\n",
      "  model_83/conv2d_1173/Conv2D (66.72m/66.72m flops)\n",
      "  model_83/conv2d_1169/Conv2D (59.49m/59.49m flops)\n",
      "  model_83/conv2d_1167/Conv2D (56.83m/56.83m flops)\n",
      "  model_83/conv2d_1163/Conv2D (47.78m/47.78m flops)\n",
      "  model_83/conv2d_1175/Conv2D (46.75m/46.75m flops)\n",
      "  model_83/conv2d_1164/Conv2D (41.80m/41.80m flops)\n",
      "  model_83/conv2d_1166/Conv2D (39.84m/39.84m flops)\n",
      "  model_83/conv2d_1174/Conv2D (36.16m/36.16m flops)\n",
      "  model_83/conv2d_1168/Conv2D (23.00m/23.00m flops)\n",
      "  model_83/conv2d_1162/Conv2D (21.23m/21.23m flops)\n",
      "  model_83/depthwise_conv2d_1079/depthwise (11.94m/11.94m flops)\n",
      "  model_83/depthwise_conv2d_1081/depthwise (10.45m/10.45m flops)\n",
      "  model_83/depthwise_conv2d_1080/depthwise (3.36m/3.36m flops)\n",
      "  model_83/depthwise_conv2d_1083/depthwise (2.94m/2.94m flops)\n",
      "  model_83/depthwise_conv2d_1082/depthwise (2.85m/2.85m flops)\n",
      "  model_83/depthwise_conv2d_1086/depthwise (2.62m/2.62m flops)\n",
      "  model_83/depthwise_conv2d_1089/depthwise (2.57m/2.57m flops)\n",
      "  model_83/depthwise_conv2d_1087/depthwise (2.36m/2.36m flops)\n",
      "  model_83/depthwise_conv2d_1088/depthwise (2.15m/2.15m flops)\n",
      "  model_83/batch_normalization_2243/FusedBatchNormV3 (1.49m/1.49m flops)\n",
      "  model_83/batch_normalization_2242/FusedBatchNormV3 (1.33m/1.33m flops)\n",
      "  model_83/batch_normalization_2241/FusedBatchNormV3 (1.33m/1.33m flops)\n",
      "  model_83/batch_normalization_2247/FusedBatchNormV3 (1.27m/1.27m flops)\n",
      "  model_83/depthwise_conv2d_1085/depthwise (1.19m/1.19m flops)\n",
      "  model_83/batch_normalization_2245/FusedBatchNormV3 (1.16m/1.16m flops)\n",
      "  model_83/batch_normalization_2246/FusedBatchNormV3 (1.16m/1.16m flops)\n",
      "  model_83/depthwise_conv2d_1084/depthwise (1.01m/1.01m flops)\n",
      "  model_83/conv2d_1163/BiasAdd (746.50k/746.50k flops)\n",
      "  model_83/conv2d_1162/BiasAdd (663.55k/663.55k flops)\n",
      "  model_83/depthwise_conv2d_1079/BiasAdd (663.55k/663.55k flops)\n",
      "  model_83/conv2d_1165/BiasAdd (632.45k/632.45k flops)\n",
      "  model_83/conv2d_1164/BiasAdd (580.61k/580.61k flops)\n",
      "  model_83/depthwise_conv2d_1081/BiasAdd (580.61k/580.61k flops)\n",
      "  model_83/batch_normalization_2251/FusedBatchNormV3 (452.05k/452.05k flops)\n",
      "  model_83/depthwise_conv2d_1091/depthwise (429.30k/429.30k flops)\n",
      "  model_83/batch_normalization_2244/FusedBatchNormV3 (373.46k/373.46k flops)\n",
      "  model_83/depthwise_conv2d_1090/depthwise (341.17k/341.17k flops)\n",
      "  model_83/batch_normalization_2249/FusedBatchNormV3 (327.35k/327.35k flops)\n",
      "  model_83/batch_normalization_2250/FusedBatchNormV3 (327.35k/327.35k flops)\n",
      "  model_83/batch_normalization_2248/FusedBatchNormV3 (316.96k/316.96k flops)\n",
      "  model_83/batch_normalization_2256/FusedBatchNormV3 (294.30k/294.30k flops)\n",
      "  model_83/batch_normalization_2255/FusedBatchNormV3 (294.30k/294.30k flops)\n",
      "  model_83/batch_normalization_2261/FusedBatchNormV3 (287.76k/287.76k flops)\n",
      "  model_83/batch_normalization_2262/FusedBatchNormV3 (287.76k/287.76k flops)\n",
      "  model_83/batch_normalization_2257/FusedBatchNormV3 (264.22k/264.22k flops)\n",
      "  model_83/batch_normalization_2258/FusedBatchNormV3 (264.22k/264.22k flops)\n",
      "  model_83/batch_normalization_2259/FusedBatchNormV3 (240.67k/240.67k flops)\n",
      "  model_83/batch_normalization_2260/FusedBatchNormV3 (240.67k/240.67k flops)\n",
      "  model_83/conv2d_1167/BiasAdd (225.50k/225.50k flops)\n",
      "  model_83/depthwise_conv2d_1080/BiasAdd (186.62k/186.62k flops)\n",
      "  model_83/depthwise_conv2d_1083/BiasAdd (163.30k/163.30k flops)\n",
      "  model_83/conv2d_1166/BiasAdd (163.30k/163.30k flops)\n",
      "  model_83/batch_normalization_2265/FusedBatchNormV3 (160.27k/160.27k flops)\n",
      "  model_83/depthwise_conv2d_1082/BiasAdd (158.11k/158.11k flops)\n",
      "  model_83/batch_normalization_2263/FusedBatchNormV3 (153.04k/153.04k flops)\n",
      "  model_83/depthwise_conv2d_1086/BiasAdd (145.80k/145.80k flops)\n",
      "  model_83/conv2d_1169/BiasAdd (145.80k/145.80k flops)\n",
      "  model_83/conv2d_1172/BiasAdd (142.56k/142.56k flops)\n",
      "  model_83/depthwise_conv2d_1089/BiasAdd (142.56k/142.56k flops)\n",
      "  model_83/batch_normalization_2253/FusedBatchNormV3 (133.42k/133.42k flops)\n",
      "  model_83/batch_normalization_2254/FusedBatchNormV3 (133.42k/133.42k flops)\n",
      "  model_83/conv2d_1170/BiasAdd (130.90k/130.90k flops)\n",
      "  model_83/depthwise_conv2d_1087/BiasAdd (130.90k/130.90k flops)\n",
      "  model_83/conv2d_1171/BiasAdd (119.23k/119.23k flops)\n",
      "  model_83/depthwise_conv2d_1088/BiasAdd (119.23k/119.23k flops)\n",
      "  model_83/batch_normalization_2252/FusedBatchNormV3 (113.80k/113.80k flops)\n",
      "  model_83/conv2d_1174/BiasAdd (77.27k/77.27k flops)\n",
      "  model_83/conv2d_1173/BiasAdd (75.82k/75.82k flops)\n",
      "  model_83/depthwise_conv2d_1085/BiasAdd (66.10k/66.10k flops)\n",
      "  model_83/conv2d_1168/BiasAdd (66.10k/66.10k flops)\n",
      "  model_83/depthwise_conv2d_1084/BiasAdd (56.38k/56.38k flops)\n",
      "  model_83/batch_normalization_2267/FusedBatchNormV3 (54.88k/54.88k flops)\n",
      "  model_83/batch_normalization_2266/FusedBatchNormV3 (53.42k/53.42k flops)\n",
      "  model_83/batch_normalization_2264/FusedBatchNormV3 (39.31k/39.31k flops)\n",
      "  model_83/global_average_pooling2d_83/Mean (24.50k/24.50k flops)\n",
      "  model_83/conv2d_1175/BiasAdd (24.50k/24.50k flops)\n",
      "  model_83/depthwise_conv2d_1091/BiasAdd (23.85k/23.85k flops)\n",
      "  model_83/dense_83/MatMul (19.60k/19.60k flops)\n",
      "  model_83/depthwise_conv2d_1090/BiasAdd (18.95k/18.95k flops)\n",
      "  model_83/dense_83/Softmax (50/50 flops)\n",
      "  model_83/dense_83/BiasAdd (10/10 flops)\n",
      "\n",
      "======================End of Report==========================\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "93.61486\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-30 13:40:58.826823: I tensorflow/core/grappler/devices.cc:66] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0\n",
      "2022-04-30 13:40:58.826940: I tensorflow/core/grappler/clusters/single_machine.cc:357] Starting new session\n",
      "2022-04-30 13:40:58.831098: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:1137] Optimization results for grappler item: graph_to_optimize\n",
      "  function_optimizer: function_optimizer did nothing. time = 0.005ms.\n",
      "  function_optimizer: function_optimizer did nothing. time = 0.001ms.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=========================Options=============================\n",
      "-max_depth                  10000\n",
      "-min_bytes                  0\n",
      "-min_peak_bytes             0\n",
      "-min_residual_bytes         0\n",
      "-min_output_bytes           0\n",
      "-min_micros                 0\n",
      "-min_accelerator_micros     0\n",
      "-min_cpu_micros             0\n",
      "-min_params                 0\n",
      "-min_float_ops              1\n",
      "-min_occurrence             0\n",
      "-step                       -1\n",
      "-order_by                   float_ops\n",
      "-account_type_regexes       .*\n",
      "-start_name_regexes         .*\n",
      "-trim_name_regexes          \n",
      "-show_name_regexes          .*\n",
      "-hide_name_regexes          \n",
      "-account_displayed_op_only  true\n",
      "-select                     float_ops\n",
      "-output                     stdout:\n",
      "\n",
      "==================Model Analysis Report======================\n",
      "\n",
      "Doc:\n",
      "scope: The nodes in the model graph are organized by their names, which is hierarchical like filesystem.\n",
      "flops: Number of float operations. Note: Please read the implementation for the math behind it.\n",
      "\n",
      "Profile:\n",
      "node name | # float_ops\n",
      "_TFProfRoot (--/1.54b flops)\n",
      "  model_84/conv2d_1187/Conv2D (161.99m/161.99m flops)\n",
      "  model_84/conv2d_1179/Conv2D (159.38m/159.38m flops)\n",
      "  model_84/conv2d_1181/Conv2D (159.38m/159.38m flops)\n",
      "  model_84/conv2d_1186/Conv2D (151.06m/151.06m flops)\n",
      "  model_84/conv2d_1184/Conv2D (127.12m/127.12m flops)\n",
      "  model_84/conv2d_1183/Conv2D (126.49m/126.49m flops)\n",
      "  model_84/conv2d_1185/Conv2D (122.43m/122.43m flops)\n",
      "  model_84/conv2d_1188/Conv2D (81.32m/81.32m flops)\n",
      "  model_84/conv2d_1180/Conv2D (79.69m/79.69m flops)\n",
      "  model_84/conv2d_1177/Conv2D (79.63m/79.63m flops)\n",
      "  model_84/conv2d_1178/Conv2D (75.89m/75.89m flops)\n",
      "  model_84/conv2d_1182/Conv2D (65.32m/65.32m flops)\n",
      "  model_84/conv2d_1189/Conv2D (49.70m/49.70m flops)\n",
      "  model_84/conv2d_1176/Conv2D (21.23m/21.23m flops)\n",
      "  model_84/depthwise_conv2d_1092/depthwise (11.94m/11.94m flops)\n",
      "  model_84/depthwise_conv2d_1094/depthwise (11.38m/11.38m flops)\n",
      "  model_84/depthwise_conv2d_1096/depthwise (5.69m/5.69m flops)\n",
      "  model_84/depthwise_conv2d_1093/depthwise (5.60m/5.60m flops)\n",
      "  model_84/depthwise_conv2d_1095/depthwise (2.94m/2.94m flops)\n",
      "  model_84/depthwise_conv2d_1102/depthwise (2.89m/2.89m flops)\n",
      "  model_84/depthwise_conv2d_1099/depthwise (2.85m/2.85m flops)\n",
      "  model_84/depthwise_conv2d_1101/depthwise (2.74m/2.74m flops)\n",
      "  model_84/batch_normalization_2270/FusedBatchNormV3 (2.49m/2.49m flops)\n",
      "  model_84/depthwise_conv2d_1100/depthwise (2.34m/2.34m flops)\n",
      "  model_84/depthwise_conv2d_1098/depthwise (2.33m/2.33m flops)\n",
      "  model_84/depthwise_conv2d_1097/depthwise (1.47m/1.47m flops)\n",
      "  model_84/batch_normalization_2269/FusedBatchNormV3 (1.33m/1.33m flops)\n",
      "  model_84/batch_normalization_2268/FusedBatchNormV3 (1.33m/1.33m flops)\n",
      "  model_84/batch_normalization_2274/FusedBatchNormV3 (1.31m/1.31m flops)\n",
      "  model_84/batch_normalization_2272/FusedBatchNormV3 (1.27m/1.27m flops)\n",
      "  model_84/batch_normalization_2273/FusedBatchNormV3 (1.27m/1.27m flops)\n",
      "  model_84/conv2d_1177/BiasAdd (1.24m/1.24m flops)\n",
      "  model_84/depthwise_conv2d_1103/depthwise (734.83k/734.83k flops)\n",
      "  model_84/conv2d_1176/BiasAdd (663.55k/663.55k flops)\n",
      "  model_84/depthwise_conv2d_1092/BiasAdd (663.55k/663.55k flops)\n",
      "  model_84/batch_normalization_2278/FusedBatchNormV3 (654.70k/654.70k flops)\n",
      "  model_84/conv2d_1179/BiasAdd (653.18k/653.18k flops)\n",
      "  model_84/batch_normalization_2276/FusedBatchNormV3 (633.91k/633.91k flops)\n",
      "  model_84/batch_normalization_2277/FusedBatchNormV3 (633.91k/633.91k flops)\n",
      "  model_84/depthwise_conv2d_1094/BiasAdd (632.45k/632.45k flops)\n",
      "  model_84/conv2d_1178/BiasAdd (632.45k/632.45k flops)\n",
      "  model_84/batch_normalization_2271/FusedBatchNormV3 (622.44k/622.44k flops)\n",
      "  model_84/depthwise_conv2d_1104/depthwise (448.20k/448.20k flops)\n",
      "  model_84/batch_normalization_2290/FusedBatchNormV3 (329.62k/329.62k flops)\n",
      "  model_84/batch_normalization_2275/FusedBatchNormV3 (327.35k/327.35k flops)\n",
      "  model_84/conv2d_1181/BiasAdd (326.59k/326.59k flops)\n",
      "  model_84/batch_normalization_2289/FusedBatchNormV3 (324.38k/324.38k flops)\n",
      "  model_84/batch_normalization_2288/FusedBatchNormV3 (324.38k/324.38k flops)\n",
      "  model_84/batch_normalization_2283/FusedBatchNormV3 (319.15k/319.15k flops)\n",
      "  model_84/batch_normalization_2282/FusedBatchNormV3 (319.15k/319.15k flops)\n",
      "  model_84/depthwise_conv2d_1096/BiasAdd (316.22k/316.22k flops)\n",
      "  model_84/conv2d_1180/BiasAdd (316.22k/316.22k flops)\n",
      "  model_84/depthwise_conv2d_1093/BiasAdd (311.04k/311.04k flops)\n",
      "  model_84/batch_normalization_2287/FusedBatchNormV3 (307.38k/307.38k flops)\n",
      "  model_84/batch_normalization_2286/FusedBatchNormV3 (307.38k/307.38k flops)\n",
      "  model_84/batch_normalization_2284/FusedBatchNormV3 (262.91k/262.91k flops)\n",
      "  model_84/batch_normalization_2285/FusedBatchNormV3 (262.91k/262.91k flops)\n",
      "  model_84/batch_normalization_2281/FusedBatchNormV3 (261.60k/261.60k flops)\n",
      "  model_84/batch_normalization_2280/FusedBatchNormV3 (261.60k/261.60k flops)\n",
      "  model_84/batch_normalization_2292/FusedBatchNormV3 (167.33k/167.33k flops)\n",
      "  model_84/batch_normalization_2279/FusedBatchNormV3 (164.81k/164.81k flops)\n",
      "  model_84/conv2d_1187/BiasAdd (163.30k/163.30k flops)\n",
      "  model_84/depthwise_conv2d_1095/BiasAdd (163.30k/163.30k flops)\n",
      "  model_84/depthwise_conv2d_1102/BiasAdd (160.70k/160.70k flops)\n",
      "  model_84/conv2d_1186/BiasAdd (160.70k/160.70k flops)\n",
      "  model_84/depthwise_conv2d_1099/BiasAdd (158.11k/158.11k flops)\n",
      "  model_84/conv2d_1183/BiasAdd (158.11k/158.11k flops)\n",
      "  model_84/depthwise_conv2d_1101/BiasAdd (152.28k/152.28k flops)\n",
      "  model_84/conv2d_1185/BiasAdd (152.28k/152.28k flops)\n",
      "  model_84/conv2d_1184/BiasAdd (130.25k/130.25k flops)\n",
      "  model_84/depthwise_conv2d_1100/BiasAdd (130.25k/130.25k flops)\n",
      "  model_84/depthwise_conv2d_1098/BiasAdd (129.60k/129.60k flops)\n",
      "  model_84/conv2d_1182/BiasAdd (129.60k/129.60k flops)\n",
      "  model_84/batch_normalization_2291/FusedBatchNormV3 (84.67k/84.67k flops)\n",
      "  model_84/depthwise_conv2d_1097/BiasAdd (81.65k/81.65k flops)\n",
      "  model_84/conv2d_1188/BiasAdd (80.68k/80.68k flops)\n",
      "  model_84/batch_normalization_2294/FusedBatchNormV3 (55.89k/55.89k flops)\n",
      "  model_84/batch_normalization_2293/FusedBatchNormV3 (55.78k/55.78k flops)\n",
      "  model_84/depthwise_conv2d_1103/BiasAdd (40.82k/40.82k flops)\n",
      "  model_84/global_average_pooling2d_84/Mean (24.95k/24.95k flops)\n",
      "  model_84/conv2d_1189/BiasAdd (24.95k/24.95k flops)\n",
      "  model_84/depthwise_conv2d_1104/BiasAdd (24.90k/24.90k flops)\n",
      "  model_84/dense_84/MatMul (19.96k/19.96k flops)\n",
      "  model_84/dense_84/Softmax (50/50 flops)\n",
      "  model_84/dense_84/BiasAdd (10/10 flops)\n",
      "\n",
      "======================End of Report==========================\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "79.443932\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-30 13:40:59.914739: I tensorflow/core/grappler/devices.cc:66] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0\n",
      "2022-04-30 13:40:59.914865: I tensorflow/core/grappler/clusters/single_machine.cc:357] Starting new session\n",
      "2022-04-30 13:40:59.919668: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:1137] Optimization results for grappler item: graph_to_optimize\n",
      "  function_optimizer: function_optimizer did nothing. time = 0.006ms.\n",
      "  function_optimizer: function_optimizer did nothing. time = 0.001ms.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=========================Options=============================\n",
      "-max_depth                  10000\n",
      "-min_bytes                  0\n",
      "-min_peak_bytes             0\n",
      "-min_residual_bytes         0\n",
      "-min_output_bytes           0\n",
      "-min_micros                 0\n",
      "-min_accelerator_micros     0\n",
      "-min_cpu_micros             0\n",
      "-min_params                 0\n",
      "-min_float_ops              1\n",
      "-min_occurrence             0\n",
      "-step                       -1\n",
      "-order_by                   float_ops\n",
      "-account_type_regexes       .*\n",
      "-start_name_regexes         .*\n",
      "-trim_name_regexes          \n",
      "-show_name_regexes          .*\n",
      "-hide_name_regexes          \n",
      "-account_displayed_op_only  true\n",
      "-select                     float_ops\n",
      "-output                     stdout:\n",
      "\n",
      "==================Model Analysis Report======================\n",
      "\n",
      "Doc:\n",
      "scope: The nodes in the model graph are organized by their names, which is hierarchical like filesystem.\n",
      "flops: Number of float operations. Note: Please read the implementation for the math behind it.\n",
      "\n",
      "Profile:\n",
      "node name | # float_ops\n",
      "_TFProfRoot (--/1.21b flops)\n",
      "  model_85/conv2d_1198/Conv2D (149.81m/149.81m flops)\n",
      "  model_85/conv2d_1201/Conv2D (146.45m/146.45m flops)\n",
      "  model_85/conv2d_1199/Conv2D (135.86m/135.86m flops)\n",
      "  model_85/conv2d_1197/Conv2D (131.89m/131.89m flops)\n",
      "  model_85/conv2d_1200/Conv2D (131.22m/131.22m flops)\n",
      "  model_85/conv2d_1193/Conv2D (87.92m/87.92m flops)\n",
      "  model_85/conv2d_1191/Conv2D (71.66m/71.66m flops)\n",
      "  model_85/conv2d_1195/Conv2D (56.40m/56.40m flops)\n",
      "  model_85/conv2d_1202/Conv2D (56.38m/56.38m flops)\n",
      "  model_85/conv2d_1196/Conv2D (45.39m/45.39m flops)\n",
      "  model_85/conv2d_1192/Conv2D (44.79m/44.79m flops)\n",
      "  model_85/conv2d_1194/Conv2D (35.17m/35.17m flops)\n",
      "  model_85/conv2d_1203/Conv2D (27.77m/27.77m flops)\n",
      "  model_85/conv2d_1190/Conv2D (21.23m/21.23m flops)\n",
      "  model_85/depthwise_conv2d_1105/depthwise (11.94m/11.94m flops)\n",
      "  model_85/depthwise_conv2d_1107/depthwise (7.46m/7.46m flops)\n",
      "  model_85/depthwise_conv2d_1106/depthwise (5.04m/5.04m flops)\n",
      "  model_85/depthwise_conv2d_1109/depthwise (2.99m/2.99m flops)\n",
      "  model_85/depthwise_conv2d_1112/depthwise (2.88m/2.88m flops)\n",
      "  model_85/depthwise_conv2d_1113/depthwise (2.73m/2.73m flops)\n",
      "  model_85/depthwise_conv2d_1115/depthwise (2.64m/2.64m flops)\n",
      "  model_85/depthwise_conv2d_1114/depthwise (2.61m/2.61m flops)\n",
      "  model_85/depthwise_conv2d_1108/depthwise (2.47m/2.47m flops)\n",
      "  model_85/depthwise_conv2d_1111/depthwise (2.40m/2.40m flops)\n",
      "  model_85/batch_normalization_2297/FusedBatchNormV3 (2.24m/2.24m flops)\n",
      "  model_85/batch_normalization_2296/FusedBatchNormV3 (1.33m/1.33m flops)\n",
      "  model_85/batch_normalization_2295/FusedBatchNormV3 (1.33m/1.33m flops)\n",
      "  model_85/conv2d_1191/BiasAdd (1.12m/1.12m flops)\n",
      "  model_85/batch_normalization_2301/FusedBatchNormV3 (1.10m/1.10m flops)\n",
      "  model_85/depthwise_conv2d_1110/depthwise (991.44k/991.44k flops)\n",
      "  model_85/batch_normalization_2299/FusedBatchNormV3 (829.92k/829.92k flops)\n",
      "  model_85/batch_normalization_2300/FusedBatchNormV3 (829.92k/829.92k flops)\n",
      "  model_85/depthwise_conv2d_1116/depthwise (729.00k/729.00k flops)\n",
      "  model_85/conv2d_1190/BiasAdd (663.55k/663.55k flops)\n",
      "  model_85/depthwise_conv2d_1105/BiasAdd (663.55k/663.55k flops)\n",
      "  model_85/batch_normalization_2298/FusedBatchNormV3 (560.20k/560.20k flops)\n",
      "  model_85/conv2d_1193/BiasAdd (549.50k/549.50k flops)\n",
      "  model_85/batch_normalization_2305/FusedBatchNormV3 (441.66k/441.66k flops)\n",
      "  model_85/conv2d_1192/BiasAdd (414.72k/414.72k flops)\n",
      "  model_85/depthwise_conv2d_1107/BiasAdd (414.72k/414.72k flops)\n",
      "  model_85/batch_normalization_2303/FusedBatchNormV3 (332.54k/332.54k flops)\n",
      "  model_85/batch_normalization_2304/FusedBatchNormV3 (332.54k/332.54k flops)\n",
      "  model_85/batch_normalization_2317/FusedBatchNormV3 (327.00k/327.00k flops)\n",
      "  model_85/batch_normalization_2310/FusedBatchNormV3 (323.08k/323.08k flops)\n",
      "  model_85/batch_normalization_2309/FusedBatchNormV3 (323.08k/323.08k flops)\n",
      "  model_85/depthwise_conv2d_1117/depthwise (313.20k/313.20k flops)\n",
      "  model_85/batch_normalization_2312/FusedBatchNormV3 (306.07k/306.07k flops)\n",
      "  model_85/batch_normalization_2311/FusedBatchNormV3 (306.07k/306.07k flops)\n",
      "  model_85/batch_normalization_2316/FusedBatchNormV3 (295.61k/295.61k flops)\n",
      "  model_85/batch_normalization_2315/FusedBatchNormV3 (295.61k/295.61k flops)\n",
      "  model_85/batch_normalization_2313/FusedBatchNormV3 (292.99k/292.99k flops)\n",
      "  model_85/batch_normalization_2314/FusedBatchNormV3 (292.99k/292.99k flops)\n",
      "  model_85/depthwise_conv2d_1106/BiasAdd (279.94k/279.94k flops)\n",
      "  model_85/batch_normalization_2302/FusedBatchNormV3 (275.39k/275.39k flops)\n",
      "  model_85/batch_normalization_2308/FusedBatchNormV3 (269.45k/269.45k flops)\n",
      "  model_85/batch_normalization_2307/FusedBatchNormV3 (269.45k/269.45k flops)\n",
      "  model_85/conv2d_1195/BiasAdd (220.32k/220.32k flops)\n",
      "  model_85/depthwise_conv2d_1109/BiasAdd (165.89k/165.89k flops)\n",
      "  model_85/conv2d_1194/BiasAdd (165.89k/165.89k flops)\n",
      "  model_85/conv2d_1201/BiasAdd (162.00k/162.00k flops)\n",
      "  model_85/depthwise_conv2d_1112/BiasAdd (160.06k/160.06k flops)\n",
      "  model_85/conv2d_1197/BiasAdd (160.06k/160.06k flops)\n",
      "  model_85/depthwise_conv2d_1113/BiasAdd (151.63k/151.63k flops)\n",
      "  model_85/conv2d_1198/BiasAdd (151.63k/151.63k flops)\n",
      "  model_85/depthwise_conv2d_1115/BiasAdd (146.45k/146.45k flops)\n",
      "  model_85/conv2d_1200/BiasAdd (146.45k/146.45k flops)\n",
      "  model_85/conv2d_1199/BiasAdd (145.15k/145.15k flops)\n",
      "  model_85/depthwise_conv2d_1114/BiasAdd (145.15k/145.15k flops)\n",
      "  model_85/depthwise_conv2d_1108/BiasAdd (137.38k/137.38k flops)\n",
      "  model_85/depthwise_conv2d_1111/BiasAdd (133.49k/133.49k flops)\n",
      "  model_85/conv2d_1196/BiasAdd (133.49k/133.49k flops)\n",
      "  model_85/batch_normalization_2319/FusedBatchNormV3 (116.93k/116.93k flops)\n",
      "  model_85/batch_normalization_2306/FusedBatchNormV3 (111.18k/111.18k flops)\n",
      "  model_85/batch_normalization_2318/FusedBatchNormV3 (84.00k/84.00k flops)\n",
      "  model_85/conv2d_1202/BiasAdd (56.38k/56.38k flops)\n",
      "  model_85/depthwise_conv2d_1110/BiasAdd (55.08k/55.08k flops)\n",
      "  model_85/batch_normalization_2321/FusedBatchNormV3 (44.69k/44.69k flops)\n",
      "  model_85/depthwise_conv2d_1116/BiasAdd (40.50k/40.50k flops)\n",
      "  model_85/batch_normalization_2320/FusedBatchNormV3 (38.98k/38.98k flops)\n",
      "  model_85/global_average_pooling2d_85/Mean (19.95k/19.95k flops)\n",
      "  model_85/conv2d_1203/BiasAdd (19.95k/19.95k flops)\n",
      "  model_85/depthwise_conv2d_1117/BiasAdd (17.40k/17.40k flops)\n",
      "  model_85/dense_85/MatMul (15.96k/15.96k flops)\n",
      "  model_85/dense_85/Softmax (50/50 flops)\n",
      "  model_85/dense_85/BiasAdd (10/10 flops)\n",
      "\n",
      "======================End of Report==========================\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "85.737364\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-30 13:41:00.848491: I tensorflow/core/grappler/devices.cc:66] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0\n",
      "2022-04-30 13:41:00.848610: I tensorflow/core/grappler/clusters/single_machine.cc:357] Starting new session\n",
      "2022-04-30 13:41:00.852906: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:1137] Optimization results for grappler item: graph_to_optimize\n",
      "  function_optimizer: function_optimizer did nothing. time = 0.005ms.\n",
      "  function_optimizer: function_optimizer did nothing. time = 0.001ms.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=========================Options=============================\n",
      "-max_depth                  10000\n",
      "-min_bytes                  0\n",
      "-min_peak_bytes             0\n",
      "-min_residual_bytes         0\n",
      "-min_output_bytes           0\n",
      "-min_micros                 0\n",
      "-min_accelerator_micros     0\n",
      "-min_cpu_micros             0\n",
      "-min_params                 0\n",
      "-min_float_ops              1\n",
      "-min_occurrence             0\n",
      "-step                       -1\n",
      "-order_by                   float_ops\n",
      "-account_type_regexes       .*\n",
      "-start_name_regexes         .*\n",
      "-trim_name_regexes          \n",
      "-show_name_regexes          .*\n",
      "-hide_name_regexes          \n",
      "-account_displayed_op_only  true\n",
      "-select                     float_ops\n",
      "-output                     stdout:\n",
      "\n",
      "==================Model Analysis Report======================\n",
      "\n",
      "Doc:\n",
      "scope: The nodes in the model graph are organized by their names, which is hierarchical like filesystem.\n",
      "flops: Number of float operations. Note: Please read the implementation for the math behind it.\n",
      "\n",
      "Profile:\n",
      "node name | # float_ops\n",
      "_TFProfRoot (--/1.32b flops)\n",
      "  model_86/conv2d_1214/Conv2D (147.93m/147.93m flops)\n",
      "  model_86/conv2d_1215/Conv2D (146.02m/146.02m flops)\n",
      "  model_86/conv2d_1213/Conv2D (136.51m/136.51m flops)\n",
      "  model_86/conv2d_1212/Conv2D (132.97m/132.97m flops)\n",
      "  model_86/conv2d_1211/Conv2D (131.80m/131.80m flops)\n",
      "  model_86/conv2d_1209/Conv2D (120.93m/120.93m flops)\n",
      "  model_86/conv2d_1207/Conv2D (87.59m/87.59m flops)\n",
      "  model_86/conv2d_1205/Conv2D (82.28m/82.28m flops)\n",
      "  model_86/conv2d_1210/Conv2D (62.99m/62.99m flops)\n",
      "  model_86/conv2d_1206/Conv2D (56.57m/56.57m flops)\n",
      "  model_86/conv2d_1208/Conv2D (53.75m/53.75m flops)\n",
      "  model_86/conv2d_1216/Conv2D (44.67m/44.67m flops)\n",
      "  model_86/conv2d_1217/Conv2D (22.45m/22.45m flops)\n",
      "  model_86/conv2d_1204/Conv2D (21.23m/21.23m flops)\n",
      "  model_86/depthwise_conv2d_1118/depthwise (11.94m/11.94m flops)\n",
      "  model_86/depthwise_conv2d_1120/depthwise (8.21m/8.21m flops)\n",
      "  model_86/depthwise_conv2d_1119/depthwise (5.79m/5.79m flops)\n",
      "  model_86/depthwise_conv2d_1122/depthwise (5.04m/5.04m flops)\n",
      "  model_86/depthwise_conv2d_1128/depthwise (2.87m/2.87m flops)\n",
      "  model_86/depthwise_conv2d_1127/depthwise (2.71m/2.71m flops)\n",
      "  model_86/depthwise_conv2d_1126/depthwise (2.65m/2.65m flops)\n",
      "  model_86/depthwise_conv2d_1125/depthwise (2.64m/2.64m flops)\n",
      "  model_86/depthwise_conv2d_1124/depthwise (2.62m/2.62m flops)\n",
      "  model_86/batch_normalization_2324/FusedBatchNormV3 (2.57m/2.57m flops)\n",
      "  model_86/depthwise_conv2d_1121/depthwise (2.24m/2.24m flops)\n",
      "  model_86/batch_normalization_2323/FusedBatchNormV3 (1.33m/1.33m flops)\n",
      "  model_86/batch_normalization_2322/FusedBatchNormV3 (1.33m/1.33m flops)\n",
      "  model_86/conv2d_1205/BiasAdd (1.29m/1.29m flops)\n",
      "  model_86/depthwise_conv2d_1123/depthwise (1.26m/1.26m flops)\n",
      "  model_86/batch_normalization_2328/FusedBatchNormV3 (995.90k/995.90k flops)\n",
      "  model_86/batch_normalization_2326/FusedBatchNormV3 (912.91k/912.91k flops)\n",
      "  model_86/batch_normalization_2327/FusedBatchNormV3 (912.91k/912.91k flops)\n",
      "  model_86/depthwise_conv2d_1129/depthwise (667.76k/667.76k flops)\n",
      "  model_86/conv2d_1204/BiasAdd (663.55k/663.55k flops)\n",
      "  model_86/depthwise_conv2d_1118/BiasAdd (663.55k/663.55k flops)\n",
      "  model_86/batch_normalization_2325/FusedBatchNormV3 (643.19k/643.19k flops)\n",
      "  model_86/batch_normalization_2330/FusedBatchNormV3 (561.17k/561.17k flops)\n",
      "  model_86/batch_normalization_2331/FusedBatchNormV3 (561.17k/561.17k flops)\n",
      "  model_86/batch_normalization_2332/FusedBatchNormV3 (561.17k/561.17k flops)\n",
      "  model_86/conv2d_1207/BiasAdd (497.66k/497.66k flops)\n",
      "  model_86/conv2d_1206/BiasAdd (456.19k/456.19k flops)\n",
      "  model_86/depthwise_conv2d_1120/BiasAdd (456.19k/456.19k flops)\n",
      "  model_86/batch_normalization_2343/FusedBatchNormV3 (321.77k/321.77k flops)\n",
      "  model_86/batch_normalization_2342/FusedBatchNormV3 (321.77k/321.77k flops)\n",
      "  model_86/depthwise_conv2d_1119/BiasAdd (321.41k/321.41k flops)\n",
      "  model_86/batch_normalization_2341/FusedBatchNormV3 (303.46k/303.46k flops)\n",
      "  model_86/batch_normalization_2340/FusedBatchNormV3 (303.46k/303.46k flops)\n",
      "  model_86/batch_normalization_2344/FusedBatchNormV3 (299.53k/299.53k flops)\n",
      "  model_86/batch_normalization_2339/FusedBatchNormV3 (296.92k/296.92k flops)\n",
      "  model_86/batch_normalization_2338/FusedBatchNormV3 (296.92k/296.92k flops)\n",
      "  model_86/batch_normalization_2336/FusedBatchNormV3 (295.61k/295.61k flops)\n",
      "  model_86/batch_normalization_2337/FusedBatchNormV3 (295.61k/295.61k flops)\n",
      "  model_86/batch_normalization_2335/FusedBatchNormV3 (294.30k/294.30k flops)\n",
      "  model_86/batch_normalization_2334/FusedBatchNormV3 (294.30k/294.30k flops)\n",
      "  model_86/conv2d_1208/BiasAdd (279.94k/279.94k flops)\n",
      "  model_86/conv2d_1209/BiasAdd (279.94k/279.94k flops)\n",
      "  model_86/depthwise_conv2d_1122/BiasAdd (279.94k/279.94k flops)\n",
      "  model_86/depthwise_conv2d_1130/depthwise (270.90k/270.90k flops)\n",
      "  model_86/batch_normalization_2329/FusedBatchNormV3 (249.41k/249.41k flops)\n",
      "  model_86/depthwise_conv2d_1128/BiasAdd (159.41k/159.41k flops)\n",
      "  model_86/conv2d_1214/BiasAdd (159.41k/159.41k flops)\n",
      "  model_86/depthwise_conv2d_1127/BiasAdd (150.34k/150.34k flops)\n",
      "  model_86/conv2d_1213/BiasAdd (150.34k/150.34k flops)\n",
      "  model_86/conv2d_1215/BiasAdd (148.39k/148.39k flops)\n",
      "  model_86/depthwise_conv2d_1126/BiasAdd (147.10k/147.10k flops)\n",
      "  model_86/conv2d_1212/BiasAdd (147.10k/147.10k flops)\n",
      "  model_86/depthwise_conv2d_1125/BiasAdd (146.45k/146.45k flops)\n",
      "  model_86/conv2d_1211/BiasAdd (146.45k/146.45k flops)\n",
      "  model_86/conv2d_1210/BiasAdd (145.80k/145.80k flops)\n",
      "  model_86/depthwise_conv2d_1124/BiasAdd (145.80k/145.80k flops)\n",
      "  model_86/batch_normalization_2333/FusedBatchNormV3 (141.26k/141.26k flops)\n",
      "  model_86/depthwise_conv2d_1121/BiasAdd (124.42k/124.42k flops)\n",
      "  model_86/batch_normalization_2346/FusedBatchNormV3 (101.14k/101.14k flops)\n",
      "  model_86/batch_normalization_2345/FusedBatchNormV3 (76.94k/76.94k flops)\n",
      "  model_86/depthwise_conv2d_1123/BiasAdd (69.98k/69.98k flops)\n",
      "  model_86/conv2d_1216/BiasAdd (48.76k/48.76k flops)\n",
      "  model_86/batch_normalization_2348/FusedBatchNormV3 (41.78k/41.78k flops)\n",
      "  model_86/depthwise_conv2d_1129/BiasAdd (37.10k/37.10k flops)\n",
      "  model_86/batch_normalization_2347/FusedBatchNormV3 (33.71k/33.71k flops)\n",
      "  model_86/global_average_pooling2d_86/Mean (18.65k/18.65k flops)\n",
      "  model_86/conv2d_1217/BiasAdd (18.65k/18.65k flops)\n",
      "  model_86/depthwise_conv2d_1130/BiasAdd (15.05k/15.05k flops)\n",
      "  model_86/dense_86/MatMul (14.92k/14.92k flops)\n",
      "  model_86/dense_86/Softmax (50/50 flops)\n",
      "  model_86/dense_86/BiasAdd (10/10 flops)\n",
      "\n",
      "======================End of Report==========================\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "84.029868\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-30 13:41:01.873430: I tensorflow/core/grappler/devices.cc:66] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0\n",
      "2022-04-30 13:41:01.873547: I tensorflow/core/grappler/clusters/single_machine.cc:357] Starting new session\n",
      "2022-04-30 13:41:01.878409: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:1137] Optimization results for grappler item: graph_to_optimize\n",
      "  function_optimizer: function_optimizer did nothing. time = 0.006ms.\n",
      "  function_optimizer: function_optimizer did nothing. time = 0.001ms.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=========================Options=============================\n",
      "-max_depth                  10000\n",
      "-min_bytes                  0\n",
      "-min_peak_bytes             0\n",
      "-min_residual_bytes         0\n",
      "-min_output_bytes           0\n",
      "-min_micros                 0\n",
      "-min_accelerator_micros     0\n",
      "-min_cpu_micros             0\n",
      "-min_params                 0\n",
      "-min_float_ops              1\n",
      "-min_occurrence             0\n",
      "-step                       -1\n",
      "-order_by                   float_ops\n",
      "-account_type_regexes       .*\n",
      "-start_name_regexes         .*\n",
      "-trim_name_regexes          \n",
      "-show_name_regexes          .*\n",
      "-hide_name_regexes          \n",
      "-account_displayed_op_only  true\n",
      "-select                     float_ops\n",
      "-output                     stdout:\n",
      "\n",
      "==================Model Analysis Report======================\n",
      "\n",
      "Doc:\n",
      "scope: The nodes in the model graph are organized by their names, which is hierarchical like filesystem.\n",
      "flops: Number of float operations. Note: Please read the implementation for the math behind it.\n",
      "\n",
      "Profile:\n",
      "node name | # float_ops\n",
      "_TFProfRoot (--/1.29b flops)\n",
      "  model_87/conv2d_1229/Conv2D (148.63m/148.63m flops)\n",
      "  model_87/conv2d_1223/Conv2D (137.73m/137.73m flops)\n",
      "  model_87/conv2d_1228/Conv2D (133.40m/133.40m flops)\n",
      "  model_87/conv2d_1226/Conv2D (113.97m/113.97m flops)\n",
      "  model_87/conv2d_1227/Conv2D (108.99m/108.99m flops)\n",
      "  model_87/conv2d_1225/Conv2D (102.69m/102.69m flops)\n",
      "  model_87/conv2d_1221/Conv2D (95.80m/95.80m flops)\n",
      "  model_87/conv2d_1230/Conv2D (75.58m/75.58m flops)\n",
      "  model_87/conv2d_1219/Conv2D (74.32m/74.32m flops)\n",
      "  model_87/conv2d_1222/Conv2D (61.59m/61.59m flops)\n",
      "  model_87/conv2d_1224/Conv2D (55.16m/55.16m flops)\n",
      "  model_87/conv2d_1220/Conv2D (48.77m/48.77m flops)\n",
      "  model_87/conv2d_1231/Conv2D (46.37m/46.37m flops)\n",
      "  model_87/conv2d_1218/Conv2D (21.23m/21.23m flops)\n",
      "  model_87/depthwise_conv2d_1131/depthwise (11.94m/11.94m flops)\n",
      "  model_87/depthwise_conv2d_1133/depthwise (7.84m/7.84m flops)\n",
      "  model_87/depthwise_conv2d_1132/depthwise (5.23m/5.23m flops)\n",
      "  model_87/depthwise_conv2d_1135/depthwise (5.04m/5.04m flops)\n",
      "  model_87/depthwise_conv2d_1141/depthwise (2.74m/2.74m flops)\n",
      "  model_87/depthwise_conv2d_1138/depthwise (2.67m/2.67m flops)\n",
      "  model_87/depthwise_conv2d_1134/depthwise (2.57m/2.57m flops)\n",
      "  model_87/depthwise_conv2d_1140/depthwise (2.55m/2.55m flops)\n",
      "  model_87/batch_normalization_2351/FusedBatchNormV3 (2.32m/2.32m flops)\n",
      "  model_87/depthwise_conv2d_1139/depthwise (2.24m/2.24m flops)\n",
      "  model_87/depthwise_conv2d_1137/depthwise (2.02m/2.02m flops)\n",
      "  model_87/depthwise_conv2d_1136/depthwise (1.43m/1.43m flops)\n",
      "  model_87/batch_normalization_2350/FusedBatchNormV3 (1.33m/1.33m flops)\n",
      "  model_87/batch_normalization_2349/FusedBatchNormV3 (1.33m/1.33m flops)\n",
      "  model_87/conv2d_1219/BiasAdd (1.16m/1.16m flops)\n",
      "  model_87/batch_normalization_2355/FusedBatchNormV3 (1.14m/1.14m flops)\n",
      "  model_87/batch_normalization_2353/FusedBatchNormV3 (871.42k/871.42k flops)\n",
      "  model_87/batch_normalization_2354/FusedBatchNormV3 (871.42k/871.42k flops)\n",
      "  model_87/depthwise_conv2d_1142/depthwise (711.50k/711.50k flops)\n",
      "  model_87/conv2d_1218/BiasAdd (663.55k/663.55k flops)\n",
      "  model_87/depthwise_conv2d_1131/BiasAdd (663.55k/663.55k flops)\n",
      "  model_87/batch_normalization_2359/FusedBatchNormV3 (639.11k/639.11k flops)\n",
      "  model_87/batch_normalization_2352/FusedBatchNormV3 (580.94k/580.94k flops)\n",
      "  model_87/conv2d_1221/BiasAdd (570.24k/570.24k flops)\n",
      "  model_87/batch_normalization_2357/FusedBatchNormV3 (561.17k/561.17k flops)\n",
      "  model_87/batch_normalization_2358/FusedBatchNormV3 (561.17k/561.17k flops)\n",
      "  model_87/depthwise_conv2d_1133/BiasAdd (435.46k/435.46k flops)\n",
      "  model_87/conv2d_1220/BiasAdd (435.46k/435.46k flops)\n",
      "  model_87/depthwise_conv2d_1143/depthwise (430.20k/430.20k flops)\n",
      "  model_87/batch_normalization_2371/FusedBatchNormV3 (319.15k/319.15k flops)\n",
      "  model_87/conv2d_1223/BiasAdd (318.82k/318.82k flops)\n",
      "  model_87/batch_normalization_2370/FusedBatchNormV3 (307.38k/307.38k flops)\n",
      "  model_87/batch_normalization_2369/FusedBatchNormV3 (307.38k/307.38k flops)\n",
      "  model_87/batch_normalization_2364/FusedBatchNormV3 (299.53k/299.53k flops)\n",
      "  model_87/batch_normalization_2363/FusedBatchNormV3 (299.53k/299.53k flops)\n",
      "  model_87/depthwise_conv2d_1132/BiasAdd (290.30k/290.30k flops)\n",
      "  model_87/batch_normalization_2367/FusedBatchNormV3 (286.45k/286.45k flops)\n",
      "  model_87/batch_normalization_2368/FusedBatchNormV3 (286.45k/286.45k flops)\n",
      "  model_87/batch_normalization_2356/FusedBatchNormV3 (285.78k/285.78k flops)\n",
      "  model_87/conv2d_1222/BiasAdd (279.94k/279.94k flops)\n",
      "  model_87/depthwise_conv2d_1135/BiasAdd (279.94k/279.94k flops)\n",
      "  model_87/batch_normalization_2365/FusedBatchNormV3 (251.14k/251.14k flops)\n",
      "  model_87/batch_normalization_2366/FusedBatchNormV3 (251.14k/251.14k flops)\n",
      "  model_87/batch_normalization_2362/FusedBatchNormV3 (226.28k/226.28k flops)\n",
      "  model_87/batch_normalization_2361/FusedBatchNormV3 (226.28k/226.28k flops)\n",
      "  model_87/batch_normalization_2360/FusedBatchNormV3 (160.88k/160.88k flops)\n",
      "  model_87/batch_normalization_2373/FusedBatchNormV3 (160.61k/160.61k flops)\n",
      "  model_87/conv2d_1229/BiasAdd (158.11k/158.11k flops)\n",
      "  model_87/depthwise_conv2d_1141/BiasAdd (152.28k/152.28k flops)\n",
      "  model_87/conv2d_1228/BiasAdd (152.28k/152.28k flops)\n",
      "  model_87/depthwise_conv2d_1138/BiasAdd (148.39k/148.39k flops)\n",
      "  model_87/conv2d_1225/BiasAdd (148.39k/148.39k flops)\n",
      "  model_87/depthwise_conv2d_1134/BiasAdd (142.56k/142.56k flops)\n",
      "  model_87/depthwise_conv2d_1140/BiasAdd (141.91k/141.91k flops)\n",
      "  model_87/conv2d_1227/BiasAdd (141.91k/141.91k flops)\n",
      "  model_87/conv2d_1226/BiasAdd (124.42k/124.42k flops)\n",
      "  model_87/depthwise_conv2d_1139/BiasAdd (124.42k/124.42k flops)\n",
      "  model_87/depthwise_conv2d_1137/BiasAdd (112.10k/112.10k flops)\n",
      "  model_87/conv2d_1224/BiasAdd (112.10k/112.10k flops)\n",
      "  model_87/batch_normalization_2372/FusedBatchNormV3 (81.98k/81.98k flops)\n",
      "  model_87/depthwise_conv2d_1136/BiasAdd (79.70k/79.70k flops)\n",
      "  model_87/conv2d_1230/BiasAdd (77.44k/77.44k flops)\n",
      "  model_87/batch_normalization_2375/FusedBatchNormV3 (54.32k/54.32k flops)\n",
      "  model_87/batch_normalization_2374/FusedBatchNormV3 (53.54k/53.54k flops)\n",
      "  model_87/depthwise_conv2d_1142/BiasAdd (39.53k/39.53k flops)\n",
      "  model_87/global_average_pooling2d_87/Mean (24.25k/24.25k flops)\n",
      "  model_87/conv2d_1231/BiasAdd (24.25k/24.25k flops)\n",
      "  model_87/depthwise_conv2d_1143/BiasAdd (23.90k/23.90k flops)\n",
      "  model_87/dense_87/MatMul (19.40k/19.40k flops)\n",
      "  model_87/dense_87/Softmax (50/50 flops)\n",
      "  model_87/dense_87/BiasAdd (10/10 flops)\n",
      "\n",
      "======================End of Report==========================\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "83.106148\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-30 13:41:02.823186: I tensorflow/core/grappler/devices.cc:66] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0\n",
      "2022-04-30 13:41:02.823304: I tensorflow/core/grappler/clusters/single_machine.cc:357] Starting new session\n",
      "2022-04-30 13:41:02.827590: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:1137] Optimization results for grappler item: graph_to_optimize\n",
      "  function_optimizer: function_optimizer did nothing. time = 0.005ms.\n",
      "  function_optimizer: function_optimizer did nothing. time = 0.001ms.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=========================Options=============================\n",
      "-max_depth                  10000\n",
      "-min_bytes                  0\n",
      "-min_peak_bytes             0\n",
      "-min_residual_bytes         0\n",
      "-min_output_bytes           0\n",
      "-min_micros                 0\n",
      "-min_accelerator_micros     0\n",
      "-min_cpu_micros             0\n",
      "-min_params                 0\n",
      "-min_float_ops              1\n",
      "-min_occurrence             0\n",
      "-step                       -1\n",
      "-order_by                   float_ops\n",
      "-account_type_regexes       .*\n",
      "-start_name_regexes         .*\n",
      "-trim_name_regexes          \n",
      "-show_name_regexes          .*\n",
      "-hide_name_regexes          \n",
      "-account_displayed_op_only  true\n",
      "-select                     float_ops\n",
      "-output                     stdout:\n",
      "\n",
      "==================Model Analysis Report======================\n",
      "\n",
      "Doc:\n",
      "scope: The nodes in the model graph are organized by their names, which is hierarchical like filesystem.\n",
      "flops: Number of float operations. Note: Please read the implementation for the math behind it.\n",
      "\n",
      "Profile:\n",
      "node name | # float_ops\n",
      "_TFProfRoot (--/1.34b flops)\n",
      "  model_88/conv2d_1243/Conv2D (156.17m/156.17m flops)\n",
      "  model_88/conv2d_1242/Conv2D (149.04m/149.04m flops)\n",
      "  model_88/conv2d_1240/Conv2D (139.00m/139.00m flops)\n",
      "  model_88/conv2d_1235/Conv2D (131.55m/131.55m flops)\n",
      "  model_88/conv2d_1241/Conv2D (129.96m/129.96m flops)\n",
      "  model_88/conv2d_1237/Conv2D (127.74m/127.74m flops)\n",
      "  model_88/conv2d_1239/Conv2D (125.61m/125.61m flops)\n",
      "  model_88/conv2d_1236/Conv2D (70.20m/70.20m flops)\n",
      "  model_88/conv2d_1238/Conv2D (56.68m/56.68m flops)\n",
      "  model_88/conv2d_1233/Conv2D (53.08m/53.08m flops)\n",
      "  model_88/conv2d_1244/Conv2D (43.41m/43.41m flops)\n",
      "  model_88/conv2d_1234/Conv2D (43.13m/43.13m flops)\n",
      "  model_88/conv2d_1245/Conv2D (27.24m/27.24m flops)\n",
      "  model_88/conv2d_1232/Conv2D (21.23m/21.23m flops)\n",
      "  model_88/depthwise_conv2d_1144/depthwise (11.94m/11.94m flops)\n",
      "  model_88/depthwise_conv2d_1146/depthwise (9.70m/9.70m flops)\n",
      "  model_88/depthwise_conv2d_1148/depthwise (5.18m/5.18m flops)\n",
      "  model_88/depthwise_conv2d_1145/depthwise (3.73m/3.73m flops)\n",
      "  model_88/depthwise_conv2d_1154/depthwise (2.92m/2.92m flops)\n",
      "  model_88/depthwise_conv2d_1151/depthwise (2.87m/2.87m flops)\n",
      "  model_88/depthwise_conv2d_1147/depthwise (2.85m/2.85m flops)\n",
      "  model_88/depthwise_conv2d_1153/depthwise (2.68m/2.68m flops)\n",
      "  model_88/depthwise_conv2d_1152/depthwise (2.54m/2.54m flops)\n",
      "  model_88/depthwise_conv2d_1150/depthwise (2.30m/2.30m flops)\n",
      "  model_88/batch_normalization_2378/FusedBatchNormV3 (1.66m/1.66m flops)\n",
      "  model_88/batch_normalization_2377/FusedBatchNormV3 (1.33m/1.33m flops)\n",
      "  model_88/batch_normalization_2376/FusedBatchNormV3 (1.33m/1.33m flops)\n",
      "  model_88/depthwise_conv2d_1149/depthwise (1.29m/1.29m flops)\n",
      "  model_88/batch_normalization_2382/FusedBatchNormV3 (1.27m/1.27m flops)\n",
      "  model_88/batch_normalization_2380/FusedBatchNormV3 (1.08m/1.08m flops)\n",
      "  model_88/batch_normalization_2381/FusedBatchNormV3 (1.08m/1.08m flops)\n",
      "  model_88/conv2d_1233/BiasAdd (829.44k/829.44k flops)\n",
      "  model_88/depthwise_conv2d_1155/depthwise (702.76k/702.76k flops)\n",
      "  model_88/conv2d_1232/BiasAdd (663.55k/663.55k flops)\n",
      "  model_88/depthwise_conv2d_1144/BiasAdd (663.55k/663.55k flops)\n",
      "  model_88/conv2d_1235/BiasAdd (632.45k/632.45k flops)\n",
      "  model_88/batch_normalization_2384/FusedBatchNormV3 (576.76k/576.76k flops)\n",
      "  model_88/batch_normalization_2385/FusedBatchNormV3 (576.76k/576.76k flops)\n",
      "  model_88/batch_normalization_2386/FusedBatchNormV3 (576.76k/576.76k flops)\n",
      "  model_88/conv2d_1234/BiasAdd (539.14k/539.14k flops)\n",
      "  model_88/depthwise_conv2d_1146/BiasAdd (539.14k/539.14k flops)\n",
      "  model_88/batch_normalization_2379/FusedBatchNormV3 (414.96k/414.96k flops)\n",
      "  model_88/batch_normalization_2397/FusedBatchNormV3 (327.00k/327.00k flops)\n",
      "  model_88/batch_normalization_2396/FusedBatchNormV3 (327.00k/327.00k flops)\n",
      "  model_88/batch_normalization_2391/FusedBatchNormV3 (321.77k/321.77k flops)\n",
      "  model_88/batch_normalization_2390/FusedBatchNormV3 (321.77k/321.77k flops)\n",
      "  model_88/batch_normalization_2383/FusedBatchNormV3 (316.96k/316.96k flops)\n",
      "  model_88/batch_normalization_2398/FusedBatchNormV3 (315.23k/315.23k flops)\n",
      "  model_88/batch_normalization_2395/FusedBatchNormV3 (300.84k/300.84k flops)\n",
      "  model_88/batch_normalization_2394/FusedBatchNormV3 (300.84k/300.84k flops)\n",
      "  model_88/conv2d_1237/BiasAdd (287.71k/287.71k flops)\n",
      "  model_88/depthwise_conv2d_1148/BiasAdd (287.71k/287.71k flops)\n",
      "  model_88/conv2d_1236/BiasAdd (287.71k/287.71k flops)\n",
      "  model_88/batch_normalization_2393/FusedBatchNormV3 (285.14k/285.14k flops)\n",
      "  model_88/batch_normalization_2392/FusedBatchNormV3 (285.14k/285.14k flops)\n",
      "  model_88/batch_normalization_2389/FusedBatchNormV3 (257.68k/257.68k flops)\n",
      "  model_88/batch_normalization_2388/FusedBatchNormV3 (257.68k/257.68k flops)\n",
      "  model_88/depthwise_conv2d_1156/depthwise (250.20k/250.20k flops)\n",
      "  model_88/depthwise_conv2d_1145/BiasAdd (207.36k/207.36k flops)\n",
      "  model_88/depthwise_conv2d_1154/BiasAdd (162.00k/162.00k flops)\n",
      "  model_88/conv2d_1242/BiasAdd (162.00k/162.00k flops)\n",
      "  model_88/conv2d_1239/BiasAdd (159.41k/159.41k flops)\n",
      "  model_88/depthwise_conv2d_1151/BiasAdd (159.41k/159.41k flops)\n",
      "  model_88/depthwise_conv2d_1147/BiasAdd (158.11k/158.11k flops)\n",
      "  model_88/conv2d_1243/BiasAdd (156.17k/156.17k flops)\n",
      "  model_88/depthwise_conv2d_1153/BiasAdd (149.04k/149.04k flops)\n",
      "  model_88/conv2d_1241/BiasAdd (149.04k/149.04k flops)\n",
      "  model_88/batch_normalization_2387/FusedBatchNormV3 (145.19k/145.19k flops)\n",
      "  model_88/conv2d_1240/BiasAdd (141.26k/141.26k flops)\n",
      "  model_88/depthwise_conv2d_1152/BiasAdd (141.26k/141.26k flops)\n",
      "  model_88/conv2d_1238/BiasAdd (127.66k/127.66k flops)\n",
      "  model_88/depthwise_conv2d_1150/BiasAdd (127.66k/127.66k flops)\n",
      "  model_88/batch_normalization_2400/FusedBatchNormV3 (93.41k/93.41k flops)\n",
      "  model_88/batch_normalization_2399/FusedBatchNormV3 (80.98k/80.98k flops)\n",
      "  model_88/depthwise_conv2d_1149/BiasAdd (71.93k/71.93k flops)\n",
      "  model_88/batch_normalization_2402/FusedBatchNormV3 (54.88k/54.88k flops)\n",
      "  model_88/conv2d_1244/BiasAdd (45.04k/45.04k flops)\n",
      "  model_88/depthwise_conv2d_1155/BiasAdd (39.04k/39.04k flops)\n",
      "  model_88/batch_normalization_2401/FusedBatchNormV3 (31.14k/31.14k flops)\n",
      "  model_88/global_average_pooling2d_88/Mean (24.50k/24.50k flops)\n",
      "  model_88/conv2d_1245/BiasAdd (24.50k/24.50k flops)\n",
      "  model_88/dense_88/MatMul (19.60k/19.60k flops)\n",
      "  model_88/depthwise_conv2d_1156/BiasAdd (13.90k/13.90k flops)\n",
      "  model_88/dense_88/Softmax (50/50 flops)\n",
      "  model_88/dense_88/BiasAdd (10/10 flops)\n",
      "\n",
      "======================End of Report==========================\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "84.094404\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-30 13:41:03.860958: I tensorflow/core/grappler/devices.cc:66] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0\n",
      "2022-04-30 13:41:03.861072: I tensorflow/core/grappler/clusters/single_machine.cc:357] Starting new session\n",
      "2022-04-30 13:41:03.866128: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:1137] Optimization results for grappler item: graph_to_optimize\n",
      "  function_optimizer: function_optimizer did nothing. time = 0.006ms.\n",
      "  function_optimizer: function_optimizer did nothing. time = 0.001ms.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=========================Options=============================\n",
      "-max_depth                  10000\n",
      "-min_bytes                  0\n",
      "-min_peak_bytes             0\n",
      "-min_residual_bytes         0\n",
      "-min_output_bytes           0\n",
      "-min_micros                 0\n",
      "-min_accelerator_micros     0\n",
      "-min_cpu_micros             0\n",
      "-min_params                 0\n",
      "-min_float_ops              1\n",
      "-min_occurrence             0\n",
      "-step                       -1\n",
      "-order_by                   float_ops\n",
      "-account_type_regexes       .*\n",
      "-start_name_regexes         .*\n",
      "-trim_name_regexes          \n",
      "-show_name_regexes          .*\n",
      "-hide_name_regexes          \n",
      "-account_displayed_op_only  true\n",
      "-select                     float_ops\n",
      "-output                     stdout:\n",
      "\n",
      "==================Model Analysis Report======================\n",
      "\n",
      "Doc:\n",
      "scope: The nodes in the model graph are organized by their names, which is hierarchical like filesystem.\n",
      "flops: Number of float operations. Note: Please read the implementation for the math behind it.\n",
      "\n",
      "Profile:\n",
      "node name | # float_ops\n",
      "_TFProfRoot (--/1.31b flops)\n",
      "  model_89/conv2d_1256/Conv2D (150.34m/150.34m flops)\n",
      "  model_89/conv2d_1254/Conv2D (144.32m/144.32m flops)\n",
      "  model_89/conv2d_1255/Conv2D (144.32m/144.32m flops)\n",
      "  model_89/conv2d_1257/Conv2D (135.43m/135.43m flops)\n",
      "  model_89/conv2d_1251/Conv2D (115.98m/115.98m flops)\n",
      "  model_89/conv2d_1253/Conv2D (111.25m/111.25m flops)\n",
      "  model_89/conv2d_1249/Conv2D (98.54m/98.54m flops)\n",
      "  model_89/conv2d_1247/Conv2D (74.32m/74.32m flops)\n",
      "  model_89/conv2d_1252/Conv2D (57.06m/57.06m flops)\n",
      "  model_89/conv2d_1250/Conv2D (52.63m/52.63m flops)\n",
      "  model_89/conv2d_1248/Conv2D (51.09m/51.09m flops)\n",
      "  model_89/conv2d_1258/Conv2D (50.38m/50.38m flops)\n",
      "  model_89/conv2d_1259/Conv2D (29.16m/29.16m flops)\n",
      "  model_89/conv2d_1246/Conv2D (21.23m/21.23m flops)\n",
      "  model_89/depthwise_conv2d_1157/depthwise (11.94m/11.94m flops)\n",
      "  model_89/depthwise_conv2d_1159/depthwise (8.21m/8.21m flops)\n",
      "  model_89/depthwise_conv2d_1158/depthwise (5.23m/5.23m flops)\n",
      "  model_89/depthwise_conv2d_1161/depthwise (4.39m/4.39m flops)\n",
      "  model_89/depthwise_conv2d_1167/depthwise (2.92m/2.92m flops)\n",
      "  model_89/depthwise_conv2d_1165/depthwise (2.80m/2.80m flops)\n",
      "  model_89/depthwise_conv2d_1164/depthwise (2.71m/2.71m flops)\n",
      "  model_89/depthwise_conv2d_1166/depthwise (2.71m/2.71m flops)\n",
      "  model_89/depthwise_conv2d_1160/depthwise (2.52m/2.52m flops)\n",
      "  model_89/batch_normalization_2405/FusedBatchNormV3 (2.32m/2.32m flops)\n",
      "  model_89/depthwise_conv2d_1163/depthwise (2.16m/2.16m flops)\n",
      "  model_89/depthwise_conv2d_1162/depthwise (1.39m/1.39m flops)\n",
      "  model_89/batch_normalization_2404/FusedBatchNormV3 (1.33m/1.33m flops)\n",
      "  model_89/batch_normalization_2403/FusedBatchNormV3 (1.33m/1.33m flops)\n",
      "  model_89/conv2d_1247/BiasAdd (1.16m/1.16m flops)\n",
      "  model_89/batch_normalization_2409/FusedBatchNormV3 (1.12m/1.12m flops)\n",
      "  model_89/batch_normalization_2407/FusedBatchNormV3 (912.91k/912.91k flops)\n",
      "  model_89/batch_normalization_2408/FusedBatchNormV3 (912.91k/912.91k flops)\n",
      "  model_89/conv2d_1246/BiasAdd (663.55k/663.55k flops)\n",
      "  model_89/depthwise_conv2d_1157/BiasAdd (663.55k/663.55k flops)\n",
      "  model_89/batch_normalization_2413/FusedBatchNormV3 (618.32k/618.32k flops)\n",
      "  model_89/depthwise_conv2d_1168/depthwise (609.44k/609.44k flops)\n",
      "  model_89/batch_normalization_2406/FusedBatchNormV3 (580.94k/580.94k flops)\n",
      "  model_89/conv2d_1249/BiasAdd (559.87k/559.87k flops)\n",
      "  model_89/batch_normalization_2412/FusedBatchNormV3 (488.42k/488.42k flops)\n",
      "  model_89/batch_normalization_2411/FusedBatchNormV3 (488.42k/488.42k flops)\n",
      "  model_89/conv2d_1248/BiasAdd (456.19k/456.19k flops)\n",
      "  model_89/depthwise_conv2d_1159/BiasAdd (456.19k/456.19k flops)\n",
      "  model_89/depthwise_conv2d_1169/depthwise (334.80k/334.80k flops)\n",
      "  model_89/batch_normalization_2424/FusedBatchNormV3 (327.00k/327.00k flops)\n",
      "  model_89/batch_normalization_2423/FusedBatchNormV3 (327.00k/327.00k flops)\n",
      "  model_89/batch_normalization_2420/FusedBatchNormV3 (313.92k/313.92k flops)\n",
      "  model_89/batch_normalization_2419/FusedBatchNormV3 (313.92k/313.92k flops)\n",
      "  model_89/conv2d_1251/BiasAdd (308.45k/308.45k flops)\n",
      "  model_89/batch_normalization_2421/FusedBatchNormV3 (303.46k/303.46k flops)\n",
      "  model_89/batch_normalization_2422/FusedBatchNormV3 (303.46k/303.46k flops)\n",
      "  model_89/batch_normalization_2418/FusedBatchNormV3 (303.46k/303.46k flops)\n",
      "  model_89/batch_normalization_2417/FusedBatchNormV3 (303.46k/303.46k flops)\n",
      "  model_89/depthwise_conv2d_1158/BiasAdd (290.30k/290.30k flops)\n",
      "  model_89/batch_normalization_2410/FusedBatchNormV3 (280.58k/280.58k flops)\n",
      "  model_89/batch_normalization_2425/FusedBatchNormV3 (273.37k/273.37k flops)\n",
      "  model_89/depthwise_conv2d_1161/BiasAdd (243.65k/243.65k flops)\n",
      "  model_89/conv2d_1250/BiasAdd (243.65k/243.65k flops)\n",
      "  model_89/batch_normalization_2416/FusedBatchNormV3 (241.98k/241.98k flops)\n",
      "  model_89/batch_normalization_2415/FusedBatchNormV3 (241.98k/241.98k flops)\n",
      "  model_89/depthwise_conv2d_1167/BiasAdd (162.00k/162.00k flops)\n",
      "  model_89/conv2d_1256/BiasAdd (162.00k/162.00k flops)\n",
      "  model_89/batch_normalization_2414/FusedBatchNormV3 (155.65k/155.65k flops)\n",
      "  model_89/conv2d_1254/BiasAdd (155.52k/155.52k flops)\n",
      "  model_89/depthwise_conv2d_1165/BiasAdd (155.52k/155.52k flops)\n",
      "  model_89/conv2d_1255/BiasAdd (150.34k/150.34k flops)\n",
      "  model_89/conv2d_1253/BiasAdd (150.34k/150.34k flops)\n",
      "  model_89/depthwise_conv2d_1164/BiasAdd (150.34k/150.34k flops)\n",
      "  model_89/depthwise_conv2d_1166/BiasAdd (150.34k/150.34k flops)\n",
      "  model_89/depthwise_conv2d_1160/BiasAdd (139.97k/139.97k flops)\n",
      "  model_89/conv2d_1257/BiasAdd (135.43k/135.43k flops)\n",
      "  model_89/batch_normalization_2427/FusedBatchNormV3 (124.99k/124.99k flops)\n",
      "  model_89/depthwise_conv2d_1163/BiasAdd (119.88k/119.88k flops)\n",
      "  model_89/conv2d_1252/BiasAdd (119.88k/119.88k flops)\n",
      "  model_89/depthwise_conv2d_1162/BiasAdd (77.11k/77.11k flops)\n",
      "  model_89/batch_normalization_2426/FusedBatchNormV3 (70.22k/70.22k flops)\n",
      "  model_89/conv2d_1258/BiasAdd (60.26k/60.26k flops)\n",
      "  model_89/batch_normalization_2429/FusedBatchNormV3 (43.90k/43.90k flops)\n",
      "  model_89/batch_normalization_2428/FusedBatchNormV3 (41.66k/41.66k flops)\n",
      "  model_89/depthwise_conv2d_1168/BiasAdd (33.86k/33.86k flops)\n",
      "  model_89/global_average_pooling2d_89/Mean (19.60k/19.60k flops)\n",
      "  model_89/conv2d_1259/BiasAdd (19.60k/19.60k flops)\n",
      "  model_89/depthwise_conv2d_1169/BiasAdd (18.60k/18.60k flops)\n",
      "  model_89/dense_89/MatMul (15.68k/15.68k flops)\n",
      "  model_89/dense_89/Softmax (50/50 flops)\n",
      "  model_89/dense_89/BiasAdd (10/10 flops)\n",
      "\n",
      "======================End of Report==========================\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "67.2045\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-30 13:41:04.797663: I tensorflow/core/grappler/devices.cc:66] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0\n",
      "2022-04-30 13:41:04.797779: I tensorflow/core/grappler/clusters/single_machine.cc:357] Starting new session\n",
      "2022-04-30 13:41:04.802023: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:1137] Optimization results for grappler item: graph_to_optimize\n",
      "  function_optimizer: function_optimizer did nothing. time = 0.005ms.\n",
      "  function_optimizer: function_optimizer did nothing. time = 0.001ms.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=========================Options=============================\n",
      "-max_depth                  10000\n",
      "-min_bytes                  0\n",
      "-min_peak_bytes             0\n",
      "-min_residual_bytes         0\n",
      "-min_output_bytes           0\n",
      "-min_micros                 0\n",
      "-min_accelerator_micros     0\n",
      "-min_cpu_micros             0\n",
      "-min_params                 0\n",
      "-min_float_ops              1\n",
      "-min_occurrence             0\n",
      "-step                       -1\n",
      "-order_by                   float_ops\n",
      "-account_type_regexes       .*\n",
      "-start_name_regexes         .*\n",
      "-trim_name_regexes          \n",
      "-show_name_regexes          .*\n",
      "-hide_name_regexes          \n",
      "-account_displayed_op_only  true\n",
      "-select                     float_ops\n",
      "-output                     stdout:\n",
      "\n",
      "==================Model Analysis Report======================\n",
      "\n",
      "Doc:\n",
      "scope: The nodes in the model graph are organized by their names, which is hierarchical like filesystem.\n",
      "flops: Number of float operations. Note: Please read the implementation for the math behind it.\n",
      "\n",
      "Profile:\n",
      "node name | # float_ops\n",
      "_TFProfRoot (--/963.96m flops)\n",
      "  model_90/conv2d_1268/Conv2D (136.33m/136.33m flops)\n",
      "  model_90/conv2d_1269/Conv2D (115.71m/115.71m flops)\n",
      "  model_90/conv2d_1265/Conv2D (97.54m/97.54m flops)\n",
      "  model_90/conv2d_1270/Conv2D (96.34m/96.34m flops)\n",
      "  model_90/conv2d_1271/Conv2D (91.09m/91.09m flops)\n",
      "  model_90/conv2d_1267/Conv2D (76.50m/76.50m flops)\n",
      "  model_90/conv2d_1264/Conv2D (53.75m/53.75m flops)\n",
      "  model_90/conv2d_1272/Conv2D (51.98m/51.98m flops)\n",
      "  model_90/conv2d_1261/Conv2D (45.12m/45.12m flops)\n",
      "  model_90/conv2d_1273/Conv2D (41.24m/41.24m flops)\n",
      "  model_90/conv2d_1263/Conv2D (38.07m/38.07m flops)\n",
      "  model_90/conv2d_1266/Conv2D (31.50m/31.50m flops)\n",
      "  model_90/conv2d_1260/Conv2D (21.23m/21.23m flops)\n",
      "  model_90/conv2d_1262/Conv2D (11.99m/11.99m flops)\n",
      "  model_90/depthwise_conv2d_1170/depthwise (11.94m/11.94m flops)\n",
      "  model_90/depthwise_conv2d_1174/depthwise (4.48m/4.48m flops)\n",
      "  model_90/depthwise_conv2d_1171/depthwise (3.17m/3.17m flops)\n",
      "  model_90/depthwise_conv2d_1172/depthwise (3.17m/3.17m flops)\n",
      "  model_90/depthwise_conv2d_1177/depthwise (2.78m/2.78m flops)\n",
      "  model_90/depthwise_conv2d_1178/depthwise (2.58m/2.58m flops)\n",
      "  model_90/depthwise_conv2d_1173/depthwise (2.52m/2.52m flops)\n",
      "  model_90/depthwise_conv2d_1179/depthwise (2.36m/2.36m flops)\n",
      "  model_90/depthwise_conv2d_1180/depthwise (2.15m/2.15m flops)\n",
      "  model_90/depthwise_conv2d_1176/depthwise (1.45m/1.45m flops)\n",
      "  model_90/batch_normalization_2432/FusedBatchNormV3 (1.41m/1.41m flops)\n",
      "  model_90/batch_normalization_2431/FusedBatchNormV3 (1.33m/1.33m flops)\n",
      "  model_90/batch_normalization_2430/FusedBatchNormV3 (1.33m/1.33m flops)\n",
      "  model_90/depthwise_conv2d_1175/depthwise (1.14m/1.14m flops)\n",
      "  model_90/batch_normalization_2436/FusedBatchNormV3 (1.12m/1.12m flops)\n",
      "  model_90/conv2d_1261/BiasAdd (705.02k/705.02k flops)\n",
      "  model_90/conv2d_1260/BiasAdd (663.55k/663.55k flops)\n",
      "  model_90/depthwise_conv2d_1170/BiasAdd (663.55k/663.55k flops)\n",
      "  model_90/conv2d_1263/BiasAdd (559.87k/559.87k flops)\n",
      "  model_90/depthwise_conv2d_1181/depthwise (556.96k/556.96k flops)\n",
      "  model_90/batch_normalization_2440/FusedBatchNormV3 (509.21k/509.21k flops)\n",
      "  model_90/batch_normalization_2438/FusedBatchNormV3 (498.82k/498.82k flops)\n",
      "  model_90/batch_normalization_2439/FusedBatchNormV3 (498.82k/498.82k flops)\n",
      "  model_90/depthwise_conv2d_1182/depthwise (378.00k/378.00k flops)\n",
      "  model_90/batch_normalization_2435/FusedBatchNormV3 (352.72k/352.72k flops)\n",
      "  model_90/batch_normalization_2433/FusedBatchNormV3 (352.72k/352.72k flops)\n",
      "  model_90/batch_normalization_2434/FusedBatchNormV3 (352.72k/352.72k flops)\n",
      "  model_90/batch_normalization_2445/FusedBatchNormV3 (311.30k/311.30k flops)\n",
      "  model_90/batch_normalization_2444/FusedBatchNormV3 (311.30k/311.30k flops)\n",
      "  model_90/batch_normalization_2447/FusedBatchNormV3 (289.07k/289.07k flops)\n",
      "  model_90/batch_normalization_2446/FusedBatchNormV3 (289.07k/289.07k flops)\n",
      "  model_90/batch_normalization_2437/FusedBatchNormV3 (280.58k/280.58k flops)\n",
      "  model_90/batch_normalization_2449/FusedBatchNormV3 (264.22k/264.22k flops)\n",
      "  model_90/batch_normalization_2448/FusedBatchNormV3 (264.22k/264.22k flops)\n",
      "  model_90/conv2d_1265/BiasAdd (254.02k/254.02k flops)\n",
      "  model_90/batch_normalization_2452/FusedBatchNormV3 (249.83k/249.83k flops)\n",
      "  model_90/depthwise_conv2d_1174/BiasAdd (248.83k/248.83k flops)\n",
      "  model_90/conv2d_1264/BiasAdd (248.83k/248.83k flops)\n",
      "  model_90/batch_normalization_2450/FusedBatchNormV3 (240.67k/240.67k flops)\n",
      "  model_90/batch_normalization_2451/FusedBatchNormV3 (240.67k/240.67k flops)\n",
      "  model_90/depthwise_conv2d_1172/BiasAdd (176.26k/176.26k flops)\n",
      "  model_90/depthwise_conv2d_1171/BiasAdd (176.26k/176.26k flops)\n",
      "  model_90/conv2d_1262/BiasAdd (176.26k/176.26k flops)\n",
      "  model_90/batch_normalization_2443/FusedBatchNormV3 (162.19k/162.19k flops)\n",
      "  model_90/batch_normalization_2442/FusedBatchNormV3 (162.19k/162.19k flops)\n",
      "  model_90/conv2d_1267/BiasAdd (154.22k/154.22k flops)\n",
      "  model_90/depthwise_conv2d_1177/BiasAdd (154.22k/154.22k flops)\n",
      "  model_90/depthwise_conv2d_1178/BiasAdd (143.21k/143.21k flops)\n",
      "  model_90/conv2d_1268/BiasAdd (143.21k/143.21k flops)\n",
      "  model_90/batch_normalization_2454/FusedBatchNormV3 (141.12k/141.12k flops)\n",
      "  model_90/depthwise_conv2d_1173/BiasAdd (139.97k/139.97k flops)\n",
      "  model_90/depthwise_conv2d_1179/BiasAdd (130.90k/130.90k flops)\n",
      "  model_90/conv2d_1269/BiasAdd (130.90k/130.90k flops)\n",
      "  model_90/batch_normalization_2441/FusedBatchNormV3 (128.18k/128.18k flops)\n",
      "  model_90/conv2d_1271/BiasAdd (123.77k/123.77k flops)\n",
      "  model_90/depthwise_conv2d_1180/BiasAdd (119.23k/119.23k flops)\n",
      "  model_90/conv2d_1270/BiasAdd (119.23k/119.23k flops)\n",
      "  model_90/depthwise_conv2d_1176/BiasAdd (80.35k/80.35k flops)\n",
      "  model_90/conv2d_1266/BiasAdd (80.35k/80.35k flops)\n",
      "  model_90/conv2d_1272/BiasAdd (68.04k/68.04k flops)\n",
      "  model_90/batch_normalization_2453/FusedBatchNormV3 (64.18k/64.18k flops)\n",
      "  model_90/depthwise_conv2d_1175/BiasAdd (63.50k/63.50k flops)\n",
      "  model_90/batch_normalization_2456/FusedBatchNormV3 (54.99k/54.99k flops)\n",
      "  model_90/batch_normalization_2455/FusedBatchNormV3 (47.04k/47.04k flops)\n",
      "  model_90/depthwise_conv2d_1181/BiasAdd (30.94k/30.94k flops)\n",
      "  model_90/global_average_pooling2d_90/Mean (24.55k/24.55k flops)\n",
      "  model_90/conv2d_1273/BiasAdd (24.55k/24.55k flops)\n",
      "  model_90/depthwise_conv2d_1182/BiasAdd (21.00k/21.00k flops)\n",
      "  model_90/dense_90/MatMul (19.64k/19.64k flops)\n",
      "  model_90/dense_90/Softmax (50/50 flops)\n",
      "  model_90/dense_90/BiasAdd (10/10 flops)\n",
      "\n",
      "======================End of Report==========================\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "98.612012\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-30 13:41:05.730989: I tensorflow/core/grappler/devices.cc:66] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0\n",
      "2022-04-30 13:41:05.731104: I tensorflow/core/grappler/clusters/single_machine.cc:357] Starting new session\n",
      "2022-04-30 13:41:05.735348: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:1137] Optimization results for grappler item: graph_to_optimize\n",
      "  function_optimizer: function_optimizer did nothing. time = 0.005ms.\n",
      "  function_optimizer: function_optimizer did nothing. time = 0.001ms.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=========================Options=============================\n",
      "-max_depth                  10000\n",
      "-min_bytes                  0\n",
      "-min_peak_bytes             0\n",
      "-min_residual_bytes         0\n",
      "-min_output_bytes           0\n",
      "-min_micros                 0\n",
      "-min_accelerator_micros     0\n",
      "-min_cpu_micros             0\n",
      "-min_params                 0\n",
      "-min_float_ops              1\n",
      "-min_occurrence             0\n",
      "-step                       -1\n",
      "-order_by                   float_ops\n",
      "-account_type_regexes       .*\n",
      "-start_name_regexes         .*\n",
      "-trim_name_regexes          \n",
      "-show_name_regexes          .*\n",
      "-hide_name_regexes          \n",
      "-account_displayed_op_only  true\n",
      "-select                     float_ops\n",
      "-output                     stdout:\n",
      "\n",
      "==================Model Analysis Report======================\n",
      "\n",
      "Doc:\n",
      "scope: The nodes in the model graph are organized by their names, which is hierarchical like filesystem.\n",
      "flops: Number of float operations. Note: Please read the implementation for the math behind it.\n",
      "\n",
      "Profile:\n",
      "node name | # float_ops\n",
      "_TFProfRoot (--/1.46b flops)\n",
      "  model_91/conv2d_1285/Conv2D (182.02m/182.02m flops)\n",
      "  model_91/conv2d_1277/Conv2D (165.53m/165.53m flops)\n",
      "  model_91/conv2d_1282/Conv2D (155.01m/155.01m flops)\n",
      "  model_91/conv2d_1281/Conv2D (131.88m/131.88m flops)\n",
      "  model_91/conv2d_1284/Conv2D (129.69m/129.69m flops)\n",
      "  model_91/conv2d_1279/Conv2D (114.24m/114.24m flops)\n",
      "  model_91/conv2d_1283/Conv2D (109.99m/109.99m flops)\n",
      "  model_91/conv2d_1286/Conv2D (80.64m/80.64m flops)\n",
      "  model_91/conv2d_1278/Conv2D (66.37m/66.37m flops)\n",
      "  model_91/conv2d_1275/Conv2D (65.54m/65.54m flops)\n",
      "  model_91/conv2d_1280/Conv2D (57.46m/57.46m flops)\n",
      "  model_91/conv2d_1276/Conv2D (54.27m/54.27m flops)\n",
      "  model_91/conv2d_1287/Conv2D (39.56m/39.56m flops)\n",
      "  model_91/conv2d_1274/Conv2D (26.21m/26.21m flops)\n",
      "  model_91/depthwise_conv2d_1183/depthwise (14.75m/14.75m flops)\n",
      "  model_91/depthwise_conv2d_1185/depthwise (12.21m/12.21m flops)\n",
      "  model_91/depthwise_conv2d_1187/depthwise (4.90m/4.90m flops)\n",
      "  model_91/depthwise_conv2d_1184/depthwise (4.61m/4.61m flops)\n",
      "  model_91/depthwise_conv2d_1186/depthwise (3.51m/3.51m flops)\n",
      "  model_91/depthwise_conv2d_1190/depthwise (3.47m/3.47m flops)\n",
      "  model_91/depthwise_conv2d_1193/depthwise (3.41m/3.41m flops)\n",
      "  model_91/depthwise_conv2d_1191/depthwise (2.89m/2.89m flops)\n",
      "  model_91/depthwise_conv2d_1189/depthwise (2.46m/2.46m flops)\n",
      "  model_91/depthwise_conv2d_1192/depthwise (2.46m/2.46m flops)\n",
      "  model_91/batch_normalization_2459/FusedBatchNormV3 (2.05m/2.05m flops)\n",
      "  model_91/batch_normalization_2458/FusedBatchNormV3 (1.64m/1.64m flops)\n",
      "  model_91/batch_normalization_2457/FusedBatchNormV3 (1.64m/1.64m flops)\n",
      "  model_91/batch_normalization_2463/FusedBatchNormV3 (1.56m/1.56m flops)\n",
      "  model_91/depthwise_conv2d_1188/depthwise (1.51m/1.51m flops)\n",
      "  model_91/batch_normalization_2461/FusedBatchNormV3 (1.36m/1.36m flops)\n",
      "  model_91/batch_normalization_2462/FusedBatchNormV3 (1.36m/1.36m flops)\n",
      "  model_91/conv2d_1275/BiasAdd (1.02m/1.02m flops)\n",
      "  model_91/depthwise_conv2d_1194/depthwise (864.00k/864.00k flops)\n",
      "  model_91/conv2d_1274/BiasAdd (819.20k/819.20k flops)\n",
      "  model_91/depthwise_conv2d_1183/BiasAdd (819.20k/819.20k flops)\n",
      "  model_91/conv2d_1277/BiasAdd (780.80k/780.80k flops)\n",
      "  model_91/conv2d_1276/BiasAdd (678.40k/678.40k flops)\n",
      "  model_91/depthwise_conv2d_1185/BiasAdd (678.40k/678.40k flops)\n",
      "  model_91/batch_normalization_2467/FusedBatchNormV3 (673.26k/673.26k flops)\n",
      "  model_91/batch_normalization_2465/FusedBatchNormV3 (545.02k/545.02k flops)\n",
      "  model_91/batch_normalization_2466/FusedBatchNormV3 (545.02k/545.02k flops)\n",
      "  model_91/batch_normalization_2460/FusedBatchNormV3 (512.24k/512.24k flops)\n",
      "  model_91/batch_normalization_2464/FusedBatchNormV3 (391.13k/391.13k flops)\n",
      "  model_91/batch_normalization_2471/FusedBatchNormV3 (388.49k/388.49k flops)\n",
      "  model_91/batch_normalization_2472/FusedBatchNormV3 (388.49k/388.49k flops)\n",
      "  model_91/batch_normalization_2479/FusedBatchNormV3 (386.88k/386.88k flops)\n",
      "  model_91/batch_normalization_2478/FusedBatchNormV3 (382.04k/382.04k flops)\n",
      "  model_91/batch_normalization_2477/FusedBatchNormV3 (382.04k/382.04k flops)\n",
      "  model_91/depthwise_conv2d_1195/depthwise (378.00k/378.00k flops)\n",
      "  model_91/conv2d_1279/BiasAdd (336.00k/336.00k flops)\n",
      "  model_91/batch_normalization_2474/FusedBatchNormV3 (324.01k/324.01k flops)\n",
      "  model_91/batch_normalization_2473/FusedBatchNormV3 (324.01k/324.01k flops)\n",
      "  model_91/batch_normalization_2470/FusedBatchNormV3 (275.65k/275.65k flops)\n",
      "  model_91/batch_normalization_2469/FusedBatchNormV3 (275.65k/275.65k flops)\n",
      "  model_91/batch_normalization_2476/FusedBatchNormV3 (275.65k/275.65k flops)\n",
      "  model_91/batch_normalization_2475/FusedBatchNormV3 (275.65k/275.65k flops)\n",
      "  model_91/depthwise_conv2d_1187/BiasAdd (272.00k/272.00k flops)\n",
      "  model_91/conv2d_1278/BiasAdd (272.00k/272.00k flops)\n",
      "  model_91/depthwise_conv2d_1184/BiasAdd (256.00k/256.00k flops)\n",
      "  model_91/depthwise_conv2d_1186/BiasAdd (195.20k/195.20k flops)\n",
      "  model_91/conv2d_1281/BiasAdd (192.80k/192.80k flops)\n",
      "  model_91/depthwise_conv2d_1190/BiasAdd (192.80k/192.80k flops)\n",
      "  model_91/conv2d_1285/BiasAdd (192.00k/192.00k flops)\n",
      "  model_91/depthwise_conv2d_1193/BiasAdd (189.60k/189.60k flops)\n",
      "  model_91/conv2d_1284/BiasAdd (189.60k/189.60k flops)\n",
      "  model_91/batch_normalization_2481/FusedBatchNormV3 (173.04k/173.04k flops)\n",
      "  model_91/batch_normalization_2468/FusedBatchNormV3 (169.26k/169.26k flops)\n",
      "  model_91/conv2d_1282/BiasAdd (160.80k/160.80k flops)\n",
      "  model_91/depthwise_conv2d_1191/BiasAdd (160.80k/160.80k flops)\n",
      "  model_91/conv2d_1280/BiasAdd (136.80k/136.80k flops)\n",
      "  model_91/depthwise_conv2d_1189/BiasAdd (136.80k/136.80k flops)\n",
      "  model_91/conv2d_1283/BiasAdd (136.80k/136.80k flops)\n",
      "  model_91/depthwise_conv2d_1192/BiasAdd (136.80k/136.80k flops)\n",
      "  model_91/batch_normalization_2480/FusedBatchNormV3 (98.88k/98.88k flops)\n",
      "  model_91/conv2d_1286/BiasAdd (84.00k/84.00k flops)\n",
      "  model_91/depthwise_conv2d_1188/BiasAdd (84.00k/84.00k flops)\n",
      "  model_91/batch_normalization_2483/FusedBatchNormV3 (52.75k/52.75k flops)\n",
      "  model_91/depthwise_conv2d_1194/BiasAdd (48.00k/48.00k flops)\n",
      "  model_91/batch_normalization_2482/FusedBatchNormV3 (47.04k/47.04k flops)\n",
      "  model_91/global_average_pooling2d_91/Mean (23.55k/23.55k flops)\n",
      "  model_91/conv2d_1287/BiasAdd (23.55k/23.55k flops)\n",
      "  model_91/depthwise_conv2d_1195/BiasAdd (21.00k/21.00k flops)\n",
      "  model_91/dense_91/MatMul (18.84k/18.84k flops)\n",
      "  model_91/dense_91/Softmax (50/50 flops)\n",
      "  model_91/dense_91/BiasAdd (10/10 flops)\n",
      "\n",
      "======================End of Report==========================\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "94.5935\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-30 13:41:06.770808: I tensorflow/core/grappler/devices.cc:66] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0\n",
      "2022-04-30 13:41:06.770924: I tensorflow/core/grappler/clusters/single_machine.cc:357] Starting new session\n",
      "2022-04-30 13:41:06.775504: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:1137] Optimization results for grappler item: graph_to_optimize\n",
      "  function_optimizer: function_optimizer did nothing. time = 0.006ms.\n",
      "  function_optimizer: function_optimizer did nothing. time = 0ms.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=========================Options=============================\n",
      "-max_depth                  10000\n",
      "-min_bytes                  0\n",
      "-min_peak_bytes             0\n",
      "-min_residual_bytes         0\n",
      "-min_output_bytes           0\n",
      "-min_micros                 0\n",
      "-min_accelerator_micros     0\n",
      "-min_cpu_micros             0\n",
      "-min_params                 0\n",
      "-min_float_ops              1\n",
      "-min_occurrence             0\n",
      "-step                       -1\n",
      "-order_by                   float_ops\n",
      "-account_type_regexes       .*\n",
      "-start_name_regexes         .*\n",
      "-trim_name_regexes          \n",
      "-show_name_regexes          .*\n",
      "-hide_name_regexes          \n",
      "-account_displayed_op_only  true\n",
      "-select                     float_ops\n",
      "-output                     stdout:\n",
      "\n",
      "==================Model Analysis Report======================\n",
      "\n",
      "Doc:\n",
      "scope: The nodes in the model graph are organized by their names, which is hierarchical like filesystem.\n",
      "flops: Number of float operations. Note: Please read the implementation for the math behind it.\n",
      "\n",
      "Profile:\n",
      "node name | # float_ops\n",
      "_TFProfRoot (--/1.18b flops)\n",
      "  model_92/conv2d_1291/Conv2D (193.54m/193.54m flops)\n",
      "  model_92/conv2d_1293/Conv2D (125.57m/125.57m flops)\n",
      "  model_92/conv2d_1298/Conv2D (116.50m/116.50m flops)\n",
      "  model_92/conv2d_1297/Conv2D (88.71m/88.71m flops)\n",
      "  model_92/conv2d_1296/Conv2D (86.59m/86.59m flops)\n",
      "  model_92/conv2d_1299/Conv2D (85.80m/85.80m flops)\n",
      "  model_92/conv2d_1292/Conv2D (72.58m/72.58m flops)\n",
      "  model_92/conv2d_1295/Conv2D (61.55m/61.55m flops)\n",
      "  model_92/conv2d_1289/Conv2D (55.71m/55.71m flops)\n",
      "  model_92/conv2d_1290/Conv2D (52.22m/52.22m flops)\n",
      "  model_92/conv2d_1301/Conv2D (48.87m/48.87m flops)\n",
      "  model_92/conv2d_1300/Conv2D (47.43m/47.43m flops)\n",
      "  model_92/conv2d_1294/Conv2D (41.16m/41.16m flops)\n",
      "  model_92/conv2d_1288/Conv2D (26.21m/26.21m flops)\n",
      "  model_92/depthwise_conv2d_1196/depthwise (14.75m/14.75m flops)\n",
      "  model_92/depthwise_conv2d_1198/depthwise (13.82m/13.82m flops)\n",
      "  model_92/depthwise_conv2d_1200/depthwise (5.18m/5.18m flops)\n",
      "  model_92/depthwise_conv2d_1197/depthwise (3.92m/3.92m flops)\n",
      "  model_92/depthwise_conv2d_1199/depthwise (3.63m/3.63m flops)\n",
      "  model_92/depthwise_conv2d_1206/depthwise (3.14m/3.14m flops)\n",
      "  model_92/depthwise_conv2d_1205/depthwise (2.40m/2.40m flops)\n",
      "  model_92/depthwise_conv2d_1204/depthwise (2.39m/2.39m flops)\n",
      "  model_92/depthwise_conv2d_1203/depthwise (2.35m/2.35m flops)\n",
      "  model_92/batch_normalization_2486/FusedBatchNormV3 (1.74m/1.74m flops)\n",
      "  model_92/depthwise_conv2d_1202/depthwise (1.70m/1.70m flops)\n",
      "  model_92/batch_normalization_2485/FusedBatchNormV3 (1.64m/1.64m flops)\n",
      "  model_92/batch_normalization_2484/FusedBatchNormV3 (1.64m/1.64m flops)\n",
      "  model_92/batch_normalization_2490/FusedBatchNormV3 (1.61m/1.61m flops)\n",
      "  model_92/depthwise_conv2d_1201/depthwise (1.57m/1.57m flops)\n",
      "  model_92/batch_normalization_2488/FusedBatchNormV3 (1.54m/1.54m flops)\n",
      "  model_92/batch_normalization_2489/FusedBatchNormV3 (1.54m/1.54m flops)\n",
      "  model_92/conv2d_1289/BiasAdd (870.40k/870.40k flops)\n",
      "  model_92/conv2d_1288/BiasAdd (819.20k/819.20k flops)\n",
      "  model_92/depthwise_conv2d_1196/BiasAdd (819.20k/819.20k flops)\n",
      "  model_92/conv2d_1291/BiasAdd (806.40k/806.40k flops)\n",
      "  model_92/conv2d_1290/BiasAdd (768.00k/768.00k flops)\n",
      "  model_92/depthwise_conv2d_1198/BiasAdd (768.00k/768.00k flops)\n",
      "  model_92/batch_normalization_2494/FusedBatchNormV3 (698.91k/698.91k flops)\n",
      "  model_92/batch_normalization_2493/FusedBatchNormV3 (577.08k/577.08k flops)\n",
      "  model_92/batch_normalization_2492/FusedBatchNormV3 (577.08k/577.08k flops)\n",
      "  model_92/depthwise_conv2d_1207/depthwise (442.80k/442.80k flops)\n",
      "  model_92/batch_normalization_2487/FusedBatchNormV3 (435.40k/435.40k flops)\n",
      "  model_92/depthwise_conv2d_1208/depthwise (433.80k/433.80k flops)\n",
      "  model_92/batch_normalization_2491/FusedBatchNormV3 (403.96k/403.96k flops)\n",
      "  model_92/batch_normalization_2505/FusedBatchNormV3 (351.42k/351.42k flops)\n",
      "  model_92/batch_normalization_2504/FusedBatchNormV3 (351.42k/351.42k flops)\n",
      "  model_92/conv2d_1293/BiasAdd (348.80k/348.80k flops)\n",
      "  model_92/conv2d_1292/BiasAdd (288.00k/288.00k flops)\n",
      "  model_92/depthwise_conv2d_1200/BiasAdd (288.00k/288.00k flops)\n",
      "  model_92/batch_normalization_2502/FusedBatchNormV3 (269.20k/269.20k flops)\n",
      "  model_92/batch_normalization_2503/FusedBatchNormV3 (269.20k/269.20k flops)\n",
      "  model_92/batch_normalization_2500/FusedBatchNormV3 (267.59k/267.59k flops)\n",
      "  model_92/batch_normalization_2501/FusedBatchNormV3 (267.59k/267.59k flops)\n",
      "  model_92/batch_normalization_2499/FusedBatchNormV3 (262.76k/262.76k flops)\n",
      "  model_92/batch_normalization_2498/FusedBatchNormV3 (262.76k/262.76k flops)\n",
      "  model_92/depthwise_conv2d_1197/BiasAdd (217.60k/217.60k flops)\n",
      "  model_92/depthwise_conv2d_1199/BiasAdd (201.60k/201.60k flops)\n",
      "  model_92/batch_normalization_2508/FusedBatchNormV3 (198.58k/198.58k flops)\n",
      "  model_92/batch_normalization_2506/FusedBatchNormV3 (198.28k/198.28k flops)\n",
      "  model_92/batch_normalization_2497/FusedBatchNormV3 (190.22k/190.22k flops)\n",
      "  model_92/batch_normalization_2496/FusedBatchNormV3 (190.22k/190.22k flops)\n",
      "  model_92/batch_normalization_2495/FusedBatchNormV3 (175.71k/175.71k flops)\n",
      "  model_92/depthwise_conv2d_1206/BiasAdd (174.40k/174.40k flops)\n",
      "  model_92/conv2d_1298/BiasAdd (174.40k/174.40k flops)\n",
      "  model_92/conv2d_1297/BiasAdd (133.60k/133.60k flops)\n",
      "  model_92/depthwise_conv2d_1205/BiasAdd (133.60k/133.60k flops)\n",
      "  model_92/conv2d_1296/BiasAdd (132.80k/132.80k flops)\n",
      "  model_92/depthwise_conv2d_1204/BiasAdd (132.80k/132.80k flops)\n",
      "  model_92/conv2d_1295/BiasAdd (130.40k/130.40k flops)\n",
      "  model_92/depthwise_conv2d_1203/BiasAdd (130.40k/130.40k flops)\n",
      "  model_92/conv2d_1299/BiasAdd (98.40k/98.40k flops)\n",
      "  model_92/conv2d_1300/BiasAdd (96.40k/96.40k flops)\n",
      "  model_92/depthwise_conv2d_1202/BiasAdd (94.40k/94.40k flops)\n",
      "  model_92/conv2d_1294/BiasAdd (94.40k/94.40k flops)\n",
      "  model_92/depthwise_conv2d_1201/BiasAdd (87.20k/87.20k flops)\n",
      "  model_92/batch_normalization_2510/FusedBatchNormV3 (56.78k/56.78k flops)\n",
      "  model_92/batch_normalization_2509/FusedBatchNormV3 (53.98k/53.98k flops)\n",
      "  model_92/batch_normalization_2507/FusedBatchNormV3 (50.68k/50.68k flops)\n",
      "  model_92/global_average_pooling2d_92/Mean (25.35k/25.35k flops)\n",
      "  model_92/conv2d_1301/BiasAdd (25.35k/25.35k flops)\n",
      "  model_92/depthwise_conv2d_1207/BiasAdd (24.60k/24.60k flops)\n",
      "  model_92/depthwise_conv2d_1208/BiasAdd (24.10k/24.10k flops)\n",
      "  model_92/dense_92/MatMul (20.28k/20.28k flops)\n",
      "  model_92/dense_92/Softmax (50/50 flops)\n",
      "  model_92/dense_92/BiasAdd (10/10 flops)\n",
      "\n",
      "======================End of Report==========================\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "94.831764\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-30 13:41:07.684579: I tensorflow/core/grappler/devices.cc:66] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0\n",
      "2022-04-30 13:41:07.684694: I tensorflow/core/grappler/clusters/single_machine.cc:357] Starting new session\n",
      "2022-04-30 13:41:07.688862: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:1137] Optimization results for grappler item: graph_to_optimize\n",
      "  function_optimizer: function_optimizer did nothing. time = 0.005ms.\n",
      "  function_optimizer: function_optimizer did nothing. time = 0.001ms.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=========================Options=============================\n",
      "-max_depth                  10000\n",
      "-min_bytes                  0\n",
      "-min_peak_bytes             0\n",
      "-min_residual_bytes         0\n",
      "-min_output_bytes           0\n",
      "-min_micros                 0\n",
      "-min_accelerator_micros     0\n",
      "-min_cpu_micros             0\n",
      "-min_params                 0\n",
      "-min_float_ops              1\n",
      "-min_occurrence             0\n",
      "-step                       -1\n",
      "-order_by                   float_ops\n",
      "-account_type_regexes       .*\n",
      "-start_name_regexes         .*\n",
      "-trim_name_regexes          \n",
      "-show_name_regexes          .*\n",
      "-hide_name_regexes          \n",
      "-account_displayed_op_only  true\n",
      "-select                     float_ops\n",
      "-output                     stdout:\n",
      "\n",
      "==================Model Analysis Report======================\n",
      "\n",
      "Doc:\n",
      "scope: The nodes in the model graph are organized by their names, which is hierarchical like filesystem.\n",
      "flops: Number of float operations. Note: Please read the implementation for the math behind it.\n",
      "\n",
      "Profile:\n",
      "node name | # float_ops\n",
      "_TFProfRoot (--/1.07b flops)\n",
      "  model_93/conv2d_1310/Conv2D (185.08m/185.08m flops)\n",
      "  model_93/conv2d_1305/Conv2D (135.48m/135.48m flops)\n",
      "  model_93/conv2d_1303/Conv2D (95.03m/95.03m flops)\n",
      "  model_93/conv2d_1311/Conv2D (86.73m/86.73m flops)\n",
      "  model_93/conv2d_1313/Conv2D (73.23m/73.23m flops)\n",
      "  model_93/conv2d_1304/Conv2D (72.76m/72.76m flops)\n",
      "  model_93/conv2d_1309/Conv2D (71.89m/71.89m flops)\n",
      "  model_93/conv2d_1307/Conv2D (63.08m/63.08m flops)\n",
      "  model_93/conv2d_1314/Conv2D (50.15m/50.15m flops)\n",
      "  model_93/conv2d_1312/Conv2D (41.22m/41.22m flops)\n",
      "  model_93/conv2d_1306/Conv2D (38.71m/38.71m flops)\n",
      "  model_93/conv2d_1308/Conv2D (26.47m/26.47m flops)\n",
      "  model_93/conv2d_1302/Conv2D (26.21m/26.21m flops)\n",
      "  model_93/conv2d_1315/Conv2D (23.00m/23.00m flops)\n",
      "  model_93/depthwise_conv2d_1209/depthwise (14.75m/14.75m flops)\n",
      "  model_93/depthwise_conv2d_1211/depthwise (11.29m/11.29m flops)\n",
      "  model_93/depthwise_conv2d_1210/depthwise (6.68m/6.68m flops)\n",
      "  model_93/depthwise_conv2d_1217/depthwise (3.48m/3.48m flops)\n",
      "  model_93/depthwise_conv2d_1216/depthwise (3.44m/3.44m flops)\n",
      "  model_93/depthwise_conv2d_1213/depthwise (3.23m/3.23m flops)\n",
      "  model_93/depthwise_conv2d_1212/depthwise (3.11m/3.11m flops)\n",
      "  model_93/batch_normalization_2513/FusedBatchNormV3 (2.97m/2.97m flops)\n",
      "  model_93/depthwise_conv2d_1219/depthwise (1.66m/1.66m flops)\n",
      "  model_93/batch_normalization_2512/FusedBatchNormV3 (1.64m/1.64m flops)\n",
      "  model_93/batch_normalization_2511/FusedBatchNormV3 (1.64m/1.64m flops)\n",
      "  model_93/depthwise_conv2d_1218/depthwise (1.61m/1.61m flops)\n",
      "  model_93/conv2d_1303/BiasAdd (1.48m/1.48m flops)\n",
      "  model_93/batch_normalization_2517/FusedBatchNormV3 (1.38m/1.38m flops)\n",
      "  model_93/depthwise_conv2d_1215/depthwise (1.35m/1.35m flops)\n",
      "  model_93/depthwise_conv2d_1214/depthwise (1.27m/1.27m flops)\n",
      "  model_93/batch_normalization_2516/FusedBatchNormV3 (1.25m/1.25m flops)\n",
      "  model_93/batch_normalization_2515/FusedBatchNormV3 (1.25m/1.25m flops)\n",
      "  model_93/depthwise_conv2d_1209/BiasAdd (819.20k/819.20k flops)\n",
      "  model_93/conv2d_1302/BiasAdd (819.20k/819.20k flops)\n",
      "  model_93/batch_normalization_2514/FusedBatchNormV3 (742.75k/742.75k flops)\n",
      "  model_93/depthwise_conv2d_1220/depthwise (716.40k/716.40k flops)\n",
      "  model_93/conv2d_1305/BiasAdd (691.20k/691.20k flops)\n",
      "  model_93/depthwise_conv2d_1211/BiasAdd (627.20k/627.20k flops)\n",
      "  model_93/conv2d_1304/BiasAdd (627.20k/627.20k flops)\n",
      "  model_93/batch_normalization_2521/FusedBatchNormV3 (564.26k/564.26k flops)\n",
      "  model_93/batch_normalization_2528/FusedBatchNormV3 (390.10k/390.10k flops)\n",
      "  model_93/batch_normalization_2527/FusedBatchNormV3 (390.10k/390.10k flops)\n",
      "  model_93/batch_normalization_2525/FusedBatchNormV3 (385.27k/385.27k flops)\n",
      "  model_93/batch_normalization_2526/FusedBatchNormV3 (385.27k/385.27k flops)\n",
      "  model_93/depthwise_conv2d_1210/BiasAdd (371.20k/371.20k flops)\n",
      "  model_93/batch_normalization_2519/FusedBatchNormV3 (359.07k/359.07k flops)\n",
      "  model_93/batch_normalization_2520/FusedBatchNormV3 (359.07k/359.07k flops)\n",
      "  model_93/batch_normalization_2518/FusedBatchNormV3 (346.25k/346.25k flops)\n",
      "  model_93/batch_normalization_2533/FusedBatchNormV3 (320.79k/320.79k flops)\n",
      "  model_93/depthwise_conv2d_1221/depthwise (283.50k/283.50k flops)\n",
      "  model_93/conv2d_1307/BiasAdd (281.60k/281.60k flops)\n",
      "  model_93/depthwise_conv2d_1217/BiasAdd (193.60k/193.60k flops)\n",
      "  model_93/conv2d_1310/BiasAdd (193.60k/193.60k flops)\n",
      "  model_93/conv2d_1309/BiasAdd (191.20k/191.20k flops)\n",
      "  model_93/depthwise_conv2d_1216/BiasAdd (191.20k/191.20k flops)\n",
      "  model_93/batch_normalization_2532/FusedBatchNormV3 (185.38k/185.38k flops)\n",
      "  model_93/batch_normalization_2531/FusedBatchNormV3 (185.38k/185.38k flops)\n",
      "  model_93/batch_normalization_2530/FusedBatchNormV3 (180.54k/180.54k flops)\n",
      "  model_93/batch_normalization_2529/FusedBatchNormV3 (180.54k/180.54k flops)\n",
      "  model_93/conv2d_1306/BiasAdd (179.20k/179.20k flops)\n",
      "  model_93/depthwise_conv2d_1213/BiasAdd (179.20k/179.20k flops)\n",
      "  model_93/depthwise_conv2d_1212/BiasAdd (172.80k/172.80k flops)\n",
      "  model_93/conv2d_1313/BiasAdd (159.20k/159.20k flops)\n",
      "  model_93/batch_normalization_2523/FusedBatchNormV3 (151.53k/151.53k flops)\n",
      "  model_93/batch_normalization_2524/FusedBatchNormV3 (151.53k/151.53k flops)\n",
      "  model_93/batch_normalization_2522/FusedBatchNormV3 (141.86k/141.86k flops)\n",
      "  model_93/batch_normalization_2535/FusedBatchNormV3 (129.78k/129.78k flops)\n",
      "  model_93/depthwise_conv2d_1219/BiasAdd (92.00k/92.00k flops)\n",
      "  model_93/conv2d_1312/BiasAdd (92.00k/92.00k flops)\n",
      "  model_93/conv2d_1311/BiasAdd (89.60k/89.60k flops)\n",
      "  model_93/depthwise_conv2d_1218/BiasAdd (89.60k/89.60k flops)\n",
      "  model_93/batch_normalization_2534/FusedBatchNormV3 (81.99k/81.99k flops)\n",
      "  model_93/depthwise_conv2d_1215/BiasAdd (75.20k/75.20k flops)\n",
      "  model_93/conv2d_1308/BiasAdd (75.20k/75.20k flops)\n",
      "  model_93/depthwise_conv2d_1214/BiasAdd (70.40k/70.40k flops)\n",
      "  model_93/conv2d_1314/BiasAdd (63.00k/63.00k flops)\n",
      "  model_93/batch_normalization_2537/FusedBatchNormV3 (40.88k/40.88k flops)\n",
      "  model_93/depthwise_conv2d_1220/BiasAdd (39.80k/39.80k flops)\n",
      "  model_93/batch_normalization_2536/FusedBatchNormV3 (35.28k/35.28k flops)\n",
      "  model_93/conv2d_1315/BiasAdd (18.25k/18.25k flops)\n",
      "  model_93/global_average_pooling2d_93/Mean (18.25k/18.25k flops)\n",
      "  model_93/depthwise_conv2d_1221/BiasAdd (15.75k/15.75k flops)\n",
      "  model_93/dense_93/MatMul (14.60k/14.60k flops)\n",
      "  model_93/dense_93/Softmax (50/50 flops)\n",
      "  model_93/dense_93/BiasAdd (10/10 flops)\n",
      "\n",
      "======================End of Report==========================\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "91.430332\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-30 13:41:08.716325: I tensorflow/core/grappler/devices.cc:66] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0\n",
      "2022-04-30 13:41:08.716441: I tensorflow/core/grappler/clusters/single_machine.cc:357] Starting new session\n",
      "2022-04-30 13:41:08.721333: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:1137] Optimization results for grappler item: graph_to_optimize\n",
      "  function_optimizer: function_optimizer did nothing. time = 0.007ms.\n",
      "  function_optimizer: function_optimizer did nothing. time = 0.001ms.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=========================Options=============================\n",
      "-max_depth                  10000\n",
      "-min_bytes                  0\n",
      "-min_peak_bytes             0\n",
      "-min_residual_bytes         0\n",
      "-min_output_bytes           0\n",
      "-min_micros                 0\n",
      "-min_accelerator_micros     0\n",
      "-min_cpu_micros             0\n",
      "-min_params                 0\n",
      "-min_float_ops              1\n",
      "-min_occurrence             0\n",
      "-step                       -1\n",
      "-order_by                   float_ops\n",
      "-account_type_regexes       .*\n",
      "-start_name_regexes         .*\n",
      "-trim_name_regexes          \n",
      "-show_name_regexes          .*\n",
      "-hide_name_regexes          \n",
      "-account_displayed_op_only  true\n",
      "-select                     float_ops\n",
      "-output                     stdout:\n",
      "\n",
      "==================Model Analysis Report======================\n",
      "\n",
      "Doc:\n",
      "scope: The nodes in the model graph are organized by their names, which is hierarchical like filesystem.\n",
      "flops: Number of float operations. Note: Please read the implementation for the math behind it.\n",
      "\n",
      "Profile:\n",
      "node name | # float_ops\n",
      "_TFProfRoot (--/1.47b flops)\n",
      "  model_94/conv2d_1326/Conv2D (173.00m/173.00m flops)\n",
      "  model_94/conv2d_1325/Conv2D (158.72m/158.72m flops)\n",
      "  model_94/conv2d_1324/Conv2D (158.08m/158.08m flops)\n",
      "  model_94/conv2d_1321/Conv2D (156.26m/156.26m flops)\n",
      "  model_94/conv2d_1323/Conv2D (155.71m/155.71m flops)\n",
      "  model_94/conv2d_1327/Conv2D (144.40m/144.40m flops)\n",
      "  model_94/conv2d_1319/Conv2D (88.88m/88.88m flops)\n",
      "  model_94/conv2d_1320/Conv2D (86.50m/86.50m flops)\n",
      "  model_94/conv2d_1322/Conv2D (70.60m/70.60m flops)\n",
      "  model_94/conv2d_1328/Conv2D (61.93m/61.93m flops)\n",
      "  model_94/conv2d_1317/Conv2D (52.43m/52.43m flops)\n",
      "  model_94/conv2d_1329/Conv2D (38.22m/38.22m flops)\n",
      "  model_94/conv2d_1316/Conv2D (26.21m/26.21m flops)\n",
      "  model_94/conv2d_1318/Conv2D (22.94m/22.94m flops)\n",
      "  model_94/depthwise_conv2d_1222/depthwise (14.75m/14.75m flops)\n",
      "  model_94/depthwise_conv2d_1224/depthwise (6.45m/6.45m flops)\n",
      "  model_94/depthwise_conv2d_1226/depthwise (6.28m/6.28m flops)\n",
      "  model_94/depthwise_conv2d_1223/depthwise (3.69m/3.69m flops)\n",
      "  model_94/depthwise_conv2d_1225/depthwise (3.57m/3.57m flops)\n",
      "  model_94/depthwise_conv2d_1231/depthwise (3.57m/3.57m flops)\n",
      "  model_94/depthwise_conv2d_1229/depthwise (3.56m/3.56m flops)\n",
      "  model_94/depthwise_conv2d_1232/depthwise (3.14m/3.14m flops)\n",
      "  model_94/depthwise_conv2d_1230/depthwise (2.88m/2.88m flops)\n",
      "  model_94/depthwise_conv2d_1228/depthwise (2.84m/2.84m flops)\n",
      "  model_94/batch_normalization_2539/FusedBatchNormV3 (1.64m/1.64m flops)\n",
      "  model_94/batch_normalization_2538/FusedBatchNormV3 (1.64m/1.64m flops)\n",
      "  model_94/batch_normalization_2540/FusedBatchNormV3 (1.64m/1.64m flops)\n",
      "  model_94/depthwise_conv2d_1227/depthwise (1.61m/1.61m flops)\n",
      "  model_94/batch_normalization_2544/FusedBatchNormV3 (1.59m/1.59m flops)\n",
      "  model_94/conv2d_1316/BiasAdd (819.20k/819.20k flops)\n",
      "  model_94/conv2d_1317/BiasAdd (819.20k/819.20k flops)\n",
      "  model_94/depthwise_conv2d_1222/BiasAdd (819.20k/819.20k flops)\n",
      "  model_94/conv2d_1319/BiasAdd (793.60k/793.60k flops)\n",
      "  model_94/depthwise_conv2d_1233/depthwise (745.20k/745.20k flops)\n",
      "  model_94/batch_normalization_2548/FusedBatchNormV3 (718.14k/718.14k flops)\n",
      "  model_94/batch_normalization_2543/FusedBatchNormV3 (717.14k/717.14k flops)\n",
      "  model_94/batch_normalization_2542/FusedBatchNormV3 (717.14k/717.14k flops)\n",
      "  model_94/batch_normalization_2546/FusedBatchNormV3 (698.91k/698.91k flops)\n",
      "  model_94/batch_normalization_2547/FusedBatchNormV3 (698.91k/698.91k flops)\n",
      "  model_94/batch_normalization_2541/FusedBatchNormV3 (409.79k/409.79k flops)\n",
      "  model_94/batch_normalization_2556/FusedBatchNormV3 (399.78k/399.78k flops)\n",
      "  model_94/batch_normalization_2557/FusedBatchNormV3 (399.78k/399.78k flops)\n",
      "  model_94/batch_normalization_2553/FusedBatchNormV3 (398.16k/398.16k flops)\n",
      "  model_94/batch_normalization_2552/FusedBatchNormV3 (398.16k/398.16k flops)\n",
      "  model_94/batch_normalization_2545/FusedBatchNormV3 (397.54k/397.54k flops)\n",
      "  model_94/conv2d_1321/BiasAdd (358.40k/358.40k flops)\n",
      "  model_94/conv2d_1318/BiasAdd (358.40k/358.40k flops)\n",
      "  model_94/depthwise_conv2d_1224/BiasAdd (358.40k/358.40k flops)\n",
      "  model_94/batch_normalization_2558/FusedBatchNormV3 (351.42k/351.42k flops)\n",
      "  model_94/batch_normalization_2559/FusedBatchNormV3 (351.42k/351.42k flops)\n",
      "  model_94/conv2d_1320/BiasAdd (348.80k/348.80k flops)\n",
      "  model_94/depthwise_conv2d_1226/BiasAdd (348.80k/348.80k flops)\n",
      "  model_94/depthwise_conv2d_1234/depthwise (336.60k/336.60k flops)\n",
      "  model_94/batch_normalization_2560/FusedBatchNormV3 (333.68k/333.68k flops)\n",
      "  model_94/batch_normalization_2554/FusedBatchNormV3 (322.40k/322.40k flops)\n",
      "  model_94/batch_normalization_2555/FusedBatchNormV3 (322.40k/322.40k flops)\n",
      "  model_94/batch_normalization_2550/FusedBatchNormV3 (317.56k/317.56k flops)\n",
      "  model_94/batch_normalization_2551/FusedBatchNormV3 (317.56k/317.56k flops)\n",
      "  model_94/depthwise_conv2d_1223/BiasAdd (204.80k/204.80k flops)\n",
      "  model_94/depthwise_conv2d_1231/BiasAdd (198.40k/198.40k flops)\n",
      "  model_94/depthwise_conv2d_1225/BiasAdd (198.40k/198.40k flops)\n",
      "  model_94/conv2d_1325/BiasAdd (198.40k/198.40k flops)\n",
      "  model_94/depthwise_conv2d_1229/BiasAdd (197.60k/197.60k flops)\n",
      "  model_94/conv2d_1323/BiasAdd (197.60k/197.60k flops)\n",
      "  model_94/batch_normalization_2549/FusedBatchNormV3 (180.54k/180.54k flops)\n",
      "  model_94/depthwise_conv2d_1232/BiasAdd (174.40k/174.40k flops)\n",
      "  model_94/conv2d_1326/BiasAdd (174.40k/174.40k flops)\n",
      "  model_94/conv2d_1327/BiasAdd (165.60k/165.60k flops)\n",
      "  model_94/depthwise_conv2d_1230/BiasAdd (160.00k/160.00k flops)\n",
      "  model_94/conv2d_1324/BiasAdd (160.00k/160.00k flops)\n",
      "  model_94/depthwise_conv2d_1228/BiasAdd (157.60k/157.60k flops)\n",
      "  model_94/conv2d_1322/BiasAdd (157.60k/157.60k flops)\n",
      "  model_94/batch_normalization_2562/FusedBatchNormV3 (154.09k/154.09k flops)\n",
      "  model_94/depthwise_conv2d_1227/BiasAdd (89.60k/89.60k flops)\n",
      "  model_94/batch_normalization_2561/FusedBatchNormV3 (85.28k/85.28k flops)\n",
      "  model_94/conv2d_1328/BiasAdd (74.80k/74.80k flops)\n",
      "  model_94/batch_normalization_2564/FusedBatchNormV3 (57.23k/57.23k flops)\n",
      "  model_94/batch_normalization_2563/FusedBatchNormV3 (41.89k/41.89k flops)\n",
      "  model_94/depthwise_conv2d_1233/BiasAdd (41.40k/41.40k flops)\n",
      "  model_94/global_average_pooling2d_94/Mean (25.55k/25.55k flops)\n",
      "  model_94/conv2d_1329/BiasAdd (25.55k/25.55k flops)\n",
      "  model_94/dense_94/MatMul (20.44k/20.44k flops)\n",
      "  model_94/depthwise_conv2d_1234/BiasAdd (18.70k/18.70k flops)\n",
      "  model_94/dense_94/Softmax (50/50 flops)\n",
      "  model_94/dense_94/BiasAdd (10/10 flops)\n",
      "\n",
      "======================End of Report==========================\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "95.63446\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-30 13:41:09.671032: I tensorflow/core/grappler/devices.cc:66] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0\n",
      "2022-04-30 13:41:09.671146: I tensorflow/core/grappler/clusters/single_machine.cc:357] Starting new session\n",
      "2022-04-30 13:41:09.675483: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:1137] Optimization results for grappler item: graph_to_optimize\n",
      "  function_optimizer: function_optimizer did nothing. time = 0.005ms.\n",
      "  function_optimizer: function_optimizer did nothing. time = 0.001ms.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=========================Options=============================\n",
      "-max_depth                  10000\n",
      "-min_bytes                  0\n",
      "-min_peak_bytes             0\n",
      "-min_residual_bytes         0\n",
      "-min_output_bytes           0\n",
      "-min_micros                 0\n",
      "-min_accelerator_micros     0\n",
      "-min_cpu_micros             0\n",
      "-min_params                 0\n",
      "-min_float_ops              1\n",
      "-min_occurrence             0\n",
      "-step                       -1\n",
      "-order_by                   float_ops\n",
      "-account_type_regexes       .*\n",
      "-start_name_regexes         .*\n",
      "-trim_name_regexes          \n",
      "-show_name_regexes          .*\n",
      "-hide_name_regexes          \n",
      "-account_displayed_op_only  true\n",
      "-select                     float_ops\n",
      "-output                     stdout:\n",
      "\n",
      "==================Model Analysis Report======================\n",
      "\n",
      "Doc:\n",
      "scope: The nodes in the model graph are organized by their names, which is hierarchical like filesystem.\n",
      "flops: Number of float operations. Note: Please read the implementation for the math behind it.\n",
      "\n",
      "Profile:\n",
      "node name | # float_ops\n",
      "_TFProfRoot (--/1.60b flops)\n",
      "  model_95/conv2d_1341/Conv2D (202.40m/202.40m flops)\n",
      "  model_95/conv2d_1340/Conv2D (193.49m/193.49m flops)\n",
      "  model_95/conv2d_1338/Conv2D (192.08m/192.08m flops)\n",
      "  model_95/conv2d_1339/Conv2D (188.14m/188.14m flops)\n",
      "  model_95/conv2d_1337/Conv2D (185.83m/185.83m flops)\n",
      "  model_95/conv2d_1335/Conv2D (93.63m/93.63m flops)\n",
      "  model_95/conv2d_1333/Conv2D (93.39m/93.39m flops)\n",
      "  model_95/conv2d_1342/Conv2D (76.40m/76.40m flops)\n",
      "  model_95/conv2d_1336/Conv2D (72.35m/72.35m flops)\n",
      "  model_95/conv2d_1331/Conv2D (72.09m/72.09m flops)\n",
      "  model_95/conv2d_1334/Conv2D (56.18m/56.18m flops)\n",
      "  model_95/conv2d_1332/Conv2D (36.04m/36.04m flops)\n",
      "  model_95/conv2d_1343/Conv2D (32.62m/32.62m flops)\n",
      "  model_95/conv2d_1330/Conv2D (26.21m/26.21m flops)\n",
      "  model_95/depthwise_conv2d_1235/depthwise (14.75m/14.75m flops)\n",
      "  model_95/depthwise_conv2d_1237/depthwise (7.37m/7.37m flops)\n",
      "  model_95/depthwise_conv2d_1236/depthwise (5.07m/5.07m flops)\n",
      "  model_95/depthwise_conv2d_1239/depthwise (4.44m/4.44m flops)\n",
      "  model_95/depthwise_conv2d_1245/depthwise (3.64m/3.64m flops)\n",
      "  model_95/depthwise_conv2d_1243/depthwise (3.54m/3.54m flops)\n",
      "  model_95/depthwise_conv2d_1242/depthwise (3.51m/3.51m flops)\n",
      "  model_95/depthwise_conv2d_1244/depthwise (3.44m/3.44m flops)\n",
      "  model_95/depthwise_conv2d_1241/depthwise (3.43m/3.43m flops)\n",
      "  model_95/depthwise_conv2d_1238/depthwise (3.28m/3.28m flops)\n",
      "  model_95/batch_normalization_2567/FusedBatchNormV3 (2.25m/2.25m flops)\n",
      "  model_95/batch_normalization_2566/FusedBatchNormV3 (1.64m/1.64m flops)\n",
      "  model_95/batch_normalization_2565/FusedBatchNormV3 (1.64m/1.64m flops)\n",
      "  model_95/batch_normalization_2571/FusedBatchNormV3 (1.46m/1.46m flops)\n",
      "  model_95/depthwise_conv2d_1240/depthwise (1.37m/1.37m flops)\n",
      "  model_95/conv2d_1331/BiasAdd (1.13m/1.13m flops)\n",
      "  model_95/depthwise_conv2d_1246/depthwise (900.00k/900.00k flops)\n",
      "  model_95/batch_normalization_2569/FusedBatchNormV3 (819.58k/819.58k flops)\n",
      "  model_95/batch_normalization_2570/FusedBatchNormV3 (819.58k/819.58k flops)\n",
      "  model_95/conv2d_1330/BiasAdd (819.20k/819.20k flops)\n",
      "  model_95/depthwise_conv2d_1235/BiasAdd (819.20k/819.20k flops)\n",
      "  model_95/conv2d_1333/BiasAdd (729.60k/729.60k flops)\n",
      "  model_95/batch_normalization_2575/FusedBatchNormV3 (609.14k/609.14k flops)\n",
      "  model_95/batch_normalization_2568/FusedBatchNormV3 (563.46k/563.46k flops)\n",
      "  model_95/batch_normalization_2573/FusedBatchNormV3 (493.72k/493.72k flops)\n",
      "  model_95/batch_normalization_2574/FusedBatchNormV3 (493.72k/493.72k flops)\n",
      "  model_95/conv2d_1332/BiasAdd (409.60k/409.60k flops)\n",
      "  model_95/depthwise_conv2d_1237/BiasAdd (409.60k/409.60k flops)\n",
      "  model_95/batch_normalization_2586/FusedBatchNormV3 (407.84k/407.84k flops)\n",
      "  model_95/batch_normalization_2585/FusedBatchNormV3 (407.84k/407.84k flops)\n",
      "  model_95/batch_normalization_2587/FusedBatchNormV3 (403.00k/403.00k flops)\n",
      "  model_95/batch_normalization_2581/FusedBatchNormV3 (396.55k/396.55k flops)\n",
      "  model_95/batch_normalization_2582/FusedBatchNormV3 (396.55k/396.55k flops)\n",
      "  model_95/batch_normalization_2580/FusedBatchNormV3 (393.33k/393.33k flops)\n",
      "  model_95/batch_normalization_2579/FusedBatchNormV3 (393.33k/393.33k flops)\n",
      "  model_95/batch_normalization_2584/FusedBatchNormV3 (385.27k/385.27k flops)\n",
      "  model_95/batch_normalization_2583/FusedBatchNormV3 (385.27k/385.27k flops)\n",
      "  model_95/batch_normalization_2578/FusedBatchNormV3 (383.66k/383.66k flops)\n",
      "  model_95/batch_normalization_2577/FusedBatchNormV3 (383.66k/383.66k flops)\n",
      "  model_95/batch_normalization_2572/FusedBatchNormV3 (365.48k/365.48k flops)\n",
      "  model_95/depthwise_conv2d_1247/depthwise (343.80k/343.80k flops)\n",
      "  model_95/conv2d_1335/BiasAdd (304.00k/304.00k flops)\n",
      "  model_95/depthwise_conv2d_1236/BiasAdd (281.60k/281.60k flops)\n",
      "  model_95/conv2d_1334/BiasAdd (246.40k/246.40k flops)\n",
      "  model_95/depthwise_conv2d_1239/BiasAdd (246.40k/246.40k flops)\n",
      "  model_95/depthwise_conv2d_1245/BiasAdd (202.40k/202.40k flops)\n",
      "  model_95/conv2d_1340/BiasAdd (202.40k/202.40k flops)\n",
      "  model_95/conv2d_1341/BiasAdd (200.00k/200.00k flops)\n",
      "  model_95/depthwise_conv2d_1243/BiasAdd (196.80k/196.80k flops)\n",
      "  model_95/conv2d_1338/BiasAdd (196.80k/196.80k flops)\n",
      "  model_95/conv2d_1337/BiasAdd (195.20k/195.20k flops)\n",
      "  model_95/depthwise_conv2d_1242/BiasAdd (195.20k/195.20k flops)\n",
      "  model_95/conv2d_1339/BiasAdd (191.20k/191.20k flops)\n",
      "  model_95/depthwise_conv2d_1244/BiasAdd (191.20k/191.20k flops)\n",
      "  model_95/depthwise_conv2d_1241/BiasAdd (190.40k/190.40k flops)\n",
      "  model_95/conv2d_1336/BiasAdd (190.40k/190.40k flops)\n",
      "  model_95/depthwise_conv2d_1238/BiasAdd (182.40k/182.40k flops)\n",
      "  model_95/batch_normalization_2589/FusedBatchNormV3 (157.38k/157.38k flops)\n",
      "  model_95/batch_normalization_2576/FusedBatchNormV3 (153.14k/153.14k flops)\n",
      "  model_95/batch_normalization_2588/FusedBatchNormV3 (103.00k/103.00k flops)\n",
      "  model_95/conv2d_1342/BiasAdd (76.40k/76.40k flops)\n",
      "  model_95/depthwise_conv2d_1240/BiasAdd (76.00k/76.00k flops)\n",
      "  model_95/depthwise_conv2d_1246/BiasAdd (50.00k/50.00k flops)\n",
      "  model_95/batch_normalization_2591/FusedBatchNormV3 (47.82k/47.82k flops)\n",
      "  model_95/batch_normalization_2590/FusedBatchNormV3 (42.78k/42.78k flops)\n",
      "  model_95/global_average_pooling2d_95/Mean (21.35k/21.35k flops)\n",
      "  model_95/conv2d_1343/BiasAdd (21.35k/21.35k flops)\n",
      "  model_95/depthwise_conv2d_1247/BiasAdd (19.10k/19.10k flops)\n",
      "  model_95/dense_95/MatMul (17.08k/17.08k flops)\n",
      "  model_95/dense_95/Softmax (50/50 flops)\n",
      "  model_95/dense_95/BiasAdd (10/10 flops)\n",
      "\n",
      "======================End of Report==========================\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "87.988052\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-30 13:41:10.714623: I tensorflow/core/grappler/devices.cc:66] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0\n",
      "2022-04-30 13:41:10.714740: I tensorflow/core/grappler/clusters/single_machine.cc:357] Starting new session\n",
      "2022-04-30 13:41:10.719564: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:1137] Optimization results for grappler item: graph_to_optimize\n",
      "  function_optimizer: function_optimizer did nothing. time = 0.006ms.\n",
      "  function_optimizer: function_optimizer did nothing. time = 0.001ms.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=========================Options=============================\n",
      "-max_depth                  10000\n",
      "-min_bytes                  0\n",
      "-min_peak_bytes             0\n",
      "-min_residual_bytes         0\n",
      "-min_output_bytes           0\n",
      "-min_micros                 0\n",
      "-min_accelerator_micros     0\n",
      "-min_cpu_micros             0\n",
      "-min_params                 0\n",
      "-min_float_ops              1\n",
      "-min_occurrence             0\n",
      "-step                       -1\n",
      "-order_by                   float_ops\n",
      "-account_type_regexes       .*\n",
      "-start_name_regexes         .*\n",
      "-trim_name_regexes          \n",
      "-show_name_regexes          .*\n",
      "-hide_name_regexes          \n",
      "-account_displayed_op_only  true\n",
      "-select                     float_ops\n",
      "-output                     stdout:\n",
      "\n",
      "==================Model Analysis Report======================\n",
      "\n",
      "Doc:\n",
      "scope: The nodes in the model graph are organized by their names, which is hierarchical like filesystem.\n",
      "flops: Number of float operations. Note: Please read the implementation for the math behind it.\n",
      "\n",
      "Profile:\n",
      "node name | # float_ops\n",
      "_TFProfRoot (--/1.37b flops)\n",
      "  model_96/conv2d_1355/Conv2D (170.01m/170.01m flops)\n",
      "  model_96/conv2d_1354/Conv2D (169.27m/169.27m flops)\n",
      "  model_96/conv2d_1353/Conv2D (166.35m/166.35m flops)\n",
      "  model_96/conv2d_1352/Conv2D (163.43m/163.43m flops)\n",
      "  model_96/conv2d_1351/Conv2D (159.85m/159.85m flops)\n",
      "  model_96/conv2d_1347/Conv2D (80.28m/80.28m flops)\n",
      "  model_96/conv2d_1349/Conv2D (76.28m/76.28m flops)\n",
      "  model_96/conv2d_1350/Conv2D (72.07m/72.07m flops)\n",
      "  model_96/conv2d_1356/Conv2D (62.10m/62.10m flops)\n",
      "  model_96/conv2d_1345/Conv2D (58.98m/58.98m flops)\n",
      "  model_96/conv2d_1348/Conv2D (42.29m/42.29m flops)\n",
      "  model_96/conv2d_1344/Conv2D (26.21m/26.21m flops)\n",
      "  model_96/conv2d_1346/Conv2D (25.80m/25.80m flops)\n",
      "  model_96/conv2d_1357/Conv2D (23.80m/23.80m flops)\n",
      "  model_96/depthwise_conv2d_1248/depthwise (14.75m/14.75m flops)\n",
      "  model_96/depthwise_conv2d_1250/depthwise (6.45m/6.45m flops)\n",
      "  model_96/depthwise_conv2d_1249/depthwise (4.15m/4.15m flops)\n",
      "  model_96/depthwise_conv2d_1252/depthwise (3.40m/3.40m flops)\n",
      "  model_96/depthwise_conv2d_1258/depthwise (3.34m/3.34m flops)\n",
      "  model_96/depthwise_conv2d_1256/depthwise (3.28m/3.28m flops)\n",
      "  model_96/depthwise_conv2d_1257/depthwise (3.28m/3.28m flops)\n",
      "  model_96/depthwise_conv2d_1251/depthwise (3.23m/3.23m flops)\n",
      "  model_96/depthwise_conv2d_1255/depthwise (3.23m/3.23m flops)\n",
      "  model_96/depthwise_conv2d_1254/depthwise (3.21m/3.21m flops)\n",
      "  model_96/batch_normalization_2594/FusedBatchNormV3 (1.84m/1.84m flops)\n",
      "  model_96/batch_normalization_2593/FusedBatchNormV3 (1.64m/1.64m flops)\n",
      "  model_96/batch_normalization_2592/FusedBatchNormV3 (1.64m/1.64m flops)\n",
      "  model_96/depthwise_conv2d_1253/depthwise (1.45m/1.45m flops)\n",
      "  model_96/batch_normalization_2598/FusedBatchNormV3 (1.43m/1.43m flops)\n",
      "  model_96/conv2d_1345/BiasAdd (921.60k/921.60k flops)\n",
      "  model_96/depthwise_conv2d_1259/depthwise (824.40k/824.40k flops)\n",
      "  model_96/conv2d_1344/BiasAdd (819.20k/819.20k flops)\n",
      "  model_96/depthwise_conv2d_1248/BiasAdd (819.20k/819.20k flops)\n",
      "  model_96/batch_normalization_2597/FusedBatchNormV3 (717.14k/717.14k flops)\n",
      "  model_96/batch_normalization_2596/FusedBatchNormV3 (717.14k/717.14k flops)\n",
      "  model_96/conv2d_1347/BiasAdd (716.80k/716.80k flops)\n",
      "  model_96/batch_normalization_2602/FusedBatchNormV3 (647.61k/647.61k flops)\n",
      "  model_96/batch_normalization_2595/FusedBatchNormV3 (461.02k/461.02k flops)\n",
      "  model_96/batch_normalization_2601/FusedBatchNormV3 (378.31k/378.31k flops)\n",
      "  model_96/batch_normalization_2600/FusedBatchNormV3 (378.31k/378.31k flops)\n",
      "  model_96/batch_normalization_2612/FusedBatchNormV3 (373.98k/373.98k flops)\n",
      "  model_96/batch_normalization_2613/FusedBatchNormV3 (373.98k/373.98k flops)\n",
      "  model_96/batch_normalization_2614/FusedBatchNormV3 (369.15k/369.15k flops)\n",
      "  model_96/batch_normalization_2608/FusedBatchNormV3 (367.54k/367.54k flops)\n",
      "  model_96/batch_normalization_2609/FusedBatchNormV3 (367.54k/367.54k flops)\n",
      "  model_96/batch_normalization_2610/FusedBatchNormV3 (367.54k/367.54k flops)\n",
      "  model_96/batch_normalization_2611/FusedBatchNormV3 (367.54k/367.54k flops)\n",
      "  model_96/batch_normalization_2607/FusedBatchNormV3 (361.09k/361.09k flops)\n",
      "  model_96/batch_normalization_2606/FusedBatchNormV3 (361.09k/361.09k flops)\n",
      "  model_96/batch_normalization_2605/FusedBatchNormV3 (359.48k/359.48k flops)\n",
      "  model_96/batch_normalization_2604/FusedBatchNormV3 (359.48k/359.48k flops)\n",
      "  model_96/batch_normalization_2599/FusedBatchNormV3 (359.07k/359.07k flops)\n",
      "  model_96/depthwise_conv2d_1250/BiasAdd (358.40k/358.40k flops)\n",
      "  model_96/conv2d_1346/BiasAdd (358.40k/358.40k flops)\n",
      "  model_96/conv2d_1349/BiasAdd (323.20k/323.20k flops)\n",
      "  model_96/depthwise_conv2d_1260/depthwise (305.10k/305.10k flops)\n",
      "  model_96/depthwise_conv2d_1249/BiasAdd (230.40k/230.40k flops)\n",
      "  model_96/depthwise_conv2d_1252/BiasAdd (188.80k/188.80k flops)\n",
      "  model_96/conv2d_1348/BiasAdd (188.80k/188.80k flops)\n",
      "  model_96/depthwise_conv2d_1258/BiasAdd (185.60k/185.60k flops)\n",
      "  model_96/conv2d_1354/BiasAdd (185.60k/185.60k flops)\n",
      "  model_96/conv2d_1355/BiasAdd (183.20k/183.20k flops)\n",
      "  model_96/depthwise_conv2d_1257/BiasAdd (182.40k/182.40k flops)\n",
      "  model_96/conv2d_1353/BiasAdd (182.40k/182.40k flops)\n",
      "  model_96/conv2d_1352/BiasAdd (182.40k/182.40k flops)\n",
      "  model_96/depthwise_conv2d_1256/BiasAdd (182.40k/182.40k flops)\n",
      "  model_96/depthwise_conv2d_1255/BiasAdd (179.20k/179.20k flops)\n",
      "  model_96/depthwise_conv2d_1251/BiasAdd (179.20k/179.20k flops)\n",
      "  model_96/conv2d_1351/BiasAdd (179.20k/179.20k flops)\n",
      "  model_96/conv2d_1350/BiasAdd (178.40k/178.40k flops)\n",
      "  model_96/depthwise_conv2d_1254/BiasAdd (178.40k/178.40k flops)\n",
      "  model_96/batch_normalization_2603/FusedBatchNormV3 (162.81k/162.81k flops)\n",
      "  model_96/batch_normalization_2616/FusedBatchNormV3 (139.67k/139.67k flops)\n",
      "  model_96/batch_normalization_2615/FusedBatchNormV3 (94.35k/94.35k flops)\n",
      "  model_96/depthwise_conv2d_1253/BiasAdd (80.80k/80.80k flops)\n",
      "  model_96/conv2d_1356/BiasAdd (67.80k/67.80k flops)\n",
      "  model_96/depthwise_conv2d_1259/BiasAdd (45.80k/45.80k flops)\n",
      "  model_96/batch_normalization_2618/FusedBatchNormV3 (39.31k/39.31k flops)\n",
      "  model_96/batch_normalization_2617/FusedBatchNormV3 (37.97k/37.97k flops)\n",
      "  model_96/global_average_pooling2d_96/Mean (17.55k/17.55k flops)\n",
      "  model_96/conv2d_1357/BiasAdd (17.55k/17.55k flops)\n",
      "  model_96/depthwise_conv2d_1260/BiasAdd (16.95k/16.95k flops)\n",
      "  model_96/dense_96/MatMul (14.04k/14.04k flops)\n",
      "  model_96/dense_96/Softmax (50/50 flops)\n",
      "  model_96/dense_96/BiasAdd (10/10 flops)\n",
      "\n",
      "======================End of Report==========================\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "93.522732\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-30 13:41:11.648864: I tensorflow/core/grappler/devices.cc:66] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0\n",
      "2022-04-30 13:41:11.648982: I tensorflow/core/grappler/clusters/single_machine.cc:357] Starting new session\n",
      "2022-04-30 13:41:11.653196: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:1137] Optimization results for grappler item: graph_to_optimize\n",
      "  function_optimizer: function_optimizer did nothing. time = 0.004ms.\n",
      "  function_optimizer: function_optimizer did nothing. time = 0.001ms.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=========================Options=============================\n",
      "-max_depth                  10000\n",
      "-min_bytes                  0\n",
      "-min_peak_bytes             0\n",
      "-min_residual_bytes         0\n",
      "-min_output_bytes           0\n",
      "-min_micros                 0\n",
      "-min_accelerator_micros     0\n",
      "-min_cpu_micros             0\n",
      "-min_params                 0\n",
      "-min_float_ops              1\n",
      "-min_occurrence             0\n",
      "-step                       -1\n",
      "-order_by                   float_ops\n",
      "-account_type_regexes       .*\n",
      "-start_name_regexes         .*\n",
      "-trim_name_regexes          \n",
      "-show_name_regexes          .*\n",
      "-hide_name_regexes          \n",
      "-account_displayed_op_only  true\n",
      "-select                     float_ops\n",
      "-output                     stdout:\n",
      "\n",
      "==================Model Analysis Report======================\n",
      "\n",
      "Doc:\n",
      "scope: The nodes in the model graph are organized by their names, which is hierarchical like filesystem.\n",
      "flops: Number of float operations. Note: Please read the implementation for the math behind it.\n",
      "\n",
      "Profile:\n",
      "node name | # float_ops\n",
      "_TFProfRoot (--/1.16b flops)\n",
      "  model_97/conv2d_1369/Conv2D (141.13m/141.13m flops)\n",
      "  model_97/conv2d_1361/Conv2D (124.83m/124.83m flops)\n",
      "  model_97/conv2d_1366/Conv2D (110.09m/110.09m flops)\n",
      "  model_97/conv2d_1367/Conv2D (102.87m/102.87m flops)\n",
      "  model_97/conv2d_1368/Conv2D (100.14m/100.14m flops)\n",
      "  model_97/conv2d_1365/Conv2D (89.01m/89.01m flops)\n",
      "  model_97/conv2d_1359/Conv2D (81.92m/81.92m flops)\n",
      "  model_97/conv2d_1363/Conv2D (78.07m/78.07m flops)\n",
      "  model_97/conv2d_1360/Conv2D (58.88m/58.88m flops)\n",
      "  model_97/conv2d_1370/Conv2D (56.30m/56.30m flops)\n",
      "  model_97/conv2d_1364/Conv2D (52.04m/52.04m flops)\n",
      "  model_97/conv2d_1362/Conv2D (38.67m/38.67m flops)\n",
      "  model_97/conv2d_1358/Conv2D (26.21m/26.21m flops)\n",
      "  model_97/conv2d_1371/Conv2D (22.54m/22.54m flops)\n",
      "  model_97/depthwise_conv2d_1261/depthwise (14.75m/14.75m flops)\n",
      "  model_97/depthwise_conv2d_1263/depthwise (10.60m/10.60m flops)\n",
      "  model_97/depthwise_conv2d_1262/depthwise (5.76m/5.76m flops)\n",
      "  model_97/depthwise_conv2d_1265/depthwise (3.28m/3.28m flops)\n",
      "  model_97/depthwise_conv2d_1264/depthwise (3.05m/3.05m flops)\n",
      "  model_97/depthwise_conv2d_1269/depthwise (2.71m/2.71m flops)\n",
      "  model_97/depthwise_conv2d_1268/depthwise (2.64m/2.64m flops)\n",
      "  model_97/depthwise_conv2d_1271/depthwise (2.64m/2.64m flops)\n",
      "  model_97/batch_normalization_2621/FusedBatchNormV3 (2.56m/2.56m flops)\n",
      "  model_97/depthwise_conv2d_1270/depthwise (2.46m/2.46m flops)\n",
      "  model_97/depthwise_conv2d_1267/depthwise (2.19m/2.19m flops)\n",
      "  model_97/batch_normalization_2620/FusedBatchNormV3 (1.64m/1.64m flops)\n",
      "  model_97/batch_normalization_2619/FusedBatchNormV3 (1.64m/1.64m flops)\n",
      "  model_97/depthwise_conv2d_1266/depthwise (1.54m/1.54m flops)\n",
      "  model_97/batch_normalization_2625/FusedBatchNormV3 (1.36m/1.36m flops)\n",
      "  model_97/conv2d_1359/BiasAdd (1.28m/1.28m flops)\n",
      "  model_97/batch_normalization_2623/FusedBatchNormV3 (1.18m/1.18m flops)\n",
      "  model_97/batch_normalization_2624/FusedBatchNormV3 (1.18m/1.18m flops)\n",
      "  model_97/depthwise_conv2d_1272/depthwise (867.60k/867.60k flops)\n",
      "  model_97/conv2d_1358/BiasAdd (819.20k/819.20k flops)\n",
      "  model_97/depthwise_conv2d_1261/BiasAdd (819.20k/819.20k flops)\n",
      "  model_97/batch_normalization_2629/FusedBatchNormV3 (686.08k/686.08k flops)\n",
      "  model_97/conv2d_1361/BiasAdd (678.40k/678.40k flops)\n",
      "  model_97/batch_normalization_2622/FusedBatchNormV3 (640.30k/640.30k flops)\n",
      "  model_97/conv2d_1360/BiasAdd (588.80k/588.80k flops)\n",
      "  model_97/depthwise_conv2d_1263/BiasAdd (588.80k/588.80k flops)\n",
      "  model_97/batch_normalization_2641/FusedBatchNormV3 (388.49k/388.49k flops)\n",
      "  model_97/batch_normalization_2627/FusedBatchNormV3 (365.48k/365.48k flops)\n",
      "  model_97/batch_normalization_2628/FusedBatchNormV3 (365.48k/365.48k flops)\n",
      "  model_97/conv2d_1363/BiasAdd (342.40k/342.40k flops)\n",
      "  model_97/batch_normalization_2626/FusedBatchNormV3 (339.84k/339.84k flops)\n",
      "  model_97/depthwise_conv2d_1262/BiasAdd (320.00k/320.00k flops)\n",
      "  model_97/batch_normalization_2636/FusedBatchNormV3 (303.06k/303.06k flops)\n",
      "  model_97/batch_normalization_2635/FusedBatchNormV3 (303.06k/303.06k flops)\n",
      "  model_97/batch_normalization_2640/FusedBatchNormV3 (295.00k/295.00k flops)\n",
      "  model_97/batch_normalization_2633/FusedBatchNormV3 (295.00k/295.00k flops)\n",
      "  model_97/batch_normalization_2639/FusedBatchNormV3 (295.00k/295.00k flops)\n",
      "  model_97/batch_normalization_2634/FusedBatchNormV3 (295.00k/295.00k flops)\n",
      "  model_97/batch_normalization_2638/FusedBatchNormV3 (275.65k/275.65k flops)\n",
      "  model_97/batch_normalization_2637/FusedBatchNormV3 (275.65k/275.65k flops)\n",
      "  model_97/depthwise_conv2d_1273/depthwise (262.80k/262.80k flops)\n",
      "  model_97/batch_normalization_2632/FusedBatchNormV3 (245.02k/245.02k flops)\n",
      "  model_97/batch_normalization_2631/FusedBatchNormV3 (245.02k/245.02k flops)\n",
      "  model_97/conv2d_1369/BiasAdd (192.80k/192.80k flops)\n",
      "  model_97/conv2d_1362/BiasAdd (182.40k/182.40k flops)\n",
      "  model_97/depthwise_conv2d_1265/BiasAdd (182.40k/182.40k flops)\n",
      "  model_97/batch_normalization_2630/FusedBatchNormV3 (172.48k/172.48k flops)\n",
      "  model_97/depthwise_conv2d_1264/BiasAdd (169.60k/169.60k flops)\n",
      "  model_97/depthwise_conv2d_1269/BiasAdd (150.40k/150.40k flops)\n",
      "  model_97/conv2d_1366/BiasAdd (150.40k/150.40k flops)\n",
      "  model_97/conv2d_1368/BiasAdd (146.40k/146.40k flops)\n",
      "  model_97/conv2d_1365/BiasAdd (146.40k/146.40k flops)\n",
      "  model_97/depthwise_conv2d_1271/BiasAdd (146.40k/146.40k flops)\n",
      "  model_97/depthwise_conv2d_1268/BiasAdd (146.40k/146.40k flops)\n",
      "  model_97/depthwise_conv2d_1270/BiasAdd (136.80k/136.80k flops)\n",
      "  model_97/conv2d_1367/BiasAdd (136.80k/136.80k flops)\n",
      "  model_97/depthwise_conv2d_1267/BiasAdd (121.60k/121.60k flops)\n",
      "  model_97/conv2d_1364/BiasAdd (121.60k/121.60k flops)\n",
      "  model_97/batch_normalization_2643/FusedBatchNormV3 (120.30k/120.30k flops)\n",
      "  model_97/batch_normalization_2642/FusedBatchNormV3 (99.29k/99.29k flops)\n",
      "  model_97/depthwise_conv2d_1266/BiasAdd (85.60k/85.60k flops)\n",
      "  model_97/conv2d_1370/BiasAdd (58.40k/58.40k flops)\n",
      "  model_97/depthwise_conv2d_1272/BiasAdd (48.20k/48.20k flops)\n",
      "  model_97/batch_normalization_2645/FusedBatchNormV3 (43.23k/43.23k flops)\n",
      "  model_97/batch_normalization_2644/FusedBatchNormV3 (32.70k/32.70k flops)\n",
      "  model_97/global_average_pooling2d_97/Mean (19.30k/19.30k flops)\n",
      "  model_97/conv2d_1371/BiasAdd (19.30k/19.30k flops)\n",
      "  model_97/dense_97/MatMul (15.44k/15.44k flops)\n",
      "  model_97/depthwise_conv2d_1273/BiasAdd (14.60k/14.60k flops)\n",
      "  model_97/dense_97/Softmax (50/50 flops)\n",
      "  model_97/dense_97/BiasAdd (10/10 flops)\n",
      "\n",
      "======================End of Report==========================\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "108.685044\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-30 13:41:12.684671: I tensorflow/core/grappler/devices.cc:66] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0\n",
      "2022-04-30 13:41:12.684789: I tensorflow/core/grappler/clusters/single_machine.cc:357] Starting new session\n",
      "2022-04-30 13:41:12.689809: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:1137] Optimization results for grappler item: graph_to_optimize\n",
      "  function_optimizer: function_optimizer did nothing. time = 0.006ms.\n",
      "  function_optimizer: function_optimizer did nothing. time = 0.001ms.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=========================Options=============================\n",
      "-max_depth                  10000\n",
      "-min_bytes                  0\n",
      "-min_peak_bytes             0\n",
      "-min_residual_bytes         0\n",
      "-min_output_bytes           0\n",
      "-min_micros                 0\n",
      "-min_accelerator_micros     0\n",
      "-min_cpu_micros             0\n",
      "-min_params                 0\n",
      "-min_float_ops              1\n",
      "-min_occurrence             0\n",
      "-step                       -1\n",
      "-order_by                   float_ops\n",
      "-account_type_regexes       .*\n",
      "-start_name_regexes         .*\n",
      "-trim_name_regexes          \n",
      "-show_name_regexes          .*\n",
      "-hide_name_regexes          \n",
      "-account_displayed_op_only  true\n",
      "-select                     float_ops\n",
      "-output                     stdout:\n",
      "\n",
      "==================Model Analysis Report======================\n",
      "\n",
      "Doc:\n",
      "scope: The nodes in the model graph are organized by their names, which is hierarchical like filesystem.\n",
      "flops: Number of float operations. Note: Please read the implementation for the math behind it.\n",
      "\n",
      "Profile:\n",
      "node name | # float_ops\n",
      "_TFProfRoot (--/1.67b flops)\n",
      "  model_98/conv2d_1381/Conv2D (192.77m/192.77m flops)\n",
      "  model_98/conv2d_1380/Conv2D (175.10m/175.10m flops)\n",
      "  model_98/conv2d_1382/Conv2D (156.67m/156.67m flops)\n",
      "  model_98/conv2d_1383/Conv2D (153.41m/153.41m flops)\n",
      "  model_98/conv2d_1377/Conv2D (148.80m/148.80m flops)\n",
      "  model_98/conv2d_1375/Conv2D (143.82m/143.82m flops)\n",
      "  model_98/conv2d_1379/Conv2D (134.64m/134.64m flops)\n",
      "  model_98/conv2d_1373/Conv2D (101.58m/101.58m flops)\n",
      "  model_98/conv2d_1374/Conv2D (84.12m/84.12m flops)\n",
      "  model_98/conv2d_1384/Conv2D (78.77m/78.77m flops)\n",
      "  model_98/conv2d_1378/Conv2D (77.20m/77.20m flops)\n",
      "  model_98/conv2d_1376/Conv2D (63.09m/63.09m flops)\n",
      "  model_98/conv2d_1385/Conv2D (41.90m/41.90m flops)\n",
      "  model_98/conv2d_1372/Conv2D (26.21m/26.21m flops)\n",
      "  model_98/depthwise_conv2d_1274/depthwise (14.75m/14.75m flops)\n",
      "  model_98/depthwise_conv2d_1276/depthwise (12.21m/12.21m flops)\n",
      "  model_98/depthwise_conv2d_1275/depthwise (7.14m/7.14m flops)\n",
      "  model_98/depthwise_conv2d_1278/depthwise (5.36m/5.36m flops)\n",
      "  model_98/depthwise_conv2d_1282/depthwise (3.61m/3.61m flops)\n",
      "  model_98/depthwise_conv2d_1283/depthwise (3.46m/3.46m flops)\n",
      "  model_98/batch_normalization_2648/FusedBatchNormV3 (3.17m/3.17m flops)\n",
      "  model_98/depthwise_conv2d_1281/depthwise (3.14m/3.14m flops)\n",
      "  model_98/depthwise_conv2d_1277/depthwise (3.05m/3.05m flops)\n",
      "  model_98/depthwise_conv2d_1284/depthwise (2.94m/2.94m flops)\n",
      "  model_98/depthwise_conv2d_1280/depthwise (2.78m/2.78m flops)\n",
      "  model_98/depthwise_conv2d_1279/depthwise (1.80m/1.80m flops)\n",
      "  model_98/batch_normalization_2647/FusedBatchNormV3 (1.64m/1.64m flops)\n",
      "  model_98/batch_normalization_2646/FusedBatchNormV3 (1.64m/1.64m flops)\n",
      "  model_98/conv2d_1373/BiasAdd (1.59m/1.59m flops)\n",
      "  model_98/batch_normalization_2650/FusedBatchNormV3 (1.36m/1.36m flops)\n",
      "  model_98/batch_normalization_2651/FusedBatchNormV3 (1.36m/1.36m flops)\n",
      "  model_98/batch_normalization_2652/FusedBatchNormV3 (1.36m/1.36m flops)\n",
      "  model_98/depthwise_conv2d_1285/depthwise (846.00k/846.00k flops)\n",
      "  model_98/conv2d_1372/BiasAdd (819.20k/819.20k flops)\n",
      "  model_98/depthwise_conv2d_1274/BiasAdd (819.20k/819.20k flops)\n",
      "  model_98/batch_normalization_2656/FusedBatchNormV3 (801.50k/801.50k flops)\n",
      "  model_98/batch_normalization_2649/FusedBatchNormV3 (793.97k/793.97k flops)\n",
      "  model_98/depthwise_conv2d_1276/BiasAdd (678.40k/678.40k flops)\n",
      "  model_98/conv2d_1375/BiasAdd (678.40k/678.40k flops)\n",
      "  model_98/conv2d_1374/BiasAdd (678.40k/678.40k flops)\n",
      "  model_98/batch_normalization_2654/FusedBatchNormV3 (596.32k/596.32k flops)\n",
      "  model_98/batch_normalization_2655/FusedBatchNormV3 (596.32k/596.32k flops)\n",
      "  model_98/batch_normalization_2663/FusedBatchNormV3 (404.61k/404.61k flops)\n",
      "  model_98/batch_normalization_2662/FusedBatchNormV3 (404.61k/404.61k flops)\n",
      "  model_98/conv2d_1377/BiasAdd (400.00k/400.00k flops)\n",
      "  model_98/depthwise_conv2d_1275/BiasAdd (396.80k/396.80k flops)\n",
      "  model_98/batch_normalization_2664/FusedBatchNormV3 (386.88k/386.88k flops)\n",
      "  model_98/batch_normalization_2665/FusedBatchNormV3 (386.88k/386.88k flops)\n",
      "  model_98/batch_normalization_2668/FusedBatchNormV3 (378.82k/378.82k flops)\n",
      "  model_98/depthwise_conv2d_1286/depthwise (377.10k/377.10k flops)\n",
      "  model_98/batch_normalization_2660/FusedBatchNormV3 (351.42k/351.42k flops)\n",
      "  model_98/batch_normalization_2661/FusedBatchNormV3 (351.42k/351.42k flops)\n",
      "  model_98/batch_normalization_2653/FusedBatchNormV3 (339.84k/339.84k flops)\n",
      "  model_98/batch_normalization_2666/FusedBatchNormV3 (328.85k/328.85k flops)\n",
      "  model_98/batch_normalization_2667/FusedBatchNormV3 (328.85k/328.85k flops)\n",
      "  model_98/batch_normalization_2659/FusedBatchNormV3 (311.12k/311.12k flops)\n",
      "  model_98/batch_normalization_2658/FusedBatchNormV3 (311.12k/311.12k flops)\n",
      "  model_98/depthwise_conv2d_1278/BiasAdd (297.60k/297.60k flops)\n",
      "  model_98/conv2d_1376/BiasAdd (297.60k/297.60k flops)\n",
      "  model_98/batch_normalization_2657/FusedBatchNormV3 (201.50k/201.50k flops)\n",
      "  model_98/depthwise_conv2d_1282/BiasAdd (200.80k/200.80k flops)\n",
      "  model_98/conv2d_1380/BiasAdd (200.80k/200.80k flops)\n",
      "  model_98/depthwise_conv2d_1283/BiasAdd (192.00k/192.00k flops)\n",
      "  model_98/conv2d_1381/BiasAdd (192.00k/192.00k flops)\n",
      "  model_98/conv2d_1383/BiasAdd (188.00k/188.00k flops)\n",
      "  model_98/depthwise_conv2d_1281/BiasAdd (174.40k/174.40k flops)\n",
      "  model_98/conv2d_1379/BiasAdd (174.40k/174.40k flops)\n",
      "  model_98/batch_normalization_2670/FusedBatchNormV3 (172.63k/172.63k flops)\n",
      "  model_98/depthwise_conv2d_1277/BiasAdd (169.60k/169.60k flops)\n",
      "  model_98/depthwise_conv2d_1284/BiasAdd (163.20k/163.20k flops)\n",
      "  model_98/conv2d_1382/BiasAdd (163.20k/163.20k flops)\n",
      "  model_98/depthwise_conv2d_1280/BiasAdd (154.40k/154.40k flops)\n",
      "  model_98/conv2d_1378/BiasAdd (154.40k/154.40k flops)\n",
      "  model_98/depthwise_conv2d_1279/BiasAdd (100.00k/100.00k flops)\n",
      "  model_98/batch_normalization_2669/FusedBatchNormV3 (96.82k/96.82k flops)\n",
      "  model_98/conv2d_1384/BiasAdd (83.80k/83.80k flops)\n",
      "  model_98/batch_normalization_2672/FusedBatchNormV3 (56.00k/56.00k flops)\n",
      "  model_98/depthwise_conv2d_1285/BiasAdd (47.00k/47.00k flops)\n",
      "  model_98/batch_normalization_2671/FusedBatchNormV3 (46.93k/46.93k flops)\n",
      "  model_98/global_average_pooling2d_98/Mean (25.00k/25.00k flops)\n",
      "  model_98/conv2d_1385/BiasAdd (25.00k/25.00k flops)\n",
      "  model_98/depthwise_conv2d_1286/BiasAdd (20.95k/20.95k flops)\n",
      "  model_98/dense_98/MatMul (20.00k/20.00k flops)\n",
      "  model_98/dense_98/Softmax (50/50 flops)\n",
      "  model_98/dense_98/BiasAdd (10/10 flops)\n",
      "\n",
      "======================End of Report==========================\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "94.53586\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-30 13:41:13.632198: I tensorflow/core/grappler/devices.cc:66] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0\n",
      "2022-04-30 13:41:13.632315: I tensorflow/core/grappler/clusters/single_machine.cc:357] Starting new session\n",
      "2022-04-30 13:41:13.636662: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:1137] Optimization results for grappler item: graph_to_optimize\n",
      "  function_optimizer: function_optimizer did nothing. time = 0.005ms.\n",
      "  function_optimizer: function_optimizer did nothing. time = 0.001ms.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=========================Options=============================\n",
      "-max_depth                  10000\n",
      "-min_bytes                  0\n",
      "-min_peak_bytes             0\n",
      "-min_residual_bytes         0\n",
      "-min_output_bytes           0\n",
      "-min_micros                 0\n",
      "-min_accelerator_micros     0\n",
      "-min_cpu_micros             0\n",
      "-min_params                 0\n",
      "-min_float_ops              1\n",
      "-min_occurrence             0\n",
      "-step                       -1\n",
      "-order_by                   float_ops\n",
      "-account_type_regexes       .*\n",
      "-start_name_regexes         .*\n",
      "-trim_name_regexes          \n",
      "-show_name_regexes          .*\n",
      "-hide_name_regexes          \n",
      "-account_displayed_op_only  true\n",
      "-select                     float_ops\n",
      "-output                     stdout:\n",
      "\n",
      "==================Model Analysis Report======================\n",
      "\n",
      "Doc:\n",
      "scope: The nodes in the model graph are organized by their names, which is hierarchical like filesystem.\n",
      "flops: Number of float operations. Note: Please read the implementation for the math behind it.\n",
      "\n",
      "Profile:\n",
      "node name | # float_ops\n",
      "_TFProfRoot (--/1.67b flops)\n",
      "  model_99/conv2d_1394/Conv2D (207.26m/207.26m flops)\n",
      "  model_99/conv2d_1395/Conv2D (204.01m/204.01m flops)\n",
      "  model_99/conv2d_1393/Conv2D (202.37m/202.37m flops)\n",
      "  model_99/conv2d_1397/Conv2D (200.79m/200.79m flops)\n",
      "  model_99/conv2d_1396/Conv2D (200.00m/200.00m flops)\n",
      "  model_99/conv2d_1398/Conv2D (99.79m/99.79m flops)\n",
      "  model_99/conv2d_1391/Conv2D (97.18m/97.18m flops)\n",
      "  model_99/conv2d_1392/Conv2D (82.53m/82.53m flops)\n",
      "  model_99/conv2d_1389/Conv2D (73.73m/73.73m flops)\n",
      "  model_99/conv2d_1387/Conv2D (72.09m/72.09m flops)\n",
      "  model_99/conv2d_1399/Conv2D (49.70m/49.70m flops)\n",
      "  model_99/conv2d_1390/Conv2D (44.85m/44.85m flops)\n",
      "  model_99/conv2d_1388/Conv2D (33.79m/33.79m flops)\n",
      "  model_99/conv2d_1386/Conv2D (26.21m/26.21m flops)\n",
      "  model_99/depthwise_conv2d_1287/depthwise (14.75m/14.75m flops)\n",
      "  model_99/depthwise_conv2d_1289/depthwise (6.91m/6.91m flops)\n",
      "  model_99/depthwise_conv2d_1288/depthwise (5.07m/5.07m flops)\n",
      "  model_99/depthwise_conv2d_1291/depthwise (4.20m/4.20m flops)\n",
      "  model_99/depthwise_conv2d_1294/depthwise (3.67m/3.67m flops)\n",
      "  model_99/depthwise_conv2d_1295/depthwise (3.66m/3.66m flops)\n",
      "  model_99/depthwise_conv2d_1296/depthwise (3.61m/3.61m flops)\n",
      "  model_99/depthwise_conv2d_1297/depthwise (3.59m/3.59m flops)\n",
      "  model_99/depthwise_conv2d_1293/depthwise (3.57m/3.57m flops)\n",
      "  model_99/depthwise_conv2d_1290/depthwise (2.76m/2.76m flops)\n",
      "  model_99/batch_normalization_2675/FusedBatchNormV3 (2.25m/2.25m flops)\n",
      "  model_99/batch_normalization_2674/FusedBatchNormV3 (1.64m/1.64m flops)\n",
      "  model_99/batch_normalization_2673/FusedBatchNormV3 (1.64m/1.64m flops)\n",
      "  model_99/depthwise_conv2d_1292/depthwise (1.50m/1.50m flops)\n",
      "  model_99/batch_normalization_2679/FusedBatchNormV3 (1.23m/1.23m flops)\n",
      "  model_99/conv2d_1387/BiasAdd (1.13m/1.13m flops)\n",
      "  model_99/depthwise_conv2d_1298/depthwise (907.20k/907.20k flops)\n",
      "  model_99/conv2d_1386/BiasAdd (819.20k/819.20k flops)\n",
      "  model_99/depthwise_conv2d_1287/BiasAdd (819.20k/819.20k flops)\n",
      "  model_99/batch_normalization_2678/FusedBatchNormV3 (768.36k/768.36k flops)\n",
      "  model_99/batch_normalization_2677/FusedBatchNormV3 (768.36k/768.36k flops)\n",
      "  model_99/batch_normalization_2683/FusedBatchNormV3 (666.85k/666.85k flops)\n",
      "  model_99/conv2d_1389/BiasAdd (614.40k/614.40k flops)\n",
      "  model_99/batch_normalization_2676/FusedBatchNormV3 (563.46k/563.46k flops)\n",
      "  model_99/batch_normalization_2681/FusedBatchNormV3 (468.08k/468.08k flops)\n",
      "  model_99/batch_normalization_2682/FusedBatchNormV3 (468.08k/468.08k flops)\n",
      "  model_99/depthwise_conv2d_1299/depthwise (445.50k/445.50k flops)\n",
      "  model_99/batch_normalization_2687/FusedBatchNormV3 (411.06k/411.06k flops)\n",
      "  model_99/batch_normalization_2688/FusedBatchNormV3 (411.06k/411.06k flops)\n",
      "  model_99/batch_normalization_2690/FusedBatchNormV3 (409.45k/409.45k flops)\n",
      "  model_99/batch_normalization_2689/FusedBatchNormV3 (409.45k/409.45k flops)\n",
      "  model_99/batch_normalization_2695/FusedBatchNormV3 (406.22k/406.22k flops)\n",
      "  model_99/batch_normalization_2691/FusedBatchNormV3 (404.61k/404.61k flops)\n",
      "  model_99/batch_normalization_2692/FusedBatchNormV3 (404.61k/404.61k flops)\n",
      "  model_99/batch_normalization_2694/FusedBatchNormV3 (401.39k/401.39k flops)\n",
      "  model_99/batch_normalization_2693/FusedBatchNormV3 (401.39k/401.39k flops)\n",
      "  model_99/batch_normalization_2686/FusedBatchNormV3 (399.78k/399.78k flops)\n",
      "  model_99/batch_normalization_2685/FusedBatchNormV3 (399.78k/399.78k flops)\n",
      "  model_99/depthwise_conv2d_1289/BiasAdd (384.00k/384.00k flops)\n",
      "  model_99/conv2d_1388/BiasAdd (384.00k/384.00k flops)\n",
      "  model_99/conv2d_1391/BiasAdd (332.80k/332.80k flops)\n",
      "  model_99/batch_normalization_2680/FusedBatchNormV3 (307.78k/307.78k flops)\n",
      "  model_99/depthwise_conv2d_1288/BiasAdd (281.60k/281.60k flops)\n",
      "  model_99/depthwise_conv2d_1291/BiasAdd (233.60k/233.60k flops)\n",
      "  model_99/conv2d_1390/BiasAdd (233.60k/233.60k flops)\n",
      "  model_99/depthwise_conv2d_1294/BiasAdd (204.00k/204.00k flops)\n",
      "  model_99/conv2d_1393/BiasAdd (204.00k/204.00k flops)\n",
      "  model_99/batch_normalization_2697/FusedBatchNormV3 (203.94k/203.94k flops)\n",
      "  model_99/conv2d_1394/BiasAdd (203.20k/203.20k flops)\n",
      "  model_99/depthwise_conv2d_1295/BiasAdd (203.20k/203.20k flops)\n",
      "  model_99/conv2d_1397/BiasAdd (201.60k/201.60k flops)\n",
      "  model_99/depthwise_conv2d_1296/BiasAdd (200.80k/200.80k flops)\n",
      "  model_99/conv2d_1395/BiasAdd (200.80k/200.80k flops)\n",
      "  model_99/depthwise_conv2d_1297/BiasAdd (199.20k/199.20k flops)\n",
      "  model_99/conv2d_1396/BiasAdd (199.20k/199.20k flops)\n",
      "  model_99/conv2d_1392/BiasAdd (198.40k/198.40k flops)\n",
      "  model_99/depthwise_conv2d_1293/BiasAdd (198.40k/198.40k flops)\n",
      "  model_99/batch_normalization_2684/FusedBatchNormV3 (167.65k/167.65k flops)\n",
      "  model_99/depthwise_conv2d_1290/BiasAdd (153.60k/153.60k flops)\n",
      "  model_99/batch_normalization_2696/FusedBatchNormV3 (103.82k/103.82k flops)\n",
      "  model_99/conv2d_1398/BiasAdd (99.00k/99.00k flops)\n",
      "  model_99/depthwise_conv2d_1292/BiasAdd (83.20k/83.20k flops)\n",
      "  model_99/batch_normalization_2699/FusedBatchNormV3 (56.22k/56.22k flops)\n",
      "  model_99/batch_normalization_2698/FusedBatchNormV3 (55.44k/55.44k flops)\n",
      "  model_99/depthwise_conv2d_1298/BiasAdd (50.40k/50.40k flops)\n",
      "  model_99/global_average_pooling2d_99/Mean (25.10k/25.10k flops)\n",
      "  model_99/conv2d_1399/BiasAdd (25.10k/25.10k flops)\n",
      "  model_99/depthwise_conv2d_1299/BiasAdd (24.75k/24.75k flops)\n",
      "  model_99/dense_99/MatMul (20.08k/20.08k flops)\n",
      "  model_99/dense_99/Softmax (50/50 flops)\n",
      "  model_99/dense_99/BiasAdd (10/10 flops)\n",
      "\n",
      "======================End of Report==========================\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "96.791836\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-30 13:41:14.680303: I tensorflow/core/grappler/devices.cc:66] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0\n",
      "2022-04-30 13:41:14.680421: I tensorflow/core/grappler/clusters/single_machine.cc:357] Starting new session\n",
      "2022-04-30 13:41:14.685391: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:1137] Optimization results for grappler item: graph_to_optimize\n",
      "  function_optimizer: function_optimizer did nothing. time = 0.006ms.\n",
      "  function_optimizer: function_optimizer did nothing. time = 0.001ms.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=========================Options=============================\n",
      "-max_depth                  10000\n",
      "-min_bytes                  0\n",
      "-min_peak_bytes             0\n",
      "-min_residual_bytes         0\n",
      "-min_output_bytes           0\n",
      "-min_micros                 0\n",
      "-min_accelerator_micros     0\n",
      "-min_cpu_micros             0\n",
      "-min_params                 0\n",
      "-min_float_ops              1\n",
      "-min_occurrence             0\n",
      "-step                       -1\n",
      "-order_by                   float_ops\n",
      "-account_type_regexes       .*\n",
      "-start_name_regexes         .*\n",
      "-trim_name_regexes          \n",
      "-show_name_regexes          .*\n",
      "-hide_name_regexes          \n",
      "-account_displayed_op_only  true\n",
      "-select                     float_ops\n",
      "-output                     stdout:\n",
      "\n",
      "==================Model Analysis Report======================\n",
      "\n",
      "Doc:\n",
      "scope: The nodes in the model graph are organized by their names, which is hierarchical like filesystem.\n",
      "flops: Number of float operations. Note: Please read the implementation for the math behind it.\n",
      "\n",
      "Profile:\n",
      "node name | # float_ops\n",
      "_TFProfRoot (--/1.37b flops)\n",
      "  model_100/conv2d_1408/Conv2D (171.85m/171.85m flops)\n",
      "  model_100/conv2d_1405/Conv2D (170.50m/170.50m flops)\n",
      "  model_100/conv2d_1411/Conv2D (140.30m/140.30m flops)\n",
      "  model_100/conv2d_1403/Conv2D (118.27m/118.27m flops)\n",
      "  model_100/conv2d_1410/Conv2D (103.90m/103.90m flops)\n",
      "  model_100/conv2d_1407/Conv2D (100.31m/100.31m flops)\n",
      "  model_100/conv2d_1409/Conv2D (96.89m/96.89m flops)\n",
      "  model_100/conv2d_1404/Conv2D (78.14m/78.14m flops)\n",
      "  model_100/conv2d_1401/Conv2D (72.09m/72.09m flops)\n",
      "  model_100/conv2d_1412/Conv2D (68.97m/68.97m flops)\n",
      "  model_100/conv2d_1406/Conv2D (49.54m/49.54m flops)\n",
      "  model_100/conv2d_1402/Conv2D (47.31m/47.31m flops)\n",
      "  model_100/conv2d_1413/Conv2D (46.51m/46.51m flops)\n",
      "  model_100/conv2d_1400/Conv2D (26.21m/26.21m flops)\n",
      "  model_100/depthwise_conv2d_1300/depthwise (14.75m/14.75m flops)\n",
      "  model_100/depthwise_conv2d_1302/depthwise (9.68m/9.68m flops)\n",
      "  model_100/depthwise_conv2d_1304/depthwise (6.39m/6.39m flops)\n",
      "  model_100/depthwise_conv2d_1301/depthwise (5.07m/5.07m flops)\n",
      "  model_100/depthwise_conv2d_1307/depthwise (3.50m/3.50m flops)\n",
      "  model_100/depthwise_conv2d_1310/depthwise (3.41m/3.41m flops)\n",
      "  model_100/depthwise_conv2d_1308/depthwise (3.18m/3.18m flops)\n",
      "  model_100/depthwise_conv2d_1303/depthwise (3.17m/3.17m flops)\n",
      "  model_100/batch_normalization_2702/FusedBatchNormV3 (2.25m/2.25m flops)\n",
      "  model_100/depthwise_conv2d_1309/depthwise (1.97m/1.97m flops)\n",
      "  model_100/depthwise_conv2d_1306/depthwise (1.86m/1.86m flops)\n",
      "  model_100/depthwise_conv2d_1305/depthwise (1.73m/1.73m flops)\n",
      "  model_100/batch_normalization_2701/FusedBatchNormV3 (1.64m/1.64m flops)\n",
      "  model_100/batch_normalization_2700/FusedBatchNormV3 (1.64m/1.64m flops)\n",
      "  model_100/batch_normalization_2706/FusedBatchNormV3 (1.41m/1.41m flops)\n",
      "  model_100/conv2d_1401/BiasAdd (1.13m/1.13m flops)\n",
      "  model_100/batch_normalization_2704/FusedBatchNormV3 (1.08m/1.08m flops)\n",
      "  model_100/batch_normalization_2705/FusedBatchNormV3 (1.08m/1.08m flops)\n",
      "  model_100/conv2d_1400/BiasAdd (819.20k/819.20k flops)\n",
      "  model_100/depthwise_conv2d_1300/BiasAdd (819.20k/819.20k flops)\n",
      "  model_100/batch_normalization_2710/FusedBatchNormV3 (769.44k/769.44k flops)\n",
      "  model_100/batch_normalization_2709/FusedBatchNormV3 (711.73k/711.73k flops)\n",
      "  model_100/batch_normalization_2708/FusedBatchNormV3 (711.73k/711.73k flops)\n",
      "  model_100/conv2d_1403/BiasAdd (704.00k/704.00k flops)\n",
      "  model_100/depthwise_conv2d_1311/depthwise (666.00k/666.00k flops)\n",
      "  model_100/batch_normalization_2703/FusedBatchNormV3 (563.46k/563.46k flops)\n",
      "  model_100/depthwise_conv2d_1302/BiasAdd (537.60k/537.60k flops)\n",
      "  model_100/conv2d_1402/BiasAdd (537.60k/537.60k flops)\n",
      "  model_100/depthwise_conv2d_1312/depthwise (419.40k/419.40k flops)\n",
      "  model_100/batch_normalization_2715/FusedBatchNormV3 (391.72k/391.72k flops)\n",
      "  model_100/batch_normalization_2714/FusedBatchNormV3 (391.72k/391.72k flops)\n",
      "  model_100/conv2d_1405/BiasAdd (384.00k/384.00k flops)\n",
      "  model_100/batch_normalization_2720/FusedBatchNormV3 (382.04k/382.04k flops)\n",
      "  model_100/batch_normalization_2721/FusedBatchNormV3 (382.04k/382.04k flops)\n",
      "  model_100/batch_normalization_2717/FusedBatchNormV3 (356.25k/356.25k flops)\n",
      "  model_100/batch_normalization_2716/FusedBatchNormV3 (356.25k/356.25k flops)\n",
      "  model_100/depthwise_conv2d_1304/BiasAdd (355.20k/355.20k flops)\n",
      "  model_100/conv2d_1404/BiasAdd (355.20k/355.20k flops)\n",
      "  model_100/batch_normalization_2707/FusedBatchNormV3 (352.66k/352.66k flops)\n",
      "  model_100/batch_normalization_2722/FusedBatchNormV3 (298.22k/298.22k flops)\n",
      "  model_100/depthwise_conv2d_1301/BiasAdd (281.60k/281.60k flops)\n",
      "  model_100/batch_normalization_2719/FusedBatchNormV3 (220.84k/220.84k flops)\n",
      "  model_100/batch_normalization_2718/FusedBatchNormV3 (220.84k/220.84k flops)\n",
      "  model_100/batch_normalization_2713/FusedBatchNormV3 (207.95k/207.95k flops)\n",
      "  model_100/batch_normalization_2712/FusedBatchNormV3 (207.95k/207.95k flops)\n",
      "  model_100/depthwise_conv2d_1307/BiasAdd (194.40k/194.40k flops)\n",
      "  model_100/conv2d_1407/BiasAdd (194.40k/194.40k flops)\n",
      "  model_100/batch_normalization_2711/FusedBatchNormV3 (193.44k/193.44k flops)\n",
      "  model_100/batch_normalization_2724/FusedBatchNormV3 (191.99k/191.99k flops)\n",
      "  model_100/depthwise_conv2d_1310/BiasAdd (189.60k/189.60k flops)\n",
      "  model_100/conv2d_1410/BiasAdd (189.60k/189.60k flops)\n",
      "  model_100/conv2d_1408/BiasAdd (176.80k/176.80k flops)\n",
      "  model_100/depthwise_conv2d_1308/BiasAdd (176.80k/176.80k flops)\n",
      "  model_100/depthwise_conv2d_1303/BiasAdd (176.00k/176.00k flops)\n",
      "  model_100/conv2d_1411/BiasAdd (148.00k/148.00k flops)\n",
      "  model_100/depthwise_conv2d_1309/BiasAdd (109.60k/109.60k flops)\n",
      "  model_100/conv2d_1409/BiasAdd (109.60k/109.60k flops)\n",
      "  model_100/depthwise_conv2d_1306/BiasAdd (103.20k/103.20k flops)\n",
      "  model_100/conv2d_1406/BiasAdd (103.20k/103.20k flops)\n",
      "  model_100/depthwise_conv2d_1305/BiasAdd (96.00k/96.00k flops)\n",
      "  model_100/conv2d_1412/BiasAdd (93.20k/93.20k flops)\n",
      "  model_100/batch_normalization_2723/FusedBatchNormV3 (76.22k/76.22k flops)\n",
      "  model_100/batch_normalization_2726/FusedBatchNormV3 (55.89k/55.89k flops)\n",
      "  model_100/batch_normalization_2725/FusedBatchNormV3 (52.19k/52.19k flops)\n",
      "  model_100/depthwise_conv2d_1311/BiasAdd (37.00k/37.00k flops)\n",
      "  model_100/global_average_pooling2d_100/Mean (24.95k/24.95k flops)\n",
      "  model_100/conv2d_1413/BiasAdd (24.95k/24.95k flops)\n",
      "  model_100/depthwise_conv2d_1312/BiasAdd (23.30k/23.30k flops)\n",
      "  model_100/dense_100/MatMul (19.96k/19.96k flops)\n",
      "  model_100/dense_100/Softmax (50/50 flops)\n",
      "  model_100/dense_100/BiasAdd (10/10 flops)\n",
      "\n",
      "======================End of Report==========================\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "122.950404\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-30 13:41:15.616683: I tensorflow/core/grappler/devices.cc:66] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0\n",
      "2022-04-30 13:41:15.616798: I tensorflow/core/grappler/clusters/single_machine.cc:357] Starting new session\n",
      "2022-04-30 13:41:15.621160: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:1137] Optimization results for grappler item: graph_to_optimize\n",
      "  function_optimizer: function_optimizer did nothing. time = 0.005ms.\n",
      "  function_optimizer: function_optimizer did nothing. time = 0.001ms.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=========================Options=============================\n",
      "-max_depth                  10000\n",
      "-min_bytes                  0\n",
      "-min_peak_bytes             0\n",
      "-min_residual_bytes         0\n",
      "-min_output_bytes           0\n",
      "-min_micros                 0\n",
      "-min_accelerator_micros     0\n",
      "-min_cpu_micros             0\n",
      "-min_params                 0\n",
      "-min_float_ops              1\n",
      "-min_occurrence             0\n",
      "-step                       -1\n",
      "-order_by                   float_ops\n",
      "-account_type_regexes       .*\n",
      "-start_name_regexes         .*\n",
      "-trim_name_regexes          \n",
      "-show_name_regexes          .*\n",
      "-hide_name_regexes          \n",
      "-account_displayed_op_only  true\n",
      "-select                     float_ops\n",
      "-output                     stdout:\n",
      "\n",
      "==================Model Analysis Report======================\n",
      "\n",
      "Doc:\n",
      "scope: The nodes in the model graph are organized by their names, which is hierarchical like filesystem.\n",
      "flops: Number of float operations. Note: Please read the implementation for the math behind it.\n",
      "\n",
      "Profile:\n",
      "node name | # float_ops\n",
      "_TFProfRoot (--/1.87b flops)\n",
      "  model_101/conv2d_1424/Conv2D (214.78m/214.78m flops)\n",
      "  model_101/conv2d_1417/Conv2D (214.66m/214.66m flops)\n",
      "  model_101/conv2d_1419/Conv2D (213.73m/213.73m flops)\n",
      "  model_101/conv2d_1422/Conv2D (167.27m/167.27m flops)\n",
      "  model_101/conv2d_1423/Conv2D (164.30m/164.30m flops)\n",
      "  model_101/conv2d_1425/Conv2D (156.47m/156.47m flops)\n",
      "  model_101/conv2d_1421/Conv2D (128.07m/128.07m flops)\n",
      "  model_101/conv2d_1418/Conv2D (112.21m/112.21m flops)\n",
      "  model_101/conv2d_1426/Conv2D (79.33m/79.33m flops)\n",
      "  model_101/conv2d_1415/Conv2D (75.33m/75.33m flops)\n",
      "  model_101/conv2d_1427/Conv2D (74.62m/74.62m flops)\n",
      "  model_101/conv2d_1420/Conv2D (68.30m/68.30m flops)\n",
      "  model_101/conv2d_1416/Conv2D (64.74m/64.74m flops)\n",
      "  model_101/conv2d_1414/Conv2D (31.72m/31.72m flops)\n",
      "  model_101/depthwise_conv2d_1313/depthwise (17.84m/17.84m flops)\n",
      "  model_101/depthwise_conv2d_1315/depthwise (15.33m/15.33m flops)\n",
      "  model_101/depthwise_conv2d_1317/depthwise (8.02m/8.02m flops)\n",
      "  model_101/depthwise_conv2d_1314/depthwise (5.30m/5.30m flops)\n",
      "  model_101/depthwise_conv2d_1316/depthwise (4.39m/4.39m flops)\n",
      "  model_101/depthwise_conv2d_1323/depthwise (4.37m/4.37m flops)\n",
      "  model_101/depthwise_conv2d_1320/depthwise (3.92m/3.92m flops)\n",
      "  model_101/depthwise_conv2d_1322/depthwise (3.85m/3.85m flops)\n",
      "  model_101/depthwise_conv2d_1321/depthwise (3.35m/3.35m flops)\n",
      "  model_101/depthwise_conv2d_1319/depthwise (2.56m/2.56m flops)\n",
      "  model_101/batch_normalization_2729/FusedBatchNormV3 (2.35m/2.35m flops)\n",
      "  model_101/depthwise_conv2d_1318/depthwise (2.09m/2.09m flops)\n",
      "  model_101/batch_normalization_2728/FusedBatchNormV3 (1.98m/1.98m flops)\n",
      "  model_101/batch_normalization_2727/FusedBatchNormV3 (1.98m/1.98m flops)\n",
      "  model_101/batch_normalization_2733/FusedBatchNormV3 (1.95m/1.95m flops)\n",
      "  model_101/batch_normalization_2731/FusedBatchNormV3 (1.70m/1.70m flops)\n",
      "  model_101/batch_normalization_2732/FusedBatchNormV3 (1.70m/1.70m flops)\n",
      "  model_101/conv2d_1415/BiasAdd (1.18m/1.18m flops)\n",
      "  model_101/conv2d_1414/BiasAdd (991.23k/991.23k flops)\n",
      "  model_101/depthwise_conv2d_1313/BiasAdd (991.23k/991.23k flops)\n",
      "  model_101/conv2d_1417/BiasAdd (975.74k/975.74k flops)\n",
      "  model_101/batch_normalization_2737/FusedBatchNormV3 (930.72k/930.72k flops)\n",
      "  model_101/batch_normalization_2735/FusedBatchNormV3 (891.94k/891.94k flops)\n",
      "  model_101/batch_normalization_2736/FusedBatchNormV3 (891.94k/891.94k flops)\n",
      "  model_101/depthwise_conv2d_1315/BiasAdd (851.84k/851.84k flops)\n",
      "  model_101/conv2d_1416/BiasAdd (851.84k/851.84k flops)\n",
      "  model_101/depthwise_conv2d_1324/depthwise (701.32k/701.32k flops)\n",
      "  model_101/depthwise_conv2d_1325/depthwise (659.66k/659.66k flops)\n",
      "  model_101/batch_normalization_2730/FusedBatchNormV3 (588.77k/588.77k flops)\n",
      "  model_101/batch_normalization_2748/FusedBatchNormV3 (488.95k/488.95k flops)\n",
      "  model_101/batch_normalization_2747/FusedBatchNormV3 (488.95k/488.95k flops)\n",
      "  model_101/batch_normalization_2734/FusedBatchNormV3 (488.63k/488.63k flops)\n",
      "  model_101/conv2d_1419/BiasAdd (464.64k/464.64k flops)\n",
      "  model_101/conv2d_1418/BiasAdd (445.28k/445.28k flops)\n",
      "  model_101/depthwise_conv2d_1317/BiasAdd (445.28k/445.28k flops)\n",
      "  model_101/batch_normalization_2741/FusedBatchNormV3 (438.30k/438.30k flops)\n",
      "  model_101/batch_normalization_2742/FusedBatchNormV3 (438.30k/438.30k flops)\n",
      "  model_101/batch_normalization_2746/FusedBatchNormV3 (430.51k/430.51k flops)\n",
      "  model_101/batch_normalization_2745/FusedBatchNormV3 (430.51k/430.51k flops)\n",
      "  model_101/batch_normalization_2743/FusedBatchNormV3 (374.02k/374.02k flops)\n",
      "  model_101/batch_normalization_2744/FusedBatchNormV3 (374.02k/374.02k flops)\n",
      "  model_101/batch_normalization_2749/FusedBatchNormV3 (313.63k/313.63k flops)\n",
      "  model_101/depthwise_conv2d_1314/BiasAdd (294.27k/294.27k flops)\n",
      "  model_101/batch_normalization_2739/FusedBatchNormV3 (286.36k/286.36k flops)\n",
      "  model_101/batch_normalization_2740/FusedBatchNormV3 (286.36k/286.36k flops)\n",
      "  model_101/batch_normalization_2751/FusedBatchNormV3 (252.46k/252.46k flops)\n",
      "  model_101/depthwise_conv2d_1316/BiasAdd (243.94k/243.94k flops)\n",
      "  model_101/conv2d_1424/BiasAdd (242.97k/242.97k flops)\n",
      "  model_101/depthwise_conv2d_1323/BiasAdd (242.97k/242.97k flops)\n",
      "  model_101/batch_normalization_2738/FusedBatchNormV3 (233.76k/233.76k flops)\n",
      "  model_101/conv2d_1421/BiasAdd (217.80k/217.80k flops)\n",
      "  model_101/depthwise_conv2d_1320/BiasAdd (217.80k/217.80k flops)\n",
      "  model_101/conv2d_1423/BiasAdd (213.93k/213.93k flops)\n",
      "  model_101/depthwise_conv2d_1322/BiasAdd (213.93k/213.93k flops)\n",
      "  model_101/conv2d_1422/BiasAdd (185.86k/185.86k flops)\n",
      "  model_101/depthwise_conv2d_1321/BiasAdd (185.86k/185.86k flops)\n",
      "  model_101/conv2d_1425/BiasAdd (155.85k/155.85k flops)\n",
      "  model_101/depthwise_conv2d_1319/BiasAdd (142.30k/142.30k flops)\n",
      "  model_101/conv2d_1420/BiasAdd (142.30k/142.30k flops)\n",
      "  model_101/conv2d_1426/BiasAdd (123.18k/123.18k flops)\n",
      "  model_101/depthwise_conv2d_1318/BiasAdd (116.16k/116.16k flops)\n",
      "  model_101/batch_normalization_2750/FusedBatchNormV3 (79.86k/79.86k flops)\n",
      "  model_101/batch_normalization_2753/FusedBatchNormV3 (79.40k/79.40k flops)\n",
      "  model_101/batch_normalization_2752/FusedBatchNormV3 (79.40k/79.40k flops)\n",
      "  model_101/depthwise_conv2d_1324/BiasAdd (38.96k/38.96k flops)\n",
      "  model_101/depthwise_conv2d_1325/BiasAdd (36.65k/36.65k flops)\n",
      "  model_101/global_average_pooling2d_101/Mean (36.65k/36.65k flops)\n",
      "  model_101/conv2d_1427/BiasAdd (36.65k/36.65k flops)\n",
      "  model_101/dense_101/MatMul (20.36k/20.36k flops)\n",
      "  model_101/dense_101/Softmax (50/50 flops)\n",
      "  model_101/dense_101/BiasAdd (10/10 flops)\n",
      "\n",
      "======================End of Report==========================\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "98.827564\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-30 13:41:16.658498: I tensorflow/core/grappler/devices.cc:66] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0\n",
      "2022-04-30 13:41:16.658612: I tensorflow/core/grappler/clusters/single_machine.cc:357] Starting new session\n",
      "2022-04-30 13:41:16.663763: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:1137] Optimization results for grappler item: graph_to_optimize\n",
      "  function_optimizer: function_optimizer did nothing. time = 0.006ms.\n",
      "  function_optimizer: function_optimizer did nothing. time = 0.001ms.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=========================Options=============================\n",
      "-max_depth                  10000\n",
      "-min_bytes                  0\n",
      "-min_peak_bytes             0\n",
      "-min_residual_bytes         0\n",
      "-min_output_bytes           0\n",
      "-min_micros                 0\n",
      "-min_accelerator_micros     0\n",
      "-min_cpu_micros             0\n",
      "-min_params                 0\n",
      "-min_float_ops              1\n",
      "-min_occurrence             0\n",
      "-step                       -1\n",
      "-order_by                   float_ops\n",
      "-account_type_regexes       .*\n",
      "-start_name_regexes         .*\n",
      "-trim_name_regexes          \n",
      "-show_name_regexes          .*\n",
      "-hide_name_regexes          \n",
      "-account_displayed_op_only  true\n",
      "-select                     float_ops\n",
      "-output                     stdout:\n",
      "\n",
      "==================Model Analysis Report======================\n",
      "\n",
      "Doc:\n",
      "scope: The nodes in the model graph are organized by their names, which is hierarchical like filesystem.\n",
      "flops: Number of float operations. Note: Please read the implementation for the math behind it.\n",
      "\n",
      "Profile:\n",
      "node name | # float_ops\n",
      "_TFProfRoot (--/1.45b flops)\n",
      "  model_102/conv2d_1438/Conv2D (194.03m/194.03m flops)\n",
      "  model_102/conv2d_1433/Conv2D (177.32m/177.32m flops)\n",
      "  model_102/conv2d_1437/Conv2D (171.45m/171.45m flops)\n",
      "  model_102/conv2d_1436/Conv2D (160.34m/160.34m flops)\n",
      "  model_102/conv2d_1439/Conv2D (138.34m/138.34m flops)\n",
      "  model_102/conv2d_1435/Conv2D (104.81m/104.81m flops)\n",
      "  model_102/conv2d_1440/Conv2D (73.64m/73.64m flops)\n",
      "  model_102/conv2d_1441/Conv2D (72.27m/72.27m flops)\n",
      "  model_102/conv2d_1429/Conv2D (67.40m/67.40m flops)\n",
      "  model_102/conv2d_1432/Conv2D (58.00m/58.00m flops)\n",
      "  model_102/conv2d_1434/Conv2D (55.52m/55.52m flops)\n",
      "  model_102/conv2d_1431/Conv2D (43.37m/43.37m flops)\n",
      "  model_102/conv2d_1428/Conv2D (31.72m/31.72m flops)\n",
      "  model_102/conv2d_1430/Conv2D (21.06m/21.06m flops)\n",
      "  model_102/depthwise_conv2d_1326/depthwise (17.84m/17.84m flops)\n",
      "  model_102/depthwise_conv2d_1330/depthwise (7.46m/7.46m flops)\n",
      "  model_102/depthwise_conv2d_1328/depthwise (5.58m/5.58m flops)\n",
      "  model_102/depthwise_conv2d_1327/depthwise (4.74m/4.74m flops)\n",
      "  model_102/depthwise_conv2d_1336/depthwise (4.04m/4.04m flops)\n",
      "  model_102/depthwise_conv2d_1335/depthwise (3.76m/3.76m flops)\n",
      "  model_102/depthwise_conv2d_1334/depthwise (3.57m/3.57m flops)\n",
      "  model_102/depthwise_conv2d_1333/depthwise (3.52m/3.52m flops)\n",
      "  model_102/depthwise_conv2d_1329/depthwise (2.44m/2.44m flops)\n",
      "  model_102/depthwise_conv2d_1332/depthwise (2.33m/2.33m flops)\n",
      "  model_102/batch_normalization_2756/FusedBatchNormV3 (2.11m/2.11m flops)\n",
      "  model_102/batch_normalization_2755/FusedBatchNormV3 (1.98m/1.98m flops)\n",
      "  model_102/batch_normalization_2754/FusedBatchNormV3 (1.98m/1.98m flops)\n",
      "  model_102/depthwise_conv2d_1331/depthwise (1.86m/1.86m flops)\n",
      "  model_102/batch_normalization_2760/FusedBatchNormV3 (1.08m/1.08m flops)\n",
      "  model_102/conv2d_1429/BiasAdd (1.05m/1.05m flops)\n",
      "  model_102/conv2d_1428/BiasAdd (991.23k/991.23k flops)\n",
      "  model_102/depthwise_conv2d_1326/BiasAdd (991.23k/991.23k flops)\n",
      "  model_102/batch_normalization_2762/FusedBatchNormV3 (829.89k/829.89k flops)\n",
      "  model_102/batch_normalization_2763/FusedBatchNormV3 (829.89k/829.89k flops)\n",
      "  model_102/batch_normalization_2764/FusedBatchNormV3 (829.89k/829.89k flops)\n",
      "  model_102/depthwise_conv2d_1337/depthwise (670.82k/670.82k flops)\n",
      "  model_102/depthwise_conv2d_1338/depthwise (640.22k/640.22k flops)\n",
      "  model_102/batch_normalization_2758/FusedBatchNormV3 (619.76k/619.76k flops)\n",
      "  model_102/batch_normalization_2759/FusedBatchNormV3 (619.76k/619.76k flops)\n",
      "  model_102/conv2d_1431/BiasAdd (542.08k/542.08k flops)\n",
      "  model_102/batch_normalization_2757/FusedBatchNormV3 (526.80k/526.80k flops)\n",
      "  model_102/batch_normalization_2774/FusedBatchNormV3 (451.94k/451.94k flops)\n",
      "  model_102/batch_normalization_2775/FusedBatchNormV3 (451.94k/451.94k flops)\n",
      "  model_102/batch_normalization_2773/FusedBatchNormV3 (420.77k/420.77k flops)\n",
      "  model_102/batch_normalization_2772/FusedBatchNormV3 (420.77k/420.77k flops)\n",
      "  model_102/depthwise_conv2d_1330/BiasAdd (414.30k/414.30k flops)\n",
      "  model_102/conv2d_1432/BiasAdd (414.30k/414.30k flops)\n",
      "  model_102/conv2d_1433/BiasAdd (414.30k/414.30k flops)\n",
      "  model_102/batch_normalization_2771/FusedBatchNormV3 (399.34k/399.34k flops)\n",
      "  model_102/batch_normalization_2770/FusedBatchNormV3 (399.34k/399.34k flops)\n",
      "  model_102/batch_normalization_2769/FusedBatchNormV3 (393.50k/393.50k flops)\n",
      "  model_102/batch_normalization_2768/FusedBatchNormV3 (393.50k/393.50k flops)\n",
      "  model_102/depthwise_conv2d_1328/BiasAdd (309.76k/309.76k flops)\n",
      "  model_102/conv2d_1430/BiasAdd (309.76k/309.76k flops)\n",
      "  model_102/batch_normalization_2776/FusedBatchNormV3 (299.99k/299.99k flops)\n",
      "  model_102/batch_normalization_2761/FusedBatchNormV3 (271.46k/271.46k flops)\n",
      "  model_102/depthwise_conv2d_1327/BiasAdd (263.30k/263.30k flops)\n",
      "  model_102/batch_normalization_2766/FusedBatchNormV3 (261.03k/261.03k flops)\n",
      "  model_102/batch_normalization_2767/FusedBatchNormV3 (261.03k/261.03k flops)\n",
      "  model_102/batch_normalization_2778/FusedBatchNormV3 (245.02k/245.02k flops)\n",
      "  model_102/depthwise_conv2d_1336/BiasAdd (224.58k/224.58k flops)\n",
      "  model_102/conv2d_1438/BiasAdd (224.58k/224.58k flops)\n",
      "  model_102/depthwise_conv2d_1335/BiasAdd (209.09k/209.09k flops)\n",
      "  model_102/conv2d_1437/BiasAdd (209.09k/209.09k flops)\n",
      "  model_102/batch_normalization_2765/FusedBatchNormV3 (208.44k/208.44k flops)\n",
      "  model_102/depthwise_conv2d_1334/BiasAdd (198.44k/198.44k flops)\n",
      "  model_102/conv2d_1436/BiasAdd (198.44k/198.44k flops)\n",
      "  model_102/conv2d_1435/BiasAdd (195.54k/195.54k flops)\n",
      "  model_102/depthwise_conv2d_1333/BiasAdd (195.54k/195.54k flops)\n",
      "  model_102/conv2d_1439/BiasAdd (149.07k/149.07k flops)\n",
      "  model_102/depthwise_conv2d_1329/BiasAdd (135.52k/135.52k flops)\n",
      "  model_102/depthwise_conv2d_1332/BiasAdd (129.71k/129.71k flops)\n",
      "  model_102/conv2d_1434/BiasAdd (129.71k/129.71k flops)\n",
      "  model_102/conv2d_1440/BiasAdd (119.55k/119.55k flops)\n",
      "  model_102/depthwise_conv2d_1331/BiasAdd (103.58k/103.58k flops)\n",
      "  model_102/batch_normalization_2780/FusedBatchNormV3 (79.25k/79.25k flops)\n",
      "  model_102/batch_normalization_2779/FusedBatchNormV3 (77.06k/77.06k flops)\n",
      "  model_102/batch_normalization_2777/FusedBatchNormV3 (76.38k/76.38k flops)\n",
      "  model_102/depthwise_conv2d_1337/BiasAdd (37.27k/37.27k flops)\n",
      "  model_102/global_average_pooling2d_102/Mean (36.58k/36.58k flops)\n",
      "  model_102/conv2d_1441/BiasAdd (36.58k/36.58k flops)\n",
      "  model_102/depthwise_conv2d_1338/BiasAdd (35.57k/35.57k flops)\n",
      "  model_102/dense_102/MatMul (20.32k/20.32k flops)\n",
      "  model_102/dense_102/Softmax (50/50 flops)\n",
      "  model_102/dense_102/BiasAdd (10/10 flops)\n",
      "\n",
      "======================End of Report==========================\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "122.292668\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-30 13:41:17.599490: I tensorflow/core/grappler/devices.cc:66] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0\n",
      "2022-04-30 13:41:17.599625: I tensorflow/core/grappler/clusters/single_machine.cc:357] Starting new session\n",
      "2022-04-30 13:41:17.603954: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:1137] Optimization results for grappler item: graph_to_optimize\n",
      "  function_optimizer: function_optimizer did nothing. time = 0.005ms.\n",
      "  function_optimizer: function_optimizer did nothing. time = 0.001ms.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=========================Options=============================\n",
      "-max_depth                  10000\n",
      "-min_bytes                  0\n",
      "-min_peak_bytes             0\n",
      "-min_residual_bytes         0\n",
      "-min_output_bytes           0\n",
      "-min_micros                 0\n",
      "-min_accelerator_micros     0\n",
      "-min_cpu_micros             0\n",
      "-min_params                 0\n",
      "-min_float_ops              1\n",
      "-min_occurrence             0\n",
      "-step                       -1\n",
      "-order_by                   float_ops\n",
      "-account_type_regexes       .*\n",
      "-start_name_regexes         .*\n",
      "-trim_name_regexes          \n",
      "-show_name_regexes          .*\n",
      "-hide_name_regexes          \n",
      "-account_displayed_op_only  true\n",
      "-select                     float_ops\n",
      "-output                     stdout:\n",
      "\n",
      "==================Model Analysis Report======================\n",
      "\n",
      "Doc:\n",
      "scope: The nodes in the model graph are organized by their names, which is hierarchical like filesystem.\n",
      "flops: Number of float operations. Note: Please read the implementation for the math behind it.\n",
      "\n",
      "Profile:\n",
      "node name | # float_ops\n",
      "_TFProfRoot (--/1.60b flops)\n",
      "  model_103/conv2d_1450/Conv2D (177.13m/177.13m flops)\n",
      "  model_103/conv2d_1451/Conv2D (175.53m/175.53m flops)\n",
      "  model_103/conv2d_1445/Conv2D (163.92m/163.92m flops)\n",
      "  model_103/conv2d_1452/Conv2D (124.65m/124.65m flops)\n",
      "  model_103/conv2d_1447/Conv2D (123.41m/123.41m flops)\n",
      "  model_103/conv2d_1443/Conv2D (118.95m/118.95m flops)\n",
      "  model_103/conv2d_1449/Conv2D (118.94m/118.94m flops)\n",
      "  model_103/conv2d_1453/Conv2D (105.87m/105.87m flops)\n",
      "  model_103/conv2d_1444/Conv2D (91.07m/91.07m flops)\n",
      "  model_103/conv2d_1454/Conv2D (83.90m/83.90m flops)\n",
      "  model_103/conv2d_1446/Conv2D (69.42m/69.42m flops)\n",
      "  model_103/conv2d_1455/Conv2D (68.45m/68.45m flops)\n",
      "  model_103/conv2d_1448/Conv2D (51.67m/51.67m flops)\n",
      "  model_103/conv2d_1442/Conv2D (31.72m/31.72m flops)\n",
      "  model_103/depthwise_conv2d_1339/depthwise (17.84m/17.84m flops)\n",
      "  model_103/depthwise_conv2d_1341/depthwise (13.66m/13.66m flops)\n",
      "  model_103/depthwise_conv2d_1340/depthwise (8.36m/8.36m flops)\n",
      "  model_103/depthwise_conv2d_1343/depthwise (5.78m/5.78m flops)\n",
      "  model_103/depthwise_conv2d_1346/depthwise (3.85m/3.85m flops)\n",
      "  model_103/depthwise_conv2d_1348/depthwise (3.82m/3.82m flops)\n",
      "  model_103/depthwise_conv2d_1342/depthwise (3.76m/3.76m flops)\n",
      "  model_103/batch_normalization_2783/FusedBatchNormV3 (3.72m/3.72m flops)\n",
      "  model_103/depthwise_conv2d_1347/depthwise (3.61m/3.61m flops)\n",
      "  model_103/depthwise_conv2d_1349/depthwise (2.56m/2.56m flops)\n",
      "  model_103/depthwise_conv2d_1345/depthwise (2.42m/2.42m flops)\n",
      "  model_103/batch_normalization_2782/FusedBatchNormV3 (1.98m/1.98m flops)\n",
      "  model_103/batch_normalization_2781/FusedBatchNormV3 (1.98m/1.98m flops)\n",
      "  model_103/conv2d_1443/BiasAdd (1.86m/1.86m flops)\n",
      "  model_103/batch_normalization_2787/FusedBatchNormV3 (1.67m/1.67m flops)\n",
      "  model_103/depthwise_conv2d_1344/depthwise (1.67m/1.67m flops)\n",
      "  model_103/batch_normalization_2785/FusedBatchNormV3 (1.52m/1.52m flops)\n",
      "  model_103/batch_normalization_2786/FusedBatchNormV3 (1.52m/1.52m flops)\n",
      "  model_103/conv2d_1442/BiasAdd (991.23k/991.23k flops)\n",
      "  model_103/depthwise_conv2d_1339/BiasAdd (991.23k/991.23k flops)\n",
      "  model_103/batch_normalization_2784/FusedBatchNormV3 (929.64k/929.64k flops)\n",
      "  model_103/conv2d_1445/BiasAdd (836.35k/836.35k flops)\n",
      "  model_103/depthwise_conv2d_1350/depthwise (810.22k/810.22k flops)\n",
      "  model_103/conv2d_1444/BiasAdd (758.91k/758.91k flops)\n",
      "  model_103/depthwise_conv2d_1341/BiasAdd (758.91k/758.91k flops)\n",
      "  model_103/batch_normalization_2791/FusedBatchNormV3 (744.58k/744.58k flops)\n",
      "  model_103/batch_normalization_2789/FusedBatchNormV3 (643.75k/643.75k flops)\n",
      "  model_103/batch_normalization_2790/FusedBatchNormV3 (643.75k/643.75k flops)\n",
      "  model_103/depthwise_conv2d_1351/depthwise (603.94k/603.94k flops)\n",
      "  model_103/depthwise_conv2d_1340/BiasAdd (464.64k/464.64k flops)\n",
      "  model_103/batch_normalization_2796/FusedBatchNormV3 (430.51k/430.51k flops)\n",
      "  model_103/batch_normalization_2795/FusedBatchNormV3 (430.51k/430.51k flops)\n",
      "  model_103/batch_normalization_2799/FusedBatchNormV3 (426.61k/426.61k flops)\n",
      "  model_103/batch_normalization_2800/FusedBatchNormV3 (426.61k/426.61k flops)\n",
      "  model_103/batch_normalization_2788/FusedBatchNormV3 (418.82k/418.82k flops)\n",
      "  model_103/batch_normalization_2798/FusedBatchNormV3 (403.24k/403.24k flops)\n",
      "  model_103/batch_normalization_2797/FusedBatchNormV3 (403.24k/403.24k flops)\n",
      "  model_103/conv2d_1447/BiasAdd (371.71k/371.71k flops)\n",
      "  model_103/batch_normalization_2803/FusedBatchNormV3 (362.33k/362.33k flops)\n",
      "  model_103/depthwise_conv2d_1343/BiasAdd (321.38k/321.38k flops)\n",
      "  model_103/conv2d_1446/BiasAdd (321.38k/321.38k flops)\n",
      "  model_103/batch_normalization_2801/FusedBatchNormV3 (286.36k/286.36k flops)\n",
      "  model_103/batch_normalization_2802/FusedBatchNormV3 (286.36k/286.36k flops)\n",
      "  model_103/batch_normalization_2793/FusedBatchNormV3 (270.77k/270.77k flops)\n",
      "  model_103/batch_normalization_2794/FusedBatchNormV3 (270.77k/270.77k flops)\n",
      "  model_103/batch_normalization_2805/FusedBatchNormV3 (231.14k/231.14k flops)\n",
      "  model_103/conv2d_1449/BiasAdd (213.93k/213.93k flops)\n",
      "  model_103/depthwise_conv2d_1346/BiasAdd (213.93k/213.93k flops)\n",
      "  model_103/depthwise_conv2d_1348/BiasAdd (211.99k/211.99k flops)\n",
      "  model_103/conv2d_1451/BiasAdd (211.99k/211.99k flops)\n",
      "  model_103/depthwise_conv2d_1342/BiasAdd (209.09k/209.09k flops)\n",
      "  model_103/depthwise_conv2d_1347/BiasAdd (200.38k/200.38k flops)\n",
      "  model_103/conv2d_1450/BiasAdd (200.38k/200.38k flops)\n",
      "  model_103/batch_normalization_2792/FusedBatchNormV3 (187.01k/187.01k flops)\n",
      "  model_103/conv2d_1453/BiasAdd (180.05k/180.05k flops)\n",
      "  model_103/depthwise_conv2d_1349/BiasAdd (142.30k/142.30k flops)\n",
      "  model_103/conv2d_1452/BiasAdd (142.30k/142.30k flops)\n",
      "  model_103/depthwise_conv2d_1345/BiasAdd (134.55k/134.55k flops)\n",
      "  model_103/conv2d_1448/BiasAdd (134.55k/134.55k flops)\n",
      "  model_103/conv2d_1454/BiasAdd (112.77k/112.77k flops)\n",
      "  model_103/depthwise_conv2d_1344/BiasAdd (92.93k/92.93k flops)\n",
      "  model_103/batch_normalization_2804/FusedBatchNormV3 (92.26k/92.26k flops)\n",
      "  model_103/batch_normalization_2807/FusedBatchNormV3 (79.56k/79.56k flops)\n",
      "  model_103/batch_normalization_2806/FusedBatchNormV3 (72.70k/72.70k flops)\n",
      "  model_103/depthwise_conv2d_1350/BiasAdd (45.01k/45.01k flops)\n",
      "  model_103/global_average_pooling2d_103/Mean (36.72k/36.72k flops)\n",
      "  model_103/conv2d_1455/BiasAdd (36.72k/36.72k flops)\n",
      "  model_103/depthwise_conv2d_1351/BiasAdd (33.55k/33.55k flops)\n",
      "  model_103/dense_103/MatMul (20.40k/20.40k flops)\n",
      "  model_103/dense_103/Softmax (50/50 flops)\n",
      "  model_103/dense_103/BiasAdd (10/10 flops)\n",
      "\n",
      "======================End of Report==========================\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "110.095876\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-30 13:41:18.636236: I tensorflow/core/grappler/devices.cc:66] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0\n",
      "2022-04-30 13:41:18.636353: I tensorflow/core/grappler/clusters/single_machine.cc:357] Starting new session\n",
      "2022-04-30 13:41:18.641534: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:1137] Optimization results for grappler item: graph_to_optimize\n",
      "  function_optimizer: function_optimizer did nothing. time = 0.006ms.\n",
      "  function_optimizer: function_optimizer did nothing. time = 0ms.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=========================Options=============================\n",
      "-max_depth                  10000\n",
      "-min_bytes                  0\n",
      "-min_peak_bytes             0\n",
      "-min_residual_bytes         0\n",
      "-min_output_bytes           0\n",
      "-min_micros                 0\n",
      "-min_accelerator_micros     0\n",
      "-min_cpu_micros             0\n",
      "-min_params                 0\n",
      "-min_float_ops              1\n",
      "-min_occurrence             0\n",
      "-step                       -1\n",
      "-order_by                   float_ops\n",
      "-account_type_regexes       .*\n",
      "-start_name_regexes         .*\n",
      "-trim_name_regexes          \n",
      "-show_name_regexes          .*\n",
      "-hide_name_regexes          \n",
      "-account_displayed_op_only  true\n",
      "-select                     float_ops\n",
      "-output                     stdout:\n",
      "\n",
      "==================Model Analysis Report======================\n",
      "\n",
      "Doc:\n",
      "scope: The nodes in the model graph are organized by their names, which is hierarchical like filesystem.\n",
      "flops: Number of float operations. Note: Please read the implementation for the math behind it.\n",
      "\n",
      "Profile:\n",
      "node name | # float_ops\n",
      "_TFProfRoot (--/1.72b flops)\n",
      "  model_104/conv2d_1464/Conv2D (229.30m/229.30m flops)\n",
      "  model_104/conv2d_1465/Conv2D (206.55m/206.55m flops)\n",
      "  model_104/conv2d_1467/Conv2D (204.17m/204.17m flops)\n",
      "  model_104/conv2d_1466/Conv2D (190.73m/190.73m flops)\n",
      "  model_104/conv2d_1463/Conv2D (169.78m/169.78m flops)\n",
      "  model_104/conv2d_1461/Conv2D (143.26m/143.26m flops)\n",
      "  model_104/conv2d_1459/Conv2D (100.36m/100.36m flops)\n",
      "  model_104/conv2d_1462/Conv2D (84.22m/84.22m flops)\n",
      "  model_104/conv2d_1457/Conv2D (75.33m/75.33m flops)\n",
      "  model_104/conv2d_1460/Conv2D (68.77m/68.77m flops)\n",
      "  model_104/conv2d_1468/Conv2D (66.33m/66.33m flops)\n",
      "  model_104/conv2d_1458/Conv2D (31.78m/31.78m flops)\n",
      "  model_104/conv2d_1456/Conv2D (31.72m/31.72m flops)\n",
      "  model_104/conv2d_1469/Conv2D (25.66m/25.66m flops)\n",
      "  model_104/depthwise_conv2d_1352/depthwise (17.84m/17.84m flops)\n",
      "  model_104/depthwise_conv2d_1354/depthwise (7.53m/7.53m flops)\n",
      "  model_104/depthwise_conv2d_1353/depthwise (5.30m/5.30m flops)\n",
      "  model_104/depthwise_conv2d_1356/depthwise (5.16m/5.16m flops)\n",
      "  model_104/depthwise_conv2d_1359/depthwise (4.39m/4.39m flops)\n",
      "  model_104/depthwise_conv2d_1355/depthwise (4.18m/4.18m flops)\n",
      "  model_104/depthwise_conv2d_1360/depthwise (4.09m/4.09m flops)\n",
      "  model_104/depthwise_conv2d_1361/depthwise (3.96m/3.96m flops)\n",
      "  model_104/depthwise_conv2d_1362/depthwise (3.78m/3.78m flops)\n",
      "  model_104/depthwise_conv2d_1358/depthwise (3.03m/3.03m flops)\n",
      "  model_104/batch_normalization_2810/FusedBatchNormV3 (2.35m/2.35m flops)\n",
      "  model_104/depthwise_conv2d_1357/depthwise (2.18m/2.18m flops)\n",
      "  model_104/batch_normalization_2809/FusedBatchNormV3 (1.98m/1.98m flops)\n",
      "  model_104/batch_normalization_2808/FusedBatchNormV3 (1.98m/1.98m flops)\n",
      "  model_104/batch_normalization_2814/FusedBatchNormV3 (1.86m/1.86m flops)\n",
      "  model_104/conv2d_1457/BiasAdd (1.18m/1.18m flops)\n",
      "  model_104/depthwise_conv2d_1363/depthwise (1.06m/1.06m flops)\n",
      "  model_104/conv2d_1456/BiasAdd (991.23k/991.23k flops)\n",
      "  model_104/depthwise_conv2d_1352/BiasAdd (991.23k/991.23k flops)\n",
      "  model_104/batch_normalization_2818/FusedBatchNormV3 (969.50k/969.50k flops)\n",
      "  model_104/conv2d_1459/BiasAdd (929.28k/929.28k flops)\n",
      "  model_104/batch_normalization_2813/FusedBatchNormV3 (836.68k/836.68k flops)\n",
      "  model_104/batch_normalization_2812/FusedBatchNormV3 (836.68k/836.68k flops)\n",
      "  model_104/batch_normalization_2811/FusedBatchNormV3 (588.77k/588.77k flops)\n",
      "  model_104/batch_normalization_2816/FusedBatchNormV3 (573.94k/573.94k flops)\n",
      "  model_104/batch_normalization_2817/FusedBatchNormV3 (573.94k/573.94k flops)\n",
      "  model_104/batch_normalization_2822/FusedBatchNormV3 (490.90k/490.90k flops)\n",
      "  model_104/batch_normalization_2823/FusedBatchNormV3 (490.90k/490.90k flops)\n",
      "  model_104/conv2d_1461/BiasAdd (484.00k/484.00k flops)\n",
      "  model_104/batch_normalization_2830/FusedBatchNormV3 (473.36k/473.36k flops)\n",
      "  model_104/batch_normalization_2815/FusedBatchNormV3 (465.36k/465.36k flops)\n",
      "  model_104/batch_normalization_2824/FusedBatchNormV3 (457.78k/457.78k flops)\n",
      "  model_104/batch_normalization_2825/FusedBatchNormV3 (457.78k/457.78k flops)\n",
      "  model_104/batch_normalization_2826/FusedBatchNormV3 (442.20k/442.20k flops)\n",
      "  model_104/batch_normalization_2827/FusedBatchNormV3 (442.20k/442.20k flops)\n",
      "  model_104/batch_normalization_2828/FusedBatchNormV3 (422.72k/422.72k flops)\n",
      "  model_104/batch_normalization_2829/FusedBatchNormV3 (422.72k/422.72k flops)\n",
      "  model_104/depthwise_conv2d_1354/BiasAdd (418.18k/418.18k flops)\n",
      "  model_104/conv2d_1458/BiasAdd (418.18k/418.18k flops)\n",
      "  model_104/depthwise_conv2d_1364/depthwise (365.47k/365.47k flops)\n",
      "  model_104/batch_normalization_2821/FusedBatchNormV3 (338.95k/338.95k flops)\n",
      "  model_104/batch_normalization_2820/FusedBatchNormV3 (338.95k/338.95k flops)\n",
      "  model_104/depthwise_conv2d_1353/BiasAdd (294.27k/294.27k flops)\n",
      "  model_104/conv2d_1460/BiasAdd (286.53k/286.53k flops)\n",
      "  model_104/depthwise_conv2d_1356/BiasAdd (286.53k/286.53k flops)\n",
      "  model_104/depthwise_conv2d_1359/BiasAdd (243.94k/243.94k flops)\n",
      "  model_104/conv2d_1463/BiasAdd (243.94k/243.94k flops)\n",
      "  model_104/batch_normalization_2819/FusedBatchNormV3 (243.50k/243.50k flops)\n",
      "  model_104/conv2d_1467/BiasAdd (235.22k/235.22k flops)\n",
      "  model_104/depthwise_conv2d_1355/BiasAdd (232.32k/232.32k flops)\n",
      "  model_104/depthwise_conv2d_1360/BiasAdd (227.48k/227.48k flops)\n",
      "  model_104/conv2d_1464/BiasAdd (227.48k/227.48k flops)\n",
      "  model_104/conv2d_1465/BiasAdd (219.74k/219.74k flops)\n",
      "  model_104/depthwise_conv2d_1361/BiasAdd (219.74k/219.74k flops)\n",
      "  model_104/conv2d_1466/BiasAdd (210.06k/210.06k flops)\n",
      "  model_104/depthwise_conv2d_1362/BiasAdd (210.06k/210.06k flops)\n",
      "  model_104/depthwise_conv2d_1358/BiasAdd (168.43k/168.43k flops)\n",
      "  model_104/conv2d_1462/BiasAdd (168.43k/168.43k flops)\n",
      "  model_104/batch_normalization_2832/FusedBatchNormV3 (139.87k/139.87k flops)\n",
      "  model_104/depthwise_conv2d_1357/BiasAdd (121.00k/121.00k flops)\n",
      "  model_104/batch_normalization_2831/FusedBatchNormV3 (120.53k/120.53k flops)\n",
      "  model_104/conv2d_1468/BiasAdd (68.24k/68.24k flops)\n",
      "  model_104/depthwise_conv2d_1363/BiasAdd (58.81k/58.81k flops)\n",
      "  model_104/batch_normalization_2834/FusedBatchNormV3 (49.30k/49.30k flops)\n",
      "  model_104/batch_normalization_2833/FusedBatchNormV3 (43.99k/43.99k flops)\n",
      "  model_104/global_average_pooling2d_104/Mean (22.75k/22.75k flops)\n",
      "  model_104/conv2d_1469/BiasAdd (22.75k/22.75k flops)\n",
      "  model_104/depthwise_conv2d_1364/BiasAdd (20.30k/20.30k flops)\n",
      "  model_104/dense_104/MatMul (12.64k/12.64k flops)\n",
      "  model_104/dense_104/Softmax (50/50 flops)\n",
      "  model_104/dense_104/BiasAdd (10/10 flops)\n",
      "\n",
      "======================End of Report==========================\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "118.037404\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-30 13:41:19.570763: I tensorflow/core/grappler/devices.cc:66] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0\n",
      "2022-04-30 13:41:19.570889: I tensorflow/core/grappler/clusters/single_machine.cc:357] Starting new session\n",
      "2022-04-30 13:41:19.575378: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:1137] Optimization results for grappler item: graph_to_optimize\n",
      "  function_optimizer: function_optimizer did nothing. time = 0.005ms.\n",
      "  function_optimizer: function_optimizer did nothing. time = 0.001ms.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=========================Options=============================\n",
      "-max_depth                  10000\n",
      "-min_bytes                  0\n",
      "-min_peak_bytes             0\n",
      "-min_residual_bytes         0\n",
      "-min_output_bytes           0\n",
      "-min_micros                 0\n",
      "-min_accelerator_micros     0\n",
      "-min_cpu_micros             0\n",
      "-min_params                 0\n",
      "-min_float_ops              1\n",
      "-min_occurrence             0\n",
      "-step                       -1\n",
      "-order_by                   float_ops\n",
      "-account_type_regexes       .*\n",
      "-start_name_regexes         .*\n",
      "-trim_name_regexes          \n",
      "-show_name_regexes          .*\n",
      "-hide_name_regexes          \n",
      "-account_displayed_op_only  true\n",
      "-select                     float_ops\n",
      "-output                     stdout:\n",
      "\n",
      "==================Model Analysis Report======================\n",
      "\n",
      "Doc:\n",
      "scope: The nodes in the model graph are organized by their names, which is hierarchical like filesystem.\n",
      "flops: Number of float operations. Note: Please read the implementation for the math behind it.\n",
      "\n",
      "Profile:\n",
      "node name | # float_ops\n",
      "_TFProfRoot (--/1.93b flops)\n",
      "  model_105/conv2d_1479/Conv2D (221.28m/221.28m flops)\n",
      "  model_105/conv2d_1478/Conv2D (218.33m/218.33m flops)\n",
      "  model_105/conv2d_1480/Conv2D (197.76m/197.76m flops)\n",
      "  model_105/conv2d_1481/Conv2D (191.61m/191.61m flops)\n",
      "  model_105/conv2d_1477/Conv2D (182.23m/182.23m flops)\n",
      "  model_105/conv2d_1475/Conv2D (175.01m/175.01m flops)\n",
      "  model_105/conv2d_1473/Conv2D (131.09m/131.09m flops)\n",
      "  model_105/conv2d_1482/Conv2D (107.83m/107.83m flops)\n",
      "  model_105/conv2d_1476/Conv2D (92.76m/92.76m flops)\n",
      "  model_105/conv2d_1471/Conv2D (79.30m/79.30m flops)\n",
      "  model_105/conv2d_1483/Conv2D (75.20m/75.20m flops)\n",
      "  model_105/conv2d_1474/Conv2D (71.24m/71.24m flops)\n",
      "  model_105/conv2d_1472/Conv2D (57.00m/57.00m flops)\n",
      "  model_105/conv2d_1470/Conv2D (31.72m/31.72m flops)\n",
      "  model_105/depthwise_conv2d_1365/depthwise (17.84m/17.84m flops)\n",
      "  model_105/depthwise_conv2d_1367/depthwise (12.82m/12.82m flops)\n",
      "  model_105/depthwise_conv2d_1369/depthwise (6.97m/6.97m flops)\n",
      "  model_105/depthwise_conv2d_1366/depthwise (5.58m/5.58m flops)\n",
      "  model_105/depthwise_conv2d_1373/depthwise (4.43m/4.43m flops)\n",
      "  model_105/depthwise_conv2d_1375/depthwise (3.96m/3.96m flops)\n",
      "  model_105/depthwise_conv2d_1374/depthwise (3.92m/3.92m flops)\n",
      "  model_105/depthwise_conv2d_1372/depthwise (3.87m/3.87m flops)\n",
      "  model_105/depthwise_conv2d_1371/depthwise (3.69m/3.69m flops)\n",
      "  model_105/depthwise_conv2d_1368/depthwise (3.21m/3.21m flops)\n",
      "  model_105/batch_normalization_2837/FusedBatchNormV3 (2.48m/2.48m flops)\n",
      "  model_105/batch_normalization_2836/FusedBatchNormV3 (1.98m/1.98m flops)\n",
      "  model_105/batch_normalization_2835/FusedBatchNormV3 (1.98m/1.98m flops)\n",
      "  model_105/depthwise_conv2d_1370/depthwise (1.97m/1.97m flops)\n",
      "  model_105/batch_normalization_2839/FusedBatchNormV3 (1.43m/1.43m flops)\n",
      "  model_105/batch_normalization_2841/FusedBatchNormV3 (1.43m/1.43m flops)\n",
      "  model_105/batch_normalization_2840/FusedBatchNormV3 (1.43m/1.43m flops)\n",
      "  model_105/conv2d_1471/BiasAdd (1.24m/1.24m flops)\n",
      "  model_105/conv2d_1470/BiasAdd (991.23k/991.23k flops)\n",
      "  model_105/depthwise_conv2d_1365/BiasAdd (991.23k/991.23k flops)\n",
      "  model_105/depthwise_conv2d_1376/depthwise (949.61k/949.61k flops)\n",
      "  model_105/batch_normalization_2845/FusedBatchNormV3 (876.43k/876.43k flops)\n",
      "  model_105/batch_normalization_2843/FusedBatchNormV3 (775.60k/775.60k flops)\n",
      "  model_105/batch_normalization_2844/FusedBatchNormV3 (775.60k/775.60k flops)\n",
      "  model_105/depthwise_conv2d_1367/BiasAdd (712.45k/712.45k flops)\n",
      "  model_105/conv2d_1473/BiasAdd (712.45k/712.45k flops)\n",
      "  model_105/conv2d_1472/BiasAdd (712.45k/712.45k flops)\n",
      "  model_105/depthwise_conv2d_1377/depthwise (662.26k/662.26k flops)\n",
      "  model_105/batch_normalization_2838/FusedBatchNormV3 (619.76k/619.76k flops)\n",
      "  model_105/batch_normalization_2852/FusedBatchNormV3 (494.79k/494.79k flops)\n",
      "  model_105/batch_normalization_2851/FusedBatchNormV3 (494.79k/494.79k flops)\n",
      "  model_105/batch_normalization_2856/FusedBatchNormV3 (442.20k/442.20k flops)\n",
      "  model_105/batch_normalization_2855/FusedBatchNormV3 (442.20k/442.20k flops)\n",
      "  model_105/batch_normalization_2853/FusedBatchNormV3 (438.30k/438.30k flops)\n",
      "  model_105/batch_normalization_2854/FusedBatchNormV3 (438.30k/438.30k flops)\n",
      "  model_105/conv2d_1475/BiasAdd (437.54k/437.54k flops)\n",
      "  model_105/batch_normalization_2850/FusedBatchNormV3 (432.46k/432.46k flops)\n",
      "  model_105/batch_normalization_2849/FusedBatchNormV3 (432.46k/432.46k flops)\n",
      "  model_105/batch_normalization_2857/FusedBatchNormV3 (424.66k/424.66k flops)\n",
      "  model_105/batch_normalization_2848/FusedBatchNormV3 (412.98k/412.98k flops)\n",
      "  model_105/batch_normalization_2847/FusedBatchNormV3 (412.98k/412.98k flops)\n",
      "  model_105/conv2d_1474/BiasAdd (387.20k/387.20k flops)\n",
      "  model_105/depthwise_conv2d_1369/BiasAdd (387.20k/387.20k flops)\n",
      "  model_105/batch_normalization_2842/FusedBatchNormV3 (356.78k/356.78k flops)\n",
      "  model_105/depthwise_conv2d_1366/BiasAdd (309.76k/309.76k flops)\n",
      "  model_105/batch_normalization_2859/FusedBatchNormV3 (253.46k/253.46k flops)\n",
      "  model_105/depthwise_conv2d_1373/BiasAdd (245.87k/245.87k flops)\n",
      "  model_105/conv2d_1478/BiasAdd (245.87k/245.87k flops)\n",
      "  model_105/batch_normalization_2846/FusedBatchNormV3 (220.12k/220.12k flops)\n",
      "  model_105/depthwise_conv2d_1375/BiasAdd (219.74k/219.74k flops)\n",
      "  model_105/conv2d_1480/BiasAdd (219.74k/219.74k flops)\n",
      "  model_105/depthwise_conv2d_1374/BiasAdd (217.80k/217.80k flops)\n",
      "  model_105/conv2d_1479/BiasAdd (217.80k/217.80k flops)\n",
      "  model_105/depthwise_conv2d_1372/BiasAdd (214.90k/214.90k flops)\n",
      "  model_105/conv2d_1477/BiasAdd (214.90k/214.90k flops)\n",
      "  model_105/conv2d_1481/BiasAdd (211.02k/211.02k flops)\n",
      "  model_105/depthwise_conv2d_1371/BiasAdd (205.22k/205.22k flops)\n",
      "  model_105/conv2d_1476/BiasAdd (205.22k/205.22k flops)\n",
      "  model_105/depthwise_conv2d_1368/BiasAdd (178.11k/178.11k flops)\n",
      "  model_105/conv2d_1482/BiasAdd (123.66k/123.66k flops)\n",
      "  model_105/depthwise_conv2d_1370/BiasAdd (109.38k/109.38k flops)\n",
      "  model_105/batch_normalization_2858/FusedBatchNormV3 (108.13k/108.13k flops)\n",
      "  model_105/batch_normalization_2861/FusedBatchNormV3 (79.72k/79.72k flops)\n",
      "  model_105/batch_normalization_2860/FusedBatchNormV3 (79.72k/79.72k flops)\n",
      "  model_105/depthwise_conv2d_1376/BiasAdd (52.76k/52.76k flops)\n",
      "  model_105/depthwise_conv2d_1377/BiasAdd (36.79k/36.79k flops)\n",
      "  model_105/global_average_pooling2d_105/Mean (36.79k/36.79k flops)\n",
      "  model_105/conv2d_1483/BiasAdd (36.79k/36.79k flops)\n",
      "  model_105/dense_105/MatMul (20.44k/20.44k flops)\n",
      "  model_105/dense_105/Softmax (50/50 flops)\n",
      "  model_105/dense_105/BiasAdd (10/10 flops)\n",
      "\n",
      "======================End of Report==========================\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "118.79682\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-30 13:41:20.512363: I tensorflow/core/grappler/devices.cc:66] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0\n",
      "2022-04-30 13:41:20.512477: I tensorflow/core/grappler/clusters/single_machine.cc:357] Starting new session\n",
      "2022-04-30 13:41:20.516727: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:1137] Optimization results for grappler item: graph_to_optimize\n",
      "  function_optimizer: function_optimizer did nothing. time = 0.005ms.\n",
      "  function_optimizer: function_optimizer did nothing. time = 0ms.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=========================Options=============================\n",
      "-max_depth                  10000\n",
      "-min_bytes                  0\n",
      "-min_peak_bytes             0\n",
      "-min_residual_bytes         0\n",
      "-min_output_bytes           0\n",
      "-min_micros                 0\n",
      "-min_accelerator_micros     0\n",
      "-min_cpu_micros             0\n",
      "-min_params                 0\n",
      "-min_float_ops              1\n",
      "-min_occurrence             0\n",
      "-step                       -1\n",
      "-order_by                   float_ops\n",
      "-account_type_regexes       .*\n",
      "-start_name_regexes         .*\n",
      "-trim_name_regexes          \n",
      "-show_name_regexes          .*\n",
      "-hide_name_regexes          \n",
      "-account_displayed_op_only  true\n",
      "-select                     float_ops\n",
      "-output                     stdout:\n",
      "\n",
      "==================Model Analysis Report======================\n",
      "\n",
      "Doc:\n",
      "scope: The nodes in the model graph are organized by their names, which is hierarchical like filesystem.\n",
      "flops: Number of float operations. Note: Please read the implementation for the math behind it.\n",
      "\n",
      "Profile:\n",
      "node name | # float_ops\n",
      "_TFProfRoot (--/1.73b flops)\n",
      "  model_106/conv2d_1487/Conv2D (219.19m/219.19m flops)\n",
      "  model_106/conv2d_1495/Conv2D (175.73m/175.73m flops)\n",
      "  model_106/conv2d_1493/Conv2D (163.06m/163.06m flops)\n",
      "  model_106/conv2d_1494/Conv2D (158.72m/158.72m flops)\n",
      "  model_106/conv2d_1492/Conv2D (155.05m/155.05m flops)\n",
      "  model_106/conv2d_1491/Conv2D (144.33m/144.33m flops)\n",
      "  model_106/conv2d_1496/Conv2D (121.95m/121.95m flops)\n",
      "  model_106/conv2d_1489/Conv2D (101.48m/101.48m flops)\n",
      "  model_106/conv2d_1485/Conv2D (79.30m/79.30m flops)\n",
      "  model_106/conv2d_1497/Conv2D (74.47m/74.47m flops)\n",
      "  model_106/conv2d_1486/Conv2D (71.86m/71.86m flops)\n",
      "  model_106/conv2d_1490/Conv2D (70.47m/70.47m flops)\n",
      "  model_106/conv2d_1488/Conv2D (59.52m/59.52m flops)\n",
      "  model_106/conv2d_1484/Conv2D (31.72m/31.72m flops)\n",
      "  model_106/depthwise_conv2d_1378/depthwise (17.84m/17.84m flops)\n",
      "  model_106/depthwise_conv2d_1380/depthwise (16.17m/16.17m flops)\n",
      "  model_106/depthwise_conv2d_1379/depthwise (5.58m/5.58m flops)\n",
      "  model_106/depthwise_conv2d_1382/depthwise (4.39m/4.39m flops)\n",
      "  model_106/depthwise_conv2d_1381/depthwise (4.25m/4.25m flops)\n",
      "  model_106/depthwise_conv2d_1387/depthwise (3.90m/3.90m flops)\n",
      "  model_106/depthwise_conv2d_1385/depthwise (3.71m/3.71m flops)\n",
      "  model_106/depthwise_conv2d_1386/depthwise (3.28m/3.28m flops)\n",
      "  model_106/depthwise_conv2d_1388/depthwise (3.19m/3.19m flops)\n",
      "  model_106/depthwise_conv2d_1384/depthwise (3.05m/3.05m flops)\n",
      "  model_106/batch_normalization_2864/FusedBatchNormV3 (2.48m/2.48m flops)\n",
      "  model_106/batch_normalization_2863/FusedBatchNormV3 (1.98m/1.98m flops)\n",
      "  model_106/batch_normalization_2862/FusedBatchNormV3 (1.98m/1.98m flops)\n",
      "  model_106/batch_normalization_2868/FusedBatchNormV3 (1.89m/1.89m flops)\n",
      "  model_106/depthwise_conv2d_1383/depthwise (1.81m/1.81m flops)\n",
      "  model_106/batch_normalization_2866/FusedBatchNormV3 (1.80m/1.80m flops)\n",
      "  model_106/batch_normalization_2867/FusedBatchNormV3 (1.80m/1.80m flops)\n",
      "  model_106/conv2d_1485/BiasAdd (1.24m/1.24m flops)\n",
      "  model_106/depthwise_conv2d_1389/depthwise (1.08m/1.08m flops)\n",
      "  model_106/conv2d_1484/BiasAdd (991.23k/991.23k flops)\n",
      "  model_106/depthwise_conv2d_1378/BiasAdd (991.23k/991.23k flops)\n",
      "  model_106/conv2d_1487/BiasAdd (944.77k/944.77k flops)\n",
      "  model_106/conv2d_1486/BiasAdd (898.30k/898.30k flops)\n",
      "  model_106/depthwise_conv2d_1380/BiasAdd (898.30k/898.30k flops)\n",
      "  model_106/batch_normalization_2872/FusedBatchNormV3 (806.62k/806.62k flops)\n",
      "  model_106/depthwise_conv2d_1390/depthwise (658.37k/658.37k flops)\n",
      "  model_106/batch_normalization_2865/FusedBatchNormV3 (619.76k/619.76k flops)\n",
      "  model_106/batch_normalization_2871/FusedBatchNormV3 (488.63k/488.63k flops)\n",
      "  model_106/batch_normalization_2870/FusedBatchNormV3 (488.63k/488.63k flops)\n",
      "  model_106/batch_normalization_2884/FusedBatchNormV3 (483.10k/483.10k flops)\n",
      "  model_106/batch_normalization_2869/FusedBatchNormV3 (473.12k/473.12k flops)\n",
      "  model_106/batch_normalization_2881/FusedBatchNormV3 (436.35k/436.35k flops)\n",
      "  model_106/batch_normalization_2880/FusedBatchNormV3 (436.35k/436.35k flops)\n",
      "  model_106/batch_normalization_2877/FusedBatchNormV3 (414.92k/414.92k flops)\n",
      "  model_106/batch_normalization_2876/FusedBatchNormV3 (414.92k/414.92k flops)\n",
      "  model_106/conv2d_1489/BiasAdd (402.69k/402.69k flops)\n",
      "  model_106/batch_normalization_2878/FusedBatchNormV3 (366.22k/366.22k flops)\n",
      "  model_106/batch_normalization_2879/FusedBatchNormV3 (366.22k/366.22k flops)\n",
      "  model_106/batch_normalization_2882/FusedBatchNormV3 (356.48k/356.48k flops)\n",
      "  model_106/batch_normalization_2883/FusedBatchNormV3 (356.48k/356.48k flops)\n",
      "  model_106/batch_normalization_2875/FusedBatchNormV3 (340.90k/340.90k flops)\n",
      "  model_106/batch_normalization_2874/FusedBatchNormV3 (340.90k/340.90k flops)\n",
      "  model_106/depthwise_conv2d_1379/BiasAdd (309.76k/309.76k flops)\n",
      "  model_106/batch_normalization_2886/FusedBatchNormV3 (251.97k/251.97k flops)\n",
      "  model_106/depthwise_conv2d_1382/BiasAdd (243.94k/243.94k flops)\n",
      "  model_106/conv2d_1488/BiasAdd (243.94k/243.94k flops)\n",
      "  model_106/conv2d_1495/BiasAdd (240.06k/240.06k flops)\n",
      "  model_106/depthwise_conv2d_1381/BiasAdd (236.19k/236.19k flops)\n",
      "  model_106/depthwise_conv2d_1387/BiasAdd (216.83k/216.83k flops)\n",
      "  model_106/conv2d_1493/BiasAdd (216.83k/216.83k flops)\n",
      "  model_106/depthwise_conv2d_1385/BiasAdd (206.18k/206.18k flops)\n",
      "  model_106/conv2d_1491/BiasAdd (206.18k/206.18k flops)\n",
      "  model_106/batch_normalization_2873/FusedBatchNormV3 (202.59k/202.59k flops)\n",
      "  model_106/depthwise_conv2d_1386/BiasAdd (181.98k/181.98k flops)\n",
      "  model_106/conv2d_1492/BiasAdd (181.98k/181.98k flops)\n",
      "  model_106/depthwise_conv2d_1388/BiasAdd (177.14k/177.14k flops)\n",
      "  model_106/conv2d_1494/BiasAdd (177.14k/177.14k flops)\n",
      "  model_106/conv2d_1490/BiasAdd (169.40k/169.40k flops)\n",
      "  model_106/depthwise_conv2d_1384/BiasAdd (169.40k/169.40k flops)\n",
      "  model_106/batch_normalization_2885/FusedBatchNormV3 (123.01k/123.01k flops)\n",
      "  model_106/conv2d_1496/BiasAdd (122.94k/122.94k flops)\n",
      "  model_106/depthwise_conv2d_1383/BiasAdd (100.67k/100.67k flops)\n",
      "  model_106/batch_normalization_2888/FusedBatchNormV3 (79.40k/79.40k flops)\n",
      "  model_106/batch_normalization_2887/FusedBatchNormV3 (79.25k/79.25k flops)\n",
      "  model_106/depthwise_conv2d_1389/BiasAdd (60.02k/60.02k flops)\n",
      "  model_106/global_average_pooling2d_106/Mean (36.65k/36.65k flops)\n",
      "  model_106/conv2d_1497/BiasAdd (36.65k/36.65k flops)\n",
      "  model_106/depthwise_conv2d_1390/BiasAdd (36.58k/36.58k flops)\n",
      "  model_106/dense_106/MatMul (20.36k/20.36k flops)\n",
      "  model_106/dense_106/Softmax (50/50 flops)\n",
      "  model_106/dense_106/BiasAdd (10/10 flops)\n",
      "\n",
      "======================End of Report==========================\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "116.365604\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-30 13:41:21.545266: I tensorflow/core/grappler/devices.cc:66] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0\n",
      "2022-04-30 13:41:21.545392: I tensorflow/core/grappler/clusters/single_machine.cc:357] Starting new session\n",
      "2022-04-30 13:41:21.550098: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:1137] Optimization results for grappler item: graph_to_optimize\n",
      "  function_optimizer: function_optimizer did nothing. time = 0.005ms.\n",
      "  function_optimizer: function_optimizer did nothing. time = 0.001ms.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=========================Options=============================\n",
      "-max_depth                  10000\n",
      "-min_bytes                  0\n",
      "-min_peak_bytes             0\n",
      "-min_residual_bytes         0\n",
      "-min_output_bytes           0\n",
      "-min_micros                 0\n",
      "-min_accelerator_micros     0\n",
      "-min_cpu_micros             0\n",
      "-min_params                 0\n",
      "-min_float_ops              1\n",
      "-min_occurrence             0\n",
      "-step                       -1\n",
      "-order_by                   float_ops\n",
      "-account_type_regexes       .*\n",
      "-start_name_regexes         .*\n",
      "-trim_name_regexes          \n",
      "-show_name_regexes          .*\n",
      "-hide_name_regexes          \n",
      "-account_displayed_op_only  true\n",
      "-select                     float_ops\n",
      "-output                     stdout:\n",
      "\n",
      "==================Model Analysis Report======================\n",
      "\n",
      "Doc:\n",
      "scope: The nodes in the model graph are organized by their names, which is hierarchical like filesystem.\n",
      "flops: Number of float operations. Note: Please read the implementation for the math behind it.\n",
      "\n",
      "Profile:\n",
      "node name | # float_ops\n",
      "_TFProfRoot (--/1.71b flops)\n",
      "  model_107/conv2d_1501/Conv2D (215.59m/215.59m flops)\n",
      "  model_107/conv2d_1507/Conv2D (193.97m/193.97m flops)\n",
      "  model_107/conv2d_1506/Conv2D (182.31m/182.31m flops)\n",
      "  model_107/conv2d_1508/Conv2D (158.78m/158.78m flops)\n",
      "  model_107/conv2d_1509/Conv2D (149.24m/149.24m flops)\n",
      "  model_107/conv2d_1505/Conv2D (138.22m/138.22m flops)\n",
      "  model_107/conv2d_1503/Conv2D (135.91m/135.91m flops)\n",
      "  model_107/conv2d_1510/Conv2D (81.62m/81.62m flops)\n",
      "  model_107/conv2d_1504/Conv2D (73.84m/73.84m flops)\n",
      "  model_107/conv2d_1502/Conv2D (69.70m/69.70m flops)\n",
      "  model_107/conv2d_1499/Conv2D (63.44m/63.44m flops)\n",
      "  model_107/conv2d_1500/Conv2D (57.49m/57.49m flops)\n",
      "  model_107/conv2d_1511/Conv2D (56.22m/56.22m flops)\n",
      "  model_107/conv2d_1498/Conv2D (31.72m/31.72m flops)\n",
      "  model_107/depthwise_conv2d_1391/depthwise (17.84m/17.84m flops)\n",
      "  model_107/depthwise_conv2d_1393/depthwise (16.17m/16.17m flops)\n",
      "  model_107/depthwise_conv2d_1395/depthwise (5.23m/5.23m flops)\n",
      "  model_107/depthwise_conv2d_1392/depthwise (4.46m/4.46m flops)\n",
      "  model_107/depthwise_conv2d_1394/depthwise (4.18m/4.18m flops)\n",
      "  model_107/depthwise_conv2d_1400/depthwise (4.06m/4.06m flops)\n",
      "  model_107/depthwise_conv2d_1398/depthwise (3.82m/3.82m flops)\n",
      "  model_107/depthwise_conv2d_1399/depthwise (3.75m/3.75m flops)\n",
      "  model_107/depthwise_conv2d_1401/depthwise (3.07m/3.07m flops)\n",
      "  model_107/depthwise_conv2d_1397/depthwise (2.84m/2.84m flops)\n",
      "  model_107/depthwise_conv2d_1396/depthwise (2.04m/2.04m flops)\n",
      "  model_107/batch_normalization_2890/FusedBatchNormV3 (1.98m/1.98m flops)\n",
      "  model_107/batch_normalization_2889/FusedBatchNormV3 (1.98m/1.98m flops)\n",
      "  model_107/batch_normalization_2891/FusedBatchNormV3 (1.98m/1.98m flops)\n",
      "  model_107/batch_normalization_2895/FusedBatchNormV3 (1.86m/1.86m flops)\n",
      "  model_107/batch_normalization_2893/FusedBatchNormV3 (1.80m/1.80m flops)\n",
      "  model_107/batch_normalization_2894/FusedBatchNormV3 (1.80m/1.80m flops)\n",
      "  model_107/conv2d_1498/BiasAdd (991.23k/991.23k flops)\n",
      "  model_107/depthwise_conv2d_1391/BiasAdd (991.23k/991.23k flops)\n",
      "  model_107/conv2d_1499/BiasAdd (991.23k/991.23k flops)\n",
      "  model_107/depthwise_conv2d_1402/depthwise (953.96k/953.96k flops)\n",
      "  model_107/conv2d_1501/BiasAdd (929.28k/929.28k flops)\n",
      "  model_107/batch_normalization_2899/FusedBatchNormV3 (907.45k/907.45k flops)\n",
      "  model_107/conv2d_1500/BiasAdd (898.30k/898.30k flops)\n",
      "  model_107/depthwise_conv2d_1393/BiasAdd (898.30k/898.30k flops)\n",
      "  model_107/batch_normalization_2897/FusedBatchNormV3 (581.70k/581.70k flops)\n",
      "  model_107/batch_normalization_2898/FusedBatchNormV3 (581.70k/581.70k flops)\n",
      "  model_107/depthwise_conv2d_1403/depthwise (498.96k/498.96k flops)\n",
      "  model_107/batch_normalization_2892/FusedBatchNormV3 (495.81k/495.81k flops)\n",
      "  model_107/batch_normalization_2896/FusedBatchNormV3 (465.36k/465.36k flops)\n",
      "  model_107/batch_normalization_2908/FusedBatchNormV3 (453.88k/453.88k flops)\n",
      "  model_107/batch_normalization_2907/FusedBatchNormV3 (453.88k/453.88k flops)\n",
      "  model_107/conv2d_1503/BiasAdd (453.02k/453.02k flops)\n",
      "  model_107/batch_normalization_2911/FusedBatchNormV3 (426.61k/426.61k flops)\n",
      "  model_107/batch_normalization_2903/FusedBatchNormV3 (426.61k/426.61k flops)\n",
      "  model_107/batch_normalization_2904/FusedBatchNormV3 (426.61k/426.61k flops)\n",
      "  model_107/batch_normalization_2905/FusedBatchNormV3 (418.82k/418.82k flops)\n",
      "  model_107/batch_normalization_2906/FusedBatchNormV3 (418.82k/418.82k flops)\n",
      "  model_107/batch_normalization_2910/FusedBatchNormV3 (342.85k/342.85k flops)\n",
      "  model_107/batch_normalization_2909/FusedBatchNormV3 (342.85k/342.85k flops)\n",
      "  model_107/batch_normalization_2902/FusedBatchNormV3 (317.52k/317.52k flops)\n",
      "  model_107/batch_normalization_2901/FusedBatchNormV3 (317.52k/317.52k flops)\n",
      "  model_107/conv2d_1502/BiasAdd (290.40k/290.40k flops)\n",
      "  model_107/depthwise_conv2d_1395/BiasAdd (290.40k/290.40k flops)\n",
      "  model_107/depthwise_conv2d_1392/BiasAdd (247.81k/247.81k flops)\n",
      "  model_107/depthwise_conv2d_1394/BiasAdd (232.32k/232.32k flops)\n",
      "  model_107/batch_normalization_2900/FusedBatchNormV3 (227.92k/227.92k flops)\n",
      "  model_107/conv2d_1507/BiasAdd (225.54k/225.54k flops)\n",
      "  model_107/depthwise_conv2d_1400/BiasAdd (225.54k/225.54k flops)\n",
      "  model_107/conv2d_1509/BiasAdd (211.99k/211.99k flops)\n",
      "  model_107/conv2d_1505/BiasAdd (211.99k/211.99k flops)\n",
      "  model_107/depthwise_conv2d_1398/BiasAdd (211.99k/211.99k flops)\n",
      "  model_107/conv2d_1506/BiasAdd (208.12k/208.12k flops)\n",
      "  model_107/depthwise_conv2d_1399/BiasAdd (208.12k/208.12k flops)\n",
      "  model_107/batch_normalization_2913/FusedBatchNormV3 (190.96k/190.96k flops)\n",
      "  model_107/depthwise_conv2d_1401/BiasAdd (170.37k/170.37k flops)\n",
      "  model_107/conv2d_1508/BiasAdd (170.37k/170.37k flops)\n",
      "  model_107/depthwise_conv2d_1397/BiasAdd (157.78k/157.78k flops)\n",
      "  model_107/conv2d_1504/BiasAdd (157.78k/157.78k flops)\n",
      "  model_107/depthwise_conv2d_1396/BiasAdd (113.26k/113.26k flops)\n",
      "  model_107/batch_normalization_2912/FusedBatchNormV3 (108.62k/108.62k flops)\n",
      "  model_107/conv2d_1510/BiasAdd (93.17k/93.17k flops)\n",
      "  model_107/batch_normalization_2915/FusedBatchNormV3 (79.09k/79.09k flops)\n",
      "  model_107/batch_normalization_2914/FusedBatchNormV3 (60.06k/60.06k flops)\n",
      "  model_107/depthwise_conv2d_1402/BiasAdd (53.00k/53.00k flops)\n",
      "  model_107/global_average_pooling2d_107/Mean (36.50k/36.50k flops)\n",
      "  model_107/conv2d_1511/BiasAdd (36.50k/36.50k flops)\n",
      "  model_107/depthwise_conv2d_1403/BiasAdd (27.72k/27.72k flops)\n",
      "  model_107/dense_107/MatMul (20.28k/20.28k flops)\n",
      "  model_107/dense_107/Softmax (50/50 flops)\n",
      "  model_107/dense_107/BiasAdd (10/10 flops)\n",
      "\n",
      "======================End of Report==========================\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "97.497116\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-30 13:41:22.468608: I tensorflow/core/grappler/devices.cc:66] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0\n",
      "2022-04-30 13:41:22.468732: I tensorflow/core/grappler/clusters/single_machine.cc:357] Starting new session\n",
      "2022-04-30 13:41:22.472980: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:1137] Optimization results for grappler item: graph_to_optimize\n",
      "  function_optimizer: function_optimizer did nothing. time = 0.005ms.\n",
      "  function_optimizer: function_optimizer did nothing. time = 0.001ms.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=========================Options=============================\n",
      "-max_depth                  10000\n",
      "-min_bytes                  0\n",
      "-min_peak_bytes             0\n",
      "-min_residual_bytes         0\n",
      "-min_output_bytes           0\n",
      "-min_micros                 0\n",
      "-min_accelerator_micros     0\n",
      "-min_cpu_micros             0\n",
      "-min_params                 0\n",
      "-min_float_ops              1\n",
      "-min_occurrence             0\n",
      "-step                       -1\n",
      "-order_by                   float_ops\n",
      "-account_type_regexes       .*\n",
      "-start_name_regexes         .*\n",
      "-trim_name_regexes          \n",
      "-show_name_regexes          .*\n",
      "-hide_name_regexes          \n",
      "-account_displayed_op_only  true\n",
      "-select                     float_ops\n",
      "-output                     stdout:\n",
      "\n",
      "==================Model Analysis Report======================\n",
      "\n",
      "Doc:\n",
      "scope: The nodes in the model graph are organized by their names, which is hierarchical like filesystem.\n",
      "flops: Number of float operations. Note: Please read the implementation for the math behind it.\n",
      "\n",
      "Profile:\n",
      "node name | # float_ops\n",
      "_TFProfRoot (--/1.37b flops)\n",
      "  model_108/conv2d_1522/Conv2D (235.27m/235.27m flops)\n",
      "  model_108/conv2d_1523/Conv2D (214.23m/214.23m flops)\n",
      "  model_108/conv2d_1521/Conv2D (136.21m/136.21m flops)\n",
      "  model_108/conv2d_1520/Conv2D (114.62m/114.62m flops)\n",
      "  model_108/conv2d_1519/Conv2D (97.78m/97.78m flops)\n",
      "  model_108/conv2d_1517/Conv2D (89.40m/89.40m flops)\n",
      "  model_108/conv2d_1524/Conv2D (83.05m/83.05m flops)\n",
      "  model_108/conv2d_1515/Conv2D (67.47m/67.47m flops)\n",
      "  model_108/conv2d_1513/Conv2D (63.44m/63.44m flops)\n",
      "  model_108/conv2d_1525/Conv2D (48.64m/48.64m flops)\n",
      "  model_108/conv2d_1516/Conv2D (37.82m/37.82m flops)\n",
      "  model_108/conv2d_1518/Conv2D (36.85m/36.85m flops)\n",
      "  model_108/conv2d_1514/Conv2D (32.71m/32.71m flops)\n",
      "  model_108/conv2d_1512/Conv2D (31.72m/31.72m flops)\n",
      "  model_108/depthwise_conv2d_1404/depthwise (17.84m/17.84m flops)\n",
      "  model_108/depthwise_conv2d_1406/depthwise (9.20m/9.20m flops)\n",
      "  model_108/depthwise_conv2d_1408/depthwise (5.16m/5.16m flops)\n",
      "  model_108/depthwise_conv2d_1405/depthwise (4.46m/4.46m flops)\n",
      "  model_108/depthwise_conv2d_1414/depthwise (4.30m/4.30m flops)\n",
      "  model_108/depthwise_conv2d_1413/depthwise (4.29m/4.29m flops)\n",
      "  model_108/depthwise_conv2d_1411/depthwise (3.61m/3.61m flops)\n",
      "  model_108/depthwise_conv2d_1412/depthwise (2.49m/2.49m flops)\n",
      "  model_108/depthwise_conv2d_1407/depthwise (2.30m/2.30m flops)\n",
      "  model_108/depthwise_conv2d_1410/depthwise (2.13m/2.13m flops)\n",
      "  model_108/batch_normalization_2917/FusedBatchNormV3 (1.98m/1.98m flops)\n",
      "  model_108/batch_normalization_2916/FusedBatchNormV3 (1.98m/1.98m flops)\n",
      "  model_108/batch_normalization_2918/FusedBatchNormV3 (1.98m/1.98m flops)\n",
      "  model_108/depthwise_conv2d_1409/depthwise (1.36m/1.36m flops)\n",
      "  model_108/batch_normalization_2920/FusedBatchNormV3 (1.02m/1.02m flops)\n",
      "  model_108/batch_normalization_2922/FusedBatchNormV3 (1.02m/1.02m flops)\n",
      "  model_108/batch_normalization_2921/FusedBatchNormV3 (1.02m/1.02m flops)\n",
      "  model_108/depthwise_conv2d_1404/BiasAdd (991.23k/991.23k flops)\n",
      "  model_108/conv2d_1513/BiasAdd (991.23k/991.23k flops)\n",
      "  model_108/conv2d_1512/BiasAdd (991.23k/991.23k flops)\n",
      "  model_108/depthwise_conv2d_1415/depthwise (975.74k/975.74k flops)\n",
      "  model_108/batch_normalization_2926/FusedBatchNormV3 (604.97k/604.97k flops)\n",
      "  model_108/batch_normalization_2925/FusedBatchNormV3 (573.94k/573.94k flops)\n",
      "  model_108/batch_normalization_2924/FusedBatchNormV3 (573.94k/573.94k flops)\n",
      "  model_108/depthwise_conv2d_1406/BiasAdd (511.10k/511.10k flops)\n",
      "  model_108/conv2d_1515/BiasAdd (511.10k/511.10k flops)\n",
      "  model_108/conv2d_1514/BiasAdd (511.10k/511.10k flops)\n",
      "  model_108/depthwise_conv2d_1416/depthwise (496.37k/496.37k flops)\n",
      "  model_108/batch_normalization_2919/FusedBatchNormV3 (495.81k/495.81k flops)\n",
      "  model_108/batch_normalization_2937/FusedBatchNormV3 (481.16k/481.16k flops)\n",
      "  model_108/batch_normalization_2936/FusedBatchNormV3 (481.16k/481.16k flops)\n",
      "  model_108/batch_normalization_2935/FusedBatchNormV3 (479.21k/479.21k flops)\n",
      "  model_108/batch_normalization_2934/FusedBatchNormV3 (479.21k/479.21k flops)\n",
      "  model_108/batch_normalization_2938/FusedBatchNormV3 (436.35k/436.35k flops)\n",
      "  model_108/batch_normalization_2930/FusedBatchNormV3 (403.24k/403.24k flops)\n",
      "  model_108/batch_normalization_2931/FusedBatchNormV3 (403.24k/403.24k flops)\n",
      "  model_108/conv2d_1517/BiasAdd (302.02k/302.02k flops)\n",
      "  model_108/depthwise_conv2d_1408/BiasAdd (286.53k/286.53k flops)\n",
      "  model_108/conv2d_1516/BiasAdd (286.53k/286.53k flops)\n",
      "  model_108/batch_normalization_2932/FusedBatchNormV3 (278.56k/278.56k flops)\n",
      "  model_108/batch_normalization_2933/FusedBatchNormV3 (278.56k/278.56k flops)\n",
      "  model_108/batch_normalization_2923/FusedBatchNormV3 (255.95k/255.95k flops)\n",
      "  model_108/depthwise_conv2d_1405/BiasAdd (247.81k/247.81k flops)\n",
      "  model_108/conv2d_1522/BiasAdd (239.10k/239.10k flops)\n",
      "  model_108/depthwise_conv2d_1414/BiasAdd (239.10k/239.10k flops)\n",
      "  model_108/conv2d_1521/BiasAdd (238.13k/238.13k flops)\n",
      "  model_108/depthwise_conv2d_1413/BiasAdd (238.13k/238.13k flops)\n",
      "  model_108/batch_normalization_2928/FusedBatchNormV3 (237.66k/237.66k flops)\n",
      "  model_108/batch_normalization_2929/FusedBatchNormV3 (237.66k/237.66k flops)\n",
      "  model_108/conv2d_1523/BiasAdd (216.83k/216.83k flops)\n",
      "  model_108/conv2d_1519/BiasAdd (200.38k/200.38k flops)\n",
      "  model_108/depthwise_conv2d_1411/BiasAdd (200.38k/200.38k flops)\n",
      "  model_108/batch_normalization_2940/FusedBatchNormV3 (189.97k/189.97k flops)\n",
      "  model_108/batch_normalization_2927/FusedBatchNormV3 (151.94k/151.94k flops)\n",
      "  model_108/conv2d_1520/BiasAdd (138.42k/138.42k flops)\n",
      "  model_108/depthwise_conv2d_1412/BiasAdd (138.42k/138.42k flops)\n",
      "  model_108/depthwise_conv2d_1407/BiasAdd (127.78k/127.78k flops)\n",
      "  model_108/depthwise_conv2d_1410/BiasAdd (118.10k/118.10k flops)\n",
      "  model_108/conv2d_1518/BiasAdd (118.10k/118.10k flops)\n",
      "  model_108/batch_normalization_2939/FusedBatchNormV3 (111.10k/111.10k flops)\n",
      "  model_108/conv2d_1524/BiasAdd (92.69k/92.69k flops)\n",
      "  model_108/depthwise_conv2d_1409/BiasAdd (75.50k/75.50k flops)\n",
      "  model_108/batch_normalization_2942/FusedBatchNormV3 (68.80k/68.80k flops)\n",
      "  model_108/batch_normalization_2941/FusedBatchNormV3 (59.75k/59.75k flops)\n",
      "  model_108/depthwise_conv2d_1415/BiasAdd (54.21k/54.21k flops)\n",
      "  model_108/global_average_pooling2d_108/Mean (31.75k/31.75k flops)\n",
      "  model_108/conv2d_1525/BiasAdd (31.75k/31.75k flops)\n",
      "  model_108/depthwise_conv2d_1416/BiasAdd (27.58k/27.58k flops)\n",
      "  model_108/dense_108/MatMul (17.64k/17.64k flops)\n",
      "  model_108/dense_108/Softmax (50/50 flops)\n",
      "  model_108/dense_108/BiasAdd (10/10 flops)\n",
      "\n",
      "======================End of Report==========================\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "115.280556\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-30 13:41:23.518727: I tensorflow/core/grappler/devices.cc:66] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0\n",
      "2022-04-30 13:41:23.518842: I tensorflow/core/grappler/clusters/single_machine.cc:357] Starting new session\n",
      "2022-04-30 13:41:23.523910: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:1137] Optimization results for grappler item: graph_to_optimize\n",
      "  function_optimizer: function_optimizer did nothing. time = 0.006ms.\n",
      "  function_optimizer: function_optimizer did nothing. time = 0.001ms.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=========================Options=============================\n",
      "-max_depth                  10000\n",
      "-min_bytes                  0\n",
      "-min_peak_bytes             0\n",
      "-min_residual_bytes         0\n",
      "-min_output_bytes           0\n",
      "-min_micros                 0\n",
      "-min_accelerator_micros     0\n",
      "-min_cpu_micros             0\n",
      "-min_params                 0\n",
      "-min_float_ops              1\n",
      "-min_occurrence             0\n",
      "-step                       -1\n",
      "-order_by                   float_ops\n",
      "-account_type_regexes       .*\n",
      "-start_name_regexes         .*\n",
      "-trim_name_regexes          \n",
      "-show_name_regexes          .*\n",
      "-hide_name_regexes          \n",
      "-account_displayed_op_only  true\n",
      "-select                     float_ops\n",
      "-output                     stdout:\n",
      "\n",
      "==================Model Analysis Report======================\n",
      "\n",
      "Doc:\n",
      "scope: The nodes in the model graph are organized by their names, which is hierarchical like filesystem.\n",
      "flops: Number of float operations. Note: Please read the implementation for the math behind it.\n",
      "\n",
      "Profile:\n",
      "node name | # float_ops\n",
      "_TFProfRoot (--/1.62b flops)\n",
      "  model_109/conv2d_1537/Conv2D (199.38m/199.38m flops)\n",
      "  model_109/conv2d_1536/Conv2D (189.97m/189.97m flops)\n",
      "  model_109/conv2d_1535/Conv2D (177.07m/177.07m flops)\n",
      "  model_109/conv2d_1534/Conv2D (167.50m/167.50m flops)\n",
      "  model_109/conv2d_1533/Conv2D (123.59m/123.59m flops)\n",
      "  model_109/conv2d_1527/Conv2D (114.98m/114.98m flops)\n",
      "  model_109/conv2d_1529/Conv2D (102.22m/102.22m flops)\n",
      "  model_109/conv2d_1531/Conv2D (97.95m/97.95m flops)\n",
      "  model_109/conv2d_1538/Conv2D (97.89m/97.89m flops)\n",
      "  model_109/conv2d_1530/Conv2D (57.93m/57.93m flops)\n",
      "  model_109/conv2d_1539/Conv2D (55.37m/55.37m flops)\n",
      "  model_109/conv2d_1532/Conv2D (54.73m/54.73m flops)\n",
      "  model_109/conv2d_1528/Conv2D (53.90m/53.90m flops)\n",
      "  model_109/conv2d_1526/Conv2D (31.72m/31.72m flops)\n",
      "  model_109/depthwise_conv2d_1417/depthwise (17.84m/17.84m flops)\n",
      "  model_109/depthwise_conv2d_1419/depthwise (8.36m/8.36m flops)\n",
      "  model_109/depthwise_conv2d_1418/depthwise (8.08m/8.08m flops)\n",
      "  model_109/depthwise_conv2d_1421/depthwise (4.74m/4.74m flops)\n",
      "  model_109/depthwise_conv2d_1426/depthwise (3.87m/3.87m flops)\n",
      "  model_109/depthwise_conv2d_1427/depthwise (3.85m/3.85m flops)\n",
      "  model_109/depthwise_conv2d_1420/depthwise (3.83m/3.83m flops)\n",
      "  model_109/depthwise_conv2d_1424/depthwise (3.66m/3.66m flops)\n",
      "  model_109/batch_normalization_2945/FusedBatchNormV3 (3.59m/3.59m flops)\n",
      "  model_109/depthwise_conv2d_1425/depthwise (3.59m/3.59m flops)\n",
      "  model_109/depthwise_conv2d_1423/depthwise (2.65m/2.65m flops)\n",
      "  model_109/batch_normalization_2944/FusedBatchNormV3 (1.98m/1.98m flops)\n",
      "  model_109/batch_normalization_2943/FusedBatchNormV3 (1.98m/1.98m flops)\n",
      "  model_109/conv2d_1527/BiasAdd (1.80m/1.80m flops)\n",
      "  model_109/batch_normalization_2949/FusedBatchNormV3 (1.70m/1.70m flops)\n",
      "  model_109/depthwise_conv2d_1422/depthwise (1.62m/1.62m flops)\n",
      "  model_109/depthwise_conv2d_1428/depthwise (1.01m/1.01m flops)\n",
      "  model_109/conv2d_1526/BiasAdd (991.23k/991.23k flops)\n",
      "  model_109/depthwise_conv2d_1417/BiasAdd (991.23k/991.23k flops)\n",
      "  model_109/batch_normalization_2948/FusedBatchNormV3 (929.64k/929.64k flops)\n",
      "  model_109/batch_normalization_2947/FusedBatchNormV3 (929.64k/929.64k flops)\n",
      "  model_109/batch_normalization_2946/FusedBatchNormV3 (898.65k/898.65k flops)\n",
      "  model_109/conv2d_1529/BiasAdd (851.84k/851.84k flops)\n",
      "  model_109/batch_normalization_2953/FusedBatchNormV3 (721.31k/721.31k flops)\n",
      "  model_109/depthwise_conv2d_1429/depthwise (562.46k/562.46k flops)\n",
      "  model_109/batch_normalization_2951/FusedBatchNormV3 (527.41k/527.41k flops)\n",
      "  model_109/batch_normalization_2952/FusedBatchNormV3 (527.41k/527.41k flops)\n",
      "  model_109/depthwise_conv2d_1419/BiasAdd (464.64k/464.64k flops)\n",
      "  model_109/conv2d_1528/BiasAdd (464.64k/464.64k flops)\n",
      "  model_109/batch_normalization_2965/FusedBatchNormV3 (453.88k/453.88k flops)\n",
      "  model_109/depthwise_conv2d_1418/BiasAdd (449.15k/449.15k flops)\n",
      "  model_109/batch_normalization_2962/FusedBatchNormV3 (432.46k/432.46k flops)\n",
      "  model_109/batch_normalization_2961/FusedBatchNormV3 (432.46k/432.46k flops)\n",
      "  model_109/batch_normalization_2964/FusedBatchNormV3 (430.51k/430.51k flops)\n",
      "  model_109/batch_normalization_2963/FusedBatchNormV3 (430.51k/430.51k flops)\n",
      "  model_109/batch_normalization_2950/FusedBatchNormV3 (426.58k/426.58k flops)\n",
      "  model_109/batch_normalization_2958/FusedBatchNormV3 (409.08k/409.08k flops)\n",
      "  model_109/batch_normalization_2957/FusedBatchNormV3 (409.08k/409.08k flops)\n",
      "  model_109/batch_normalization_2960/FusedBatchNormV3 (401.29k/401.29k flops)\n",
      "  model_109/batch_normalization_2959/FusedBatchNormV3 (401.29k/401.29k flops)\n",
      "  model_109/conv2d_1531/BiasAdd (360.10k/360.10k flops)\n",
      "  model_109/batch_normalization_2955/FusedBatchNormV3 (296.10k/296.10k flops)\n",
      "  model_109/batch_normalization_2956/FusedBatchNormV3 (296.10k/296.10k flops)\n",
      "  model_109/conv2d_1530/BiasAdd (263.30k/263.30k flops)\n",
      "  model_109/depthwise_conv2d_1421/BiasAdd (263.30k/263.30k flops)\n",
      "  model_109/conv2d_1537/BiasAdd (225.54k/225.54k flops)\n",
      "  model_109/batch_normalization_2967/FusedBatchNormV3 (215.26k/215.26k flops)\n",
      "  model_109/conv2d_1535/BiasAdd (214.90k/214.90k flops)\n",
      "  model_109/depthwise_conv2d_1426/BiasAdd (214.90k/214.90k flops)\n",
      "  model_109/depthwise_conv2d_1427/BiasAdd (213.93k/213.93k flops)\n",
      "  model_109/conv2d_1536/BiasAdd (213.93k/213.93k flops)\n",
      "  model_109/depthwise_conv2d_1420/BiasAdd (212.96k/212.96k flops)\n",
      "  model_109/conv2d_1533/BiasAdd (203.28k/203.28k flops)\n",
      "  model_109/depthwise_conv2d_1424/BiasAdd (203.28k/203.28k flops)\n",
      "  model_109/conv2d_1534/BiasAdd (199.41k/199.41k flops)\n",
      "  model_109/depthwise_conv2d_1425/BiasAdd (199.41k/199.41k flops)\n",
      "  model_109/batch_normalization_2954/FusedBatchNormV3 (181.16k/181.16k flops)\n",
      "  model_109/conv2d_1532/BiasAdd (147.14k/147.14k flops)\n",
      "  model_109/depthwise_conv2d_1423/BiasAdd (147.14k/147.14k flops)\n",
      "  model_109/batch_normalization_2966/FusedBatchNormV3 (115.57k/115.57k flops)\n",
      "  model_109/conv2d_1538/BiasAdd (105.03k/105.03k flops)\n",
      "  model_109/depthwise_conv2d_1422/BiasAdd (90.02k/90.02k flops)\n",
      "  model_109/batch_normalization_2969/FusedBatchNormV3 (69.11k/69.11k flops)\n",
      "  model_109/batch_normalization_2968/FusedBatchNormV3 (67.70k/67.70k flops)\n",
      "  model_109/depthwise_conv2d_1428/BiasAdd (56.39k/56.39k flops)\n",
      "  model_109/global_average_pooling2d_109/Mean (31.90k/31.90k flops)\n",
      "  model_109/conv2d_1539/BiasAdd (31.90k/31.90k flops)\n",
      "  model_109/depthwise_conv2d_1429/BiasAdd (31.25k/31.25k flops)\n",
      "  model_109/dense_109/MatMul (17.72k/17.72k flops)\n",
      "  model_109/dense_109/Softmax (50/50 flops)\n",
      "  model_109/dense_109/BiasAdd (10/10 flops)\n",
      "\n",
      "======================End of Report==========================\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "125.676668\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-30 13:41:24.448720: I tensorflow/core/grappler/devices.cc:66] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0\n",
      "2022-04-30 13:41:24.448835: I tensorflow/core/grappler/clusters/single_machine.cc:357] Starting new session\n",
      "2022-04-30 13:41:24.453161: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:1137] Optimization results for grappler item: graph_to_optimize\n",
      "  function_optimizer: function_optimizer did nothing. time = 0.004ms.\n",
      "  function_optimizer: function_optimizer did nothing. time = 0.001ms.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=========================Options=============================\n",
      "-max_depth                  10000\n",
      "-min_bytes                  0\n",
      "-min_peak_bytes             0\n",
      "-min_residual_bytes         0\n",
      "-min_output_bytes           0\n",
      "-min_micros                 0\n",
      "-min_accelerator_micros     0\n",
      "-min_cpu_micros             0\n",
      "-min_params                 0\n",
      "-min_float_ops              1\n",
      "-min_occurrence             0\n",
      "-step                       -1\n",
      "-order_by                   float_ops\n",
      "-account_type_regexes       .*\n",
      "-start_name_regexes         .*\n",
      "-trim_name_regexes          \n",
      "-show_name_regexes          .*\n",
      "-hide_name_regexes          \n",
      "-account_displayed_op_only  true\n",
      "-select                     float_ops\n",
      "-output                     stdout:\n",
      "\n",
      "==================Model Analysis Report======================\n",
      "\n",
      "Doc:\n",
      "scope: The nodes in the model graph are organized by their names, which is hierarchical like filesystem.\n",
      "flops: Number of float operations. Note: Please read the implementation for the math behind it.\n",
      "\n",
      "Profile:\n",
      "node name | # float_ops\n",
      "_TFProfRoot (--/1.91b flops)\n",
      "  model_110/conv2d_1543/Conv2D (241.98m/241.98m flops)\n",
      "  model_110/conv2d_1548/Conv2D (222.89m/222.89m flops)\n",
      "  model_110/conv2d_1549/Conv2D (200.98m/200.98m flops)\n",
      "  model_110/conv2d_1547/Conv2D (187.55m/187.55m flops)\n",
      "  model_110/conv2d_1551/Conv2D (174.01m/174.01m flops)\n",
      "  model_110/conv2d_1550/Conv2D (171.57m/171.57m flops)\n",
      "  model_110/conv2d_1545/Conv2D (148.59m/148.59m flops)\n",
      "  model_110/conv2d_1546/Conv2D (93.78m/93.78m flops)\n",
      "  model_110/conv2d_1541/Conv2D (83.26m/83.26m flops)\n",
      "  model_110/conv2d_1542/Conv2D (80.66m/80.66m flops)\n",
      "  model_110/conv2d_1544/Conv2D (80.01m/80.01m flops)\n",
      "  model_110/conv2d_1552/Conv2D (55.10m/55.10m flops)\n",
      "  model_110/conv2d_1553/Conv2D (37.23m/37.23m flops)\n",
      "  model_110/conv2d_1540/Conv2D (31.72m/31.72m flops)\n",
      "  model_110/depthwise_conv2d_1430/depthwise (17.84m/17.84m flops)\n",
      "  model_110/depthwise_conv2d_1432/depthwise (17.28m/17.28m flops)\n",
      "  model_110/depthwise_conv2d_1431/depthwise (5.85m/5.85m flops)\n",
      "  model_110/depthwise_conv2d_1434/depthwise (5.72m/5.72m flops)\n",
      "  model_110/depthwise_conv2d_1433/depthwise (4.39m/4.39m flops)\n",
      "  model_110/depthwise_conv2d_1438/depthwise (4.29m/4.29m flops)\n",
      "  model_110/depthwise_conv2d_1437/depthwise (4.08m/4.08m flops)\n",
      "  model_110/depthwise_conv2d_1439/depthwise (3.68m/3.68m flops)\n",
      "  model_110/depthwise_conv2d_1440/depthwise (3.66m/3.66m flops)\n",
      "  model_110/depthwise_conv2d_1436/depthwise (3.61m/3.61m flops)\n",
      "  model_110/batch_normalization_2972/FusedBatchNormV3 (2.60m/2.60m flops)\n",
      "  model_110/depthwise_conv2d_1435/depthwise (2.04m/2.04m flops)\n",
      "  model_110/batch_normalization_2971/FusedBatchNormV3 (1.98m/1.98m flops)\n",
      "  model_110/batch_normalization_2970/FusedBatchNormV3 (1.98m/1.98m flops)\n",
      "  model_110/batch_normalization_2976/FusedBatchNormV3 (1.95m/1.95m flops)\n",
      "  model_110/batch_normalization_2974/FusedBatchNormV3 (1.92m/1.92m flops)\n",
      "  model_110/batch_normalization_2975/FusedBatchNormV3 (1.92m/1.92m flops)\n",
      "  model_110/conv2d_1541/BiasAdd (1.30m/1.30m flops)\n",
      "  model_110/conv2d_1540/BiasAdd (991.23k/991.23k flops)\n",
      "  model_110/depthwise_conv2d_1430/BiasAdd (991.23k/991.23k flops)\n",
      "  model_110/conv2d_1543/BiasAdd (975.74k/975.74k flops)\n",
      "  model_110/conv2d_1542/BiasAdd (960.26k/960.26k flops)\n",
      "  model_110/depthwise_conv2d_1432/BiasAdd (960.26k/960.26k flops)\n",
      "  model_110/depthwise_conv2d_1441/depthwise (932.18k/932.18k flops)\n",
      "  model_110/batch_normalization_2980/FusedBatchNormV3 (907.45k/907.45k flops)\n",
      "  model_110/batch_normalization_2973/FusedBatchNormV3 (650.75k/650.75k flops)\n",
      "  model_110/batch_normalization_2978/FusedBatchNormV3 (635.99k/635.99k flops)\n",
      "  model_110/batch_normalization_2979/FusedBatchNormV3 (635.99k/635.99k flops)\n",
      "  model_110/batch_normalization_2977/FusedBatchNormV3 (488.63k/488.63k flops)\n",
      "  model_110/batch_normalization_2987/FusedBatchNormV3 (479.21k/479.21k flops)\n",
      "  model_110/batch_normalization_2986/FusedBatchNormV3 (479.21k/479.21k flops)\n",
      "  model_110/batch_normalization_2985/FusedBatchNormV3 (455.83k/455.83k flops)\n",
      "  model_110/batch_normalization_2984/FusedBatchNormV3 (455.83k/455.83k flops)\n",
      "  model_110/conv2d_1545/BiasAdd (453.02k/453.02k flops)\n",
      "  model_110/batch_normalization_2992/FusedBatchNormV3 (416.87k/416.87k flops)\n",
      "  model_110/batch_normalization_2989/FusedBatchNormV3 (411.03k/411.03k flops)\n",
      "  model_110/batch_normalization_2988/FusedBatchNormV3 (411.03k/411.03k flops)\n",
      "  model_110/batch_normalization_2991/FusedBatchNormV3 (409.08k/409.08k flops)\n",
      "  model_110/batch_normalization_2990/FusedBatchNormV3 (409.08k/409.08k flops)\n",
      "  model_110/batch_normalization_2982/FusedBatchNormV3 (403.24k/403.24k flops)\n",
      "  model_110/batch_normalization_2983/FusedBatchNormV3 (403.24k/403.24k flops)\n",
      "  model_110/depthwise_conv2d_1442/depthwise (344.74k/344.74k flops)\n",
      "  model_110/depthwise_conv2d_1431/BiasAdd (325.25k/325.25k flops)\n",
      "  model_110/depthwise_conv2d_1434/BiasAdd (317.50k/317.50k flops)\n",
      "  model_110/conv2d_1544/BiasAdd (317.50k/317.50k flops)\n",
      "  model_110/depthwise_conv2d_1433/BiasAdd (243.94k/243.94k flops)\n",
      "  model_110/depthwise_conv2d_1438/BiasAdd (238.13k/238.13k flops)\n",
      "  model_110/conv2d_1548/BiasAdd (238.13k/238.13k flops)\n",
      "  model_110/batch_normalization_2981/FusedBatchNormV3 (227.92k/227.92k flops)\n",
      "  model_110/depthwise_conv2d_1437/BiasAdd (226.51k/226.51k flops)\n",
      "  model_110/conv2d_1547/BiasAdd (226.51k/226.51k flops)\n",
      "  model_110/conv2d_1551/BiasAdd (207.15k/207.15k flops)\n",
      "  model_110/depthwise_conv2d_1439/BiasAdd (204.25k/204.25k flops)\n",
      "  model_110/conv2d_1549/BiasAdd (204.25k/204.25k flops)\n",
      "  model_110/conv2d_1550/BiasAdd (203.28k/203.28k flops)\n",
      "  model_110/depthwise_conv2d_1440/BiasAdd (203.28k/203.28k flops)\n",
      "  model_110/conv2d_1546/BiasAdd (200.38k/200.38k flops)\n",
      "  model_110/depthwise_conv2d_1436/BiasAdd (200.38k/200.38k flops)\n",
      "  model_110/batch_normalization_2994/FusedBatchNormV3 (131.94k/131.94k flops)\n",
      "  model_110/depthwise_conv2d_1435/BiasAdd (113.26k/113.26k flops)\n",
      "  model_110/batch_normalization_2993/FusedBatchNormV3 (106.14k/106.14k flops)\n",
      "  model_110/batch_normalization_2996/FusedBatchNormV3 (75.82k/75.82k flops)\n",
      "  model_110/conv2d_1552/BiasAdd (64.37k/64.37k flops)\n",
      "  model_110/depthwise_conv2d_1441/BiasAdd (51.79k/51.79k flops)\n",
      "  model_110/batch_normalization_2995/FusedBatchNormV3 (41.50k/41.50k flops)\n",
      "  model_110/global_average_pooling2d_110/Mean (34.99k/34.99k flops)\n",
      "  model_110/conv2d_1553/BiasAdd (34.99k/34.99k flops)\n",
      "  model_110/dense_110/MatMul (19.44k/19.44k flops)\n",
      "  model_110/depthwise_conv2d_1442/BiasAdd (19.15k/19.15k flops)\n",
      "  model_110/dense_110/Softmax (50/50 flops)\n",
      "  model_110/dense_110/BiasAdd (10/10 flops)\n",
      "\n",
      "======================End of Report==========================\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "138.752124\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-30 13:41:25.501323: I tensorflow/core/grappler/devices.cc:66] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0\n",
      "2022-04-30 13:41:25.501444: I tensorflow/core/grappler/clusters/single_machine.cc:357] Starting new session\n",
      "2022-04-30 13:41:25.506291: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:1137] Optimization results for grappler item: graph_to_optimize\n",
      "  function_optimizer: function_optimizer did nothing. time = 0.006ms.\n",
      "  function_optimizer: function_optimizer did nothing. time = 0.001ms.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=========================Options=============================\n",
      "-max_depth                  10000\n",
      "-min_bytes                  0\n",
      "-min_peak_bytes             0\n",
      "-min_residual_bytes         0\n",
      "-min_output_bytes           0\n",
      "-min_micros                 0\n",
      "-min_accelerator_micros     0\n",
      "-min_cpu_micros             0\n",
      "-min_params                 0\n",
      "-min_float_ops              1\n",
      "-min_occurrence             0\n",
      "-step                       -1\n",
      "-order_by                   float_ops\n",
      "-account_type_regexes       .*\n",
      "-start_name_regexes         .*\n",
      "-trim_name_regexes          \n",
      "-show_name_regexes          .*\n",
      "-hide_name_regexes          \n",
      "-account_displayed_op_only  true\n",
      "-select                     float_ops\n",
      "-output                     stdout:\n",
      "\n",
      "==================Model Analysis Report======================\n",
      "\n",
      "Doc:\n",
      "scope: The nodes in the model graph are organized by their names, which is hierarchical like filesystem.\n",
      "flops: Number of float operations. Note: Please read the implementation for the math behind it.\n",
      "\n",
      "Profile:\n",
      "node name | # float_ops\n",
      "_TFProfRoot (--/2.05b flops)\n",
      "  model_111/conv2d_1559/Conv2D (269.84m/269.84m flops)\n",
      "  model_111/conv2d_1562/Conv2D (237.07m/237.07m flops)\n",
      "  model_111/conv2d_1563/Conv2D (210.97m/210.97m flops)\n",
      "  model_111/conv2d_1557/Conv2D (191.47m/191.47m flops)\n",
      "  model_111/conv2d_1565/Conv2D (165.75m/165.75m flops)\n",
      "  model_111/conv2d_1564/Conv2D (147.50m/147.50m flops)\n",
      "  model_111/conv2d_1561/Conv2D (135.61m/135.61m flops)\n",
      "  model_111/conv2d_1566/Conv2D (121.05m/121.05m flops)\n",
      "  model_111/conv2d_1558/Conv2D (117.23m/117.23m flops)\n",
      "  model_111/conv2d_1555/Conv2D (84.93m/84.93m flops)\n",
      "  model_111/conv2d_1560/Conv2D (75.89m/75.89m flops)\n",
      "  model_111/conv2d_1567/Conv2D (70.24m/70.24m flops)\n",
      "  model_111/conv2d_1556/Conv2D (65.03m/65.03m flops)\n",
      "  model_111/conv2d_1554/Conv2D (37.75m/37.75m flops)\n",
      "  model_111/depthwise_conv2d_1443/depthwise (21.23m/21.23m flops)\n",
      "  model_111/depthwise_conv2d_1445/depthwise (16.26m/16.26m flops)\n",
      "  model_111/depthwise_conv2d_1447/depthwise (9.95m/9.95m flops)\n",
      "  model_111/depthwise_conv2d_1444/depthwise (5.97m/5.97m flops)\n",
      "  model_111/depthwise_conv2d_1451/depthwise (4.89m/4.89m flops)\n",
      "  model_111/depthwise_conv2d_1450/depthwise (4.52m/4.52m flops)\n",
      "  model_111/depthwise_conv2d_1446/depthwise (4.40m/4.40m flops)\n",
      "  model_111/depthwise_conv2d_1452/depthwise (4.02m/4.02m flops)\n",
      "  model_111/depthwise_conv2d_1453/depthwise (3.42m/3.42m flops)\n",
      "  model_111/depthwise_conv2d_1449/depthwise (2.80m/2.80m flops)\n",
      "  model_111/batch_normalization_2999/FusedBatchNormV3 (2.65m/2.65m flops)\n",
      "  model_111/depthwise_conv2d_1448/depthwise (2.53m/2.53m flops)\n",
      "  model_111/batch_normalization_2998/FusedBatchNormV3 (2.36m/2.36m flops)\n",
      "  model_111/batch_normalization_2997/FusedBatchNormV3 (2.36m/2.36m flops)\n",
      "  model_111/batch_normalization_3003/FusedBatchNormV3 (1.95m/1.95m flops)\n",
      "  model_111/batch_normalization_3001/FusedBatchNormV3 (1.81m/1.81m flops)\n",
      "  model_111/batch_normalization_3002/FusedBatchNormV3 (1.81m/1.81m flops)\n",
      "  model_111/conv2d_1555/BiasAdd (1.33m/1.33m flops)\n",
      "  model_111/conv2d_1554/BiasAdd (1.18m/1.18m flops)\n",
      "  model_111/depthwise_conv2d_1443/BiasAdd (1.18m/1.18m flops)\n",
      "  model_111/depthwise_conv2d_1454/depthwise (1.13m/1.13m flops)\n",
      "  model_111/batch_normalization_3007/FusedBatchNormV3 (1.13m/1.13m flops)\n",
      "  model_111/batch_normalization_3005/FusedBatchNormV3 (1.11m/1.11m flops)\n",
      "  model_111/batch_normalization_3006/FusedBatchNormV3 (1.11m/1.11m flops)\n",
      "  model_111/conv2d_1557/BiasAdd (976.90k/976.90k flops)\n",
      "  model_111/conv2d_1556/BiasAdd (903.17k/903.17k flops)\n",
      "  model_111/depthwise_conv2d_1445/BiasAdd (903.17k/903.17k flops)\n",
      "  model_111/batch_normalization_3000/FusedBatchNormV3 (663.77k/663.77k flops)\n",
      "  model_111/depthwise_conv2d_1455/depthwise (624.67k/624.67k flops)\n",
      "  model_111/conv2d_1559/BiasAdd (562.18k/562.18k flops)\n",
      "  model_111/conv2d_1558/BiasAdd (552.96k/552.96k flops)\n",
      "  model_111/depthwise_conv2d_1447/BiasAdd (552.96k/552.96k flops)\n",
      "  model_111/batch_normalization_3014/FusedBatchNormV3 (546.58k/546.58k flops)\n",
      "  model_111/batch_normalization_3013/FusedBatchNormV3 (546.58k/546.58k flops)\n",
      "  model_111/batch_normalization_3012/FusedBatchNormV3 (504.89k/504.89k flops)\n",
      "  model_111/batch_normalization_3011/FusedBatchNormV3 (504.89k/504.89k flops)\n",
      "  model_111/batch_normalization_3019/FusedBatchNormV3 (504.89k/504.89k flops)\n",
      "  model_111/batch_normalization_3004/FusedBatchNormV3 (489.08k/489.08k flops)\n",
      "  model_111/batch_normalization_3016/FusedBatchNormV3 (449.30k/449.30k flops)\n",
      "  model_111/batch_normalization_3015/FusedBatchNormV3 (449.30k/449.30k flops)\n",
      "  model_111/batch_normalization_3018/FusedBatchNormV3 (382.14k/382.14k flops)\n",
      "  model_111/batch_normalization_3017/FusedBatchNormV3 (382.14k/382.14k flops)\n",
      "  model_111/depthwise_conv2d_1444/BiasAdd (331.78k/331.78k flops)\n",
      "  model_111/batch_normalization_3009/FusedBatchNormV3 (312.66k/312.66k flops)\n",
      "  model_111/batch_normalization_3010/FusedBatchNormV3 (312.66k/312.66k flops)\n",
      "  model_111/batch_normalization_3021/FusedBatchNormV3 (283.42k/283.42k flops)\n",
      "  model_111/batch_normalization_3008/FusedBatchNormV3 (282.55k/282.55k flops)\n",
      "  model_111/conv2d_1562/BiasAdd (271.87k/271.87k flops)\n",
      "  model_111/depthwise_conv2d_1451/BiasAdd (271.87k/271.87k flops)\n",
      "  model_111/depthwise_conv2d_1450/BiasAdd (251.14k/251.14k flops)\n",
      "  model_111/conv2d_1561/BiasAdd (251.14k/251.14k flops)\n",
      "  model_111/conv2d_1565/BiasAdd (251.14k/251.14k flops)\n",
      "  model_111/depthwise_conv2d_1446/BiasAdd (244.22k/244.22k flops)\n",
      "  model_111/depthwise_conv2d_1452/BiasAdd (223.49k/223.49k flops)\n",
      "  model_111/conv2d_1563/BiasAdd (223.49k/223.49k flops)\n",
      "  model_111/depthwise_conv2d_1453/BiasAdd (190.08k/190.08k flops)\n",
      "  model_111/conv2d_1564/BiasAdd (190.08k/190.08k flops)\n",
      "  model_111/conv2d_1560/BiasAdd (155.52k/155.52k flops)\n",
      "  model_111/depthwise_conv2d_1449/BiasAdd (155.52k/155.52k flops)\n",
      "  model_111/depthwise_conv2d_1448/BiasAdd (140.54k/140.54k flops)\n",
      "  model_111/conv2d_1566/BiasAdd (138.82k/138.82k flops)\n",
      "  model_111/batch_normalization_3020/FusedBatchNormV3 (128.18k/128.18k flops)\n",
      "  model_111/batch_normalization_3023/FusedBatchNormV3 (78.94k/78.94k flops)\n",
      "  model_111/batch_normalization_3022/FusedBatchNormV3 (75.19k/75.19k flops)\n",
      "  model_111/depthwise_conv2d_1454/BiasAdd (62.78k/62.78k flops)\n",
      "  model_111/global_average_pooling2d_111/Mean (36.43k/36.43k flops)\n",
      "  model_111/conv2d_1567/BiasAdd (36.43k/36.43k flops)\n",
      "  model_111/depthwise_conv2d_1455/BiasAdd (34.70k/34.70k flops)\n",
      "  model_111/dense_111/MatMul (20.24k/20.24k flops)\n",
      "  model_111/dense_111/Softmax (50/50 flops)\n",
      "  model_111/dense_111/BiasAdd (10/10 flops)\n",
      "\n",
      "======================End of Report==========================\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "146.900076\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-30 13:41:26.442142: I tensorflow/core/grappler/devices.cc:66] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0\n",
      "2022-04-30 13:41:26.442259: I tensorflow/core/grappler/clusters/single_machine.cc:357] Starting new session\n",
      "2022-04-30 13:41:26.446506: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:1137] Optimization results for grappler item: graph_to_optimize\n",
      "  function_optimizer: function_optimizer did nothing. time = 0.005ms.\n",
      "  function_optimizer: function_optimizer did nothing. time = 0.001ms.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=========================Options=============================\n",
      "-max_depth                  10000\n",
      "-min_bytes                  0\n",
      "-min_peak_bytes             0\n",
      "-min_residual_bytes         0\n",
      "-min_output_bytes           0\n",
      "-min_micros                 0\n",
      "-min_accelerator_micros     0\n",
      "-min_cpu_micros             0\n",
      "-min_params                 0\n",
      "-min_float_ops              1\n",
      "-min_occurrence             0\n",
      "-step                       -1\n",
      "-order_by                   float_ops\n",
      "-account_type_regexes       .*\n",
      "-start_name_regexes         .*\n",
      "-trim_name_regexes          \n",
      "-show_name_regexes          .*\n",
      "-hide_name_regexes          \n",
      "-account_displayed_op_only  true\n",
      "-select                     float_ops\n",
      "-output                     stdout:\n",
      "\n",
      "==================Model Analysis Report======================\n",
      "\n",
      "Doc:\n",
      "scope: The nodes in the model graph are organized by their names, which is hierarchical like filesystem.\n",
      "flops: Number of float operations. Note: Please read the implementation for the math behind it.\n",
      "\n",
      "Profile:\n",
      "node name | # float_ops\n",
      "_TFProfRoot (--/2.20b flops)\n",
      "  model_112/conv2d_1577/Conv2D (274.34m/274.34m flops)\n",
      "  model_112/conv2d_1578/Conv2D (248.58m/248.58m flops)\n",
      "  model_112/conv2d_1576/Conv2D (217.89m/217.89m flops)\n",
      "  model_112/conv2d_1571/Conv2D (205.70m/205.70m flops)\n",
      "  model_112/conv2d_1579/Conv2D (198.46m/198.46m flops)\n",
      "  model_112/conv2d_1573/Conv2D (176.50m/176.50m flops)\n",
      "  model_112/conv2d_1575/Conv2D (164.53m/164.53m flops)\n",
      "  model_112/conv2d_1569/Conv2D (122.68m/122.68m flops)\n",
      "  model_112/conv2d_1574/Conv2D (107.41m/107.41m flops)\n",
      "  model_112/conv2d_1580/Conv2D (95.43m/95.43m flops)\n",
      "  model_112/conv2d_1572/Conv2D (86.85m/86.85m flops)\n",
      "  model_112/conv2d_1570/Conv2D (86.26m/86.26m flops)\n",
      "  model_112/conv2d_1581/Conv2D (55.59m/55.59m flops)\n",
      "  model_112/conv2d_1568/Conv2D (37.75m/37.75m flops)\n",
      "  model_112/depthwise_conv2d_1456/depthwise (21.23m/21.23m flops)\n",
      "  model_112/depthwise_conv2d_1458/depthwise (14.93m/14.93m flops)\n",
      "  model_112/depthwise_conv2d_1457/depthwise (8.63m/8.63m flops)\n",
      "  model_112/depthwise_conv2d_1460/depthwise (6.30m/6.30m flops)\n",
      "  model_112/depthwise_conv2d_1459/depthwise (5.14m/5.14m flops)\n",
      "  model_112/depthwise_conv2d_1464/depthwise (5.08m/5.08m flops)\n",
      "  model_112/depthwise_conv2d_1465/depthwise (5.04m/5.04m flops)\n",
      "  model_112/depthwise_conv2d_1466/depthwise (4.60m/4.60m flops)\n",
      "  model_112/depthwise_conv2d_1463/depthwise (4.00m/4.00m flops)\n",
      "  model_112/depthwise_conv2d_1462/depthwise (3.84m/3.84m flops)\n",
      "  model_112/batch_normalization_3026/FusedBatchNormV3 (3.83m/3.83m flops)\n",
      "  model_112/depthwise_conv2d_1461/depthwise (2.61m/2.61m flops)\n",
      "  model_112/batch_normalization_3025/FusedBatchNormV3 (2.36m/2.36m flops)\n",
      "  model_112/batch_normalization_3024/FusedBatchNormV3 (2.36m/2.36m flops)\n",
      "  model_112/batch_normalization_3030/FusedBatchNormV3 (2.29m/2.29m flops)\n",
      "  model_112/conv2d_1569/BiasAdd (1.92m/1.92m flops)\n",
      "  model_112/batch_normalization_3028/FusedBatchNormV3 (1.66m/1.66m flops)\n",
      "  model_112/batch_normalization_3029/FusedBatchNormV3 (1.66m/1.66m flops)\n",
      "  model_112/conv2d_1568/BiasAdd (1.18m/1.18m flops)\n",
      "  model_112/depthwise_conv2d_1456/BiasAdd (1.18m/1.18m flops)\n",
      "  model_112/batch_normalization_3034/FusedBatchNormV3 (1.16m/1.16m flops)\n",
      "  model_112/conv2d_1571/BiasAdd (1.14m/1.14m flops)\n",
      "  model_112/depthwise_conv2d_1467/depthwise (1.01m/1.01m flops)\n",
      "  model_112/batch_normalization_3027/FusedBatchNormV3 (958.78k/958.78k flops)\n",
      "  model_112/conv2d_1570/BiasAdd (829.44k/829.44k flops)\n",
      "  model_112/depthwise_conv2d_1458/BiasAdd (829.44k/829.44k flops)\n",
      "  model_112/batch_normalization_3032/FusedBatchNormV3 (701.33k/701.33k flops)\n",
      "  model_112/batch_normalization_3033/FusedBatchNormV3 (701.33k/701.33k flops)\n",
      "  model_112/conv2d_1573/BiasAdd (580.61k/580.61k flops)\n",
      "  model_112/batch_normalization_3031/FusedBatchNormV3 (572.14k/572.14k flops)\n",
      "  model_112/batch_normalization_3040/FusedBatchNormV3 (567.42k/567.42k flops)\n",
      "  model_112/batch_normalization_3041/FusedBatchNormV3 (567.42k/567.42k flops)\n",
      "  model_112/batch_normalization_3042/FusedBatchNormV3 (562.79k/562.79k flops)\n",
      "  model_112/batch_normalization_3043/FusedBatchNormV3 (562.79k/562.79k flops)\n",
      "  model_112/depthwise_conv2d_1468/depthwise (553.39k/553.39k flops)\n",
      "  model_112/batch_normalization_3045/FusedBatchNormV3 (514.15k/514.15k flops)\n",
      "  model_112/batch_normalization_3044/FusedBatchNormV3 (514.15k/514.15k flops)\n",
      "  model_112/depthwise_conv2d_1457/BiasAdd (479.23k/479.23k flops)\n",
      "  model_112/batch_normalization_3046/FusedBatchNormV3 (449.30k/449.30k flops)\n",
      "  model_112/batch_normalization_3039/FusedBatchNormV3 (446.99k/446.99k flops)\n",
      "  model_112/batch_normalization_3038/FusedBatchNormV3 (446.99k/446.99k flops)\n",
      "  model_112/batch_normalization_3037/FusedBatchNormV3 (428.46k/428.46k flops)\n",
      "  model_112/batch_normalization_3036/FusedBatchNormV3 (428.46k/428.46k flops)\n",
      "  model_112/depthwise_conv2d_1460/BiasAdd (350.21k/350.21k flops)\n",
      "  model_112/conv2d_1572/BiasAdd (350.21k/350.21k flops)\n",
      "  model_112/batch_normalization_3035/FusedBatchNormV3 (291.82k/291.82k flops)\n",
      "  model_112/depthwise_conv2d_1459/BiasAdd (285.70k/285.70k flops)\n",
      "  model_112/depthwise_conv2d_1464/BiasAdd (282.24k/282.24k flops)\n",
      "  model_112/conv2d_1576/BiasAdd (282.24k/282.24k flops)\n",
      "  model_112/depthwise_conv2d_1465/BiasAdd (279.94k/279.94k flops)\n",
      "  model_112/conv2d_1577/BiasAdd (279.94k/279.94k flops)\n",
      "  model_112/conv2d_1578/BiasAdd (255.74k/255.74k flops)\n",
      "  model_112/depthwise_conv2d_1466/BiasAdd (255.74k/255.74k flops)\n",
      "  model_112/batch_normalization_3048/FusedBatchNormV3 (251.08k/251.08k flops)\n",
      "  model_112/conv2d_1579/BiasAdd (223.49k/223.49k flops)\n",
      "  model_112/conv2d_1575/BiasAdd (222.34k/222.34k flops)\n",
      "  model_112/depthwise_conv2d_1463/BiasAdd (222.34k/222.34k flops)\n",
      "  model_112/depthwise_conv2d_1462/BiasAdd (213.12k/213.12k flops)\n",
      "  model_112/conv2d_1574/BiasAdd (213.12k/213.12k flops)\n",
      "  model_112/depthwise_conv2d_1461/BiasAdd (145.15k/145.15k flops)\n",
      "  model_112/conv2d_1580/BiasAdd (122.98k/122.98k flops)\n",
      "  model_112/batch_normalization_3047/FusedBatchNormV3 (114.07k/114.07k flops)\n",
      "  model_112/batch_normalization_3050/FusedBatchNormV3 (70.51k/70.51k flops)\n",
      "  model_112/batch_normalization_3049/FusedBatchNormV3 (66.61k/66.61k flops)\n",
      "  model_112/depthwise_conv2d_1467/BiasAdd (55.87k/55.87k flops)\n",
      "  model_112/global_average_pooling2d_112/Mean (32.54k/32.54k flops)\n",
      "  model_112/conv2d_1581/BiasAdd (32.54k/32.54k flops)\n",
      "  model_112/depthwise_conv2d_1468/BiasAdd (30.74k/30.74k flops)\n",
      "  model_112/dense_112/MatMul (18.08k/18.08k flops)\n",
      "  model_112/dense_112/Softmax (50/50 flops)\n",
      "  model_112/dense_112/BiasAdd (10/10 flops)\n",
      "\n",
      "======================End of Report==========================\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "155.255324\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-30 13:41:27.483968: I tensorflow/core/grappler/devices.cc:66] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0\n",
      "2022-04-30 13:41:27.484058: I tensorflow/core/grappler/clusters/single_machine.cc:357] Starting new session\n",
      "2022-04-30 13:41:27.488961: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:1137] Optimization results for grappler item: graph_to_optimize\n",
      "  function_optimizer: function_optimizer did nothing. time = 0.006ms.\n",
      "  function_optimizer: function_optimizer did nothing. time = 0.001ms.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=========================Options=============================\n",
      "-max_depth                  10000\n",
      "-min_bytes                  0\n",
      "-min_peak_bytes             0\n",
      "-min_residual_bytes         0\n",
      "-min_output_bytes           0\n",
      "-min_micros                 0\n",
      "-min_accelerator_micros     0\n",
      "-min_cpu_micros             0\n",
      "-min_params                 0\n",
      "-min_float_ops              1\n",
      "-min_occurrence             0\n",
      "-step                       -1\n",
      "-order_by                   float_ops\n",
      "-account_type_regexes       .*\n",
      "-start_name_regexes         .*\n",
      "-trim_name_regexes          \n",
      "-show_name_regexes          .*\n",
      "-hide_name_regexes          \n",
      "-account_displayed_op_only  true\n",
      "-select                     float_ops\n",
      "-output                     stdout:\n",
      "\n",
      "==================Model Analysis Report======================\n",
      "\n",
      "Doc:\n",
      "scope: The nodes in the model graph are organized by their names, which is hierarchical like filesystem.\n",
      "flops: Number of float operations. Note: Please read the implementation for the math behind it.\n",
      "\n",
      "Profile:\n",
      "node name | # float_ops\n",
      "_TFProfRoot (--/2.45b flops)\n",
      "  model_113/conv2d_1590/Conv2D (282.24m/282.24m flops)\n",
      "  model_113/conv2d_1591/Conv2D (248.37m/248.37m flops)\n",
      "  model_113/conv2d_1589/Conv2D (244.22m/244.22m flops)\n",
      "  model_113/conv2d_1587/Conv2D (241.92m/241.92m flops)\n",
      "  model_113/conv2d_1592/Conv2D (236.21m/236.21m flops)\n",
      "  model_113/conv2d_1585/Conv2D (235.34m/235.34m flops)\n",
      "  model_113/conv2d_1593/Conv2D (228.69m/228.69m flops)\n",
      "  model_113/conv2d_1583/Conv2D (122.68m/122.68m flops)\n",
      "  model_113/conv2d_1588/Conv2D (122.11m/122.11m flops)\n",
      "  model_113/conv2d_1586/Conv2D (110.32m/110.32m flops)\n",
      "  model_113/conv2d_1584/Conv2D (107.35m/107.35m flops)\n",
      "  model_113/conv2d_1594/Conv2D (74.59m/74.59m flops)\n",
      "  model_113/conv2d_1582/Conv2D (37.75m/37.75m flops)\n",
      "  model_113/conv2d_1595/Conv2D (34.15m/34.15m flops)\n",
      "  model_113/depthwise_conv2d_1469/depthwise (21.23m/21.23m flops)\n",
      "  model_113/depthwise_conv2d_1471/depthwise (18.58m/18.58m flops)\n",
      "  model_113/depthwise_conv2d_1473/depthwise (8.71m/8.71m flops)\n",
      "  model_113/depthwise_conv2d_1470/depthwise (8.63m/8.63m flops)\n",
      "  model_113/depthwise_conv2d_1476/depthwise (5.18m/5.18m flops)\n",
      "  model_113/depthwise_conv2d_1477/depthwise (5.08m/5.08m flops)\n",
      "  model_113/depthwise_conv2d_1479/depthwise (4.83m/4.83m flops)\n",
      "  model_113/depthwise_conv2d_1472/depthwise (4.73m/4.73m flops)\n",
      "  model_113/depthwise_conv2d_1478/depthwise (4.56m/4.56m flops)\n",
      "  model_113/depthwise_conv2d_1475/depthwise (4.40m/4.40m flops)\n",
      "  model_113/batch_normalization_3053/FusedBatchNormV3 (3.83m/3.83m flops)\n",
      "  model_113/depthwise_conv2d_1474/depthwise (2.59m/2.59m flops)\n",
      "  model_113/batch_normalization_3052/FusedBatchNormV3 (2.36m/2.36m flops)\n",
      "  model_113/batch_normalization_3051/FusedBatchNormV3 (2.36m/2.36m flops)\n",
      "  model_113/batch_normalization_3057/FusedBatchNormV3 (2.10m/2.10m flops)\n",
      "  model_113/batch_normalization_3055/FusedBatchNormV3 (2.07m/2.07m flops)\n",
      "  model_113/batch_normalization_3056/FusedBatchNormV3 (2.07m/2.07m flops)\n",
      "  model_113/conv2d_1583/BiasAdd (1.92m/1.92m flops)\n",
      "  model_113/conv2d_1582/BiasAdd (1.18m/1.18m flops)\n",
      "  model_113/depthwise_conv2d_1469/BiasAdd (1.18m/1.18m flops)\n",
      "  model_113/batch_normalization_3061/FusedBatchNormV3 (1.15m/1.15m flops)\n",
      "  model_113/depthwise_conv2d_1480/depthwise (1.10m/1.10m flops)\n",
      "  model_113/conv2d_1585/BiasAdd (1.05m/1.05m flops)\n",
      "  model_113/depthwise_conv2d_1471/BiasAdd (1.03m/1.03m flops)\n",
      "  model_113/conv2d_1584/BiasAdd (1.03m/1.03m flops)\n",
      "  model_113/batch_normalization_3060/FusedBatchNormV3 (968.94k/968.94k flops)\n",
      "  model_113/batch_normalization_3059/FusedBatchNormV3 (968.94k/968.94k flops)\n",
      "  model_113/batch_normalization_3054/FusedBatchNormV3 (958.78k/958.78k flops)\n",
      "  model_113/batch_normalization_3065/FusedBatchNormV3 (579.00k/579.00k flops)\n",
      "  model_113/batch_normalization_3066/FusedBatchNormV3 (579.00k/579.00k flops)\n",
      "  model_113/conv2d_1587/BiasAdd (576.00k/576.00k flops)\n",
      "  model_113/batch_normalization_3068/FusedBatchNormV3 (567.42k/567.42k flops)\n",
      "  model_113/batch_normalization_3067/FusedBatchNormV3 (567.42k/567.42k flops)\n",
      "  model_113/batch_normalization_3071/FusedBatchNormV3 (539.63k/539.63k flops)\n",
      "  model_113/batch_normalization_3072/FusedBatchNormV3 (539.63k/539.63k flops)\n",
      "  model_113/batch_normalization_3058/FusedBatchNormV3 (526.00k/526.00k flops)\n",
      "  model_113/batch_normalization_3069/FusedBatchNormV3 (509.52k/509.52k flops)\n",
      "  model_113/batch_normalization_3070/FusedBatchNormV3 (509.52k/509.52k flops)\n",
      "  model_113/batch_normalization_3073/FusedBatchNormV3 (493.31k/493.31k flops)\n",
      "  model_113/batch_normalization_3064/FusedBatchNormV3 (490.99k/490.99k flops)\n",
      "  model_113/batch_normalization_3063/FusedBatchNormV3 (490.99k/490.99k flops)\n",
      "  model_113/depthwise_conv2d_1473/BiasAdd (483.84k/483.84k flops)\n",
      "  model_113/conv2d_1586/BiasAdd (483.84k/483.84k flops)\n",
      "  model_113/depthwise_conv2d_1470/BiasAdd (479.23k/479.23k flops)\n",
      "  model_113/depthwise_conv2d_1481/depthwise (393.98k/393.98k flops)\n",
      "  model_113/batch_normalization_3062/FusedBatchNormV3 (289.50k/289.50k flops)\n",
      "  model_113/depthwise_conv2d_1476/BiasAdd (288.00k/288.00k flops)\n",
      "  model_113/conv2d_1589/BiasAdd (288.00k/288.00k flops)\n",
      "  model_113/depthwise_conv2d_1477/BiasAdd (282.24k/282.24k flops)\n",
      "  model_113/conv2d_1590/BiasAdd (282.24k/282.24k flops)\n",
      "  model_113/depthwise_conv2d_1479/BiasAdd (268.42k/268.42k flops)\n",
      "  model_113/conv2d_1592/BiasAdd (268.42k/268.42k flops)\n",
      "  model_113/depthwise_conv2d_1472/BiasAdd (262.66k/262.66k flops)\n",
      "  model_113/depthwise_conv2d_1478/BiasAdd (253.44k/253.44k flops)\n",
      "  model_113/conv2d_1591/BiasAdd (253.44k/253.44k flops)\n",
      "  model_113/conv2d_1593/BiasAdd (245.38k/245.38k flops)\n",
      "  model_113/conv2d_1588/BiasAdd (244.22k/244.22k flops)\n",
      "  model_113/depthwise_conv2d_1475/BiasAdd (244.22k/244.22k flops)\n",
      "  model_113/batch_normalization_3075/FusedBatchNormV3 (178.75k/178.75k flops)\n",
      "  model_113/depthwise_conv2d_1474/BiasAdd (144.00k/144.00k flops)\n",
      "  model_113/batch_normalization_3074/FusedBatchNormV3 (125.24k/125.24k flops)\n",
      "  model_113/conv2d_1594/BiasAdd (87.55k/87.55k flops)\n",
      "  model_113/depthwise_conv2d_1480/BiasAdd (61.34k/61.34k flops)\n",
      "  model_113/batch_normalization_3077/FusedBatchNormV3 (60.84k/60.84k flops)\n",
      "  model_113/batch_normalization_3076/FusedBatchNormV3 (47.42k/47.42k flops)\n",
      "  model_113/global_average_pooling2d_113/Mean (28.08k/28.08k flops)\n",
      "  model_113/conv2d_1595/BiasAdd (28.08k/28.08k flops)\n",
      "  model_113/depthwise_conv2d_1481/BiasAdd (21.89k/21.89k flops)\n",
      "  model_113/dense_113/MatMul (15.60k/15.60k flops)\n",
      "  model_113/dense_113/Softmax (50/50 flops)\n",
      "  model_113/dense_113/BiasAdd (10/10 flops)\n",
      "\n",
      "======================End of Report==========================\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "139.0423\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-30 13:41:28.419029: I tensorflow/core/grappler/devices.cc:66] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0\n",
      "2022-04-30 13:41:28.419144: I tensorflow/core/grappler/clusters/single_machine.cc:357] Starting new session\n",
      "2022-04-30 13:41:28.423469: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:1137] Optimization results for grappler item: graph_to_optimize\n",
      "  function_optimizer: function_optimizer did nothing. time = 0.005ms.\n",
      "  function_optimizer: function_optimizer did nothing. time = 0.001ms.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=========================Options=============================\n",
      "-max_depth                  10000\n",
      "-min_bytes                  0\n",
      "-min_peak_bytes             0\n",
      "-min_residual_bytes         0\n",
      "-min_output_bytes           0\n",
      "-min_micros                 0\n",
      "-min_accelerator_micros     0\n",
      "-min_cpu_micros             0\n",
      "-min_params                 0\n",
      "-min_float_ops              1\n",
      "-min_occurrence             0\n",
      "-step                       -1\n",
      "-order_by                   float_ops\n",
      "-account_type_regexes       .*\n",
      "-start_name_regexes         .*\n",
      "-trim_name_regexes          \n",
      "-show_name_regexes          .*\n",
      "-hide_name_regexes          \n",
      "-account_displayed_op_only  true\n",
      "-select                     float_ops\n",
      "-output                     stdout:\n",
      "\n",
      "==================Model Analysis Report======================\n",
      "\n",
      "Doc:\n",
      "scope: The nodes in the model graph are organized by their names, which is hierarchical like filesystem.\n",
      "flops: Number of float operations. Note: Please read the implementation for the math behind it.\n",
      "\n",
      "Profile:\n",
      "node name | # float_ops\n",
      "_TFProfRoot (--/2.29b flops)\n",
      "  model_114/conv2d_1606/Conv2D (290.31m/290.31m flops)\n",
      "  model_114/conv2d_1607/Conv2D (290.31m/290.31m flops)\n",
      "  model_114/conv2d_1605/Conv2D (255.61m/255.61m flops)\n",
      "  model_114/conv2d_1604/Conv2D (230.15m/230.15m flops)\n",
      "  model_114/conv2d_1603/Conv2D (229.11m/229.11m flops)\n",
      "  model_114/conv2d_1599/Conv2D (225.61m/225.61m flops)\n",
      "  model_114/conv2d_1601/Conv2D (140.18m/140.18m flops)\n",
      "  model_114/conv2d_1602/Conv2D (118.61m/118.61m flops)\n",
      "  model_114/conv2d_1608/Conv2D (108.43m/108.43m flops)\n",
      "  model_114/conv2d_1597/Conv2D (75.50m/75.50m flops)\n",
      "  model_114/conv2d_1600/Conv2D (71.88m/71.88m flops)\n",
      "  model_114/conv2d_1598/Conv2D (60.16m/60.16m flops)\n",
      "  model_114/conv2d_1609/Conv2D (41.26m/41.26m flops)\n",
      "  model_114/conv2d_1596/Conv2D (37.75m/37.75m flops)\n",
      "  model_114/depthwise_conv2d_1482/depthwise (21.23m/21.23m flops)\n",
      "  model_114/depthwise_conv2d_1484/depthwise (16.92m/16.92m flops)\n",
      "  model_114/depthwise_conv2d_1486/depthwise (5.39m/5.39m flops)\n",
      "  model_114/depthwise_conv2d_1483/depthwise (5.31m/5.31m flops)\n",
      "  model_114/depthwise_conv2d_1491/depthwise (5.20m/5.20m flops)\n",
      "  model_114/depthwise_conv2d_1492/depthwise (5.20m/5.20m flops)\n",
      "  model_114/depthwise_conv2d_1485/depthwise (4.98m/4.98m flops)\n",
      "  model_114/depthwise_conv2d_1489/depthwise (4.69m/4.69m flops)\n",
      "  model_114/depthwise_conv2d_1490/depthwise (4.58m/4.58m flops)\n",
      "  model_114/depthwise_conv2d_1488/depthwise (4.56m/4.56m flops)\n",
      "  model_114/depthwise_conv2d_1487/depthwise (2.43m/2.43m flops)\n",
      "  model_114/batch_normalization_3079/FusedBatchNormV3 (2.36m/2.36m flops)\n",
      "  model_114/batch_normalization_3078/FusedBatchNormV3 (2.36m/2.36m flops)\n",
      "  model_114/batch_normalization_3080/FusedBatchNormV3 (2.36m/2.36m flops)\n",
      "  model_114/batch_normalization_3084/FusedBatchNormV3 (2.21m/2.21m flops)\n",
      "  model_114/batch_normalization_3082/FusedBatchNormV3 (1.88m/1.88m flops)\n",
      "  model_114/batch_normalization_3083/FusedBatchNormV3 (1.88m/1.88m flops)\n",
      "  model_114/depthwise_conv2d_1493/depthwise (1.30m/1.30m flops)\n",
      "  model_114/conv2d_1596/BiasAdd (1.18m/1.18m flops)\n",
      "  model_114/depthwise_conv2d_1482/BiasAdd (1.18m/1.18m flops)\n",
      "  model_114/conv2d_1597/BiasAdd (1.18m/1.18m flops)\n",
      "  model_114/conv2d_1599/BiasAdd (1.11m/1.11m flops)\n",
      "  model_114/batch_normalization_3088/FusedBatchNormV3 (1.08m/1.08m flops)\n",
      "  model_114/depthwise_conv2d_1484/BiasAdd (940.03k/940.03k flops)\n",
      "  model_114/conv2d_1598/BiasAdd (940.03k/940.03k flops)\n",
      "  model_114/batch_normalization_3087/FusedBatchNormV3 (599.82k/599.82k flops)\n",
      "  model_114/batch_normalization_3086/FusedBatchNormV3 (599.82k/599.82k flops)\n",
      "  model_114/batch_normalization_3081/FusedBatchNormV3 (590.02k/590.02k flops)\n",
      "  model_114/batch_normalization_3100/FusedBatchNormV3 (581.32k/581.32k flops)\n",
      "  model_114/batch_normalization_3096/FusedBatchNormV3 (581.32k/581.32k flops)\n",
      "  model_114/batch_normalization_3097/FusedBatchNormV3 (581.32k/581.32k flops)\n",
      "  model_114/batch_normalization_3098/FusedBatchNormV3 (581.32k/581.32k flops)\n",
      "  model_114/batch_normalization_3099/FusedBatchNormV3 (581.32k/581.32k flops)\n",
      "  model_114/batch_normalization_3085/FusedBatchNormV3 (553.68k/553.68k flops)\n",
      "  model_114/conv2d_1601/BiasAdd (539.14k/539.14k flops)\n",
      "  model_114/batch_normalization_3093/FusedBatchNormV3 (523.42k/523.42k flops)\n",
      "  model_114/batch_normalization_3092/FusedBatchNormV3 (523.42k/523.42k flops)\n",
      "  model_114/batch_normalization_3095/FusedBatchNormV3 (511.84k/511.84k flops)\n",
      "  model_114/batch_normalization_3094/FusedBatchNormV3 (511.84k/511.84k flops)\n",
      "  model_114/batch_normalization_3091/FusedBatchNormV3 (509.52k/509.52k flops)\n",
      "  model_114/batch_normalization_3090/FusedBatchNormV3 (509.52k/509.52k flops)\n",
      "  model_114/depthwise_conv2d_1494/depthwise (486.00k/486.00k flops)\n",
      "  model_114/depthwise_conv2d_1486/BiasAdd (299.52k/299.52k flops)\n",
      "  model_114/conv2d_1600/BiasAdd (299.52k/299.52k flops)\n",
      "  model_114/depthwise_conv2d_1483/BiasAdd (294.91k/294.91k flops)\n",
      "  model_114/depthwise_conv2d_1491/BiasAdd (289.15k/289.15k flops)\n",
      "  model_114/depthwise_conv2d_1492/BiasAdd (289.15k/289.15k flops)\n",
      "  model_114/conv2d_1605/BiasAdd (289.15k/289.15k flops)\n",
      "  model_114/conv2d_1607/BiasAdd (289.15k/289.15k flops)\n",
      "  model_114/conv2d_1606/BiasAdd (289.15k/289.15k flops)\n",
      "  model_114/depthwise_conv2d_1485/BiasAdd (276.48k/276.48k flops)\n",
      "  model_114/batch_normalization_3089/FusedBatchNormV3 (270.97k/270.97k flops)\n",
      "  model_114/conv2d_1603/BiasAdd (260.35k/260.35k flops)\n",
      "  model_114/depthwise_conv2d_1489/BiasAdd (260.35k/260.35k flops)\n",
      "  model_114/conv2d_1604/BiasAdd (254.59k/254.59k flops)\n",
      "  model_114/depthwise_conv2d_1490/BiasAdd (254.59k/254.59k flops)\n",
      "  model_114/depthwise_conv2d_1488/BiasAdd (253.44k/253.44k flops)\n",
      "  model_114/conv2d_1602/BiasAdd (253.44k/253.44k flops)\n",
      "  model_114/batch_normalization_3102/FusedBatchNormV3 (220.50k/220.50k flops)\n",
      "  model_114/batch_normalization_3101/FusedBatchNormV3 (147.59k/147.59k flops)\n",
      "  model_114/depthwise_conv2d_1487/BiasAdd (134.78k/134.78k flops)\n",
      "  model_114/conv2d_1608/BiasAdd (108.00k/108.00k flops)\n",
      "  model_114/depthwise_conv2d_1493/BiasAdd (72.29k/72.29k flops)\n",
      "  model_114/batch_normalization_3104/FusedBatchNormV3 (59.59k/59.59k flops)\n",
      "  model_114/batch_normalization_3103/FusedBatchNormV3 (58.50k/58.50k flops)\n",
      "  model_114/global_average_pooling2d_114/Mean (27.50k/27.50k flops)\n",
      "  model_114/conv2d_1609/BiasAdd (27.50k/27.50k flops)\n",
      "  model_114/depthwise_conv2d_1494/BiasAdd (27.00k/27.00k flops)\n",
      "  model_114/dense_114/MatMul (15.28k/15.28k flops)\n",
      "  model_114/dense_114/Softmax (50/50 flops)\n",
      "  model_114/dense_114/BiasAdd (10/10 flops)\n",
      "\n",
      "======================End of Report==========================\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "145.768652\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-30 13:41:29.471940: I tensorflow/core/grappler/devices.cc:66] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0\n",
      "2022-04-30 13:41:29.472067: I tensorflow/core/grappler/clusters/single_machine.cc:357] Starting new session\n",
      "2022-04-30 13:41:29.477204: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:1137] Optimization results for grappler item: graph_to_optimize\n",
      "  function_optimizer: function_optimizer did nothing. time = 0.006ms.\n",
      "  function_optimizer: function_optimizer did nothing. time = 0.001ms.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=========================Options=============================\n",
      "-max_depth                  10000\n",
      "-min_bytes                  0\n",
      "-min_peak_bytes             0\n",
      "-min_residual_bytes         0\n",
      "-min_output_bytes           0\n",
      "-min_micros                 0\n",
      "-min_accelerator_micros     0\n",
      "-min_cpu_micros             0\n",
      "-min_params                 0\n",
      "-min_float_ops              1\n",
      "-min_occurrence             0\n",
      "-step                       -1\n",
      "-order_by                   float_ops\n",
      "-account_type_regexes       .*\n",
      "-start_name_regexes         .*\n",
      "-trim_name_regexes          \n",
      "-show_name_regexes          .*\n",
      "-hide_name_regexes          \n",
      "-account_displayed_op_only  true\n",
      "-select                     float_ops\n",
      "-output                     stdout:\n",
      "\n",
      "==================Model Analysis Report======================\n",
      "\n",
      "Doc:\n",
      "scope: The nodes in the model graph are organized by their names, which is hierarchical like filesystem.\n",
      "flops: Number of float operations. Note: Please read the implementation for the math behind it.\n",
      "\n",
      "Profile:\n",
      "node name | # float_ops\n",
      "_TFProfRoot (--/2.15b flops)\n",
      "  model_115/conv2d_1618/Conv2D (256.61m/256.61m flops)\n",
      "  model_115/conv2d_1619/Conv2D (253.30m/253.30m flops)\n",
      "  model_115/conv2d_1620/Conv2D (208.79m/208.79m flops)\n",
      "  model_115/conv2d_1621/Conv2D (198.80m/198.80m flops)\n",
      "  model_115/conv2d_1617/Conv2D (198.63m/198.63m flops)\n",
      "  model_115/conv2d_1615/Conv2D (160.91m/160.91m flops)\n",
      "  model_115/conv2d_1611/Conv2D (146.28m/146.28m flops)\n",
      "  model_115/conv2d_1613/Conv2D (130.06m/130.06m flops)\n",
      "  model_115/conv2d_1622/Conv2D (124.38m/124.38m flops)\n",
      "  model_115/conv2d_1612/Conv2D (95.99m/95.99m flops)\n",
      "  model_115/conv2d_1616/Conv2D (82.69m/82.69m flops)\n",
      "  model_115/conv2d_1623/Conv2D (71.56m/71.56m flops)\n",
      "  model_115/conv2d_1614/Conv2D (69.67m/69.67m flops)\n",
      "  model_115/conv2d_1610/Conv2D (37.75m/37.75m flops)\n",
      "  model_115/depthwise_conv2d_1495/depthwise (21.23m/21.23m flops)\n",
      "  model_115/depthwise_conv2d_1497/depthwise (13.93m/13.93m flops)\n",
      "  model_115/depthwise_conv2d_1496/depthwise (10.29m/10.29m flops)\n",
      "  model_115/depthwise_conv2d_1499/depthwise (7.46m/7.46m flops)\n",
      "  model_115/depthwise_conv2d_1503/depthwise (4.96m/4.96m flops)\n",
      "  model_115/depthwise_conv2d_1502/depthwise (4.83m/4.83m flops)\n",
      "  model_115/depthwise_conv2d_1504/depthwise (4.77m/4.77m flops)\n",
      "  model_115/batch_normalization_3107/FusedBatchNormV3 (4.57m/4.57m flops)\n",
      "  model_115/depthwise_conv2d_1505/depthwise (4.08m/4.08m flops)\n",
      "  model_115/depthwise_conv2d_1501/depthwise (3.84m/3.84m flops)\n",
      "  model_115/depthwise_conv2d_1498/depthwise (3.48m/3.48m flops)\n",
      "  model_115/batch_normalization_3106/FusedBatchNormV3 (2.36m/2.36m flops)\n",
      "  model_115/batch_normalization_3105/FusedBatchNormV3 (2.36m/2.36m flops)\n",
      "  model_115/conv2d_1611/BiasAdd (2.29m/2.29m flops)\n",
      "  model_115/depthwise_conv2d_1500/depthwise (2.01m/2.01m flops)\n",
      "  model_115/batch_normalization_3109/FusedBatchNormV3 (1.55m/1.55m flops)\n",
      "  model_115/batch_normalization_3110/FusedBatchNormV3 (1.55m/1.55m flops)\n",
      "  model_115/batch_normalization_3111/FusedBatchNormV3 (1.55m/1.55m flops)\n",
      "  model_115/conv2d_1610/BiasAdd (1.18m/1.18m flops)\n",
      "  model_115/depthwise_conv2d_1495/BiasAdd (1.18m/1.18m flops)\n",
      "  model_115/batch_normalization_3108/FusedBatchNormV3 (1.14m/1.14m flops)\n",
      "  model_115/depthwise_conv2d_1506/depthwise (1.14m/1.14m flops)\n",
      "  model_115/batch_normalization_3115/FusedBatchNormV3 (895.12k/895.12k flops)\n",
      "  model_115/batch_normalization_3113/FusedBatchNormV3 (830.52k/830.52k flops)\n",
      "  model_115/batch_normalization_3114/FusedBatchNormV3 (830.52k/830.52k flops)\n",
      "  model_115/conv2d_1613/BiasAdd (774.14k/774.14k flops)\n",
      "  model_115/conv2d_1612/BiasAdd (774.14k/774.14k flops)\n",
      "  model_115/depthwise_conv2d_1497/BiasAdd (774.14k/774.14k flops)\n",
      "  model_115/depthwise_conv2d_1507/depthwise (638.93k/638.93k flops)\n",
      "  model_115/depthwise_conv2d_1496/BiasAdd (571.39k/571.39k flops)\n",
      "  model_115/batch_normalization_3121/FusedBatchNormV3 (553.52k/553.52k flops)\n",
      "  model_115/batch_normalization_3122/FusedBatchNormV3 (553.52k/553.52k flops)\n",
      "  model_115/batch_normalization_3120/FusedBatchNormV3 (539.63k/539.63k flops)\n",
      "  model_115/batch_normalization_3119/FusedBatchNormV3 (539.63k/539.63k flops)\n",
      "  model_115/batch_normalization_3123/FusedBatchNormV3 (532.68k/532.68k flops)\n",
      "  model_115/batch_normalization_3124/FusedBatchNormV3 (532.68k/532.68k flops)\n",
      "  model_115/batch_normalization_3127/FusedBatchNormV3 (507.20k/507.20k flops)\n",
      "  model_115/batch_normalization_3125/FusedBatchNormV3 (456.25k/456.25k flops)\n",
      "  model_115/batch_normalization_3126/FusedBatchNormV3 (456.25k/456.25k flops)\n",
      "  model_115/conv2d_1615/BiasAdd (446.98k/446.98k flops)\n",
      "  model_115/batch_normalization_3118/FusedBatchNormV3 (428.46k/428.46k flops)\n",
      "  model_115/batch_normalization_3117/FusedBatchNormV3 (428.46k/428.46k flops)\n",
      "  model_115/conv2d_1614/BiasAdd (414.72k/414.72k flops)\n",
      "  model_115/depthwise_conv2d_1499/BiasAdd (414.72k/414.72k flops)\n",
      "  model_115/batch_normalization_3112/FusedBatchNormV3 (387.58k/387.58k flops)\n",
      "  model_115/batch_normalization_3129/FusedBatchNormV3 (289.88k/289.88k flops)\n",
      "  model_115/depthwise_conv2d_1503/BiasAdd (275.33k/275.33k flops)\n",
      "  model_115/conv2d_1618/BiasAdd (275.33k/275.33k flops)\n",
      "  model_115/conv2d_1617/BiasAdd (268.42k/268.42k flops)\n",
      "  model_115/depthwise_conv2d_1502/BiasAdd (268.42k/268.42k flops)\n",
      "  model_115/depthwise_conv2d_1504/BiasAdd (264.96k/264.96k flops)\n",
      "  model_115/conv2d_1619/BiasAdd (264.96k/264.96k flops)\n",
      "  model_115/conv2d_1621/BiasAdd (252.29k/252.29k flops)\n",
      "  model_115/depthwise_conv2d_1505/BiasAdd (226.94k/226.94k flops)\n",
      "  model_115/conv2d_1620/BiasAdd (226.94k/226.94k flops)\n",
      "  model_115/batch_normalization_3116/FusedBatchNormV3 (224.65k/224.65k flops)\n",
      "  model_115/depthwise_conv2d_1501/BiasAdd (213.12k/213.12k flops)\n",
      "  model_115/conv2d_1616/BiasAdd (213.12k/213.12k flops)\n",
      "  model_115/depthwise_conv2d_1498/BiasAdd (193.54k/193.54k flops)\n",
      "  model_115/conv2d_1622/BiasAdd (141.98k/141.98k flops)\n",
      "  model_115/batch_normalization_3128/FusedBatchNormV3 (128.77k/128.77k flops)\n",
      "  model_115/depthwise_conv2d_1500/BiasAdd (111.74k/111.74k flops)\n",
      "  model_115/batch_normalization_3131/FusedBatchNormV3 (78.62k/78.62k flops)\n",
      "  model_115/batch_normalization_3130/FusedBatchNormV3 (76.91k/76.91k flops)\n",
      "  model_115/depthwise_conv2d_1506/BiasAdd (63.07k/63.07k flops)\n",
      "  model_115/global_average_pooling2d_115/Mean (36.29k/36.29k flops)\n",
      "  model_115/conv2d_1623/BiasAdd (36.29k/36.29k flops)\n",
      "  model_115/depthwise_conv2d_1507/BiasAdd (35.50k/35.50k flops)\n",
      "  model_115/dense_115/MatMul (20.16k/20.16k flops)\n",
      "  model_115/dense_115/Softmax (50/50 flops)\n",
      "  model_115/dense_115/BiasAdd (10/10 flops)\n",
      "\n",
      "======================End of Report==========================\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "146.204132\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-30 13:41:30.421115: I tensorflow/core/grappler/devices.cc:66] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0\n",
      "2022-04-30 13:41:30.421230: I tensorflow/core/grappler/clusters/single_machine.cc:357] Starting new session\n",
      "2022-04-30 13:41:30.425633: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:1137] Optimization results for grappler item: graph_to_optimize\n",
      "  function_optimizer: function_optimizer did nothing. time = 0.005ms.\n",
      "  function_optimizer: function_optimizer did nothing. time = 0.001ms.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=========================Options=============================\n",
      "-max_depth                  10000\n",
      "-min_bytes                  0\n",
      "-min_peak_bytes             0\n",
      "-min_residual_bytes         0\n",
      "-min_output_bytes           0\n",
      "-min_micros                 0\n",
      "-min_accelerator_micros     0\n",
      "-min_cpu_micros             0\n",
      "-min_params                 0\n",
      "-min_float_ops              1\n",
      "-min_occurrence             0\n",
      "-step                       -1\n",
      "-order_by                   float_ops\n",
      "-account_type_regexes       .*\n",
      "-start_name_regexes         .*\n",
      "-trim_name_regexes          \n",
      "-show_name_regexes          .*\n",
      "-hide_name_regexes          \n",
      "-account_displayed_op_only  true\n",
      "-select                     float_ops\n",
      "-output                     stdout:\n",
      "\n",
      "==================Model Analysis Report======================\n",
      "\n",
      "Doc:\n",
      "scope: The nodes in the model graph are organized by their names, which is hierarchical like filesystem.\n",
      "flops: Number of float operations. Note: Please read the implementation for the math behind it.\n",
      "\n",
      "Profile:\n",
      "node name | # float_ops\n",
      "_TFProfRoot (--/2.38b flops)\n",
      "  model_116/conv2d_1632/Conv2D (284.41m/284.41m flops)\n",
      "  model_116/conv2d_1633/Conv2D (278.56m/278.56m flops)\n",
      "  model_116/conv2d_1635/Conv2D (270.89m/270.89m flops)\n",
      "  model_116/conv2d_1631/Conv2D (264.26m/264.26m flops)\n",
      "  model_116/conv2d_1634/Conv2D (261.02m/261.02m flops)\n",
      "  model_116/conv2d_1627/Conv2D (177.02m/177.02m flops)\n",
      "  model_116/conv2d_1629/Conv2D (130.06m/130.06m flops)\n",
      "  model_116/conv2d_1625/Conv2D (117.96m/117.96m flops)\n",
      "  model_116/conv2d_1636/Conv2D (117.80m/117.80m flops)\n",
      "  model_116/conv2d_1630/Conv2D (91.35m/91.35m flops)\n",
      "  model_116/conv2d_1626/Conv2D (90.32m/90.32m flops)\n",
      "  model_116/conv2d_1628/Conv2D (75.87m/75.87m flops)\n",
      "  model_116/conv2d_1637/Conv2D (60.45m/60.45m flops)\n",
      "  model_116/conv2d_1624/Conv2D (37.75m/37.75m flops)\n",
      "  model_116/depthwise_conv2d_1508/depthwise (21.23m/21.23m flops)\n",
      "  model_116/depthwise_conv2d_1510/depthwise (16.26m/16.26m flops)\n",
      "  model_116/depthwise_conv2d_1509/depthwise (8.29m/8.29m flops)\n",
      "  model_116/depthwise_conv2d_1512/depthwise (6.97m/6.97m flops)\n",
      "  model_116/depthwise_conv2d_1516/depthwise (5.27m/5.27m flops)\n",
      "  model_116/depthwise_conv2d_1515/depthwise (5.04m/5.04m flops)\n",
      "  model_116/depthwise_conv2d_1517/depthwise (4.94m/4.94m flops)\n",
      "  model_116/depthwise_conv2d_1518/depthwise (4.94m/4.94m flops)\n",
      "  model_116/depthwise_conv2d_1514/depthwise (4.89m/4.89m flops)\n",
      "  model_116/depthwise_conv2d_1511/depthwise (4.06m/4.06m flops)\n",
      "  model_116/batch_normalization_3134/FusedBatchNormV3 (3.69m/3.69m flops)\n",
      "  model_116/batch_normalization_3133/FusedBatchNormV3 (2.36m/2.36m flops)\n",
      "  model_116/batch_normalization_3132/FusedBatchNormV3 (2.36m/2.36m flops)\n",
      "  model_116/conv2d_1625/BiasAdd (1.84m/1.84m flops)\n",
      "  model_116/batch_normalization_3136/FusedBatchNormV3 (1.81m/1.81m flops)\n",
      "  model_116/batch_normalization_3137/FusedBatchNormV3 (1.81m/1.81m flops)\n",
      "  model_116/batch_normalization_3138/FusedBatchNormV3 (1.81m/1.81m flops)\n",
      "  model_116/depthwise_conv2d_1513/depthwise (1.74m/1.74m flops)\n",
      "  model_116/depthwise_conv2d_1519/depthwise (1.28m/1.28m flops)\n",
      "  model_116/conv2d_1624/BiasAdd (1.18m/1.18m flops)\n",
      "  model_116/depthwise_conv2d_1508/BiasAdd (1.18m/1.18m flops)\n",
      "  model_116/batch_normalization_3135/FusedBatchNormV3 (921.90k/921.90k flops)\n",
      "  model_116/conv2d_1626/BiasAdd (903.17k/903.17k flops)\n",
      "  model_116/depthwise_conv2d_1510/BiasAdd (903.17k/903.17k flops)\n",
      "  model_116/conv2d_1627/BiasAdd (903.17k/903.17k flops)\n",
      "  model_116/batch_normalization_3140/FusedBatchNormV3 (775.15k/775.15k flops)\n",
      "  model_116/batch_normalization_3141/FusedBatchNormV3 (775.15k/775.15k flops)\n",
      "  model_116/batch_normalization_3142/FusedBatchNormV3 (775.15k/775.15k flops)\n",
      "  model_116/batch_normalization_3148/FusedBatchNormV3 (588.26k/588.26k flops)\n",
      "  model_116/batch_normalization_3149/FusedBatchNormV3 (588.26k/588.26k flops)\n",
      "  model_116/batch_normalization_3154/FusedBatchNormV3 (572.05k/572.05k flops)\n",
      "  model_116/batch_normalization_3147/FusedBatchNormV3 (562.79k/562.79k flops)\n",
      "  model_116/batch_normalization_3146/FusedBatchNormV3 (562.79k/562.79k flops)\n",
      "  model_116/batch_normalization_3153/FusedBatchNormV3 (551.21k/551.21k flops)\n",
      "  model_116/batch_normalization_3152/FusedBatchNormV3 (551.21k/551.21k flops)\n",
      "  model_116/batch_normalization_3150/FusedBatchNormV3 (551.21k/551.21k flops)\n",
      "  model_116/batch_normalization_3151/FusedBatchNormV3 (551.21k/551.21k flops)\n",
      "  model_116/batch_normalization_3145/FusedBatchNormV3 (546.58k/546.58k flops)\n",
      "  model_116/batch_normalization_3144/FusedBatchNormV3 (546.58k/546.58k flops)\n",
      "  model_116/depthwise_conv2d_1520/depthwise (536.54k/536.54k flops)\n",
      "  model_116/depthwise_conv2d_1509/BiasAdd (460.80k/460.80k flops)\n",
      "  model_116/batch_normalization_3139/FusedBatchNormV3 (452.17k/452.17k flops)\n",
      "  model_116/conv2d_1629/BiasAdd (387.07k/387.07k flops)\n",
      "  model_116/depthwise_conv2d_1512/BiasAdd (387.07k/387.07k flops)\n",
      "  model_116/conv2d_1628/BiasAdd (387.07k/387.07k flops)\n",
      "  model_116/conv2d_1632/BiasAdd (292.61k/292.61k flops)\n",
      "  model_116/depthwise_conv2d_1516/BiasAdd (292.61k/292.61k flops)\n",
      "  model_116/conv2d_1635/BiasAdd (284.54k/284.54k flops)\n",
      "  model_116/conv2d_1631/BiasAdd (279.94k/279.94k flops)\n",
      "  model_116/depthwise_conv2d_1515/BiasAdd (279.94k/279.94k flops)\n",
      "  model_116/conv2d_1633/BiasAdd (274.18k/274.18k flops)\n",
      "  model_116/depthwise_conv2d_1517/BiasAdd (274.18k/274.18k flops)\n",
      "  model_116/depthwise_conv2d_1518/BiasAdd (274.18k/274.18k flops)\n",
      "  model_116/conv2d_1634/BiasAdd (274.18k/274.18k flops)\n",
      "  model_116/conv2d_1630/BiasAdd (271.87k/271.87k flops)\n",
      "  model_116/depthwise_conv2d_1514/BiasAdd (271.87k/271.87k flops)\n",
      "  model_116/batch_normalization_3156/FusedBatchNormV3 (243.43k/243.43k flops)\n",
      "  model_116/depthwise_conv2d_1511/BiasAdd (225.79k/225.79k flops)\n",
      "  model_116/batch_normalization_3143/FusedBatchNormV3 (194.54k/194.54k flops)\n",
      "  model_116/batch_normalization_3155/FusedBatchNormV3 (145.24k/145.24k flops)\n",
      "  model_116/conv2d_1636/BiasAdd (119.23k/119.23k flops)\n",
      "  model_116/depthwise_conv2d_1513/BiasAdd (96.77k/96.77k flops)\n",
      "  model_116/batch_normalization_3158/FusedBatchNormV3 (79.09k/79.09k flops)\n",
      "  model_116/depthwise_conv2d_1519/BiasAdd (71.14k/71.14k flops)\n",
      "  model_116/batch_normalization_3157/FusedBatchNormV3 (64.58k/64.58k flops)\n",
      "  model_116/global_average_pooling2d_116/Mean (36.50k/36.50k flops)\n",
      "  model_116/conv2d_1637/BiasAdd (36.50k/36.50k flops)\n",
      "  model_116/depthwise_conv2d_1520/BiasAdd (29.81k/29.81k flops)\n",
      "  model_116/dense_116/MatMul (20.28k/20.28k flops)\n",
      "  model_116/dense_116/Softmax (50/50 flops)\n",
      "  model_116/dense_116/BiasAdd (10/10 flops)\n",
      "\n",
      "======================End of Report==========================\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "133.336372\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-30 13:41:31.450770: I tensorflow/core/grappler/devices.cc:66] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0\n",
      "2022-04-30 13:41:31.450890: I tensorflow/core/grappler/clusters/single_machine.cc:357] Starting new session\n",
      "2022-04-30 13:41:31.455981: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:1137] Optimization results for grappler item: graph_to_optimize\n",
      "  function_optimizer: function_optimizer did nothing. time = 0.006ms.\n",
      "  function_optimizer: function_optimizer did nothing. time = 0.001ms.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=========================Options=============================\n",
      "-max_depth                  10000\n",
      "-min_bytes                  0\n",
      "-min_peak_bytes             0\n",
      "-min_residual_bytes         0\n",
      "-min_output_bytes           0\n",
      "-min_micros                 0\n",
      "-min_accelerator_micros     0\n",
      "-min_cpu_micros             0\n",
      "-min_params                 0\n",
      "-min_float_ops              1\n",
      "-min_occurrence             0\n",
      "-step                       -1\n",
      "-order_by                   float_ops\n",
      "-account_type_regexes       .*\n",
      "-start_name_regexes         .*\n",
      "-trim_name_regexes          \n",
      "-show_name_regexes          .*\n",
      "-hide_name_regexes          \n",
      "-account_displayed_op_only  true\n",
      "-select                     float_ops\n",
      "-output                     stdout:\n",
      "\n",
      "==================Model Analysis Report======================\n",
      "\n",
      "Doc:\n",
      "scope: The nodes in the model graph are organized by their names, which is hierarchical like filesystem.\n",
      "flops: Number of float operations. Note: Please read the implementation for the math behind it.\n",
      "\n",
      "Profile:\n",
      "node name | # float_ops\n",
      "_TFProfRoot (--/2.29b flops)\n",
      "  model_117/conv2d_1649/Conv2D (296.12m/296.12m flops)\n",
      "  model_117/conv2d_1646/Conv2D (291.47m/291.47m flops)\n",
      "  model_117/conv2d_1648/Conv2D (291.46m/291.46m flops)\n",
      "  model_117/conv2d_1647/Conv2D (290.30m/290.30m flops)\n",
      "  model_117/conv2d_1645/Conv2D (289.15m/289.15m flops)\n",
      "  model_117/conv2d_1641/Conv2D (123.27m/123.27m flops)\n",
      "  model_117/conv2d_1643/Conv2D (114.87m/114.87m flops)\n",
      "  model_117/conv2d_1650/Conv2D (96.85m/96.85m flops)\n",
      "  model_117/conv2d_1644/Conv2D (94.46m/94.46m flops)\n",
      "  model_117/conv2d_1639/Conv2D (89.65m/89.65m flops)\n",
      "  model_117/conv2d_1642/Conv2D (61.64m/61.64m flops)\n",
      "  model_117/conv2d_1640/Conv2D (53.23m/53.23m flops)\n",
      "  model_117/conv2d_1651/Conv2D (45.85m/45.85m flops)\n",
      "  model_117/conv2d_1638/Conv2D (37.75m/37.75m flops)\n",
      "  model_117/depthwise_conv2d_1521/depthwise (21.23m/21.23m flops)\n",
      "  model_117/depthwise_conv2d_1523/depthwise (12.61m/12.61m flops)\n",
      "  model_117/depthwise_conv2d_1522/depthwise (6.30m/6.30m flops)\n",
      "  model_117/depthwise_conv2d_1525/depthwise (6.30m/6.30m flops)\n",
      "  model_117/depthwise_conv2d_1531/depthwise (5.25m/5.25m flops)\n",
      "  model_117/depthwise_conv2d_1529/depthwise (5.23m/5.23m flops)\n",
      "  model_117/depthwise_conv2d_1528/depthwise (5.20m/5.20m flops)\n",
      "  model_117/depthwise_conv2d_1527/depthwise (5.18m/5.18m flops)\n",
      "  model_117/depthwise_conv2d_1530/depthwise (5.18m/5.18m flops)\n",
      "  model_117/depthwise_conv2d_1524/depthwise (3.65m/3.65m flops)\n",
      "  model_117/batch_normalization_3161/FusedBatchNormV3 (2.80m/2.80m flops)\n",
      "  model_117/batch_normalization_3160/FusedBatchNormV3 (2.36m/2.36m flops)\n",
      "  model_117/batch_normalization_3159/FusedBatchNormV3 (2.36m/2.36m flops)\n",
      "  model_117/depthwise_conv2d_1526/depthwise (1.70m/1.70m flops)\n",
      "  model_117/batch_normalization_3165/FusedBatchNormV3 (1.62m/1.62m flops)\n",
      "  model_117/batch_normalization_3163/FusedBatchNormV3 (1.40m/1.40m flops)\n",
      "  model_117/batch_normalization_3164/FusedBatchNormV3 (1.40m/1.40m flops)\n",
      "  model_117/conv2d_1639/BiasAdd (1.40m/1.40m flops)\n",
      "  model_117/depthwise_conv2d_1532/depthwise (1.32m/1.32m flops)\n",
      "  model_117/conv2d_1638/BiasAdd (1.18m/1.18m flops)\n",
      "  model_117/depthwise_conv2d_1521/BiasAdd (1.18m/1.18m flops)\n",
      "  model_117/conv2d_1641/BiasAdd (811.01k/811.01k flops)\n",
      "  model_117/batch_normalization_3169/FusedBatchNormV3 (756.70k/756.70k flops)\n",
      "  model_117/batch_normalization_3167/FusedBatchNormV3 (701.33k/701.33k flops)\n",
      "  model_117/batch_normalization_3168/FusedBatchNormV3 (701.33k/701.33k flops)\n",
      "  model_117/batch_normalization_3162/FusedBatchNormV3 (700.64k/700.64k flops)\n",
      "  model_117/conv2d_1640/BiasAdd (700.42k/700.42k flops)\n",
      "  model_117/depthwise_conv2d_1523/BiasAdd (700.42k/700.42k flops)\n",
      "  model_117/batch_normalization_3181/FusedBatchNormV3 (588.26k/588.26k flops)\n",
      "  model_117/batch_normalization_3180/FusedBatchNormV3 (585.95k/585.95k flops)\n",
      "  model_117/batch_normalization_3179/FusedBatchNormV3 (585.95k/585.95k flops)\n",
      "  model_117/batch_normalization_3176/FusedBatchNormV3 (583.63k/583.63k flops)\n",
      "  model_117/batch_normalization_3175/FusedBatchNormV3 (583.63k/583.63k flops)\n",
      "  model_117/batch_normalization_3174/FusedBatchNormV3 (581.32k/581.32k flops)\n",
      "  model_117/batch_normalization_3173/FusedBatchNormV3 (581.32k/581.32k flops)\n",
      "  model_117/batch_normalization_3172/FusedBatchNormV3 (579.00k/579.00k flops)\n",
      "  model_117/batch_normalization_3171/FusedBatchNormV3 (579.00k/579.00k flops)\n",
      "  model_117/batch_normalization_3177/FusedBatchNormV3 (579.00k/579.00k flops)\n",
      "  model_117/batch_normalization_3178/FusedBatchNormV3 (579.00k/579.00k flops)\n",
      "  model_117/depthwise_conv2d_1533/depthwise (428.98k/428.98k flops)\n",
      "  model_117/batch_normalization_3166/FusedBatchNormV3 (406.03k/406.03k flops)\n",
      "  model_117/conv2d_1643/BiasAdd (377.86k/377.86k flops)\n",
      "  model_117/conv2d_1642/BiasAdd (350.21k/350.21k flops)\n",
      "  model_117/depthwise_conv2d_1525/BiasAdd (350.21k/350.21k flops)\n",
      "  model_117/depthwise_conv2d_1522/BiasAdd (350.21k/350.21k flops)\n",
      "  model_117/conv2d_1649/BiasAdd (292.61k/292.61k flops)\n",
      "  model_117/conv2d_1648/BiasAdd (291.46k/291.46k flops)\n",
      "  model_117/depthwise_conv2d_1531/BiasAdd (291.46k/291.46k flops)\n",
      "  model_117/depthwise_conv2d_1529/BiasAdd (290.30k/290.30k flops)\n",
      "  model_117/conv2d_1646/BiasAdd (290.30k/290.30k flops)\n",
      "  model_117/conv2d_1645/BiasAdd (289.15k/289.15k flops)\n",
      "  model_117/depthwise_conv2d_1528/BiasAdd (289.15k/289.15k flops)\n",
      "  model_117/conv2d_1644/BiasAdd (288.00k/288.00k flops)\n",
      "  model_117/conv2d_1647/BiasAdd (288.00k/288.00k flops)\n",
      "  model_117/depthwise_conv2d_1527/BiasAdd (288.00k/288.00k flops)\n",
      "  model_117/depthwise_conv2d_1530/BiasAdd (288.00k/288.00k flops)\n",
      "  model_117/depthwise_conv2d_1524/BiasAdd (202.75k/202.75k flops)\n",
      "  model_117/batch_normalization_3183/FusedBatchNormV3 (194.63k/194.63k flops)\n",
      "  model_117/batch_normalization_3170/FusedBatchNormV3 (189.91k/189.91k flops)\n",
      "  model_117/batch_normalization_3182/FusedBatchNormV3 (149.35k/149.35k flops)\n",
      "  model_117/conv2d_1650/BiasAdd (95.33k/95.33k flops)\n",
      "  model_117/depthwise_conv2d_1526/BiasAdd (94.46k/94.46k flops)\n",
      "  model_117/batch_normalization_3185/FusedBatchNormV3 (75.04k/75.04k flops)\n",
      "  model_117/depthwise_conv2d_1532/BiasAdd (73.15k/73.15k flops)\n",
      "  model_117/batch_normalization_3184/FusedBatchNormV3 (51.64k/51.64k flops)\n",
      "  model_117/global_average_pooling2d_117/Mean (34.63k/34.63k flops)\n",
      "  model_117/conv2d_1651/BiasAdd (34.63k/34.63k flops)\n",
      "  model_117/depthwise_conv2d_1533/BiasAdd (23.83k/23.83k flops)\n",
      "  model_117/dense_117/MatMul (19.24k/19.24k flops)\n",
      "  model_117/dense_117/Softmax (50/50 flops)\n",
      "  model_117/dense_117/BiasAdd (10/10 flops)\n",
      "\n",
      "======================End of Report==========================\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "136.831452\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-30 13:41:32.395857: I tensorflow/core/grappler/devices.cc:66] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0\n",
      "2022-04-30 13:41:32.395975: I tensorflow/core/grappler/clusters/single_machine.cc:357] Starting new session\n",
      "2022-04-30 13:41:32.400398: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:1137] Optimization results for grappler item: graph_to_optimize\n",
      "  function_optimizer: function_optimizer did nothing. time = 0.005ms.\n",
      "  function_optimizer: function_optimizer did nothing. time = 0.001ms.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=========================Options=============================\n",
      "-max_depth                  10000\n",
      "-min_bytes                  0\n",
      "-min_peak_bytes             0\n",
      "-min_residual_bytes         0\n",
      "-min_output_bytes           0\n",
      "-min_micros                 0\n",
      "-min_accelerator_micros     0\n",
      "-min_cpu_micros             0\n",
      "-min_params                 0\n",
      "-min_float_ops              1\n",
      "-min_occurrence             0\n",
      "-step                       -1\n",
      "-order_by                   float_ops\n",
      "-account_type_regexes       .*\n",
      "-start_name_regexes         .*\n",
      "-trim_name_regexes          \n",
      "-show_name_regexes          .*\n",
      "-hide_name_regexes          \n",
      "-account_displayed_op_only  true\n",
      "-select                     float_ops\n",
      "-output                     stdout:\n",
      "\n",
      "==================Model Analysis Report======================\n",
      "\n",
      "Doc:\n",
      "scope: The nodes in the model graph are organized by their names, which is hierarchical like filesystem.\n",
      "flops: Number of float operations. Note: Please read the implementation for the math behind it.\n",
      "\n",
      "Profile:\n",
      "node name | # float_ops\n",
      "_TFProfRoot (--/2.19b flops)\n",
      "  model_118/conv2d_1661/Conv2D (281.06m/281.06m flops)\n",
      "  model_118/conv2d_1660/Conv2D (259.08m/259.08m flops)\n",
      "  model_118/conv2d_1662/Conv2D (234.03m/234.03m flops)\n",
      "  model_118/conv2d_1663/Conv2D (233.06m/233.06m flops)\n",
      "  model_118/conv2d_1657/Conv2D (223.03m/223.03m flops)\n",
      "  model_118/conv2d_1659/Conv2D (190.96m/190.96m flops)\n",
      "  model_118/conv2d_1653/Conv2D (108.53m/108.53m flops)\n",
      "  model_118/conv2d_1655/Conv2D (107.42m/107.42m flops)\n",
      "  model_118/conv2d_1658/Conv2D (103.15m/103.15m flops)\n",
      "  model_118/conv2d_1664/Conv2D (102.31m/102.31m flops)\n",
      "  model_118/conv2d_1656/Conv2D (86.63m/86.63m flops)\n",
      "  model_118/conv2d_1665/Conv2D (53.48m/53.48m flops)\n",
      "  model_118/conv2d_1654/Conv2D (52.57m/52.57m flops)\n",
      "  model_118/conv2d_1652/Conv2D (37.75m/37.75m flops)\n",
      "  model_118/depthwise_conv2d_1534/depthwise (21.23m/21.23m flops)\n",
      "  model_118/depthwise_conv2d_1536/depthwise (10.29m/10.29m flops)\n",
      "  model_118/depthwise_conv2d_1538/depthwise (8.29m/8.29m flops)\n",
      "  model_118/depthwise_conv2d_1535/depthwise (7.63m/7.63m flops)\n",
      "  model_118/depthwise_conv2d_1542/depthwise (5.20m/5.20m flops)\n",
      "  model_118/depthwise_conv2d_1543/depthwise (5.04m/5.04m flops)\n",
      "  model_118/depthwise_conv2d_1541/depthwise (4.64m/4.64m flops)\n",
      "  model_118/depthwise_conv2d_1544/depthwise (4.33m/4.33m flops)\n",
      "  model_118/depthwise_conv2d_1537/depthwise (3.90m/3.90m flops)\n",
      "  model_118/depthwise_conv2d_1540/depthwise (3.84m/3.84m flops)\n",
      "  model_118/batch_normalization_3188/FusedBatchNormV3 (3.39m/3.39m flops)\n",
      "  model_118/depthwise_conv2d_1539/depthwise (2.51m/2.51m flops)\n",
      "  model_118/batch_normalization_3187/FusedBatchNormV3 (2.36m/2.36m flops)\n",
      "  model_118/batch_normalization_3186/FusedBatchNormV3 (2.36m/2.36m flops)\n",
      "  model_118/batch_normalization_3192/FusedBatchNormV3 (1.73m/1.73m flops)\n",
      "  model_118/conv2d_1653/BiasAdd (1.70m/1.70m flops)\n",
      "  model_118/depthwise_conv2d_1545/depthwise (1.25m/1.25m flops)\n",
      "  model_118/conv2d_1652/BiasAdd (1.18m/1.18m flops)\n",
      "  model_118/depthwise_conv2d_1534/BiasAdd (1.18m/1.18m flops)\n",
      "  model_118/batch_normalization_3191/FusedBatchNormV3 (1.14m/1.14m flops)\n",
      "  model_118/batch_normalization_3190/FusedBatchNormV3 (1.14m/1.14m flops)\n",
      "  model_118/batch_normalization_3196/FusedBatchNormV3 (1.12m/1.12m flops)\n",
      "  model_118/batch_normalization_3194/FusedBatchNormV3 (922.80k/922.80k flops)\n",
      "  model_118/batch_normalization_3195/FusedBatchNormV3 (922.80k/922.80k flops)\n",
      "  model_118/conv2d_1655/BiasAdd (866.30k/866.30k flops)\n",
      "  model_118/batch_normalization_3189/FusedBatchNormV3 (848.15k/848.15k flops)\n",
      "  model_118/batch_normalization_3203/FusedBatchNormV3 (581.32k/581.32k flops)\n",
      "  model_118/batch_normalization_3202/FusedBatchNormV3 (581.32k/581.32k flops)\n",
      "  model_118/depthwise_conv2d_1536/BiasAdd (571.39k/571.39k flops)\n",
      "  model_118/conv2d_1654/BiasAdd (571.39k/571.39k flops)\n",
      "  model_118/batch_normalization_3205/FusedBatchNormV3 (562.79k/562.79k flops)\n",
      "  model_118/batch_normalization_3204/FusedBatchNormV3 (562.79k/562.79k flops)\n",
      "  model_118/batch_normalization_3208/FusedBatchNormV3 (560.47k/560.47k flops)\n",
      "  model_118/conv2d_1657/BiasAdd (557.57k/557.57k flops)\n",
      "  model_118/batch_normalization_3201/FusedBatchNormV3 (518.78k/518.78k flops)\n",
      "  model_118/batch_normalization_3200/FusedBatchNormV3 (518.78k/518.78k flops)\n",
      "  model_118/batch_normalization_3206/FusedBatchNormV3 (484.04k/484.04k flops)\n",
      "  model_118/batch_normalization_3207/FusedBatchNormV3 (484.04k/484.04k flops)\n",
      "  model_118/depthwise_conv2d_1546/depthwise (475.63k/475.63k flops)\n",
      "  model_118/conv2d_1656/BiasAdd (460.80k/460.80k flops)\n",
      "  model_118/depthwise_conv2d_1538/BiasAdd (460.80k/460.80k flops)\n",
      "  model_118/batch_normalization_3193/FusedBatchNormV3 (433.72k/433.72k flops)\n",
      "  model_118/batch_normalization_3199/FusedBatchNormV3 (428.46k/428.46k flops)\n",
      "  model_118/batch_normalization_3198/FusedBatchNormV3 (428.46k/428.46k flops)\n",
      "  model_118/depthwise_conv2d_1535/BiasAdd (423.94k/423.94k flops)\n",
      "  model_118/depthwise_conv2d_1542/BiasAdd (289.15k/289.15k flops)\n",
      "  model_118/conv2d_1660/BiasAdd (289.15k/289.15k flops)\n",
      "  model_118/batch_normalization_3197/FusedBatchNormV3 (280.24k/280.24k flops)\n",
      "  model_118/conv2d_1661/BiasAdd (279.94k/279.94k flops)\n",
      "  model_118/depthwise_conv2d_1543/BiasAdd (279.94k/279.94k flops)\n",
      "  model_118/conv2d_1663/BiasAdd (278.78k/278.78k flops)\n",
      "  model_118/conv2d_1659/BiasAdd (258.05k/258.05k flops)\n",
      "  model_118/depthwise_conv2d_1541/BiasAdd (258.05k/258.05k flops)\n",
      "  model_118/conv2d_1662/BiasAdd (240.77k/240.77k flops)\n",
      "  model_118/depthwise_conv2d_1544/BiasAdd (240.77k/240.77k flops)\n",
      "  model_118/depthwise_conv2d_1537/BiasAdd (216.58k/216.58k flops)\n",
      "  model_118/batch_normalization_3210/FusedBatchNormV3 (215.80k/215.80k flops)\n",
      "  model_118/depthwise_conv2d_1540/BiasAdd (213.12k/213.12k flops)\n",
      "  model_118/conv2d_1658/BiasAdd (213.12k/213.12k flops)\n",
      "  model_118/batch_normalization_3209/FusedBatchNormV3 (142.30k/142.30k flops)\n",
      "  model_118/depthwise_conv2d_1539/BiasAdd (139.39k/139.39k flops)\n",
      "  model_118/conv2d_1664/BiasAdd (105.70k/105.70k flops)\n",
      "  model_118/batch_normalization_3212/FusedBatchNormV3 (78.94k/78.94k flops)\n",
      "  model_118/depthwise_conv2d_1545/BiasAdd (69.70k/69.70k flops)\n",
      "  model_118/batch_normalization_3211/FusedBatchNormV3 (57.25k/57.25k flops)\n",
      "  model_118/global_average_pooling2d_118/Mean (36.43k/36.43k flops)\n",
      "  model_118/conv2d_1665/BiasAdd (36.43k/36.43k flops)\n",
      "  model_118/depthwise_conv2d_1546/BiasAdd (26.42k/26.42k flops)\n",
      "  model_118/dense_118/MatMul (20.24k/20.24k flops)\n",
      "  model_118/dense_118/Softmax (50/50 flops)\n",
      "  model_118/dense_118/BiasAdd (10/10 flops)\n",
      "\n",
      "======================End of Report==========================\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "157.206188\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-30 13:41:33.450858: I tensorflow/core/grappler/devices.cc:66] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0\n",
      "2022-04-30 13:41:33.450927: I tensorflow/core/grappler/clusters/single_machine.cc:357] Starting new session\n",
      "2022-04-30 13:41:33.456038: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:1137] Optimization results for grappler item: graph_to_optimize\n",
      "  function_optimizer: function_optimizer did nothing. time = 0.006ms.\n",
      "  function_optimizer: function_optimizer did nothing. time = 0ms.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=========================Options=============================\n",
      "-max_depth                  10000\n",
      "-min_bytes                  0\n",
      "-min_peak_bytes             0\n",
      "-min_residual_bytes         0\n",
      "-min_output_bytes           0\n",
      "-min_micros                 0\n",
      "-min_accelerator_micros     0\n",
      "-min_cpu_micros             0\n",
      "-min_params                 0\n",
      "-min_float_ops              1\n",
      "-min_occurrence             0\n",
      "-step                       -1\n",
      "-order_by                   float_ops\n",
      "-account_type_regexes       .*\n",
      "-start_name_regexes         .*\n",
      "-trim_name_regexes          \n",
      "-show_name_regexes          .*\n",
      "-hide_name_regexes          \n",
      "-account_displayed_op_only  true\n",
      "-select                     float_ops\n",
      "-output                     stdout:\n",
      "\n",
      "==================Model Analysis Report======================\n",
      "\n",
      "Doc:\n",
      "scope: The nodes in the model graph are organized by their names, which is hierarchical like filesystem.\n",
      "flops: Number of float operations. Note: Please read the implementation for the math behind it.\n",
      "\n",
      "Profile:\n",
      "node name | # float_ops\n",
      "_TFProfRoot (--/2.81b flops)\n",
      "  model_119/conv2d_1673/Conv2D (297.29m/297.29m flops)\n",
      "  model_119/conv2d_1674/Conv2D (297.29m/297.29m flops)\n",
      "  model_119/conv2d_1675/Conv2D (297.29m/297.29m flops)\n",
      "  model_119/conv2d_1676/Conv2D (297.29m/297.29m flops)\n",
      "  model_119/conv2d_1677/Conv2D (297.29m/297.29m flops)\n",
      "  model_119/conv2d_1671/Conv2D (269.86m/269.86m flops)\n",
      "  model_119/conv2d_1669/Conv2D (218.53m/218.53m flops)\n",
      "  model_119/conv2d_1672/Conv2D (141.62m/141.62m flops)\n",
      "  model_119/conv2d_1678/Conv2D (129.63m/129.63m flops)\n",
      "  model_119/conv2d_1670/Conv2D (127.13m/127.13m flops)\n",
      "  model_119/conv2d_1667/Conv2D (113.25m/113.25m flops)\n",
      "  model_119/conv2d_1668/Conv2D (92.01m/92.01m flops)\n",
      "  model_119/conv2d_1679/Conv2D (62.77m/62.77m flops)\n",
      "  model_119/conv2d_1666/Conv2D (37.75m/37.75m flops)\n",
      "  model_119/depthwise_conv2d_1547/depthwise (21.23m/21.23m flops)\n",
      "  model_119/depthwise_conv2d_1549/depthwise (17.25m/17.25m flops)\n",
      "  model_119/depthwise_conv2d_1551/depthwise (10.04m/10.04m flops)\n",
      "  model_119/depthwise_conv2d_1548/depthwise (7.96m/7.96m flops)\n",
      "  model_119/depthwise_conv2d_1553/depthwise (5.27m/5.27m flops)\n",
      "  model_119/depthwise_conv2d_1554/depthwise (5.27m/5.27m flops)\n",
      "  model_119/depthwise_conv2d_1555/depthwise (5.27m/5.27m flops)\n",
      "  model_119/depthwise_conv2d_1556/depthwise (5.27m/5.27m flops)\n",
      "  model_119/depthwise_conv2d_1557/depthwise (5.27m/5.27m flops)\n",
      "  model_119/depthwise_conv2d_1550/depthwise (4.73m/4.73m flops)\n",
      "  model_119/batch_normalization_3215/FusedBatchNormV3 (3.54m/3.54m flops)\n",
      "  model_119/depthwise_conv2d_1552/depthwise (2.51m/2.51m flops)\n",
      "  model_119/batch_normalization_3214/FusedBatchNormV3 (2.36m/2.36m flops)\n",
      "  model_119/batch_normalization_3213/FusedBatchNormV3 (2.36m/2.36m flops)\n",
      "  model_119/batch_normalization_3219/FusedBatchNormV3 (2.10m/2.10m flops)\n",
      "  model_119/batch_normalization_3217/FusedBatchNormV3 (1.92m/1.92m flops)\n",
      "  model_119/batch_normalization_3218/FusedBatchNormV3 (1.92m/1.92m flops)\n",
      "  model_119/conv2d_1667/BiasAdd (1.77m/1.77m flops)\n",
      "  model_119/depthwise_conv2d_1558/depthwise (1.32m/1.32m flops)\n",
      "  model_119/conv2d_1666/BiasAdd (1.18m/1.18m flops)\n",
      "  model_119/depthwise_conv2d_1547/BiasAdd (1.18m/1.18m flops)\n",
      "  model_119/batch_normalization_3223/FusedBatchNormV3 (1.12m/1.12m flops)\n",
      "  model_119/batch_normalization_3222/FusedBatchNormV3 (1.12m/1.12m flops)\n",
      "  model_119/batch_normalization_3221/FusedBatchNormV3 (1.12m/1.12m flops)\n",
      "  model_119/conv2d_1669/BiasAdd (1.05m/1.05m flops)\n",
      "  model_119/depthwise_conv2d_1549/BiasAdd (958.46k/958.46k flops)\n",
      "  model_119/conv2d_1668/BiasAdd (958.46k/958.46k flops)\n",
      "  model_119/batch_normalization_3216/FusedBatchNormV3 (885.02k/885.02k flops)\n",
      "  model_119/batch_normalization_3235/FusedBatchNormV3 (588.26k/588.26k flops)\n",
      "  model_119/batch_normalization_3225/FusedBatchNormV3 (588.26k/588.26k flops)\n",
      "  model_119/batch_normalization_3226/FusedBatchNormV3 (588.26k/588.26k flops)\n",
      "  model_119/batch_normalization_3227/FusedBatchNormV3 (588.26k/588.26k flops)\n",
      "  model_119/batch_normalization_3228/FusedBatchNormV3 (588.26k/588.26k flops)\n",
      "  model_119/batch_normalization_3229/FusedBatchNormV3 (588.26k/588.26k flops)\n",
      "  model_119/batch_normalization_3230/FusedBatchNormV3 (588.26k/588.26k flops)\n",
      "  model_119/batch_normalization_3231/FusedBatchNormV3 (588.26k/588.26k flops)\n",
      "  model_119/batch_normalization_3232/FusedBatchNormV3 (588.26k/588.26k flops)\n",
      "  model_119/batch_normalization_3233/FusedBatchNormV3 (588.26k/588.26k flops)\n",
      "  model_119/batch_normalization_3234/FusedBatchNormV3 (588.26k/588.26k flops)\n",
      "  model_119/depthwise_conv2d_1559/depthwise (574.13k/574.13k flops)\n",
      "  model_119/conv2d_1670/BiasAdd (557.57k/557.57k flops)\n",
      "  model_119/depthwise_conv2d_1551/BiasAdd (557.57k/557.57k flops)\n",
      "  model_119/conv2d_1671/BiasAdd (557.57k/557.57k flops)\n",
      "  model_119/batch_normalization_3220/FusedBatchNormV3 (526.00k/526.00k flops)\n",
      "  model_119/depthwise_conv2d_1548/BiasAdd (442.37k/442.37k flops)\n",
      "  model_119/depthwise_conv2d_1553/BiasAdd (292.61k/292.61k flops)\n",
      "  model_119/depthwise_conv2d_1554/BiasAdd (292.61k/292.61k flops)\n",
      "  model_119/depthwise_conv2d_1555/BiasAdd (292.61k/292.61k flops)\n",
      "  model_119/depthwise_conv2d_1556/BiasAdd (292.61k/292.61k flops)\n",
      "  model_119/depthwise_conv2d_1557/BiasAdd (292.61k/292.61k flops)\n",
      "  model_119/conv2d_1677/BiasAdd (292.61k/292.61k flops)\n",
      "  model_119/conv2d_1676/BiasAdd (292.61k/292.61k flops)\n",
      "  model_119/conv2d_1675/BiasAdd (292.61k/292.61k flops)\n",
      "  model_119/conv2d_1674/BiasAdd (292.61k/292.61k flops)\n",
      "  model_119/conv2d_1673/BiasAdd (292.61k/292.61k flops)\n",
      "  model_119/conv2d_1672/BiasAdd (292.61k/292.61k flops)\n",
      "  model_119/batch_normalization_3224/FusedBatchNormV3 (280.24k/280.24k flops)\n",
      "  model_119/depthwise_conv2d_1550/BiasAdd (262.66k/262.66k flops)\n",
      "  model_119/batch_normalization_3237/FusedBatchNormV3 (260.48k/260.48k flops)\n",
      "  model_119/batch_normalization_3236/FusedBatchNormV3 (149.35k/149.35k flops)\n",
      "  model_119/depthwise_conv2d_1552/BiasAdd (139.39k/139.39k flops)\n",
      "  model_119/conv2d_1678/BiasAdd (127.58k/127.58k flops)\n",
      "  model_119/batch_normalization_3239/FusedBatchNormV3 (76.75k/76.75k flops)\n",
      "  model_119/depthwise_conv2d_1558/BiasAdd (73.15k/73.15k flops)\n",
      "  model_119/batch_normalization_3238/FusedBatchNormV3 (69.11k/69.11k flops)\n",
      "  model_119/global_average_pooling2d_119/Mean (35.42k/35.42k flops)\n",
      "  model_119/conv2d_1679/BiasAdd (35.42k/35.42k flops)\n",
      "  model_119/depthwise_conv2d_1559/BiasAdd (31.90k/31.90k flops)\n",
      "  model_119/dense_119/MatMul (19.68k/19.68k flops)\n",
      "  model_119/dense_119/Softmax (50/50 flops)\n",
      "  model_119/dense_119/BiasAdd (10/10 flops)\n",
      "\n",
      "======================End of Report==========================\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "158.253004\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-30 13:41:34.412607: I tensorflow/core/grappler/devices.cc:66] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0\n",
      "2022-04-30 13:41:34.412724: I tensorflow/core/grappler/clusters/single_machine.cc:357] Starting new session\n",
      "2022-04-30 13:41:34.417128: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:1137] Optimization results for grappler item: graph_to_optimize\n",
      "  function_optimizer: function_optimizer did nothing. time = 0.006ms.\n",
      "  function_optimizer: function_optimizer did nothing. time = 0.001ms.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=========================Options=============================\n",
      "-max_depth                  10000\n",
      "-min_bytes                  0\n",
      "-min_peak_bytes             0\n",
      "-min_residual_bytes         0\n",
      "-min_output_bytes           0\n",
      "-min_micros                 0\n",
      "-min_accelerator_micros     0\n",
      "-min_cpu_micros             0\n",
      "-min_params                 0\n",
      "-min_float_ops              1\n",
      "-min_occurrence             0\n",
      "-step                       -1\n",
      "-order_by                   float_ops\n",
      "-account_type_regexes       .*\n",
      "-start_name_regexes         .*\n",
      "-trim_name_regexes          \n",
      "-show_name_regexes          .*\n",
      "-hide_name_regexes          \n",
      "-account_displayed_op_only  true\n",
      "-select                     float_ops\n",
      "-output                     stdout:\n",
      "\n",
      "==================Model Analysis Report======================\n",
      "\n",
      "Doc:\n",
      "scope: The nodes in the model graph are organized by their names, which is hierarchical like filesystem.\n",
      "flops: Number of float operations. Note: Please read the implementation for the math behind it.\n",
      "\n",
      "Profile:\n",
      "node name | # float_ops\n",
      "_TFProfRoot (--/2.48b flops)\n",
      "  model_120/conv2d_1683/Conv2D (292.63m/292.63m flops)\n",
      "  model_120/conv2d_1689/Conv2D (266.02m/266.02m flops)\n",
      "  model_120/conv2d_1690/Conv2D (263.71m/263.71m flops)\n",
      "  model_120/conv2d_1691/Conv2D (262.66m/262.66m flops)\n",
      "  model_120/conv2d_1688/Conv2D (254.36m/254.36m flops)\n",
      "  model_120/conv2d_1687/Conv2D (247.73m/247.73m flops)\n",
      "  model_120/conv2d_1681/Conv2D (136.84m/136.84m flops)\n",
      "  model_120/conv2d_1682/Conv2D (134.70m/134.70m flops)\n",
      "  model_120/conv2d_1692/Conv2D (120.67m/120.67m flops)\n",
      "  model_120/conv2d_1685/Conv2D (108.82m/108.82m flops)\n",
      "  model_120/conv2d_1686/Conv2D (84.64m/84.64m flops)\n",
      "  model_120/conv2d_1684/Conv2D (83.61m/83.61m flops)\n",
      "  model_120/conv2d_1693/Conv2D (54.06m/54.06m flops)\n",
      "  model_120/conv2d_1680/Conv2D (37.75m/37.75m flops)\n",
      "  model_120/depthwise_conv2d_1560/depthwise (21.23m/21.23m flops)\n",
      "  model_120/depthwise_conv2d_1562/depthwise (20.90m/20.90m flops)\n",
      "  model_120/depthwise_conv2d_1561/depthwise (9.62m/9.62m flops)\n",
      "  model_120/depthwise_conv2d_1564/depthwise (5.97m/5.97m flops)\n",
      "  model_120/depthwise_conv2d_1563/depthwise (5.23m/5.23m flops)\n",
      "  model_120/depthwise_conv2d_1569/depthwise (5.20m/5.20m flops)\n",
      "  model_120/depthwise_conv2d_1567/depthwise (4.98m/4.98m flops)\n",
      "  model_120/depthwise_conv2d_1568/depthwise (4.77m/4.77m flops)\n",
      "  model_120/depthwise_conv2d_1570/depthwise (4.73m/4.73m flops)\n",
      "  model_120/depthwise_conv2d_1566/depthwise (4.64m/4.64m flops)\n",
      "  model_120/batch_normalization_3242/FusedBatchNormV3 (4.28m/4.28m flops)\n",
      "  model_120/batch_normalization_3241/FusedBatchNormV3 (2.36m/2.36m flops)\n",
      "  model_120/batch_normalization_3240/FusedBatchNormV3 (2.36m/2.36m flops)\n",
      "  model_120/batch_normalization_3244/FusedBatchNormV3 (2.32m/2.32m flops)\n",
      "  model_120/batch_normalization_3245/FusedBatchNormV3 (2.32m/2.32m flops)\n",
      "  model_120/batch_normalization_3246/FusedBatchNormV3 (2.32m/2.32m flops)\n",
      "  model_120/conv2d_1681/BiasAdd (2.14m/2.14m flops)\n",
      "  model_120/depthwise_conv2d_1565/depthwise (1.70m/1.70m flops)\n",
      "  model_120/depthwise_conv2d_1571/depthwise (1.30m/1.30m flops)\n",
      "  model_120/conv2d_1680/BiasAdd (1.18m/1.18m flops)\n",
      "  model_120/depthwise_conv2d_1560/BiasAdd (1.18m/1.18m flops)\n",
      "  model_120/conv2d_1682/BiasAdd (1.16m/1.16m flops)\n",
      "  model_120/depthwise_conv2d_1562/BiasAdd (1.16m/1.16m flops)\n",
      "  model_120/conv2d_1683/BiasAdd (1.16m/1.16m flops)\n",
      "  model_120/batch_normalization_3243/FusedBatchNormV3 (1.07m/1.07m flops)\n",
      "  model_120/batch_normalization_3250/FusedBatchNormV3 (756.70k/756.70k flops)\n",
      "  model_120/batch_normalization_3248/FusedBatchNormV3 (664.42k/664.42k flops)\n",
      "  model_120/batch_normalization_3249/FusedBatchNormV3 (664.42k/664.42k flops)\n",
      "  model_120/batch_normalization_3247/FusedBatchNormV3 (581.36k/581.36k flops)\n",
      "  model_120/batch_normalization_3259/FusedBatchNormV3 (581.32k/581.32k flops)\n",
      "  model_120/batch_normalization_3258/FusedBatchNormV3 (581.32k/581.32k flops)\n",
      "  model_120/batch_normalization_3262/FusedBatchNormV3 (579.00k/579.00k flops)\n",
      "  model_120/batch_normalization_3254/FusedBatchNormV3 (555.84k/555.84k flops)\n",
      "  model_120/batch_normalization_3255/FusedBatchNormV3 (555.84k/555.84k flops)\n",
      "  model_120/depthwise_conv2d_1572/depthwise (543.02k/543.02k flops)\n",
      "  model_120/depthwise_conv2d_1561/BiasAdd (534.53k/534.53k flops)\n",
      "  model_120/batch_normalization_3256/FusedBatchNormV3 (532.68k/532.68k flops)\n",
      "  model_120/batch_normalization_3257/FusedBatchNormV3 (532.68k/532.68k flops)\n",
      "  model_120/batch_normalization_3261/FusedBatchNormV3 (528.05k/528.05k flops)\n",
      "  model_120/batch_normalization_3260/FusedBatchNormV3 (528.05k/528.05k flops)\n",
      "  model_120/batch_normalization_3252/FusedBatchNormV3 (518.78k/518.78k flops)\n",
      "  model_120/batch_normalization_3253/FusedBatchNormV3 (518.78k/518.78k flops)\n",
      "  model_120/conv2d_1685/BiasAdd (377.86k/377.86k flops)\n",
      "  model_120/conv2d_1684/BiasAdd (331.78k/331.78k flops)\n",
      "  model_120/depthwise_conv2d_1564/BiasAdd (331.78k/331.78k flops)\n",
      "  model_120/depthwise_conv2d_1563/BiasAdd (290.30k/290.30k flops)\n",
      "  model_120/depthwise_conv2d_1569/BiasAdd (289.15k/289.15k flops)\n",
      "  model_120/conv2d_1689/BiasAdd (289.15k/289.15k flops)\n",
      "  model_120/conv2d_1691/BiasAdd (288.00k/288.00k flops)\n",
      "  model_120/conv2d_1687/BiasAdd (276.48k/276.48k flops)\n",
      "  model_120/depthwise_conv2d_1567/BiasAdd (276.48k/276.48k flops)\n",
      "  model_120/conv2d_1688/BiasAdd (264.96k/264.96k flops)\n",
      "  model_120/depthwise_conv2d_1568/BiasAdd (264.96k/264.96k flops)\n",
      "  model_120/conv2d_1690/BiasAdd (262.66k/262.66k flops)\n",
      "  model_120/depthwise_conv2d_1570/BiasAdd (262.66k/262.66k flops)\n",
      "  model_120/conv2d_1686/BiasAdd (258.05k/258.05k flops)\n",
      "  model_120/depthwise_conv2d_1566/BiasAdd (258.05k/258.05k flops)\n",
      "  model_120/batch_normalization_3264/FusedBatchNormV3 (246.37k/246.37k flops)\n",
      "  model_120/batch_normalization_3251/FusedBatchNormV3 (189.91k/189.91k flops)\n",
      "  model_120/batch_normalization_3263/FusedBatchNormV3 (147.00k/147.00k flops)\n",
      "  model_120/conv2d_1692/BiasAdd (120.67k/120.67k flops)\n",
      "  model_120/depthwise_conv2d_1565/BiasAdd (94.46k/94.46k flops)\n",
      "  model_120/depthwise_conv2d_1571/BiasAdd (72.00k/72.00k flops)\n",
      "  model_120/batch_normalization_3266/FusedBatchNormV3 (69.89k/69.89k flops)\n",
      "  model_120/batch_normalization_3265/FusedBatchNormV3 (65.36k/65.36k flops)\n",
      "  model_120/global_average_pooling2d_120/Mean (32.26k/32.26k flops)\n",
      "  model_120/conv2d_1693/BiasAdd (32.26k/32.26k flops)\n",
      "  model_120/depthwise_conv2d_1572/BiasAdd (30.17k/30.17k flops)\n",
      "  model_120/dense_120/MatMul (17.92k/17.92k flops)\n",
      "  model_120/dense_120/Softmax (50/50 flops)\n",
      "  model_120/dense_120/BiasAdd (10/10 flops)\n",
      "\n",
      "======================End of Report==========================\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "165.666316\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-30 13:41:35.339052: I tensorflow/core/grappler/devices.cc:66] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0\n",
      "2022-04-30 13:41:35.339167: I tensorflow/core/grappler/clusters/single_machine.cc:357] Starting new session\n",
      "2022-04-30 13:41:35.343372: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:1137] Optimization results for grappler item: graph_to_optimize\n",
      "  function_optimizer: function_optimizer did nothing. time = 0.006ms.\n",
      "  function_optimizer: function_optimizer did nothing. time = 0.001ms.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=========================Options=============================\n",
      "-max_depth                  10000\n",
      "-min_bytes                  0\n",
      "-min_peak_bytes             0\n",
      "-min_residual_bytes         0\n",
      "-min_output_bytes           0\n",
      "-min_micros                 0\n",
      "-min_accelerator_micros     0\n",
      "-min_cpu_micros             0\n",
      "-min_params                 0\n",
      "-min_float_ops              1\n",
      "-min_occurrence             0\n",
      "-step                       -1\n",
      "-order_by                   float_ops\n",
      "-account_type_regexes       .*\n",
      "-start_name_regexes         .*\n",
      "-trim_name_regexes          \n",
      "-show_name_regexes          .*\n",
      "-hide_name_regexes          \n",
      "-account_displayed_op_only  true\n",
      "-select                     float_ops\n",
      "-output                     stdout:\n",
      "\n",
      "==================Model Analysis Report======================\n",
      "\n",
      "Doc:\n",
      "scope: The nodes in the model graph are organized by their names, which is hierarchical like filesystem.\n",
      "flops: Number of float operations. Note: Please read the implementation for the math behind it.\n",
      "\n",
      "Profile:\n",
      "node name | # float_ops\n",
      "_TFProfRoot (--/2.89b flops)\n",
      "  model_121/conv2d_1705/Conv2D (336.65m/336.65m flops)\n",
      "  model_121/conv2d_1699/Conv2D (332.59m/332.59m flops)\n",
      "  model_121/conv2d_1704/Conv2D (312.41m/312.41m flops)\n",
      "  model_121/conv2d_1702/Conv2D (307.46m/307.46m flops)\n",
      "  model_121/conv2d_1701/Conv2D (292.94m/292.94m flops)\n",
      "  model_121/conv2d_1703/Conv2D (292.33m/292.33m flops)\n",
      "  model_121/conv2d_1706/Conv2D (164.61m/164.61m flops)\n",
      "  model_121/conv2d_1700/Conv2D (150.07m/150.07m flops)\n",
      "  model_121/conv2d_1697/Conv2D (123.56m/123.56m flops)\n",
      "  model_121/conv2d_1695/Conv2D (121.83m/121.83m flops)\n",
      "  model_121/conv2d_1698/Conv2D (111.75m/111.75m flops)\n",
      "  model_121/conv2d_1707/Conv2D (95.83m/95.83m flops)\n",
      "  model_121/conv2d_1696/Conv2D (64.72m/64.72m flops)\n",
      "  model_121/conv2d_1694/Conv2D (44.30m/44.30m flops)\n",
      "  model_121/depthwise_conv2d_1573/depthwise (24.92m/24.92m flops)\n",
      "  model_121/depthwise_conv2d_1575/depthwise (13.24m/13.24m flops)\n",
      "  model_121/depthwise_conv2d_1577/depthwise (11.97m/11.97m flops)\n",
      "  model_121/depthwise_conv2d_1574/depthwise (8.57m/8.57m flops)\n",
      "  model_121/depthwise_conv2d_1583/depthwise (6.06m/6.06m flops)\n",
      "  model_121/depthwise_conv2d_1580/depthwise (5.94m/5.94m flops)\n",
      "  model_121/depthwise_conv2d_1581/depthwise (5.67m/5.67m flops)\n",
      "  model_121/depthwise_conv2d_1582/depthwise (5.65m/5.65m flops)\n",
      "  model_121/depthwise_conv2d_1579/depthwise (5.40m/5.40m flops)\n",
      "  model_121/depthwise_conv2d_1576/depthwise (4.09m/4.09m flops)\n",
      "  model_121/batch_normalization_3269/FusedBatchNormV3 (3.81m/3.81m flops)\n",
      "  model_121/depthwise_conv2d_1578/depthwise (3.04m/3.04m flops)\n",
      "  model_121/batch_normalization_3268/FusedBatchNormV3 (2.77m/2.77m flops)\n",
      "  model_121/batch_normalization_3267/FusedBatchNormV3 (2.77m/2.77m flops)\n",
      "  model_121/conv2d_1695/BiasAdd (1.90m/1.90m flops)\n",
      "  model_121/batch_normalization_3273/FusedBatchNormV3 (1.82m/1.82m flops)\n",
      "  model_121/depthwise_conv2d_1584/depthwise (1.52m/1.52m flops)\n",
      "  model_121/batch_normalization_3271/FusedBatchNormV3 (1.47m/1.47m flops)\n",
      "  model_121/batch_normalization_3272/FusedBatchNormV3 (1.47m/1.47m flops)\n",
      "  model_121/conv2d_1694/BiasAdd (1.38m/1.38m flops)\n",
      "  model_121/depthwise_conv2d_1573/BiasAdd (1.38m/1.38m flops)\n",
      "  model_121/batch_normalization_3277/FusedBatchNormV3 (1.35m/1.35m flops)\n",
      "  model_121/batch_normalization_3275/FusedBatchNormV3 (1.33m/1.33m flops)\n",
      "  model_121/batch_normalization_3276/FusedBatchNormV3 (1.33m/1.33m flops)\n",
      "  model_121/batch_normalization_3270/FusedBatchNormV3 (952.07k/952.07k flops)\n",
      "  model_121/conv2d_1697/BiasAdd (908.54k/908.54k flops)\n",
      "  model_121/depthwise_conv2d_1585/depthwise (859.07k/859.07k flops)\n",
      "  model_121/depthwise_conv2d_1575/BiasAdd (735.49k/735.49k flops)\n",
      "  model_121/conv2d_1696/BiasAdd (735.49k/735.49k flops)\n",
      "  model_121/batch_normalization_3289/FusedBatchNormV3 (679.00k/679.00k flops)\n",
      "  model_121/batch_normalization_3288/FusedBatchNormV3 (676.28k/676.28k flops)\n",
      "  model_121/batch_normalization_3287/FusedBatchNormV3 (676.28k/676.28k flops)\n",
      "  model_121/conv2d_1699/BiasAdd (676.00k/676.00k flops)\n",
      "  model_121/depthwise_conv2d_1577/BiasAdd (665.18k/665.18k flops)\n",
      "  model_121/conv2d_1698/BiasAdd (665.18k/665.18k flops)\n",
      "  model_121/batch_normalization_3281/FusedBatchNormV3 (662.70k/662.70k flops)\n",
      "  model_121/batch_normalization_3282/FusedBatchNormV3 (662.70k/662.70k flops)\n",
      "  model_121/batch_normalization_3283/FusedBatchNormV3 (632.83k/632.83k flops)\n",
      "  model_121/batch_normalization_3284/FusedBatchNormV3 (632.83k/632.83k flops)\n",
      "  model_121/batch_normalization_3286/FusedBatchNormV3 (630.11k/630.11k flops)\n",
      "  model_121/batch_normalization_3285/FusedBatchNormV3 (630.11k/630.11k flops)\n",
      "  model_121/batch_normalization_3280/FusedBatchNormV3 (602.95k/602.95k flops)\n",
      "  model_121/batch_normalization_3279/FusedBatchNormV3 (602.95k/602.95k flops)\n",
      "  model_121/depthwise_conv2d_1574/BiasAdd (475.90k/475.90k flops)\n",
      "  model_121/batch_normalization_3274/FusedBatchNormV3 (454.78k/454.78k flops)\n",
      "  model_121/batch_normalization_3278/FusedBatchNormV3 (339.50k/339.50k flops)\n",
      "  model_121/conv2d_1705/BiasAdd (338.00k/338.00k flops)\n",
      "  model_121/depthwise_conv2d_1583/BiasAdd (336.65k/336.65k flops)\n",
      "  model_121/conv2d_1704/BiasAdd (336.65k/336.65k flops)\n",
      "  model_121/batch_normalization_3291/FusedBatchNormV3 (335.06k/335.06k flops)\n",
      "  model_121/depthwise_conv2d_1580/BiasAdd (329.89k/329.89k flops)\n",
      "  model_121/conv2d_1701/BiasAdd (329.89k/329.89k flops)\n",
      "  model_121/depthwise_conv2d_1581/BiasAdd (315.02k/315.02k flops)\n",
      "  model_121/conv2d_1702/BiasAdd (315.02k/315.02k flops)\n",
      "  model_121/depthwise_conv2d_1582/BiasAdd (313.66k/313.66k flops)\n",
      "  model_121/conv2d_1703/BiasAdd (313.66k/313.66k flops)\n",
      "  model_121/depthwise_conv2d_1579/BiasAdd (300.14k/300.14k flops)\n",
      "  model_121/conv2d_1700/BiasAdd (300.14k/300.14k flops)\n",
      "  model_121/depthwise_conv2d_1576/BiasAdd (227.14k/227.14k flops)\n",
      "  model_121/batch_normalization_3290/FusedBatchNormV3 (172.00k/172.00k flops)\n",
      "  model_121/depthwise_conv2d_1578/BiasAdd (169.00k/169.00k flops)\n",
      "  model_121/conv2d_1706/BiasAdd (164.61k/164.61k flops)\n",
      "  model_121/batch_normalization_3293/FusedBatchNormV3 (104.42k/104.42k flops)\n",
      "  model_121/batch_normalization_3292/FusedBatchNormV3 (101.30k/101.30k flops)\n",
      "  model_121/depthwise_conv2d_1584/BiasAdd (84.50k/84.50k flops)\n",
      "  model_121/global_average_pooling2d_121/Mean (49.20k/49.20k flops)\n",
      "  model_121/conv2d_1707/BiasAdd (49.20k/49.20k flops)\n",
      "  model_121/depthwise_conv2d_1585/BiasAdd (47.73k/47.73k flops)\n",
      "  model_121/dense_121/MatMul (20.08k/20.08k flops)\n",
      "  model_121/dense_121/Softmax (50/50 flops)\n",
      "  model_121/dense_121/BiasAdd (10/10 flops)\n",
      "\n",
      "======================End of Report==========================\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "166.61798\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-30 13:41:36.413432: I tensorflow/core/grappler/devices.cc:66] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0\n",
      "2022-04-30 13:41:36.413545: I tensorflow/core/grappler/clusters/single_machine.cc:357] Starting new session\n",
      "2022-04-30 13:41:36.418137: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:1137] Optimization results for grappler item: graph_to_optimize\n",
      "  function_optimizer: function_optimizer did nothing. time = 0.005ms.\n",
      "  function_optimizer: function_optimizer did nothing. time = 0.001ms.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=========================Options=============================\n",
      "-max_depth                  10000\n",
      "-min_bytes                  0\n",
      "-min_peak_bytes             0\n",
      "-min_residual_bytes         0\n",
      "-min_output_bytes           0\n",
      "-min_micros                 0\n",
      "-min_accelerator_micros     0\n",
      "-min_cpu_micros             0\n",
      "-min_params                 0\n",
      "-min_float_ops              1\n",
      "-min_occurrence             0\n",
      "-step                       -1\n",
      "-order_by                   float_ops\n",
      "-account_type_regexes       .*\n",
      "-start_name_regexes         .*\n",
      "-trim_name_regexes          \n",
      "-show_name_regexes          .*\n",
      "-hide_name_regexes          \n",
      "-account_displayed_op_only  true\n",
      "-select                     float_ops\n",
      "-output                     stdout:\n",
      "\n",
      "==================Model Analysis Report======================\n",
      "\n",
      "Doc:\n",
      "scope: The nodes in the model graph are organized by their names, which is hierarchical like filesystem.\n",
      "flops: Number of float operations. Note: Please read the implementation for the math behind it.\n",
      "\n",
      "Profile:\n",
      "node name | # float_ops\n",
      "_TFProfRoot (--/2.25b flops)\n",
      "  model_122/conv2d_1711/Conv2D (343.43m/343.43m flops)\n",
      "  model_122/conv2d_1718/Conv2D (252.32m/252.32m flops)\n",
      "  model_122/conv2d_1719/Conv2D (247.06m/247.06m flops)\n",
      "  model_122/conv2d_1717/Conv2D (190.02m/190.02m flops)\n",
      "  model_122/conv2d_1713/Conv2D (186.90m/186.90m flops)\n",
      "  model_122/conv2d_1716/Conv2D (149.44m/149.44m flops)\n",
      "  model_122/conv2d_1712/Conv2D (122.65m/122.65m flops)\n",
      "  model_122/conv2d_1715/Conv2D (119.22m/119.22m flops)\n",
      "  model_122/conv2d_1709/Conv2D (105.22m/105.22m flops)\n",
      "  model_122/conv2d_1710/Conv2D (103.57m/103.57m flops)\n",
      "  model_122/conv2d_1720/Conv2D (101.92m/101.92m flops)\n",
      "  model_122/conv2d_1714/Conv2D (75.80m/75.80m flops)\n",
      "  model_122/conv2d_1721/Conv2D (67.91m/67.91m flops)\n",
      "  model_122/conv2d_1708/Conv2D (44.30m/44.30m flops)\n",
      "  model_122/depthwise_conv2d_1586/depthwise (24.92m/24.92m flops)\n",
      "  model_122/depthwise_conv2d_1588/depthwise (24.53m/24.53m flops)\n",
      "  model_122/depthwise_conv2d_1590/depthwise (8.76m/8.76m flops)\n",
      "  model_122/depthwise_conv2d_1587/depthwise (7.40m/7.40m flops)\n",
      "  model_122/depthwise_conv2d_1589/depthwise (6.13m/6.13m flops)\n",
      "  model_122/depthwise_conv2d_1596/depthwise (5.91m/5.91m flops)\n",
      "  model_122/depthwise_conv2d_1595/depthwise (4.67m/4.67m flops)\n",
      "  model_122/depthwise_conv2d_1594/depthwise (4.45m/4.45m flops)\n",
      "  model_122/depthwise_conv2d_1593/depthwise (3.67m/3.67m flops)\n",
      "  model_122/depthwise_conv2d_1592/depthwise (3.55m/3.55m flops)\n",
      "  model_122/batch_normalization_3296/FusedBatchNormV3 (3.29m/3.29m flops)\n",
      "  model_122/batch_normalization_3295/FusedBatchNormV3 (2.77m/2.77m flops)\n",
      "  model_122/batch_normalization_3294/FusedBatchNormV3 (2.77m/2.77m flops)\n",
      "  model_122/batch_normalization_3298/FusedBatchNormV3 (2.73m/2.73m flops)\n",
      "  model_122/batch_normalization_3299/FusedBatchNormV3 (2.73m/2.73m flops)\n",
      "  model_122/batch_normalization_3300/FusedBatchNormV3 (2.73m/2.73m flops)\n",
      "  model_122/depthwise_conv2d_1591/depthwise (2.34m/2.34m flops)\n",
      "  model_122/conv2d_1709/BiasAdd (1.64m/1.64m flops)\n",
      "  model_122/conv2d_1708/BiasAdd (1.38m/1.38m flops)\n",
      "  model_122/depthwise_conv2d_1586/BiasAdd (1.38m/1.38m flops)\n",
      "  model_122/conv2d_1711/BiasAdd (1.36m/1.36m flops)\n",
      "  model_122/conv2d_1710/BiasAdd (1.36m/1.36m flops)\n",
      "  model_122/depthwise_conv2d_1588/BiasAdd (1.36m/1.36m flops)\n",
      "  model_122/depthwise_conv2d_1597/depthwise (1.14m/1.14m flops)\n",
      "  model_122/batch_normalization_3304/FusedBatchNormV3 (1.04m/1.04m flops)\n",
      "  model_122/batch_normalization_3303/FusedBatchNormV3 (974.52k/974.52k flops)\n",
      "  model_122/batch_normalization_3302/FusedBatchNormV3 (974.52k/974.52k flops)\n",
      "  model_122/batch_normalization_3297/FusedBatchNormV3 (822.24k/822.24k flops)\n",
      "  model_122/depthwise_conv2d_1598/depthwise (707.36k/707.36k flops)\n",
      "  model_122/batch_normalization_3301/FusedBatchNormV3 (682.16k/682.16k flops)\n",
      "  model_122/batch_normalization_3314/FusedBatchNormV3 (659.99k/659.99k flops)\n",
      "  model_122/batch_normalization_3315/FusedBatchNormV3 (659.99k/659.99k flops)\n",
      "  model_122/batch_normalization_3312/FusedBatchNormV3 (521.47k/521.47k flops)\n",
      "  model_122/batch_normalization_3313/FusedBatchNormV3 (521.47k/521.47k flops)\n",
      "  model_122/conv2d_1713/BiasAdd (519.17k/519.17k flops)\n",
      "  model_122/batch_normalization_3316/FusedBatchNormV3 (510.61k/510.61k flops)\n",
      "  model_122/batch_normalization_3311/FusedBatchNormV3 (497.03k/497.03k flops)\n",
      "  model_122/batch_normalization_3310/FusedBatchNormV3 (497.03k/497.03k flops)\n",
      "  model_122/depthwise_conv2d_1590/BiasAdd (486.72k/486.72k flops)\n",
      "  model_122/conv2d_1712/BiasAdd (486.72k/486.72k flops)\n",
      "  model_122/depthwise_conv2d_1587/BiasAdd (411.01k/411.01k flops)\n",
      "  model_122/batch_normalization_3308/FusedBatchNormV3 (410.12k/410.12k flops)\n",
      "  model_122/batch_normalization_3309/FusedBatchNormV3 (410.12k/410.12k flops)\n",
      "  model_122/batch_normalization_3307/FusedBatchNormV3 (396.54k/396.54k flops)\n",
      "  model_122/batch_normalization_3306/FusedBatchNormV3 (396.54k/396.54k flops)\n",
      "  model_122/depthwise_conv2d_1589/BiasAdd (340.70k/340.70k flops)\n",
      "  model_122/depthwise_conv2d_1596/BiasAdd (328.54k/328.54k flops)\n",
      "  model_122/conv2d_1718/BiasAdd (328.54k/328.54k flops)\n",
      "  model_122/batch_normalization_3318/FusedBatchNormV3 (275.89k/275.89k flops)\n",
      "  model_122/batch_normalization_3305/FusedBatchNormV3 (260.74k/260.74k flops)\n",
      "  model_122/depthwise_conv2d_1595/BiasAdd (259.58k/259.58k flops)\n",
      "  model_122/conv2d_1717/BiasAdd (259.58k/259.58k flops)\n",
      "  model_122/conv2d_1719/BiasAdd (254.18k/254.18k flops)\n",
      "  model_122/conv2d_1716/BiasAdd (247.42k/247.42k flops)\n",
      "  model_122/depthwise_conv2d_1594/BiasAdd (247.42k/247.42k flops)\n",
      "  model_122/depthwise_conv2d_1593/BiasAdd (204.15k/204.15k flops)\n",
      "  model_122/conv2d_1715/BiasAdd (204.15k/204.15k flops)\n",
      "  model_122/depthwise_conv2d_1592/BiasAdd (197.39k/197.39k flops)\n",
      "  model_122/conv2d_1714/BiasAdd (197.39k/197.39k flops)\n",
      "  model_122/conv2d_1720/BiasAdd (135.54k/135.54k flops)\n",
      "  model_122/depthwise_conv2d_1591/BiasAdd (129.79k/129.79k flops)\n",
      "  model_122/batch_normalization_3317/FusedBatchNormV3 (129.34k/129.34k flops)\n",
      "  model_122/batch_normalization_3320/FusedBatchNormV3 (89.86k/89.86k flops)\n",
      "  model_122/batch_normalization_3319/FusedBatchNormV3 (83.41k/83.41k flops)\n",
      "  model_122/depthwise_conv2d_1597/BiasAdd (63.54k/63.54k flops)\n",
      "  model_122/global_average_pooling2d_122/Mean (42.34k/42.34k flops)\n",
      "  model_122/conv2d_1721/BiasAdd (42.34k/42.34k flops)\n",
      "  model_122/depthwise_conv2d_1598/BiasAdd (39.30k/39.30k flops)\n",
      "  model_122/dense_122/MatMul (17.28k/17.28k flops)\n",
      "  model_122/dense_122/Softmax (50/50 flops)\n",
      "  model_122/dense_122/BiasAdd (10/10 flops)\n",
      "\n",
      "======================End of Report==========================\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "170.388636\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-30 13:41:37.348845: I tensorflow/core/grappler/devices.cc:66] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0\n",
      "2022-04-30 13:41:37.348958: I tensorflow/core/grappler/clusters/single_machine.cc:357] Starting new session\n",
      "2022-04-30 13:41:37.353268: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:1137] Optimization results for grappler item: graph_to_optimize\n",
      "  function_optimizer: function_optimizer did nothing. time = 0.005ms.\n",
      "  function_optimizer: function_optimizer did nothing. time = 0.001ms.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=========================Options=============================\n",
      "-max_depth                  10000\n",
      "-min_bytes                  0\n",
      "-min_peak_bytes             0\n",
      "-min_residual_bytes         0\n",
      "-min_output_bytes           0\n",
      "-min_micros                 0\n",
      "-min_accelerator_micros     0\n",
      "-min_cpu_micros             0\n",
      "-min_params                 0\n",
      "-min_float_ops              1\n",
      "-min_occurrence             0\n",
      "-step                       -1\n",
      "-order_by                   float_ops\n",
      "-account_type_regexes       .*\n",
      "-start_name_regexes         .*\n",
      "-trim_name_regexes          \n",
      "-show_name_regexes          .*\n",
      "-hide_name_regexes          \n",
      "-account_displayed_op_only  true\n",
      "-select                     float_ops\n",
      "-output                     stdout:\n",
      "\n",
      "==================Model Analysis Report======================\n",
      "\n",
      "Doc:\n",
      "scope: The nodes in the model graph are organized by their names, which is hierarchical like filesystem.\n",
      "flops: Number of float operations. Note: Please read the implementation for the math behind it.\n",
      "\n",
      "Profile:\n",
      "node name | # float_ops\n",
      "_TFProfRoot (--/2.04b flops)\n",
      "  model_123/conv2d_1725/Conv2D (311.50m/311.50m flops)\n",
      "  model_123/conv2d_1727/Conv2D (182.40m/182.40m flops)\n",
      "  model_123/conv2d_1731/Conv2D (181.11m/181.11m flops)\n",
      "  model_123/conv2d_1732/Conv2D (179.28m/179.28m flops)\n",
      "  model_123/conv2d_1733/Conv2D (177.17m/177.17m flops)\n",
      "  model_123/conv2d_1730/Conv2D (156.61m/156.61m flops)\n",
      "  model_123/conv2d_1723/Conv2D (149.52m/149.52m flops)\n",
      "  model_123/conv2d_1724/Conv2D (140.18m/140.18m flops)\n",
      "  model_123/conv2d_1729/Conv2D (116.07m/116.07m flops)\n",
      "  model_123/conv2d_1728/Conv2D (97.91m/97.91m flops)\n",
      "  model_123/conv2d_1726/Conv2D (88.26m/88.26m flops)\n",
      "  model_123/conv2d_1734/Conv2D (49.74m/49.74m flops)\n",
      "  model_123/conv2d_1722/Conv2D (44.30m/44.30m flops)\n",
      "  model_123/depthwise_conv2d_1599/depthwise (24.92m/24.92m flops)\n",
      "  model_123/depthwise_conv2d_1601/depthwise (23.36m/23.36m flops)\n",
      "  model_123/conv2d_1735/Conv2D (23.09m/23.09m flops)\n",
      "  model_123/depthwise_conv2d_1600/depthwise (10.51m/10.51m flops)\n",
      "  model_123/depthwise_conv2d_1603/depthwise (6.62m/6.62m flops)\n",
      "  model_123/depthwise_conv2d_1602/depthwise (5.84m/5.84m flops)\n",
      "  model_123/depthwise_conv2d_1607/depthwise (4.79m/4.79m flops)\n",
      "  model_123/depthwise_conv2d_1609/depthwise (4.75m/4.75m flops)\n",
      "  model_123/batch_normalization_3323/FusedBatchNormV3 (4.67m/4.67m flops)\n",
      "  model_123/depthwise_conv2d_1608/depthwise (4.14m/4.14m flops)\n",
      "  model_123/depthwise_conv2d_1606/depthwise (3.58m/3.58m flops)\n",
      "  model_123/depthwise_conv2d_1605/depthwise (3.55m/3.55m flops)\n",
      "  model_123/depthwise_conv2d_1604/depthwise (3.02m/3.02m flops)\n",
      "  model_123/batch_normalization_3322/FusedBatchNormV3 (2.77m/2.77m flops)\n",
      "  model_123/batch_normalization_3321/FusedBatchNormV3 (2.77m/2.77m flops)\n",
      "  model_123/batch_normalization_3325/FusedBatchNormV3 (2.60m/2.60m flops)\n",
      "  model_123/batch_normalization_3326/FusedBatchNormV3 (2.60m/2.60m flops)\n",
      "  model_123/batch_normalization_3327/FusedBatchNormV3 (2.60m/2.60m flops)\n",
      "  model_123/conv2d_1723/BiasAdd (2.34m/2.34m flops)\n",
      "  model_123/conv2d_1722/BiasAdd (1.38m/1.38m flops)\n",
      "  model_123/depthwise_conv2d_1599/BiasAdd (1.38m/1.38m flops)\n",
      "  model_123/batch_normalization_3331/FusedBatchNormV3 (1.34m/1.34m flops)\n",
      "  model_123/conv2d_1725/BiasAdd (1.30m/1.30m flops)\n",
      "  model_123/depthwise_conv2d_1601/BiasAdd (1.30m/1.30m flops)\n",
      "  model_123/conv2d_1724/BiasAdd (1.30m/1.30m flops)\n",
      "  model_123/batch_normalization_3324/FusedBatchNormV3 (1.17m/1.17m flops)\n",
      "  model_123/depthwise_conv2d_1610/depthwise (1.02m/1.02m flops)\n",
      "  model_123/batch_normalization_3329/FusedBatchNormV3 (736.30k/736.30k flops)\n",
      "  model_123/batch_normalization_3330/FusedBatchNormV3 (736.30k/736.30k flops)\n",
      "  model_123/conv2d_1727/BiasAdd (670.59k/670.59k flops)\n",
      "  model_123/batch_normalization_3328/FusedBatchNormV3 (649.68k/649.68k flops)\n",
      "  model_123/depthwise_conv2d_1600/BiasAdd (584.06k/584.06k flops)\n",
      "  model_123/batch_normalization_3337/FusedBatchNormV3 (535.05k/535.05k flops)\n",
      "  model_123/batch_normalization_3338/FusedBatchNormV3 (535.05k/535.05k flops)\n",
      "  model_123/batch_normalization_3341/FusedBatchNormV3 (529.62k/529.62k flops)\n",
      "  model_123/batch_normalization_3342/FusedBatchNormV3 (529.62k/529.62k flops)\n",
      "  model_123/batch_normalization_3339/FusedBatchNormV3 (461.72k/461.72k flops)\n",
      "  model_123/batch_normalization_3340/FusedBatchNormV3 (461.72k/461.72k flops)\n",
      "  model_123/batch_normalization_3343/FusedBatchNormV3 (456.29k/456.29k flops)\n",
      "  model_123/batch_normalization_3336/FusedBatchNormV3 (399.25k/399.25k flops)\n",
      "  model_123/batch_normalization_3335/FusedBatchNormV3 (399.25k/399.25k flops)\n",
      "  model_123/batch_normalization_3334/FusedBatchNormV3 (396.54k/396.54k flops)\n",
      "  model_123/batch_normalization_3333/FusedBatchNormV3 (396.54k/396.54k flops)\n",
      "  model_123/depthwise_conv2d_1611/depthwise (386.32k/386.32k flops)\n",
      "  model_123/depthwise_conv2d_1603/BiasAdd (367.74k/367.74k flops)\n",
      "  model_123/conv2d_1726/BiasAdd (367.74k/367.74k flops)\n",
      "  model_123/batch_normalization_3332/FusedBatchNormV3 (336.78k/336.78k flops)\n",
      "  model_123/depthwise_conv2d_1602/BiasAdd (324.48k/324.48k flops)\n",
      "  model_123/depthwise_conv2d_1607/BiasAdd (266.34k/266.34k flops)\n",
      "  model_123/conv2d_1730/BiasAdd (266.34k/266.34k flops)\n",
      "  model_123/depthwise_conv2d_1609/BiasAdd (263.64k/263.64k flops)\n",
      "  model_123/conv2d_1732/BiasAdd (263.64k/263.64k flops)\n",
      "  model_123/depthwise_conv2d_1608/BiasAdd (229.84k/229.84k flops)\n",
      "  model_123/conv2d_1731/BiasAdd (229.84k/229.84k flops)\n",
      "  model_123/conv2d_1733/BiasAdd (227.14k/227.14k flops)\n",
      "  model_123/conv2d_1729/BiasAdd (198.74k/198.74k flops)\n",
      "  model_123/depthwise_conv2d_1606/BiasAdd (198.74k/198.74k flops)\n",
      "  model_123/depthwise_conv2d_1605/BiasAdd (197.39k/197.39k flops)\n",
      "  model_123/conv2d_1728/BiasAdd (197.39k/197.39k flops)\n",
      "  model_123/depthwise_conv2d_1604/BiasAdd (167.65k/167.65k flops)\n",
      "  model_123/batch_normalization_3345/FusedBatchNormV3 (150.67k/150.67k flops)\n",
      "  model_123/batch_normalization_3344/FusedBatchNormV3 (115.58k/115.58k flops)\n",
      "  model_123/conv2d_1734/BiasAdd (74.02k/74.02k flops)\n",
      "  model_123/depthwise_conv2d_1610/BiasAdd (56.78k/56.78k flops)\n",
      "  model_123/batch_normalization_3347/FusedBatchNormV3 (55.95k/55.95k flops)\n",
      "  model_123/batch_normalization_3346/FusedBatchNormV3 (45.55k/45.55k flops)\n",
      "  model_123/global_average_pooling2d_123/Mean (26.36k/26.36k flops)\n",
      "  model_123/conv2d_1735/BiasAdd (26.36k/26.36k flops)\n",
      "  model_123/depthwise_conv2d_1611/BiasAdd (21.46k/21.46k flops)\n",
      "  model_123/dense_123/MatMul (10.76k/10.76k flops)\n",
      "  model_123/dense_123/Softmax (50/50 flops)\n",
      "  model_123/dense_123/BiasAdd (10/10 flops)\n",
      "\n",
      "======================End of Report==========================\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "173.843108\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-30 13:41:38.377379: I tensorflow/core/grappler/devices.cc:66] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0\n",
      "2022-04-30 13:41:38.377494: I tensorflow/core/grappler/clusters/single_machine.cc:357] Starting new session\n",
      "2022-04-30 13:41:38.382506: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:1137] Optimization results for grappler item: graph_to_optimize\n",
      "  function_optimizer: function_optimizer did nothing. time = 0.006ms.\n",
      "  function_optimizer: function_optimizer did nothing. time = 0.001ms.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=========================Options=============================\n",
      "-max_depth                  10000\n",
      "-min_bytes                  0\n",
      "-min_peak_bytes             0\n",
      "-min_residual_bytes         0\n",
      "-min_output_bytes           0\n",
      "-min_micros                 0\n",
      "-min_accelerator_micros     0\n",
      "-min_cpu_micros             0\n",
      "-min_params                 0\n",
      "-min_float_ops              1\n",
      "-min_occurrence             0\n",
      "-step                       -1\n",
      "-order_by                   float_ops\n",
      "-account_type_regexes       .*\n",
      "-start_name_regexes         .*\n",
      "-trim_name_regexes          \n",
      "-show_name_regexes          .*\n",
      "-hide_name_regexes          \n",
      "-account_displayed_op_only  true\n",
      "-select                     float_ops\n",
      "-output                     stdout:\n",
      "\n",
      "==================Model Analysis Report======================\n",
      "\n",
      "Doc:\n",
      "scope: The nodes in the model graph are organized by their names, which is hierarchical like filesystem.\n",
      "flops: Number of float operations. Note: Please read the implementation for the math behind it.\n",
      "\n",
      "Profile:\n",
      "node name | # float_ops\n",
      "_TFProfRoot (--/2.67b flops)\n",
      "  model_124/conv2d_1741/Conv2D (303.11m/303.11m flops)\n",
      "  model_124/conv2d_1745/Conv2D (291.85m/291.85m flops)\n",
      "  model_124/conv2d_1747/Conv2D (287.33m/287.33m flops)\n",
      "  model_124/conv2d_1744/Conv2D (276.17m/276.17m flops)\n",
      "  model_124/conv2d_1746/Conv2D (274.83m/274.83m flops)\n",
      "  model_124/conv2d_1743/Conv2D (257.59m/257.59m flops)\n",
      "  model_124/conv2d_1737/Conv2D (171.67m/171.67m flops)\n",
      "  model_124/conv2d_1742/Conv2D (139.48m/139.48m flops)\n",
      "  model_124/conv2d_1739/Conv2D (135.68m/135.68m flops)\n",
      "  model_124/conv2d_1740/Conv2D (119.78m/119.78m flops)\n",
      "  model_124/conv2d_1748/Conv2D (98.51m/98.51m flops)\n",
      "  model_124/conv2d_1738/Conv2D (85.84m/85.84m flops)\n",
      "  model_124/conv2d_1736/Conv2D (44.30m/44.30m flops)\n",
      "  model_124/conv2d_1749/Conv2D (40.30m/40.30m flops)\n",
      "  model_124/depthwise_conv2d_1612/depthwise (24.92m/24.92m flops)\n",
      "  model_124/depthwise_conv2d_1614/depthwise (12.46m/12.46m flops)\n",
      "  model_124/depthwise_conv2d_1613/depthwise (12.07m/12.07m flops)\n",
      "  model_124/depthwise_conv2d_1616/depthwise (11.00m/11.00m flops)\n",
      "  model_124/depthwise_conv2d_1621/depthwise (5.89m/5.89m flops)\n",
      "  model_124/depthwise_conv2d_1619/depthwise (5.57m/5.57m flops)\n",
      "  model_124/depthwise_conv2d_1620/depthwise (5.43m/5.43m flops)\n",
      "  model_124/batch_normalization_3350/FusedBatchNormV3 (5.37m/5.37m flops)\n",
      "  model_124/depthwise_conv2d_1622/depthwise (5.11m/5.11m flops)\n",
      "  model_124/depthwise_conv2d_1618/depthwise (5.06m/5.06m flops)\n",
      "  model_124/depthwise_conv2d_1615/depthwise (4.77m/4.77m flops)\n",
      "  model_124/depthwise_conv2d_1617/depthwise (3.02m/3.02m flops)\n",
      "  model_124/batch_normalization_3349/FusedBatchNormV3 (2.77m/2.77m flops)\n",
      "  model_124/batch_normalization_3348/FusedBatchNormV3 (2.77m/2.77m flops)\n",
      "  model_124/conv2d_1737/BiasAdd (2.68m/2.68m flops)\n",
      "  model_124/batch_normalization_3354/FusedBatchNormV3 (2.12m/2.12m flops)\n",
      "  model_124/depthwise_conv2d_1623/depthwise (1.54m/1.54m flops)\n",
      "  model_124/batch_normalization_3352/FusedBatchNormV3 (1.38m/1.38m flops)\n",
      "  model_124/batch_normalization_3353/FusedBatchNormV3 (1.38m/1.38m flops)\n",
      "  model_124/conv2d_1736/BiasAdd (1.38m/1.38m flops)\n",
      "  model_124/depthwise_conv2d_1612/BiasAdd (1.38m/1.38m flops)\n",
      "  model_124/batch_normalization_3358/FusedBatchNormV3 (1.34m/1.34m flops)\n",
      "  model_124/batch_normalization_3351/FusedBatchNormV3 (1.34m/1.34m flops)\n",
      "  model_124/batch_normalization_3357/FusedBatchNormV3 (1.22m/1.22m flops)\n",
      "  model_124/batch_normalization_3356/FusedBatchNormV3 (1.22m/1.22m flops)\n",
      "  model_124/conv2d_1739/BiasAdd (1.06m/1.06m flops)\n",
      "  model_124/depthwise_conv2d_1614/BiasAdd (692.22k/692.22k flops)\n",
      "  model_124/conv2d_1738/BiasAdd (692.22k/692.22k flops)\n",
      "  model_124/batch_normalization_3370/FusedBatchNormV3 (687.15k/687.15k flops)\n",
      "  model_124/depthwise_conv2d_1613/BiasAdd (670.59k/670.59k flops)\n",
      "  model_124/conv2d_1741/BiasAdd (670.59k/670.59k flops)\n",
      "  model_124/batch_normalization_3366/FusedBatchNormV3 (657.27k/657.27k flops)\n",
      "  model_124/batch_normalization_3367/FusedBatchNormV3 (657.27k/657.27k flops)\n",
      "  model_124/batch_normalization_3362/FusedBatchNormV3 (621.96k/621.96k flops)\n",
      "  model_124/batch_normalization_3363/FusedBatchNormV3 (621.96k/621.96k flops)\n",
      "  model_124/conv2d_1740/BiasAdd (611.10k/611.10k flops)\n",
      "  model_124/depthwise_conv2d_1616/BiasAdd (611.10k/611.10k flops)\n",
      "  model_124/batch_normalization_3364/FusedBatchNormV3 (605.67k/605.67k flops)\n",
      "  model_124/batch_normalization_3365/FusedBatchNormV3 (605.67k/605.67k flops)\n",
      "  model_124/batch_normalization_3368/FusedBatchNormV3 (570.36k/570.36k flops)\n",
      "  model_124/batch_normalization_3369/FusedBatchNormV3 (570.36k/570.36k flops)\n",
      "  model_124/batch_normalization_3361/FusedBatchNormV3 (564.93k/564.93k flops)\n",
      "  model_124/batch_normalization_3360/FusedBatchNormV3 (564.93k/564.93k flops)\n",
      "  model_124/batch_normalization_3355/FusedBatchNormV3 (530.57k/530.57k flops)\n",
      "  model_124/depthwise_conv2d_1624/depthwise (508.03k/508.03k flops)\n",
      "  model_124/conv2d_1747/BiasAdd (342.06k/342.06k flops)\n",
      "  model_124/batch_normalization_3359/FusedBatchNormV3 (336.78k/336.78k flops)\n",
      "  model_124/depthwise_conv2d_1621/BiasAdd (327.18k/327.18k flops)\n",
      "  model_124/conv2d_1745/BiasAdd (327.18k/327.18k flops)\n",
      "  model_124/depthwise_conv2d_1619/BiasAdd (309.61k/309.61k flops)\n",
      "  model_124/conv2d_1743/BiasAdd (309.61k/309.61k flops)\n",
      "  model_124/conv2d_1744/BiasAdd (301.50k/301.50k flops)\n",
      "  model_124/depthwise_conv2d_1620/BiasAdd (301.50k/301.50k flops)\n",
      "  model_124/depthwise_conv2d_1622/BiasAdd (283.92k/283.92k flops)\n",
      "  model_124/conv2d_1746/BiasAdd (283.92k/283.92k flops)\n",
      "  model_124/depthwise_conv2d_1618/BiasAdd (281.22k/281.22k flops)\n",
      "  model_124/conv2d_1742/BiasAdd (281.22k/281.22k flops)\n",
      "  model_124/depthwise_conv2d_1615/BiasAdd (264.99k/264.99k flops)\n",
      "  model_124/batch_normalization_3372/FusedBatchNormV3 (198.14k/198.14k flops)\n",
      "  model_124/batch_normalization_3371/FusedBatchNormV3 (174.06k/174.06k flops)\n",
      "  model_124/depthwise_conv2d_1617/BiasAdd (167.65k/167.65k flops)\n",
      "  model_124/conv2d_1748/BiasAdd (97.34k/97.34k flops)\n",
      "  model_124/depthwise_conv2d_1623/BiasAdd (85.51k/85.51k flops)\n",
      "  model_124/batch_normalization_3374/FusedBatchNormV3 (74.26k/74.26k flops)\n",
      "  model_124/batch_normalization_3373/FusedBatchNormV3 (59.90k/59.90k flops)\n",
      "  model_124/global_average_pooling2d_124/Mean (34.99k/34.99k flops)\n",
      "  model_124/conv2d_1749/BiasAdd (34.99k/34.99k flops)\n",
      "  model_124/depthwise_conv2d_1624/BiasAdd (28.22k/28.22k flops)\n",
      "  model_124/dense_124/MatMul (14.28k/14.28k flops)\n",
      "  model_124/dense_124/Softmax (50/50 flops)\n",
      "  model_124/dense_124/BiasAdd (10/10 flops)\n",
      "\n",
      "======================End of Report==========================\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "140.437284\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-30 13:41:39.315943: I tensorflow/core/grappler/devices.cc:66] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0\n",
      "2022-04-30 13:41:39.316058: I tensorflow/core/grappler/clusters/single_machine.cc:357] Starting new session\n",
      "2022-04-30 13:41:39.320393: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:1137] Optimization results for grappler item: graph_to_optimize\n",
      "  function_optimizer: function_optimizer did nothing. time = 0.005ms.\n",
      "  function_optimizer: function_optimizer did nothing. time = 0.001ms.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=========================Options=============================\n",
      "-max_depth                  10000\n",
      "-min_bytes                  0\n",
      "-min_peak_bytes             0\n",
      "-min_residual_bytes         0\n",
      "-min_output_bytes           0\n",
      "-min_micros                 0\n",
      "-min_accelerator_micros     0\n",
      "-min_cpu_micros             0\n",
      "-min_params                 0\n",
      "-min_float_ops              1\n",
      "-min_occurrence             0\n",
      "-step                       -1\n",
      "-order_by                   float_ops\n",
      "-account_type_regexes       .*\n",
      "-start_name_regexes         .*\n",
      "-trim_name_regexes          \n",
      "-show_name_regexes          .*\n",
      "-hide_name_regexes          \n",
      "-account_displayed_op_only  true\n",
      "-select                     float_ops\n",
      "-output                     stdout:\n",
      "\n",
      "==================Model Analysis Report======================\n",
      "\n",
      "Doc:\n",
      "scope: The nodes in the model graph are organized by their names, which is hierarchical like filesystem.\n",
      "flops: Number of float operations. Note: Please read the implementation for the math behind it.\n",
      "\n",
      "Profile:\n",
      "node name | # float_ops\n",
      "_TFProfRoot (--/1.27b flops)\n",
      "  model_125/conv2d_1753/Conv2D (214.16m/214.16m flops)\n",
      "  model_125/conv2d_1751/Conv2D (121.83m/121.83m flops)\n",
      "  model_125/conv2d_1755/Conv2D (96.76m/96.76m flops)\n",
      "  model_125/conv2d_1752/Conv2D (85.66m/85.66m flops)\n",
      "  model_125/conv2d_1761/Conv2D (85.42m/85.42m flops)\n",
      "  model_125/conv2d_1762/Conv2D (84.10m/84.10m flops)\n",
      "  model_125/conv2d_1759/Conv2D (80.71m/80.71m flops)\n",
      "  model_125/conv2d_1760/Conv2D (79.72m/79.72m flops)\n",
      "  model_125/conv2d_1754/Conv2D (74.95m/74.95m flops)\n",
      "  model_125/conv2d_1763/Conv2D (59.15m/59.15m flops)\n",
      "  model_125/conv2d_1758/Conv2D (47.89m/47.89m flops)\n",
      "  model_125/conv2d_1757/Conv2D (47.31m/47.31m flops)\n",
      "  model_125/conv2d_1750/Conv2D (44.30m/44.30m flops)\n",
      "  model_125/conv2d_1756/Conv2D (31.10m/31.10m flops)\n",
      "  model_125/depthwise_conv2d_1625/depthwise (24.92m/24.92m flops)\n",
      "  model_125/depthwise_conv2d_1627/depthwise (17.52m/17.52m flops)\n",
      "  model_125/depthwise_conv2d_1626/depthwise (8.57m/8.57m flops)\n",
      "  model_125/depthwise_conv2d_1629/depthwise (6.13m/6.13m flops)\n",
      "  model_125/depthwise_conv2d_1628/depthwise (5.35m/5.35m flops)\n",
      "  model_125/depthwise_conv2d_1634/depthwise (4.43m/4.43m flops)\n",
      "  model_125/batch_normalization_3377/FusedBatchNormV3 (3.81m/3.81m flops)\n",
      "  model_125/batch_normalization_3376/FusedBatchNormV3 (2.77m/2.77m flops)\n",
      "  model_125/batch_normalization_3375/FusedBatchNormV3 (2.77m/2.77m flops)\n",
      "  model_125/depthwise_conv2d_1632/depthwise (2.63m/2.63m flops)\n",
      "  model_125/batch_normalization_3381/FusedBatchNormV3 (2.38m/2.38m flops)\n",
      "  model_125/depthwise_conv2d_1633/depthwise (2.00m/2.00m flops)\n",
      "  model_125/depthwise_conv2d_1631/depthwise (1.97m/1.97m flops)\n",
      "  model_125/depthwise_conv2d_1635/depthwise (1.97m/1.97m flops)\n",
      "  model_125/batch_normalization_3380/FusedBatchNormV3 (1.95m/1.95m flops)\n",
      "  model_125/batch_normalization_3379/FusedBatchNormV3 (1.95m/1.95m flops)\n",
      "  model_125/conv2d_1751/BiasAdd (1.90m/1.90m flops)\n",
      "  model_125/depthwise_conv2d_1630/depthwise (1.73m/1.73m flops)\n",
      "  model_125/conv2d_1750/BiasAdd (1.38m/1.38m flops)\n",
      "  model_125/depthwise_conv2d_1625/BiasAdd (1.38m/1.38m flops)\n",
      "  model_125/conv2d_1753/BiasAdd (1.19m/1.19m flops)\n",
      "  model_125/depthwise_conv2d_1636/depthwise (1.19m/1.19m flops)\n",
      "  model_125/depthwise_conv2d_1627/BiasAdd (973.44k/973.44k flops)\n",
      "  model_125/conv2d_1752/BiasAdd (973.44k/973.44k flops)\n",
      "  model_125/batch_normalization_3378/FusedBatchNormV3 (952.07k/952.07k flops)\n",
      "  model_125/batch_normalization_3385/FusedBatchNormV3 (768.79k/768.79k flops)\n",
      "  model_125/batch_normalization_3383/FusedBatchNormV3 (682.16k/682.16k flops)\n",
      "  model_125/batch_normalization_3384/FusedBatchNormV3 (682.16k/682.16k flops)\n",
      "  model_125/batch_normalization_3382/FusedBatchNormV3 (595.54k/595.54k flops)\n",
      "  model_125/depthwise_conv2d_1637/depthwise (562.72k/562.72k flops)\n",
      "  model_125/batch_normalization_3397/FusedBatchNormV3 (529.62k/529.62k flops)\n",
      "  model_125/batch_normalization_3394/FusedBatchNormV3 (494.31k/494.31k flops)\n",
      "  model_125/batch_normalization_3393/FusedBatchNormV3 (494.31k/494.31k flops)\n",
      "  model_125/depthwise_conv2d_1626/BiasAdd (475.90k/475.90k flops)\n",
      "  model_125/conv2d_1755/BiasAdd (383.97k/383.97k flops)\n",
      "  model_125/depthwise_conv2d_1629/BiasAdd (340.70k/340.70k flops)\n",
      "  model_125/conv2d_1754/BiasAdd (340.70k/340.70k flops)\n",
      "  model_125/depthwise_conv2d_1628/BiasAdd (297.44k/297.44k flops)\n",
      "  model_125/batch_normalization_3390/FusedBatchNormV3 (293.33k/293.33k flops)\n",
      "  model_125/batch_normalization_3389/FusedBatchNormV3 (293.33k/293.33k flops)\n",
      "  model_125/conv2d_1761/BiasAdd (263.64k/263.64k flops)\n",
      "  model_125/conv2d_1759/BiasAdd (246.06k/246.06k flops)\n",
      "  model_125/depthwise_conv2d_1634/BiasAdd (246.06k/246.06k flops)\n",
      "  model_125/batch_normalization_3392/FusedBatchNormV3 (222.71k/222.71k flops)\n",
      "  model_125/batch_normalization_3391/FusedBatchNormV3 (222.71k/222.71k flops)\n",
      "  model_125/batch_normalization_3387/FusedBatchNormV3 (220.00k/220.00k flops)\n",
      "  model_125/batch_normalization_3388/FusedBatchNormV3 (220.00k/220.00k flops)\n",
      "  model_125/batch_normalization_3395/FusedBatchNormV3 (220.00k/220.00k flops)\n",
      "  model_125/batch_normalization_3396/FusedBatchNormV3 (220.00k/220.00k flops)\n",
      "  model_125/batch_normalization_3399/FusedBatchNormV3 (219.47k/219.47k flops)\n",
      "  model_125/batch_normalization_3386/FusedBatchNormV3 (192.84k/192.84k flops)\n",
      "  model_125/depthwise_conv2d_1632/BiasAdd (146.02k/146.02k flops)\n",
      "  model_125/conv2d_1757/BiasAdd (146.02k/146.02k flops)\n",
      "  model_125/batch_normalization_3398/FusedBatchNormV3 (134.16k/134.16k flops)\n",
      "  model_125/conv2d_1758/BiasAdd (110.86k/110.86k flops)\n",
      "  model_125/depthwise_conv2d_1633/BiasAdd (110.86k/110.86k flops)\n",
      "  model_125/depthwise_conv2d_1631/BiasAdd (109.51k/109.51k flops)\n",
      "  model_125/conv2d_1760/BiasAdd (109.51k/109.51k flops)\n",
      "  model_125/conv2d_1756/BiasAdd (109.51k/109.51k flops)\n",
      "  model_125/depthwise_conv2d_1635/BiasAdd (109.51k/109.51k flops)\n",
      "  model_125/conv2d_1762/BiasAdd (107.82k/107.82k flops)\n",
      "  model_125/batch_normalization_3401/FusedBatchNormV3 (98.38k/98.38k flops)\n",
      "  model_125/depthwise_conv2d_1630/BiasAdd (95.99k/95.99k flops)\n",
      "  model_125/batch_normalization_3400/FusedBatchNormV3 (66.35k/66.35k flops)\n",
      "  model_125/depthwise_conv2d_1636/BiasAdd (65.91k/65.91k flops)\n",
      "  model_125/global_average_pooling2d_125/Mean (46.35k/46.35k flops)\n",
      "  model_125/conv2d_1763/BiasAdd (46.35k/46.35k flops)\n",
      "  model_125/depthwise_conv2d_1637/BiasAdd (31.26k/31.26k flops)\n",
      "  model_125/dense_125/MatMul (18.92k/18.92k flops)\n",
      "  model_125/dense_125/Softmax (50/50 flops)\n",
      "  model_125/dense_125/BiasAdd (10/10 flops)\n",
      "\n",
      "======================End of Report==========================\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "141.560372\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-30 13:41:40.338116: I tensorflow/core/grappler/devices.cc:66] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0\n",
      "2022-04-30 13:41:40.338243: I tensorflow/core/grappler/clusters/single_machine.cc:357] Starting new session\n",
      "2022-04-30 13:41:40.343327: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:1137] Optimization results for grappler item: graph_to_optimize\n",
      "  function_optimizer: function_optimizer did nothing. time = 0.006ms.\n",
      "  function_optimizer: function_optimizer did nothing. time = 0.001ms.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=========================Options=============================\n",
      "-max_depth                  10000\n",
      "-min_bytes                  0\n",
      "-min_peak_bytes             0\n",
      "-min_residual_bytes         0\n",
      "-min_output_bytes           0\n",
      "-min_micros                 0\n",
      "-min_accelerator_micros     0\n",
      "-min_cpu_micros             0\n",
      "-min_params                 0\n",
      "-min_float_ops              1\n",
      "-min_occurrence             0\n",
      "-step                       -1\n",
      "-order_by                   float_ops\n",
      "-account_type_regexes       .*\n",
      "-start_name_regexes         .*\n",
      "-trim_name_regexes          \n",
      "-show_name_regexes          .*\n",
      "-hide_name_regexes          \n",
      "-account_displayed_op_only  true\n",
      "-select                     float_ops\n",
      "-output                     stdout:\n",
      "\n",
      "==================Model Analysis Report======================\n",
      "\n",
      "Doc:\n",
      "scope: The nodes in the model graph are organized by their names, which is hierarchical like filesystem.\n",
      "flops: Number of float operations. Note: Please read the implementation for the math behind it.\n",
      "\n",
      "Profile:\n",
      "node name | # float_ops\n",
      "_TFProfRoot (--/1.38b flops)\n",
      "  model_126/conv2d_1774/Conv2D (274.51m/274.51m flops)\n",
      "  model_126/conv2d_1767/Conv2D (150.04m/150.04m flops)\n",
      "  model_126/conv2d_1765/Conv2D (138.44m/138.44m flops)\n",
      "  model_126/conv2d_1773/Conv2D (122.00m/122.00m flops)\n",
      "  model_126/conv2d_1772/Conv2D (115.26m/115.26m flops)\n",
      "  model_126/conv2d_1775/Conv2D (82.94m/82.94m flops)\n",
      "  model_126/conv2d_1766/Conv2D (73.55m/73.55m flops)\n",
      "  model_126/conv2d_1771/Conv2D (70.83m/70.83m flops)\n",
      "  model_126/conv2d_1769/Conv2D (70.26m/70.26m flops)\n",
      "  model_126/conv2d_1768/Conv2D (61.78m/61.78m flops)\n",
      "  model_126/conv2d_1764/Conv2D (44.30m/44.30m flops)\n",
      "  model_126/conv2d_1777/Conv2D (29.91m/29.91m flops)\n",
      "  model_126/depthwise_conv2d_1638/depthwise (24.92m/24.92m flops)\n",
      "  model_126/conv2d_1770/Conv2D (18.51m/18.51m flops)\n",
      "  model_126/conv2d_1776/Conv2D (15.55m/15.55m flops)\n",
      "  model_126/depthwise_conv2d_1640/depthwise (13.24m/13.24m flops)\n",
      "  model_126/depthwise_conv2d_1639/depthwise (9.73m/9.73m flops)\n",
      "  model_126/depthwise_conv2d_1647/depthwise (5.72m/5.72m flops)\n",
      "  model_126/depthwise_conv2d_1642/depthwise (5.45m/5.45m flops)\n",
      "  model_126/depthwise_conv2d_1645/depthwise (5.40m/5.40m flops)\n",
      "  model_126/depthwise_conv2d_1648/depthwise (5.26m/5.26m flops)\n",
      "  model_126/depthwise_conv2d_1641/depthwise (4.96m/4.96m flops)\n",
      "  model_126/batch_normalization_3404/FusedBatchNormV3 (4.33m/4.33m flops)\n",
      "  model_126/batch_normalization_3403/FusedBatchNormV3 (2.77m/2.77m flops)\n",
      "  model_126/batch_normalization_3402/FusedBatchNormV3 (2.77m/2.77m flops)\n",
      "  model_126/depthwise_conv2d_1646/depthwise (2.34m/2.34m flops)\n",
      "  model_126/batch_normalization_3408/FusedBatchNormV3 (2.21m/2.21m flops)\n",
      "  model_126/conv2d_1765/BiasAdd (2.16m/2.16m flops)\n",
      "  model_126/batch_normalization_3407/FusedBatchNormV3 (1.47m/1.47m flops)\n",
      "  model_126/batch_normalization_3406/FusedBatchNormV3 (1.47m/1.47m flops)\n",
      "  model_126/depthwise_conv2d_1644/depthwise (1.44m/1.44m flops)\n",
      "  model_126/depthwise_conv2d_1643/depthwise (1.41m/1.41m flops)\n",
      "  model_126/conv2d_1764/BiasAdd (1.38m/1.38m flops)\n",
      "  model_126/depthwise_conv2d_1638/BiasAdd (1.38m/1.38m flops)\n",
      "  model_126/conv2d_1767/BiasAdd (1.10m/1.10m flops)\n",
      "  model_126/batch_normalization_3405/FusedBatchNormV3 (1.08m/1.08m flops)\n",
      "  model_126/depthwise_conv2d_1640/BiasAdd (735.49k/735.49k flops)\n",
      "  model_126/conv2d_1766/BiasAdd (735.49k/735.49k flops)\n",
      "  model_126/batch_normalization_3420/FusedBatchNormV3 (638.26k/638.26k flops)\n",
      "  model_126/batch_normalization_3421/FusedBatchNormV3 (638.26k/638.26k flops)\n",
      "  model_126/batch_normalization_3412/FusedBatchNormV3 (628.02k/628.02k flops)\n",
      "  model_126/batch_normalization_3411/FusedBatchNormV3 (606.37k/606.37k flops)\n",
      "  model_126/batch_normalization_3410/FusedBatchNormV3 (606.37k/606.37k flops)\n",
      "  model_126/batch_normalization_3417/FusedBatchNormV3 (602.95k/602.95k flops)\n",
      "  model_126/batch_normalization_3416/FusedBatchNormV3 (602.95k/602.95k flops)\n",
      "  model_126/batch_normalization_3423/FusedBatchNormV3 (586.66k/586.66k flops)\n",
      "  model_126/batch_normalization_3422/FusedBatchNormV3 (586.66k/586.66k flops)\n",
      "  model_126/batch_normalization_3409/FusedBatchNormV3 (552.23k/552.23k flops)\n",
      "  model_126/depthwise_conv2d_1639/BiasAdd (540.80k/540.80k flops)\n",
      "  model_126/depthwise_conv2d_1649/depthwise (431.96k/431.96k flops)\n",
      "  model_126/conv2d_1773/BiasAdd (317.72k/317.72k flops)\n",
      "  model_126/depthwise_conv2d_1647/BiasAdd (317.72k/317.72k flops)\n",
      "  model_126/conv2d_1769/BiasAdd (313.66k/313.66k flops)\n",
      "  model_126/conv2d_1768/BiasAdd (302.85k/302.85k flops)\n",
      "  model_126/depthwise_conv2d_1642/BiasAdd (302.85k/302.85k flops)\n",
      "  model_126/depthwise_conv2d_1645/BiasAdd (300.14k/300.14k flops)\n",
      "  model_126/conv2d_1771/BiasAdd (300.14k/300.14k flops)\n",
      "  model_126/depthwise_conv2d_1648/BiasAdd (292.03k/292.03k flops)\n",
      "  model_126/conv2d_1774/BiasAdd (292.03k/292.03k flops)\n",
      "  model_126/depthwise_conv2d_1650/depthwise (285.77k/285.77k flops)\n",
      "  model_126/depthwise_conv2d_1641/BiasAdd (275.81k/275.81k flops)\n",
      "  model_126/batch_normalization_3418/FusedBatchNormV3 (260.74k/260.74k flops)\n",
      "  model_126/batch_normalization_3419/FusedBatchNormV3 (260.74k/260.74k flops)\n",
      "  model_126/batch_normalization_3424/FusedBatchNormV3 (192.84k/192.84k flops)\n",
      "  model_126/batch_normalization_3414/FusedBatchNormV3 (160.24k/160.24k flops)\n",
      "  model_126/batch_normalization_3415/FusedBatchNormV3 (160.24k/160.24k flops)\n",
      "  model_126/batch_normalization_3413/FusedBatchNormV3 (157.53k/157.53k flops)\n",
      "  model_126/conv2d_1772/BiasAdd (129.79k/129.79k flops)\n",
      "  model_126/depthwise_conv2d_1646/BiasAdd (129.79k/129.79k flops)\n",
      "  model_126/batch_normalization_3426/FusedBatchNormV3 (111.46k/111.46k flops)\n",
      "  model_126/batch_normalization_3428/FusedBatchNormV3 (97.97k/97.97k flops)\n",
      "  model_126/conv2d_1775/BiasAdd (95.99k/95.99k flops)\n",
      "  model_126/depthwise_conv2d_1644/BiasAdd (79.77k/79.77k flops)\n",
      "  model_126/conv2d_1770/BiasAdd (79.77k/79.77k flops)\n",
      "  model_126/depthwise_conv2d_1643/BiasAdd (78.42k/78.42k flops)\n",
      "  model_126/conv2d_1776/BiasAdd (54.76k/54.76k flops)\n",
      "  model_126/batch_normalization_3425/FusedBatchNormV3 (48.85k/48.85k flops)\n",
      "  model_126/global_average_pooling2d_126/Mean (46.16k/46.16k flops)\n",
      "  model_126/conv2d_1777/BiasAdd (46.16k/46.16k flops)\n",
      "  model_126/batch_normalization_3427/FusedBatchNormV3 (33.70k/33.70k flops)\n",
      "  model_126/depthwise_conv2d_1649/BiasAdd (24.00k/24.00k flops)\n",
      "  model_126/dense_126/MatMul (18.84k/18.84k flops)\n",
      "  model_126/depthwise_conv2d_1650/BiasAdd (15.88k/15.88k flops)\n",
      "  model_126/dense_126/Softmax (50/50 flops)\n",
      "  model_126/dense_126/BiasAdd (10/10 flops)\n",
      "\n",
      "======================End of Report==========================\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "178.957868\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-30 13:41:41.257125: I tensorflow/core/grappler/devices.cc:66] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0\n",
      "2022-04-30 13:41:41.257241: I tensorflow/core/grappler/clusters/single_machine.cc:357] Starting new session\n",
      "2022-04-30 13:41:41.261653: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:1137] Optimization results for grappler item: graph_to_optimize\n",
      "  function_optimizer: function_optimizer did nothing. time = 0.005ms.\n",
      "  function_optimizer: function_optimizer did nothing. time = 0.001ms.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=========================Options=============================\n",
      "-max_depth                  10000\n",
      "-min_bytes                  0\n",
      "-min_peak_bytes             0\n",
      "-min_residual_bytes         0\n",
      "-min_output_bytes           0\n",
      "-min_micros                 0\n",
      "-min_accelerator_micros     0\n",
      "-min_cpu_micros             0\n",
      "-min_params                 0\n",
      "-min_float_ops              1\n",
      "-min_occurrence             0\n",
      "-step                       -1\n",
      "-order_by                   float_ops\n",
      "-account_type_regexes       .*\n",
      "-start_name_regexes         .*\n",
      "-trim_name_regexes          \n",
      "-show_name_regexes          .*\n",
      "-hide_name_regexes          \n",
      "-account_displayed_op_only  true\n",
      "-select                     float_ops\n",
      "-output                     stdout:\n",
      "\n",
      "==================Model Analysis Report======================\n",
      "\n",
      "Doc:\n",
      "scope: The nodes in the model graph are organized by their names, which is hierarchical like filesystem.\n",
      "flops: Number of float operations. Note: Please read the implementation for the math behind it.\n",
      "\n",
      "Profile:\n",
      "node name | # float_ops\n",
      "_TFProfRoot (--/3.19b flops)\n",
      "  model_127/conv2d_1788/Conv2D (344.79m/344.79m flops)\n",
      "  model_127/conv2d_1786/Conv2D (344.78m/344.78m flops)\n",
      "  model_127/conv2d_1785/Conv2D (343.41m/343.41m flops)\n",
      "  model_127/conv2d_1787/Conv2D (342.07m/342.07m flops)\n",
      "  model_127/conv2d_1789/Conv2D (342.06m/342.06m flops)\n",
      "  model_127/conv2d_1781/Conv2D (291.08m/291.08m flops)\n",
      "  model_127/conv2d_1783/Conv2D (270.81m/270.81m flops)\n",
      "  model_127/conv2d_1784/Conv2D (158.18m/158.18m flops)\n",
      "  model_127/conv2d_1790/Conv2D (145.00m/145.00m flops)\n",
      "  model_127/conv2d_1782/Conv2D (134.25m/134.25m flops)\n",
      "  model_127/conv2d_1779/Conv2D (105.22m/105.22m flops)\n",
      "  model_127/conv2d_1780/Conv2D (95.35m/95.35m flops)\n",
      "  model_127/conv2d_1791/Conv2D (79.71m/79.71m flops)\n",
      "  model_127/conv2d_1778/Conv2D (44.30m/44.30m flops)\n",
      "  model_127/depthwise_conv2d_1651/depthwise (24.92m/24.92m flops)\n",
      "  model_127/depthwise_conv2d_1653/depthwise (22.58m/22.58m flops)\n",
      "  model_127/depthwise_conv2d_1655/depthwise (10.42m/10.42m flops)\n",
      "  model_127/depthwise_conv2d_1652/depthwise (7.40m/7.40m flops)\n",
      "  model_127/depthwise_conv2d_1658/depthwise (6.18m/6.18m flops)\n",
      "  model_127/depthwise_conv2d_1661/depthwise (6.16m/6.16m flops)\n",
      "  model_127/depthwise_conv2d_1660/depthwise (6.13m/6.13m flops)\n",
      "  model_127/depthwise_conv2d_1659/depthwise (6.11m/6.11m flops)\n",
      "  model_127/depthwise_conv2d_1657/depthwise (6.08m/6.08m flops)\n",
      "  model_127/depthwise_conv2d_1654/depthwise (5.65m/5.65m flops)\n",
      "  model_127/batch_normalization_3431/FusedBatchNormV3 (3.29m/3.29m flops)\n",
      "  model_127/depthwise_conv2d_1656/depthwise (2.85m/2.85m flops)\n",
      "  model_127/batch_normalization_3430/FusedBatchNormV3 (2.77m/2.77m flops)\n",
      "  model_127/batch_normalization_3429/FusedBatchNormV3 (2.77m/2.77m flops)\n",
      "  model_127/batch_normalization_3433/FusedBatchNormV3 (2.51m/2.51m flops)\n",
      "  model_127/batch_normalization_3434/FusedBatchNormV3 (2.51m/2.51m flops)\n",
      "  model_127/batch_normalization_3435/FusedBatchNormV3 (2.51m/2.51m flops)\n",
      "  model_127/conv2d_1779/BiasAdd (1.64m/1.64m flops)\n",
      "  model_127/depthwise_conv2d_1662/depthwise (1.52m/1.52m flops)\n",
      "  model_127/conv2d_1778/BiasAdd (1.38m/1.38m flops)\n",
      "  model_127/depthwise_conv2d_1651/BiasAdd (1.38m/1.38m flops)\n",
      "  model_127/batch_normalization_3439/FusedBatchNormV3 (1.27m/1.27m flops)\n",
      "  model_127/depthwise_conv2d_1653/BiasAdd (1.25m/1.25m flops)\n",
      "  model_127/conv2d_1780/BiasAdd (1.25m/1.25m flops)\n",
      "  model_127/conv2d_1781/BiasAdd (1.25m/1.25m flops)\n",
      "  model_127/batch_normalization_3438/FusedBatchNormV3 (1.16m/1.16m flops)\n",
      "  model_127/batch_normalization_3437/FusedBatchNormV3 (1.16m/1.16m flops)\n",
      "  model_127/batch_normalization_3432/FusedBatchNormV3 (822.24k/822.24k flops)\n",
      "  model_127/depthwise_conv2d_1663/depthwise (756.76k/756.76k flops)\n",
      "  model_127/batch_normalization_3443/FusedBatchNormV3 (689.86k/689.86k flops)\n",
      "  model_127/batch_normalization_3444/FusedBatchNormV3 (689.86k/689.86k flops)\n",
      "  model_127/batch_normalization_3450/FusedBatchNormV3 (687.15k/687.15k flops)\n",
      "  model_127/batch_normalization_3449/FusedBatchNormV3 (687.15k/687.15k flops)\n",
      "  model_127/batch_normalization_3447/FusedBatchNormV3 (684.43k/684.43k flops)\n",
      "  model_127/batch_normalization_3448/FusedBatchNormV3 (684.43k/684.43k flops)\n",
      "  model_127/batch_normalization_3445/FusedBatchNormV3 (681.72k/681.72k flops)\n",
      "  model_127/batch_normalization_3446/FusedBatchNormV3 (681.72k/681.72k flops)\n",
      "  model_127/batch_normalization_3441/FusedBatchNormV3 (679.00k/679.00k flops)\n",
      "  model_127/batch_normalization_3451/FusedBatchNormV3 (679.00k/679.00k flops)\n",
      "  model_127/batch_normalization_3442/FusedBatchNormV3 (679.00k/679.00k flops)\n",
      "  model_127/conv2d_1783/BiasAdd (632.74k/632.74k flops)\n",
      "  model_127/batch_normalization_3436/FusedBatchNormV3 (628.02k/628.02k flops)\n",
      "  model_127/conv2d_1782/BiasAdd (578.66k/578.66k flops)\n",
      "  model_127/depthwise_conv2d_1655/BiasAdd (578.66k/578.66k flops)\n",
      "  model_127/depthwise_conv2d_1652/BiasAdd (411.01k/411.01k flops)\n",
      "  model_127/depthwise_conv2d_1658/BiasAdd (343.41k/343.41k flops)\n",
      "  model_127/conv2d_1785/BiasAdd (343.41k/343.41k flops)\n",
      "  model_127/depthwise_conv2d_1661/BiasAdd (342.06k/342.06k flops)\n",
      "  model_127/conv2d_1788/BiasAdd (342.06k/342.06k flops)\n",
      "  model_127/depthwise_conv2d_1660/BiasAdd (340.70k/340.70k flops)\n",
      "  model_127/conv2d_1787/BiasAdd (340.70k/340.70k flops)\n",
      "  model_127/conv2d_1786/BiasAdd (339.35k/339.35k flops)\n",
      "  model_127/depthwise_conv2d_1659/BiasAdd (339.35k/339.35k flops)\n",
      "  model_127/conv2d_1789/BiasAdd (338.00k/338.00k flops)\n",
      "  model_127/depthwise_conv2d_1657/BiasAdd (338.00k/338.00k flops)\n",
      "  model_127/conv2d_1784/BiasAdd (338.00k/338.00k flops)\n",
      "  model_127/batch_normalization_3440/FusedBatchNormV3 (317.77k/317.77k flops)\n",
      "  model_127/depthwise_conv2d_1654/BiasAdd (313.66k/313.66k flops)\n",
      "  model_127/batch_normalization_3453/FusedBatchNormV3 (295.15k/295.15k flops)\n",
      "  model_127/batch_normalization_3452/FusedBatchNormV3 (172.00k/172.00k flops)\n",
      "  model_127/depthwise_conv2d_1656/BiasAdd (158.18k/158.18k flops)\n",
      "  model_127/conv2d_1790/BiasAdd (145.00k/145.00k flops)\n",
      "  model_127/batch_normalization_3455/FusedBatchNormV3 (98.59k/98.59k flops)\n",
      "  model_127/batch_normalization_3454/FusedBatchNormV3 (89.23k/89.23k flops)\n",
      "  model_127/depthwise_conv2d_1662/BiasAdd (84.50k/84.50k flops)\n",
      "  model_127/global_average_pooling2d_127/Mean (46.45k/46.45k flops)\n",
      "  model_127/conv2d_1791/BiasAdd (46.45k/46.45k flops)\n",
      "  model_127/depthwise_conv2d_1663/BiasAdd (42.04k/42.04k flops)\n",
      "  model_127/dense_127/MatMul (18.96k/18.96k flops)\n",
      "  model_127/dense_127/Softmax (50/50 flops)\n",
      "  model_127/dense_127/BiasAdd (10/10 flops)\n",
      "\n",
      "======================End of Report==========================\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "160.083652\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-30 13:41:42.317757: I tensorflow/core/grappler/devices.cc:66] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0\n",
      "2022-04-30 13:41:42.317878: I tensorflow/core/grappler/clusters/single_machine.cc:357] Starting new session\n",
      "2022-04-30 13:41:42.323025: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:1137] Optimization results for grappler item: graph_to_optimize\n",
      "  function_optimizer: function_optimizer did nothing. time = 0.006ms.\n",
      "  function_optimizer: function_optimizer did nothing. time = 0ms.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=========================Options=============================\n",
      "-max_depth                  10000\n",
      "-min_bytes                  0\n",
      "-min_peak_bytes             0\n",
      "-min_residual_bytes         0\n",
      "-min_output_bytes           0\n",
      "-min_micros                 0\n",
      "-min_accelerator_micros     0\n",
      "-min_cpu_micros             0\n",
      "-min_params                 0\n",
      "-min_float_ops              1\n",
      "-min_occurrence             0\n",
      "-step                       -1\n",
      "-order_by                   float_ops\n",
      "-account_type_regexes       .*\n",
      "-start_name_regexes         .*\n",
      "-trim_name_regexes          \n",
      "-show_name_regexes          .*\n",
      "-hide_name_regexes          \n",
      "-account_displayed_op_only  true\n",
      "-select                     float_ops\n",
      "-output                     stdout:\n",
      "\n",
      "==================Model Analysis Report======================\n",
      "\n",
      "Doc:\n",
      "scope: The nodes in the model graph are organized by their names, which is hierarchical like filesystem.\n",
      "flops: Number of float operations. Note: Please read the implementation for the math behind it.\n",
      "\n",
      "Profile:\n",
      "node name | # float_ops\n",
      "_TFProfRoot (--/2.30b flops)\n",
      "  model_128/conv2d_1795/Conv2D (321.97m/321.97m flops)\n",
      "  model_128/conv2d_1800/Conv2D (272.40m/272.40m flops)\n",
      "  model_128/conv2d_1801/Conv2D (249.90m/249.90m flops)\n",
      "  model_128/conv2d_1802/Conv2D (245.33m/245.33m flops)\n",
      "  model_128/conv2d_1799/Conv2D (213.94m/213.94m flops)\n",
      "  model_128/conv2d_1803/Conv2D (203.48m/203.48m flops)\n",
      "  model_128/conv2d_1804/Conv2D (104.81m/104.81m flops)\n",
      "  model_128/conv2d_1797/Conv2D (102.21m/102.21m flops)\n",
      "  model_128/conv2d_1793/Conv2D (88.60m/88.60m flops)\n",
      "  model_128/conv2d_1794/Conv2D (84.45m/84.45m flops)\n",
      "  model_128/conv2d_1796/Conv2D (83.13m/83.13m flops)\n",
      "  model_128/conv2d_1805/Conv2D (77.28m/77.28m flops)\n",
      "  model_128/conv2d_1798/Conv2D (69.76m/69.76m flops)\n",
      "  model_128/conv2d_1792/Conv2D (44.30m/44.30m flops)\n",
      "  model_128/depthwise_conv2d_1664/depthwise (24.92m/24.92m flops)\n",
      "  model_128/depthwise_conv2d_1666/depthwise (23.75m/23.75m flops)\n",
      "  model_128/depthwise_conv2d_1665/depthwise (6.23m/6.23m flops)\n",
      "  model_128/depthwise_conv2d_1668/depthwise (6.13m/6.13m flops)\n",
      "  model_128/depthwise_conv2d_1667/depthwise (5.94m/5.94m flops)\n",
      "  model_128/depthwise_conv2d_1671/depthwise (5.60m/5.60m flops)\n",
      "  model_128/depthwise_conv2d_1672/depthwise (5.33m/5.33m flops)\n",
      "  model_128/depthwise_conv2d_1674/depthwise (5.23m/5.23m flops)\n",
      "  model_128/depthwise_conv2d_1673/depthwise (5.13m/5.13m flops)\n",
      "  model_128/depthwise_conv2d_1670/depthwise (4.19m/4.19m flops)\n",
      "  model_128/batch_normalization_3457/FusedBatchNormV3 (2.77m/2.77m flops)\n",
      "  model_128/batch_normalization_3456/FusedBatchNormV3 (2.77m/2.77m flops)\n",
      "  model_128/batch_normalization_3458/FusedBatchNormV3 (2.77m/2.77m flops)\n",
      "  model_128/batch_normalization_3462/FusedBatchNormV3 (2.64m/2.64m flops)\n",
      "  model_128/batch_normalization_3461/FusedBatchNormV3 (2.64m/2.64m flops)\n",
      "  model_128/batch_normalization_3460/FusedBatchNormV3 (2.64m/2.64m flops)\n",
      "  model_128/depthwise_conv2d_1669/depthwise (1.83m/1.83m flops)\n",
      "  model_128/depthwise_conv2d_1664/BiasAdd (1.38m/1.38m flops)\n",
      "  model_128/conv2d_1793/BiasAdd (1.38m/1.38m flops)\n",
      "  model_128/conv2d_1792/BiasAdd (1.38m/1.38m flops)\n",
      "  model_128/conv2d_1795/BiasAdd (1.32m/1.32m flops)\n",
      "  model_128/conv2d_1794/BiasAdd (1.32m/1.32m flops)\n",
      "  model_128/depthwise_conv2d_1666/BiasAdd (1.32m/1.32m flops)\n",
      "  model_128/depthwise_conv2d_1675/depthwise (1.06m/1.06m flops)\n",
      "  model_128/batch_normalization_3466/FusedBatchNormV3 (812.10k/812.10k flops)\n",
      "  model_128/depthwise_conv2d_1676/depthwise (781.45k/781.45k flops)\n",
      "  model_128/batch_normalization_3459/FusedBatchNormV3 (692.42k/692.42k flops)\n",
      "  model_128/batch_normalization_3465/FusedBatchNormV3 (682.16k/682.16k flops)\n",
      "  model_128/batch_normalization_3464/FusedBatchNormV3 (682.16k/682.16k flops)\n",
      "  model_128/batch_normalization_3463/FusedBatchNormV3 (660.51k/660.51k flops)\n",
      "  model_128/batch_normalization_3470/FusedBatchNormV3 (624.68k/624.68k flops)\n",
      "  model_128/batch_normalization_3471/FusedBatchNormV3 (624.68k/624.68k flops)\n",
      "  model_128/batch_normalization_3473/FusedBatchNormV3 (594.80k/594.80k flops)\n",
      "  model_128/batch_normalization_3472/FusedBatchNormV3 (594.80k/594.80k flops)\n",
      "  model_128/batch_normalization_3476/FusedBatchNormV3 (583.94k/583.94k flops)\n",
      "  model_128/batch_normalization_3477/FusedBatchNormV3 (583.94k/583.94k flops)\n",
      "  model_128/batch_normalization_3474/FusedBatchNormV3 (573.08k/573.08k flops)\n",
      "  model_128/batch_normalization_3475/FusedBatchNormV3 (573.08k/573.08k flops)\n",
      "  model_128/batch_normalization_3478/FusedBatchNormV3 (475.30k/475.30k flops)\n",
      "  model_128/batch_normalization_3468/FusedBatchNormV3 (467.15k/467.15k flops)\n",
      "  model_128/batch_normalization_3469/FusedBatchNormV3 (467.15k/467.15k flops)\n",
      "  model_128/conv2d_1797/BiasAdd (405.60k/405.60k flops)\n",
      "  model_128/depthwise_conv2d_1665/BiasAdd (346.11k/346.11k flops)\n",
      "  model_128/conv2d_1796/BiasAdd (340.70k/340.70k flops)\n",
      "  model_128/depthwise_conv2d_1668/BiasAdd (340.70k/340.70k flops)\n",
      "  model_128/depthwise_conv2d_1667/BiasAdd (329.89k/329.89k flops)\n",
      "  model_128/depthwise_conv2d_1671/BiasAdd (310.96k/310.96k flops)\n",
      "  model_128/conv2d_1799/BiasAdd (310.96k/310.96k flops)\n",
      "  model_128/batch_normalization_3480/FusedBatchNormV3 (304.78k/304.78k flops)\n",
      "  model_128/depthwise_conv2d_1672/BiasAdd (296.09k/296.09k flops)\n",
      "  model_128/conv2d_1800/BiasAdd (296.09k/296.09k flops)\n",
      "  model_128/depthwise_conv2d_1674/BiasAdd (290.68k/290.68k flops)\n",
      "  model_128/conv2d_1802/BiasAdd (290.68k/290.68k flops)\n",
      "  model_128/depthwise_conv2d_1673/BiasAdd (285.27k/285.27k flops)\n",
      "  model_128/conv2d_1801/BiasAdd (285.27k/285.27k flops)\n",
      "  model_128/conv2d_1803/BiasAdd (236.60k/236.60k flops)\n",
      "  model_128/conv2d_1798/BiasAdd (232.54k/232.54k flops)\n",
      "  model_128/depthwise_conv2d_1670/BiasAdd (232.54k/232.54k flops)\n",
      "  model_128/batch_normalization_3467/FusedBatchNormV3 (203.70k/203.70k flops)\n",
      "  model_128/conv2d_1804/BiasAdd (149.73k/149.73k flops)\n",
      "  model_128/batch_normalization_3479/FusedBatchNormV3 (120.40k/120.40k flops)\n",
      "  model_128/depthwise_conv2d_1669/BiasAdd (101.40k/101.40k flops)\n",
      "  model_128/batch_normalization_3482/FusedBatchNormV3 (92.56k/92.56k flops)\n",
      "  model_128/batch_normalization_3481/FusedBatchNormV3 (92.14k/92.14k flops)\n",
      "  model_128/depthwise_conv2d_1675/BiasAdd (59.15k/59.15k flops)\n",
      "  model_128/global_average_pooling2d_128/Mean (43.61k/43.61k flops)\n",
      "  model_128/conv2d_1805/BiasAdd (43.61k/43.61k flops)\n",
      "  model_128/depthwise_conv2d_1676/BiasAdd (43.41k/43.41k flops)\n",
      "  model_128/dense_128/MatMul (17.80k/17.80k flops)\n",
      "  model_128/dense_128/Softmax (50/50 flops)\n",
      "  model_128/dense_128/BiasAdd (10/10 flops)\n",
      "\n",
      "======================End of Report==========================\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "150.161748\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-30 13:41:43.258722: I tensorflow/core/grappler/devices.cc:66] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0\n",
      "2022-04-30 13:41:43.258836: I tensorflow/core/grappler/clusters/single_machine.cc:357] Starting new session\n",
      "2022-04-30 13:41:43.263323: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:1137] Optimization results for grappler item: graph_to_optimize\n",
      "  function_optimizer: function_optimizer did nothing. time = 0.005ms.\n",
      "  function_optimizer: function_optimizer did nothing. time = 0.001ms.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=========================Options=============================\n",
      "-max_depth                  10000\n",
      "-min_bytes                  0\n",
      "-min_peak_bytes             0\n",
      "-min_residual_bytes         0\n",
      "-min_output_bytes           0\n",
      "-min_micros                 0\n",
      "-min_accelerator_micros     0\n",
      "-min_cpu_micros             0\n",
      "-min_params                 0\n",
      "-min_float_ops              1\n",
      "-min_occurrence             0\n",
      "-step                       -1\n",
      "-order_by                   float_ops\n",
      "-account_type_regexes       .*\n",
      "-start_name_regexes         .*\n",
      "-trim_name_regexes          \n",
      "-show_name_regexes          .*\n",
      "-hide_name_regexes          \n",
      "-account_displayed_op_only  true\n",
      "-select                     float_ops\n",
      "-output                     stdout:\n",
      "\n",
      "==================Model Analysis Report======================\n",
      "\n",
      "Doc:\n",
      "scope: The nodes in the model graph are organized by their names, which is hierarchical like filesystem.\n",
      "flops: Number of float operations. Note: Please read the implementation for the math behind it.\n",
      "\n",
      "Profile:\n",
      "node name | # float_ops\n",
      "_TFProfRoot (--/2.24b flops)\n",
      "  model_129/conv2d_1817/Conv2D (307.39m/307.39m flops)\n",
      "  model_129/conv2d_1811/Conv2D (278.23m/278.23m flops)\n",
      "  model_129/conv2d_1816/Conv2D (260.97m/260.97m flops)\n",
      "  model_129/conv2d_1815/Conv2D (222.72m/222.72m flops)\n",
      "  model_129/conv2d_1814/Conv2D (209.87m/209.87m flops)\n",
      "  model_129/conv2d_1813/Conv2D (193.97m/193.97m flops)\n",
      "  model_129/conv2d_1812/Conv2D (116.78m/116.78m flops)\n",
      "  model_129/conv2d_1807/Conv2D (116.29m/116.29m flops)\n",
      "  model_129/conv2d_1818/Conv2D (106.33m/106.33m flops)\n",
      "  model_129/conv2d_1809/Conv2D (84.80m/84.80m flops)\n",
      "  model_129/conv2d_1810/Conv2D (82.53m/82.53m flops)\n",
      "  model_129/conv2d_1808/Conv2D (50.88m/50.88m flops)\n",
      "  model_129/conv2d_1819/Conv2D (44.42m/44.42m flops)\n",
      "  model_129/conv2d_1806/Conv2D (44.30m/44.30m flops)\n",
      "  model_129/depthwise_conv2d_1677/depthwise (24.92m/24.92m flops)\n",
      "  model_129/depthwise_conv2d_1679/depthwise (10.90m/10.90m flops)\n",
      "  model_129/depthwise_conv2d_1681/depthwise (10.61m/10.61m flops)\n",
      "  model_129/depthwise_conv2d_1678/depthwise (8.18m/8.18m flops)\n",
      "  model_129/depthwise_conv2d_1687/depthwise (5.65m/5.65m flops)\n",
      "  model_129/depthwise_conv2d_1686/depthwise (5.06m/5.06m flops)\n",
      "  model_129/depthwise_conv2d_1685/depthwise (4.82m/4.82m flops)\n",
      "  model_129/depthwise_conv2d_1684/depthwise (4.77m/4.77m flops)\n",
      "  model_129/depthwise_conv2d_1683/depthwise (4.45m/4.45m flops)\n",
      "  model_129/batch_normalization_3485/FusedBatchNormV3 (3.63m/3.63m flops)\n",
      "  model_129/depthwise_conv2d_1680/depthwise (3.41m/3.41m flops)\n",
      "  model_129/depthwise_conv2d_1682/depthwise (2.87m/2.87m flops)\n",
      "  model_129/batch_normalization_3484/FusedBatchNormV3 (2.77m/2.77m flops)\n",
      "  model_129/batch_normalization_3483/FusedBatchNormV3 (2.77m/2.77m flops)\n",
      "  model_129/conv2d_1807/BiasAdd (1.82m/1.82m flops)\n",
      "  model_129/batch_normalization_3489/FusedBatchNormV3 (1.51m/1.51m flops)\n",
      "  model_129/depthwise_conv2d_1688/depthwise (1.49m/1.49m flops)\n",
      "  model_129/conv2d_1806/BiasAdd (1.38m/1.38m flops)\n",
      "  model_129/depthwise_conv2d_1677/BiasAdd (1.38m/1.38m flops)\n",
      "  model_129/batch_normalization_3493/FusedBatchNormV3 (1.28m/1.28m flops)\n",
      "  model_129/batch_normalization_3488/FusedBatchNormV3 (1.21m/1.21m flops)\n",
      "  model_129/batch_normalization_3487/FusedBatchNormV3 (1.21m/1.21m flops)\n",
      "  model_129/batch_normalization_3491/FusedBatchNormV3 (1.18m/1.18m flops)\n",
      "  model_129/batch_normalization_3492/FusedBatchNormV3 (1.18m/1.18m flops)\n",
      "  model_129/batch_normalization_3486/FusedBatchNormV3 (908.80k/908.80k flops)\n",
      "  model_129/conv2d_1809/BiasAdd (757.12k/757.12k flops)\n",
      "  model_129/batch_normalization_3505/FusedBatchNormV3 (665.42k/665.42k flops)\n",
      "  model_129/conv2d_1811/BiasAdd (638.14k/638.14k flops)\n",
      "  model_129/batch_normalization_3503/FusedBatchNormV3 (630.11k/630.11k flops)\n",
      "  model_129/batch_normalization_3504/FusedBatchNormV3 (630.11k/630.11k flops)\n",
      "  model_129/depthwise_conv2d_1679/BiasAdd (605.70k/605.70k flops)\n",
      "  model_129/conv2d_1808/BiasAdd (605.70k/605.70k flops)\n",
      "  model_129/depthwise_conv2d_1681/BiasAdd (589.47k/589.47k flops)\n",
      "  model_129/conv2d_1810/BiasAdd (589.47k/589.47k flops)\n",
      "  model_129/depthwise_conv2d_1689/depthwise (566.24k/566.24k flops)\n",
      "  model_129/batch_normalization_3501/FusedBatchNormV3 (564.93k/564.93k flops)\n",
      "  model_129/batch_normalization_3502/FusedBatchNormV3 (564.93k/564.93k flops)\n",
      "  model_129/batch_normalization_3499/FusedBatchNormV3 (537.77k/537.77k flops)\n",
      "  model_129/batch_normalization_3500/FusedBatchNormV3 (537.77k/537.77k flops)\n",
      "  model_129/batch_normalization_3497/FusedBatchNormV3 (532.34k/532.34k flops)\n",
      "  model_129/batch_normalization_3498/FusedBatchNormV3 (532.34k/532.34k flops)\n",
      "  model_129/batch_normalization_3496/FusedBatchNormV3 (497.03k/497.03k flops)\n",
      "  model_129/batch_normalization_3495/FusedBatchNormV3 (497.03k/497.03k flops)\n",
      "  model_129/depthwise_conv2d_1678/BiasAdd (454.27k/454.27k flops)\n",
      "  model_129/batch_normalization_3490/FusedBatchNormV3 (378.98k/378.98k flops)\n",
      "  model_129/conv2d_1817/BiasAdd (331.24k/331.24k flops)\n",
      "  model_129/batch_normalization_3494/FusedBatchNormV3 (320.49k/320.49k flops)\n",
      "  model_129/depthwise_conv2d_1687/BiasAdd (313.66k/313.66k flops)\n",
      "  model_129/conv2d_1816/BiasAdd (313.66k/313.66k flops)\n",
      "  model_129/conv2d_1815/BiasAdd (281.22k/281.22k flops)\n",
      "  model_129/depthwise_conv2d_1686/BiasAdd (281.22k/281.22k flops)\n",
      "  model_129/conv2d_1814/BiasAdd (267.70k/267.70k flops)\n",
      "  model_129/depthwise_conv2d_1685/BiasAdd (267.70k/267.70k flops)\n",
      "  model_129/conv2d_1813/BiasAdd (264.99k/264.99k flops)\n",
      "  model_129/depthwise_conv2d_1684/BiasAdd (264.99k/264.99k flops)\n",
      "  model_129/depthwise_conv2d_1683/BiasAdd (247.42k/247.42k flops)\n",
      "  model_129/conv2d_1812/BiasAdd (247.42k/247.42k flops)\n",
      "  model_129/batch_normalization_3507/FusedBatchNormV3 (220.85k/220.85k flops)\n",
      "  model_129/depthwise_conv2d_1680/BiasAdd (189.28k/189.28k flops)\n",
      "  model_129/batch_normalization_3506/FusedBatchNormV3 (168.56k/168.56k flops)\n",
      "  model_129/depthwise_conv2d_1682/BiasAdd (159.54k/159.54k flops)\n",
      "  model_129/conv2d_1818/BiasAdd (108.50k/108.50k flops)\n",
      "  model_129/depthwise_conv2d_1688/BiasAdd (82.81k/82.81k flops)\n",
      "  model_129/batch_normalization_3509/FusedBatchNormV3 (73.42k/73.42k flops)\n",
      "  model_129/batch_normalization_3508/FusedBatchNormV3 (66.77k/66.77k flops)\n",
      "  model_129/global_average_pooling2d_129/Mean (34.59k/34.59k flops)\n",
      "  model_129/conv2d_1819/BiasAdd (34.59k/34.59k flops)\n",
      "  model_129/depthwise_conv2d_1689/BiasAdd (31.46k/31.46k flops)\n",
      "  model_129/dense_129/MatMul (14.12k/14.12k flops)\n",
      "  model_129/dense_129/Softmax (50/50 flops)\n",
      "  model_129/dense_129/BiasAdd (10/10 flops)\n",
      "\n",
      "======================End of Report==========================\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "161.733228\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-30 13:41:44.290521: I tensorflow/core/grappler/devices.cc:66] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0\n",
      "2022-04-30 13:41:44.290637: I tensorflow/core/grappler/clusters/single_machine.cc:357] Starting new session\n",
      "2022-04-30 13:41:44.295834: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:1137] Optimization results for grappler item: graph_to_optimize\n",
      "  function_optimizer: function_optimizer did nothing. time = 0.005ms.\n",
      "  function_optimizer: function_optimizer did nothing. time = 0.001ms.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=========================Options=============================\n",
      "-max_depth                  10000\n",
      "-min_bytes                  0\n",
      "-min_peak_bytes             0\n",
      "-min_residual_bytes         0\n",
      "-min_output_bytes           0\n",
      "-min_micros                 0\n",
      "-min_accelerator_micros     0\n",
      "-min_cpu_micros             0\n",
      "-min_params                 0\n",
      "-min_float_ops              1\n",
      "-min_occurrence             0\n",
      "-step                       -1\n",
      "-order_by                   float_ops\n",
      "-account_type_regexes       .*\n",
      "-start_name_regexes         .*\n",
      "-trim_name_regexes          \n",
      "-show_name_regexes          .*\n",
      "-hide_name_regexes          \n",
      "-account_displayed_op_only  true\n",
      "-select                     float_ops\n",
      "-output                     stdout:\n",
      "\n",
      "==================Model Analysis Report======================\n",
      "\n",
      "Doc:\n",
      "scope: The nodes in the model graph are organized by their names, which is hierarchical like filesystem.\n",
      "flops: Number of float operations. Note: Please read the implementation for the math behind it.\n",
      "\n",
      "Profile:\n",
      "node name | # float_ops\n",
      "_TFProfRoot (--/2.23b flops)\n",
      "  model_130/conv2d_1831/Conv2D (263.69m/263.69m flops)\n",
      "  model_130/conv2d_1829/Conv2D (252.32m/252.32m flops)\n",
      "  model_130/conv2d_1825/Conv2D (249.07m/249.07m flops)\n",
      "  model_130/conv2d_1828/Conv2D (235.23m/235.23m flops)\n",
      "  model_130/conv2d_1830/Conv2D (220.13m/220.13m flops)\n",
      "  model_130/conv2d_1823/Conv2D (152.29m/152.29m flops)\n",
      "  model_130/conv2d_1821/Conv2D (143.98m/143.98m flops)\n",
      "  model_130/conv2d_1827/Conv2D (138.43m/138.43m flops)\n",
      "  model_130/conv2d_1824/Conv2D (120.17m/120.17m flops)\n",
      "  model_130/conv2d_1826/Conv2D (88.16m/88.16m flops)\n",
      "  model_130/conv2d_1832/Conv2D (78.67m/78.67m flops)\n",
      "  model_130/conv2d_1822/Conv2D (71.99m/71.99m flops)\n",
      "  model_130/conv2d_1820/Conv2D (44.30m/44.30m flops)\n",
      "  model_130/conv2d_1833/Conv2D (43.04m/43.04m flops)\n",
      "  model_130/depthwise_conv2d_1690/depthwise (24.92m/24.92m flops)\n",
      "  model_130/depthwise_conv2d_1692/depthwise (12.46m/12.46m flops)\n",
      "  model_130/depthwise_conv2d_1691/depthwise (10.12m/10.12m flops)\n",
      "  model_130/depthwise_conv2d_1694/depthwise (9.83m/9.83m flops)\n",
      "  model_130/depthwise_conv2d_1698/depthwise (5.91m/5.91m flops)\n",
      "  model_130/depthwise_conv2d_1693/depthwise (5.35m/5.35m flops)\n",
      "  model_130/depthwise_conv2d_1700/depthwise (5.16m/5.16m flops)\n",
      "  model_130/depthwise_conv2d_1699/depthwise (4.67m/4.67m flops)\n",
      "  model_130/batch_normalization_3512/FusedBatchNormV3 (4.50m/4.50m flops)\n",
      "  model_130/depthwise_conv2d_1697/depthwise (4.36m/4.36m flops)\n",
      "  model_130/depthwise_conv2d_1696/depthwise (3.48m/3.48m flops)\n",
      "  model_130/depthwise_conv2d_1695/depthwise (2.77m/2.77m flops)\n",
      "  model_130/batch_normalization_3511/FusedBatchNormV3 (2.77m/2.77m flops)\n",
      "  model_130/batch_normalization_3510/FusedBatchNormV3 (2.77m/2.77m flops)\n",
      "  model_130/batch_normalization_3516/FusedBatchNormV3 (2.38m/2.38m flops)\n",
      "  model_130/conv2d_1821/BiasAdd (2.25m/2.25m flops)\n",
      "  model_130/depthwise_conv2d_1701/depthwise (1.40m/1.40m flops)\n",
      "  model_130/batch_normalization_3514/FusedBatchNormV3 (1.38m/1.38m flops)\n",
      "  model_130/batch_normalization_3515/FusedBatchNormV3 (1.38m/1.38m flops)\n",
      "  model_130/conv2d_1820/BiasAdd (1.38m/1.38m flops)\n",
      "  model_130/depthwise_conv2d_1690/BiasAdd (1.38m/1.38m flops)\n",
      "  model_130/batch_normalization_3520/FusedBatchNormV3 (1.23m/1.23m flops)\n",
      "  model_130/conv2d_1823/BiasAdd (1.19m/1.19m flops)\n",
      "  model_130/batch_normalization_3513/FusedBatchNormV3 (1.13m/1.13m flops)\n",
      "  model_130/batch_normalization_3519/FusedBatchNormV3 (1.09m/1.09m flops)\n",
      "  model_130/batch_normalization_3518/FusedBatchNormV3 (1.09m/1.09m flops)\n",
      "  model_130/depthwise_conv2d_1692/BiasAdd (692.22k/692.22k flops)\n",
      "  model_130/conv2d_1822/BiasAdd (692.22k/692.22k flops)\n",
      "  model_130/batch_normalization_3527/FusedBatchNormV3 (659.99k/659.99k flops)\n",
      "  model_130/batch_normalization_3526/FusedBatchNormV3 (659.99k/659.99k flops)\n",
      "  model_130/batch_normalization_3532/FusedBatchNormV3 (624.68k/624.68k flops)\n",
      "  model_130/conv2d_1825/BiasAdd (616.51k/616.51k flops)\n",
      "  model_130/batch_normalization_3517/FusedBatchNormV3 (595.54k/595.54k flops)\n",
      "  model_130/batch_normalization_3530/FusedBatchNormV3 (575.79k/575.79k flops)\n",
      "  model_130/batch_normalization_3531/FusedBatchNormV3 (575.79k/575.79k flops)\n",
      "  model_130/depthwise_conv2d_1691/BiasAdd (562.43k/562.43k flops)\n",
      "  model_130/depthwise_conv2d_1694/BiasAdd (546.21k/546.21k flops)\n",
      "  model_130/conv2d_1824/BiasAdd (546.21k/546.21k flops)\n",
      "  model_130/batch_normalization_3528/FusedBatchNormV3 (521.47k/521.47k flops)\n",
      "  model_130/batch_normalization_3529/FusedBatchNormV3 (521.47k/521.47k flops)\n",
      "  model_130/batch_normalization_3525/FusedBatchNormV3 (486.16k/486.16k flops)\n",
      "  model_130/batch_normalization_3524/FusedBatchNormV3 (486.16k/486.16k flops)\n",
      "  model_130/depthwise_conv2d_1702/depthwise (446.29k/446.29k flops)\n",
      "  model_130/batch_normalization_3522/FusedBatchNormV3 (388.39k/388.39k flops)\n",
      "  model_130/batch_normalization_3523/FusedBatchNormV3 (388.39k/388.39k flops)\n",
      "  model_130/depthwise_conv2d_1698/BiasAdd (328.54k/328.54k flops)\n",
      "  model_130/conv2d_1828/BiasAdd (328.54k/328.54k flops)\n",
      "  model_130/conv2d_1831/BiasAdd (310.96k/310.96k flops)\n",
      "  model_130/batch_normalization_3521/FusedBatchNormV3 (309.62k/309.62k flops)\n",
      "  model_130/depthwise_conv2d_1693/BiasAdd (297.44k/297.44k flops)\n",
      "  model_130/depthwise_conv2d_1700/BiasAdd (286.62k/286.62k flops)\n",
      "  model_130/conv2d_1830/BiasAdd (286.62k/286.62k flops)\n",
      "  model_130/conv2d_1829/BiasAdd (259.58k/259.58k flops)\n",
      "  model_130/depthwise_conv2d_1699/BiasAdd (259.58k/259.58k flops)\n",
      "  model_130/conv2d_1827/BiasAdd (242.01k/242.01k flops)\n",
      "  model_130/depthwise_conv2d_1697/BiasAdd (242.01k/242.01k flops)\n",
      "  model_130/depthwise_conv2d_1696/BiasAdd (193.34k/193.34k flops)\n",
      "  model_130/conv2d_1826/BiasAdd (193.34k/193.34k flops)\n",
      "  model_130/batch_normalization_3534/FusedBatchNormV3 (174.06k/174.06k flops)\n",
      "  model_130/batch_normalization_3533/FusedBatchNormV3 (158.24k/158.24k flops)\n",
      "  model_130/depthwise_conv2d_1695/BiasAdd (154.13k/154.13k flops)\n",
      "  model_130/batch_normalization_3536/FusedBatchNormV3 (90.27k/90.27k flops)\n",
      "  model_130/conv2d_1832/BiasAdd (85.51k/85.51k flops)\n",
      "  model_130/depthwise_conv2d_1701/BiasAdd (77.74k/77.74k flops)\n",
      "  model_130/batch_normalization_3535/FusedBatchNormV3 (52.62k/52.62k flops)\n",
      "  model_130/global_average_pooling2d_130/Mean (42.53k/42.53k flops)\n",
      "  model_130/conv2d_1833/BiasAdd (42.53k/42.53k flops)\n",
      "  model_130/depthwise_conv2d_1702/BiasAdd (24.79k/24.79k flops)\n",
      "  model_130/dense_130/MatMul (17.36k/17.36k flops)\n",
      "  model_130/dense_130/Softmax (50/50 flops)\n",
      "  model_130/dense_130/BiasAdd (10/10 flops)\n",
      "\n",
      "======================End of Report==========================\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "181.074652\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-30 13:41:45.210860: I tensorflow/core/grappler/devices.cc:66] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0\n",
      "2022-04-30 13:41:45.210975: I tensorflow/core/grappler/clusters/single_machine.cc:357] Starting new session\n",
      "2022-04-30 13:41:45.215431: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:1137] Optimization results for grappler item: graph_to_optimize\n",
      "  function_optimizer: function_optimizer did nothing. time = 0.006ms.\n",
      "  function_optimizer: function_optimizer did nothing. time = 0.001ms.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=========================Options=============================\n",
      "-max_depth                  10000\n",
      "-min_bytes                  0\n",
      "-min_peak_bytes             0\n",
      "-min_residual_bytes         0\n",
      "-min_output_bytes           0\n",
      "-min_micros                 0\n",
      "-min_accelerator_micros     0\n",
      "-min_cpu_micros             0\n",
      "-min_params                 0\n",
      "-min_float_ops              1\n",
      "-min_occurrence             0\n",
      "-step                       -1\n",
      "-order_by                   float_ops\n",
      "-account_type_regexes       .*\n",
      "-start_name_regexes         .*\n",
      "-trim_name_regexes          \n",
      "-show_name_regexes          .*\n",
      "-hide_name_regexes          \n",
      "-account_displayed_op_only  true\n",
      "-select                     float_ops\n",
      "-output                     stdout:\n",
      "\n",
      "==================Model Analysis Report======================\n",
      "\n",
      "Doc:\n",
      "scope: The nodes in the model graph are organized by their names, which is hierarchical like filesystem.\n",
      "flops: Number of float operations. Note: Please read the implementation for the math behind it.\n",
      "\n",
      "Profile:\n",
      "node name | # float_ops\n",
      "_TFProfRoot (--/2.57b flops)\n",
      "  model_131/conv2d_1843/Conv2D (344.56m/344.56m flops)\n",
      "  model_131/conv2d_1844/Conv2D (344.56m/344.56m flops)\n",
      "  model_131/conv2d_1845/Conv2D (296.70m/296.70m flops)\n",
      "  model_131/conv2d_1837/Conv2D (240.84m/240.84m flops)\n",
      "  model_131/conv2d_1842/Conv2D (226.97m/226.97m flops)\n",
      "  model_131/conv2d_1839/Conv2D (221.45m/221.45m flops)\n",
      "  model_131/conv2d_1841/Conv2D (156.17m/156.17m flops)\n",
      "  model_131/conv2d_1835/Conv2D (115.61m/115.61m flops)\n",
      "  model_131/conv2d_1838/Conv2D (114.15m/114.15m flops)\n",
      "  model_131/conv2d_1840/Conv2D (91.26m/91.26m flops)\n",
      "  model_131/conv2d_1836/Conv2D (86.70m/86.70m flops)\n",
      "  model_131/conv2d_1846/Conv2D (86.43m/86.43m flops)\n",
      "  model_131/conv2d_1834/Conv2D (51.38m/51.38m flops)\n",
      "  model_131/conv2d_1847/Conv2D (44.01m/44.01m flops)\n",
      "  model_131/depthwise_conv2d_1703/depthwise (28.90m/28.90m flops)\n",
      "  model_131/depthwise_conv2d_1705/depthwise (21.68m/21.68m flops)\n",
      "  model_131/depthwise_conv2d_1707/depthwise (10.27m/10.27m flops)\n",
      "  model_131/depthwise_conv2d_1704/depthwise (8.13m/8.13m flops)\n",
      "  model_131/depthwise_conv2d_1712/depthwise (7.11m/7.11m flops)\n",
      "  model_131/depthwise_conv2d_1711/depthwise (6.15m/6.15m flops)\n",
      "  model_131/depthwise_conv2d_1713/depthwise (6.15m/6.15m flops)\n",
      "  model_131/depthwise_conv2d_1706/depthwise (5.64m/5.64m flops)\n",
      "  model_131/depthwise_conv2d_1710/depthwise (4.69m/4.69m flops)\n",
      "  model_131/depthwise_conv2d_1709/depthwise (4.23m/4.23m flops)\n",
      "  model_131/batch_normalization_3539/FusedBatchNormV3 (3.61m/3.61m flops)\n",
      "  model_131/batch_normalization_3538/FusedBatchNormV3 (3.21m/3.21m flops)\n",
      "  model_131/batch_normalization_3537/FusedBatchNormV3 (3.21m/3.21m flops)\n",
      "  model_131/depthwise_conv2d_1708/depthwise (2.74m/2.74m flops)\n",
      "  model_131/batch_normalization_3543/FusedBatchNormV3 (2.51m/2.51m flops)\n",
      "  model_131/batch_normalization_3541/FusedBatchNormV3 (2.41m/2.41m flops)\n",
      "  model_131/batch_normalization_3542/FusedBatchNormV3 (2.41m/2.41m flops)\n",
      "  model_131/conv2d_1835/BiasAdd (1.81m/1.81m flops)\n",
      "  model_131/conv2d_1834/BiasAdd (1.61m/1.61m flops)\n",
      "  model_131/depthwise_conv2d_1703/BiasAdd (1.61m/1.61m flops)\n",
      "  model_131/depthwise_conv2d_1714/depthwise (1.53m/1.53m flops)\n",
      "  model_131/conv2d_1837/BiasAdd (1.25m/1.25m flops)\n",
      "  model_131/batch_normalization_3547/FusedBatchNormV3 (1.22m/1.22m flops)\n",
      "  model_131/conv2d_1836/BiasAdd (1.20m/1.20m flops)\n",
      "  model_131/depthwise_conv2d_1705/BiasAdd (1.20m/1.20m flops)\n",
      "  model_131/batch_normalization_3545/FusedBatchNormV3 (1.14m/1.14m flops)\n",
      "  model_131/batch_normalization_3546/FusedBatchNormV3 (1.14m/1.14m flops)\n",
      "  model_131/batch_normalization_3540/FusedBatchNormV3 (903.38k/903.38k flops)\n",
      "  model_131/batch_normalization_3555/FusedBatchNormV3 (793.30k/793.30k flops)\n",
      "  model_131/batch_normalization_3556/FusedBatchNormV3 (793.30k/793.30k flops)\n",
      "  model_131/batch_normalization_3554/FusedBatchNormV3 (686.26k/686.26k flops)\n",
      "  model_131/batch_normalization_3557/FusedBatchNormV3 (686.26k/686.26k flops)\n",
      "  model_131/batch_normalization_3553/FusedBatchNormV3 (686.26k/686.26k flops)\n",
      "  model_131/batch_normalization_3558/FusedBatchNormV3 (686.26k/686.26k flops)\n",
      "  model_131/batch_normalization_3559/FusedBatchNormV3 (683.12k/683.12k flops)\n",
      "  model_131/batch_normalization_3544/FusedBatchNormV3 (627.80k/627.80k flops)\n",
      "  model_131/conv2d_1839/BiasAdd (608.38k/608.38k flops)\n",
      "  model_131/conv2d_1838/BiasAdd (570.75k/570.75k flops)\n",
      "  model_131/depthwise_conv2d_1707/BiasAdd (570.75k/570.75k flops)\n",
      "  model_131/batch_normalization_3551/FusedBatchNormV3 (522.57k/522.57k flops)\n",
      "  model_131/batch_normalization_3552/FusedBatchNormV3 (522.57k/522.57k flops)\n",
      "  model_131/batch_normalization_3550/FusedBatchNormV3 (472.20k/472.20k flops)\n",
      "  model_131/batch_normalization_3549/FusedBatchNormV3 (472.20k/472.20k flops)\n",
      "  model_131/depthwise_conv2d_1704/BiasAdd (451.58k/451.58k flops)\n",
      "  model_131/depthwise_conv2d_1715/depthwise (448.06k/448.06k flops)\n",
      "  model_131/depthwise_conv2d_1712/BiasAdd (395.14k/395.14k flops)\n",
      "  model_131/conv2d_1843/BiasAdd (395.14k/395.14k flops)\n",
      "  model_131/depthwise_conv2d_1711/BiasAdd (341.82k/341.82k flops)\n",
      "  model_131/depthwise_conv2d_1713/BiasAdd (341.82k/341.82k flops)\n",
      "  model_131/conv2d_1842/BiasAdd (341.82k/341.82k flops)\n",
      "  model_131/conv2d_1844/BiasAdd (341.82k/341.82k flops)\n",
      "  model_131/conv2d_1845/BiasAdd (340.26k/340.26k flops)\n",
      "  model_131/depthwise_conv2d_1706/BiasAdd (313.60k/313.60k flops)\n",
      "  model_131/batch_normalization_3548/FusedBatchNormV3 (305.36k/305.36k flops)\n",
      "  model_131/conv2d_1841/BiasAdd (260.29k/260.29k flops)\n",
      "  model_131/depthwise_conv2d_1710/BiasAdd (260.29k/260.29k flops)\n",
      "  model_131/conv2d_1840/BiasAdd (235.20k/235.20k flops)\n",
      "  model_131/depthwise_conv2d_1709/BiasAdd (235.20k/235.20k flops)\n",
      "  model_131/batch_normalization_3561/FusedBatchNormV3 (202.18k/202.18k flops)\n",
      "  model_131/batch_normalization_3560/FusedBatchNormV3 (172.73k/172.73k flops)\n",
      "  model_131/depthwise_conv2d_1708/BiasAdd (152.10k/152.10k flops)\n",
      "  model_131/conv2d_1846/BiasAdd (99.57k/99.57k flops)\n",
      "  model_131/batch_normalization_3563/FusedBatchNormV3 (91.94k/91.94k flops)\n",
      "  model_131/depthwise_conv2d_1714/BiasAdd (85.06k/85.06k flops)\n",
      "  model_131/batch_normalization_3562/FusedBatchNormV3 (52.83k/52.83k flops)\n",
      "  model_131/global_average_pooling2d_131/Mean (43.32k/43.32k flops)\n",
      "  model_131/conv2d_1847/BiasAdd (43.32k/43.32k flops)\n",
      "  model_131/depthwise_conv2d_1715/BiasAdd (24.89k/24.89k flops)\n",
      "  model_131/dense_131/MatMul (17.68k/17.68k flops)\n",
      "  model_131/dense_131/Softmax (50/50 flops)\n",
      "  model_131/dense_131/BiasAdd (10/10 flops)\n",
      "\n",
      "======================End of Report==========================\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "172.033348\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-30 13:41:46.130555: I tensorflow/core/grappler/devices.cc:66] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0\n",
      "2022-04-30 13:41:46.130669: I tensorflow/core/grappler/clusters/single_machine.cc:357] Starting new session\n",
      "2022-04-30 13:41:46.134960: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:1137] Optimization results for grappler item: graph_to_optimize\n",
      "  function_optimizer: function_optimizer did nothing. time = 0.005ms.\n",
      "  function_optimizer: function_optimizer did nothing. time = 0.001ms.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=========================Options=============================\n",
      "-max_depth                  10000\n",
      "-min_bytes                  0\n",
      "-min_peak_bytes             0\n",
      "-min_residual_bytes         0\n",
      "-min_output_bytes           0\n",
      "-min_micros                 0\n",
      "-min_accelerator_micros     0\n",
      "-min_cpu_micros             0\n",
      "-min_params                 0\n",
      "-min_float_ops              1\n",
      "-min_occurrence             0\n",
      "-step                       -1\n",
      "-order_by                   float_ops\n",
      "-account_type_regexes       .*\n",
      "-start_name_regexes         .*\n",
      "-trim_name_regexes          \n",
      "-show_name_regexes          .*\n",
      "-hide_name_regexes          \n",
      "-account_displayed_op_only  true\n",
      "-select                     float_ops\n",
      "-output                     stdout:\n",
      "\n",
      "==================Model Analysis Report======================\n",
      "\n",
      "Doc:\n",
      "scope: The nodes in the model graph are organized by their names, which is hierarchical like filesystem.\n",
      "flops: Number of float operations. Note: Please read the implementation for the math behind it.\n",
      "\n",
      "Profile:\n",
      "node name | # float_ops\n",
      "_TFProfRoot (--/2.08b flops)\n",
      "  model_132/conv2d_1859/Conv2D (324.43m/324.43m flops)\n",
      "  model_132/conv2d_1858/Conv2D (225.57m/225.57m flops)\n",
      "  model_132/conv2d_1851/Conv2D (209.84m/209.84m flops)\n",
      "  model_132/conv2d_1856/Conv2D (165.62m/165.62m flops)\n",
      "  model_132/conv2d_1857/Conv2D (164.60m/164.60m flops)\n",
      "  model_132/conv2d_1855/Conv2D (154.37m/154.37m flops)\n",
      "  model_132/conv2d_1849/Conv2D (141.30m/141.30m flops)\n",
      "  model_132/conv2d_1853/Conv2D (122.33m/122.33m flops)\n",
      "  model_132/conv2d_1860/Conv2D (95.35m/95.35m flops)\n",
      "  model_132/conv2d_1850/Conv2D (90.52m/90.52m flops)\n",
      "  model_132/conv2d_1854/Conv2D (87.13m/87.13m flops)\n",
      "  model_132/conv2d_1852/Conv2D (67.81m/67.81m flops)\n",
      "  model_132/conv2d_1848/Conv2D (51.38m/51.38m flops)\n",
      "  model_132/conv2d_1861/Conv2D (42.46m/42.46m flops)\n",
      "  model_132/depthwise_conv2d_1716/depthwise (28.90m/28.90m flops)\n",
      "  model_132/depthwise_conv2d_1718/depthwise (18.51m/18.51m flops)\n",
      "  model_132/depthwise_conv2d_1717/depthwise (9.93m/9.93m flops)\n",
      "  model_132/depthwise_conv2d_1726/depthwise (6.27m/6.27m flops)\n",
      "  model_132/depthwise_conv2d_1720/depthwise (5.98m/5.98m flops)\n",
      "  model_132/depthwise_conv2d_1719/depthwise (5.76m/5.76m flops)\n",
      "  model_132/depthwise_conv2d_1723/depthwise (4.60m/4.60m flops)\n",
      "  model_132/depthwise_conv2d_1724/depthwise (4.57m/4.57m flops)\n",
      "  model_132/depthwise_conv2d_1725/depthwise (4.57m/4.57m flops)\n",
      "  model_132/batch_normalization_3566/FusedBatchNormV3 (4.42m/4.42m flops)\n",
      "  model_132/depthwise_conv2d_1722/depthwise (4.26m/4.26m flops)\n",
      "  model_132/batch_normalization_3565/FusedBatchNormV3 (3.21m/3.21m flops)\n",
      "  model_132/batch_normalization_3564/FusedBatchNormV3 (3.21m/3.21m flops)\n",
      "  model_132/depthwise_conv2d_1721/depthwise (2.60m/2.60m flops)\n",
      "  model_132/batch_normalization_3570/FusedBatchNormV3 (2.56m/2.56m flops)\n",
      "  model_132/conv2d_1849/BiasAdd (2.21m/2.21m flops)\n",
      "  model_132/batch_normalization_3568/FusedBatchNormV3 (2.06m/2.06m flops)\n",
      "  model_132/batch_normalization_3569/FusedBatchNormV3 (2.06m/2.06m flops)\n",
      "  model_132/depthwise_conv2d_1727/depthwise (1.64m/1.64m flops)\n",
      "  model_132/conv2d_1848/BiasAdd (1.61m/1.61m flops)\n",
      "  model_132/depthwise_conv2d_1716/BiasAdd (1.61m/1.61m flops)\n",
      "  model_132/conv2d_1851/BiasAdd (1.28m/1.28m flops)\n",
      "  model_132/batch_normalization_3574/FusedBatchNormV3 (1.16m/1.16m flops)\n",
      "  model_132/batch_normalization_3567/FusedBatchNormV3 (1.10m/1.10m flops)\n",
      "  model_132/conv2d_1850/BiasAdd (1.03m/1.03m flops)\n",
      "  model_132/depthwise_conv2d_1718/BiasAdd (1.03m/1.03m flops)\n",
      "  model_132/batch_normalization_3586/FusedBatchNormV3 (733.48k/733.48k flops)\n",
      "  model_132/batch_normalization_3585/FusedBatchNormV3 (698.86k/698.86k flops)\n",
      "  model_132/batch_normalization_3584/FusedBatchNormV3 (698.86k/698.86k flops)\n",
      "  model_132/batch_normalization_3572/FusedBatchNormV3 (665.47k/665.47k flops)\n",
      "  model_132/batch_normalization_3573/FusedBatchNormV3 (665.47k/665.47k flops)\n",
      "  model_132/batch_normalization_3571/FusedBatchNormV3 (640.36k/640.36k flops)\n",
      "  model_132/conv2d_1853/BiasAdd (577.02k/577.02k flops)\n",
      "  model_132/depthwise_conv2d_1717/BiasAdd (551.94k/551.94k flops)\n",
      "  model_132/batch_normalization_3579/FusedBatchNormV3 (513.12k/513.12k flops)\n",
      "  model_132/batch_normalization_3578/FusedBatchNormV3 (513.12k/513.12k flops)\n",
      "  model_132/batch_normalization_3582/FusedBatchNormV3 (509.98k/509.98k flops)\n",
      "  model_132/batch_normalization_3583/FusedBatchNormV3 (509.98k/509.98k flops)\n",
      "  model_132/batch_normalization_3580/FusedBatchNormV3 (509.98k/509.98k flops)\n",
      "  model_132/batch_normalization_3581/FusedBatchNormV3 (509.98k/509.98k flops)\n",
      "  model_132/batch_normalization_3577/FusedBatchNormV3 (475.35k/475.35k flops)\n",
      "  model_132/batch_normalization_3576/FusedBatchNormV3 (475.35k/475.35k flops)\n",
      "  model_132/depthwise_conv2d_1728/depthwise (460.40k/460.40k flops)\n",
      "  model_132/conv2d_1859/BiasAdd (365.34k/365.34k flops)\n",
      "  model_132/depthwise_conv2d_1726/BiasAdd (348.10k/348.10k flops)\n",
      "  model_132/conv2d_1858/BiasAdd (348.10k/348.10k flops)\n",
      "  model_132/conv2d_1852/BiasAdd (332.42k/332.42k flops)\n",
      "  model_132/depthwise_conv2d_1720/BiasAdd (332.42k/332.42k flops)\n",
      "  model_132/depthwise_conv2d_1719/BiasAdd (319.87k/319.87k flops)\n",
      "  model_132/batch_normalization_3575/FusedBatchNormV3 (289.62k/289.62k flops)\n",
      "  model_132/conv2d_1855/BiasAdd (255.58k/255.58k flops)\n",
      "  model_132/depthwise_conv2d_1723/BiasAdd (255.58k/255.58k flops)\n",
      "  model_132/depthwise_conv2d_1724/BiasAdd (254.02k/254.02k flops)\n",
      "  model_132/depthwise_conv2d_1725/BiasAdd (254.02k/254.02k flops)\n",
      "  model_132/conv2d_1857/BiasAdd (254.02k/254.02k flops)\n",
      "  model_132/conv2d_1856/BiasAdd (254.02k/254.02k flops)\n",
      "  model_132/depthwise_conv2d_1722/BiasAdd (236.77k/236.77k flops)\n",
      "  model_132/conv2d_1854/BiasAdd (236.77k/236.77k flops)\n",
      "  model_132/batch_normalization_3588/FusedBatchNormV3 (207.76k/207.76k flops)\n",
      "  model_132/batch_normalization_3587/FusedBatchNormV3 (185.47k/185.47k flops)\n",
      "  model_132/depthwise_conv2d_1721/BiasAdd (144.26k/144.26k flops)\n",
      "  model_132/conv2d_1860/BiasAdd (102.31k/102.31k flops)\n",
      "  model_132/depthwise_conv2d_1727/BiasAdd (91.34k/91.34k flops)\n",
      "  model_132/batch_normalization_3590/FusedBatchNormV3 (86.32k/86.32k flops)\n",
      "  model_132/batch_normalization_3589/FusedBatchNormV3 (54.29k/54.29k flops)\n",
      "  model_132/global_average_pooling2d_132/Mean (40.67k/40.67k flops)\n",
      "  model_132/conv2d_1861/BiasAdd (40.67k/40.67k flops)\n",
      "  model_132/depthwise_conv2d_1728/BiasAdd (25.58k/25.58k flops)\n",
      "  model_132/dense_132/MatMul (16.60k/16.60k flops)\n",
      "  model_132/dense_132/Softmax (50/50 flops)\n",
      "  model_132/dense_132/BiasAdd (10/10 flops)\n",
      "\n",
      "======================End of Report==========================\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "156.057372\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-30 13:41:47.162433: I tensorflow/core/grappler/devices.cc:66] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0\n",
      "2022-04-30 13:41:47.162550: I tensorflow/core/grappler/clusters/single_machine.cc:357] Starting new session\n",
      "2022-04-30 13:41:47.167241: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:1137] Optimization results for grappler item: graph_to_optimize\n",
      "  function_optimizer: function_optimizer did nothing. time = 0.006ms.\n",
      "  function_optimizer: function_optimizer did nothing. time = 0.001ms.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=========================Options=============================\n",
      "-max_depth                  10000\n",
      "-min_bytes                  0\n",
      "-min_peak_bytes             0\n",
      "-min_residual_bytes         0\n",
      "-min_output_bytes           0\n",
      "-min_micros                 0\n",
      "-min_accelerator_micros     0\n",
      "-min_cpu_micros             0\n",
      "-min_params                 0\n",
      "-min_float_ops              1\n",
      "-min_occurrence             0\n",
      "-step                       -1\n",
      "-order_by                   float_ops\n",
      "-account_type_regexes       .*\n",
      "-start_name_regexes         .*\n",
      "-trim_name_regexes          \n",
      "-show_name_regexes          .*\n",
      "-hide_name_regexes          \n",
      "-account_displayed_op_only  true\n",
      "-select                     float_ops\n",
      "-output                     stdout:\n",
      "\n",
      "==================Model Analysis Report======================\n",
      "\n",
      "Doc:\n",
      "scope: The nodes in the model graph are organized by their names, which is hierarchical like filesystem.\n",
      "flops: Number of float operations. Note: Please read the implementation for the math behind it.\n",
      "\n",
      "Profile:\n",
      "node name | # float_ops\n",
      "_TFProfRoot (--/2.90b flops)\n",
      "  model_133/conv2d_1871/Conv2D (393.57m/393.57m flops)\n",
      "  model_133/conv2d_1872/Conv2D (392.00m/392.00m flops)\n",
      "  model_133/conv2d_1870/Conv2D (388.85m/388.85m flops)\n",
      "  model_133/conv2d_1873/Conv2D (384.16m/384.16m flops)\n",
      "  model_133/conv2d_1869/Conv2D (370.25m/370.25m flops)\n",
      "  model_133/conv2d_1867/Conv2D (206.00m/206.00m flops)\n",
      "  model_133/conv2d_1868/Conv2D (178.38m/178.38m flops)\n",
      "  model_133/conv2d_1874/Conv2D (148.29m/148.29m flops)\n",
      "  model_133/conv2d_1863/Conv2D (102.76m/102.76m flops)\n",
      "  model_133/conv2d_1875/Conv2D (62.49m/62.49m flops)\n",
      "  model_133/conv2d_1862/Conv2D (51.38m/51.38m flops)\n",
      "  model_133/conv2d_1866/Conv2D (32.89m/32.89m flops)\n",
      "  model_133/conv2d_1865/Conv2D (30.51m/30.51m flops)\n",
      "  model_133/depthwise_conv2d_1729/depthwise (28.90m/28.90m flops)\n",
      "  model_133/conv2d_1864/Conv2D (25.69m/25.69m flops)\n",
      "  model_133/depthwise_conv2d_1733/depthwise (7.79m/7.79m flops)\n",
      "  model_133/depthwise_conv2d_1730/depthwise (7.23m/7.23m flops)\n",
      "  model_133/depthwise_conv2d_1731/depthwise (7.23m/7.23m flops)\n",
      "  model_133/depthwise_conv2d_1737/depthwise (7.08m/7.08m flops)\n",
      "  model_133/depthwise_conv2d_1738/depthwise (7.06m/7.06m flops)\n",
      "  model_133/depthwise_conv2d_1739/depthwise (7.06m/7.06m flops)\n",
      "  model_133/depthwise_conv2d_1736/depthwise (6.97m/6.97m flops)\n",
      "  model_133/depthwise_conv2d_1735/depthwise (6.75m/6.75m flops)\n",
      "  model_133/depthwise_conv2d_1734/depthwise (3.36m/3.36m flops)\n",
      "  model_133/batch_normalization_3592/FusedBatchNormV3 (3.21m/3.21m flops)\n",
      "  model_133/batch_normalization_3591/FusedBatchNormV3 (3.21m/3.21m flops)\n",
      "  model_133/batch_normalization_3593/FusedBatchNormV3 (3.21m/3.21m flops)\n",
      "  model_133/depthwise_conv2d_1732/depthwise (2.15m/2.15m flops)\n",
      "  model_133/depthwise_conv2d_1740/depthwise (1.73m/1.73m flops)\n",
      "  model_133/conv2d_1863/BiasAdd (1.61m/1.61m flops)\n",
      "  model_133/depthwise_conv2d_1729/BiasAdd (1.61m/1.61m flops)\n",
      "  model_133/conv2d_1862/BiasAdd (1.61m/1.61m flops)\n",
      "  model_133/batch_normalization_3601/FusedBatchNormV3 (1.49m/1.49m flops)\n",
      "  model_133/batch_normalization_3597/FusedBatchNormV3 (953.57k/953.57k flops)\n",
      "  model_133/batch_normalization_3599/FusedBatchNormV3 (866.36k/866.36k flops)\n",
      "  model_133/batch_normalization_3600/FusedBatchNormV3 (866.36k/866.36k flops)\n",
      "  model_133/batch_normalization_3596/FusedBatchNormV3 (803.01k/803.01k flops)\n",
      "  model_133/batch_normalization_3595/FusedBatchNormV3 (803.01k/803.01k flops)\n",
      "  model_133/batch_normalization_3594/FusedBatchNormV3 (803.01k/803.01k flops)\n",
      "  model_133/batch_normalization_3608/FusedBatchNormV3 (790.15k/790.15k flops)\n",
      "  model_133/batch_normalization_3607/FusedBatchNormV3 (790.15k/790.15k flops)\n",
      "  model_133/batch_normalization_3611/FusedBatchNormV3 (787.00k/787.00k flops)\n",
      "  model_133/batch_normalization_3610/FusedBatchNormV3 (787.00k/787.00k flops)\n",
      "  model_133/batch_normalization_3612/FusedBatchNormV3 (787.00k/787.00k flops)\n",
      "  model_133/batch_normalization_3609/FusedBatchNormV3 (787.00k/787.00k flops)\n",
      "  model_133/batch_normalization_3606/FusedBatchNormV3 (777.56k/777.56k flops)\n",
      "  model_133/batch_normalization_3605/FusedBatchNormV3 (777.56k/777.56k flops)\n",
      "  model_133/batch_normalization_3613/FusedBatchNormV3 (771.26k/771.26k flops)\n",
      "  model_133/batch_normalization_3603/FusedBatchNormV3 (752.37k/752.37k flops)\n",
      "  model_133/batch_normalization_3604/FusedBatchNormV3 (752.37k/752.37k flops)\n",
      "  model_133/conv2d_1867/BiasAdd (746.37k/746.37k flops)\n",
      "  model_133/depthwise_conv2d_1741/depthwise (680.90k/680.90k flops)\n",
      "  model_133/conv2d_1865/BiasAdd (476.67k/476.67k flops)\n",
      "  model_133/conv2d_1866/BiasAdd (432.77k/432.77k flops)\n",
      "  model_133/depthwise_conv2d_1733/BiasAdd (432.77k/432.77k flops)\n",
      "  model_133/conv2d_1864/BiasAdd (401.41k/401.41k flops)\n",
      "  model_133/depthwise_conv2d_1731/BiasAdd (401.41k/401.41k flops)\n",
      "  model_133/depthwise_conv2d_1730/BiasAdd (401.41k/401.41k flops)\n",
      "  model_133/depthwise_conv2d_1737/BiasAdd (393.57k/393.57k flops)\n",
      "  model_133/conv2d_1870/BiasAdd (393.57k/393.57k flops)\n",
      "  model_133/conv2d_1871/BiasAdd (392.00k/392.00k flops)\n",
      "  model_133/depthwise_conv2d_1738/BiasAdd (392.00k/392.00k flops)\n",
      "  model_133/conv2d_1872/BiasAdd (392.00k/392.00k flops)\n",
      "  model_133/depthwise_conv2d_1739/BiasAdd (392.00k/392.00k flops)\n",
      "  model_133/conv2d_1869/BiasAdd (387.30k/387.30k flops)\n",
      "  model_133/depthwise_conv2d_1736/BiasAdd (387.30k/387.30k flops)\n",
      "  model_133/conv2d_1873/BiasAdd (384.16k/384.16k flops)\n",
      "  model_133/conv2d_1868/BiasAdd (374.75k/374.75k flops)\n",
      "  model_133/depthwise_conv2d_1735/BiasAdd (374.75k/374.75k flops)\n",
      "  model_133/batch_normalization_3602/FusedBatchNormV3 (374.61k/374.61k flops)\n",
      "  model_133/batch_normalization_3615/FusedBatchNormV3 (307.26k/307.26k flops)\n",
      "  model_133/batch_normalization_3598/FusedBatchNormV3 (238.56k/238.56k flops)\n",
      "  model_133/batch_normalization_3614/FusedBatchNormV3 (195.02k/195.02k flops)\n",
      "  model_133/depthwise_conv2d_1734/BiasAdd (186.59k/186.59k flops)\n",
      "  model_133/conv2d_1874/BiasAdd (151.31k/151.31k flops)\n",
      "  model_133/depthwise_conv2d_1732/BiasAdd (119.17k/119.17k flops)\n",
      "  model_133/depthwise_conv2d_1740/BiasAdd (96.04k/96.04k flops)\n",
      "  model_133/batch_normalization_3617/FusedBatchNormV3 (85.90k/85.90k flops)\n",
      "  model_133/batch_normalization_3616/FusedBatchNormV3 (80.29k/80.29k flops)\n",
      "  model_133/global_average_pooling2d_133/Mean (40.47k/40.47k flops)\n",
      "  model_133/conv2d_1875/BiasAdd (40.47k/40.47k flops)\n",
      "  model_133/depthwise_conv2d_1741/BiasAdd (37.83k/37.83k flops)\n",
      "  model_133/dense_133/MatMul (16.52k/16.52k flops)\n",
      "  model_133/dense_133/Softmax (50/50 flops)\n",
      "  model_133/dense_133/BiasAdd (10/10 flops)\n",
      "\n",
      "======================End of Report==========================\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "191.6543\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-30 13:41:48.102720: I tensorflow/core/grappler/devices.cc:66] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0\n",
      "2022-04-30 13:41:48.102835: I tensorflow/core/grappler/clusters/single_machine.cc:357] Starting new session\n",
      "2022-04-30 13:41:48.107085: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:1137] Optimization results for grappler item: graph_to_optimize\n",
      "  function_optimizer: function_optimizer did nothing. time = 0.005ms.\n",
      "  function_optimizer: function_optimizer did nothing. time = 0.001ms.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=========================Options=============================\n",
      "-max_depth                  10000\n",
      "-min_bytes                  0\n",
      "-min_peak_bytes             0\n",
      "-min_residual_bytes         0\n",
      "-min_output_bytes           0\n",
      "-min_micros                 0\n",
      "-min_accelerator_micros     0\n",
      "-min_cpu_micros             0\n",
      "-min_params                 0\n",
      "-min_float_ops              1\n",
      "-min_occurrence             0\n",
      "-step                       -1\n",
      "-order_by                   float_ops\n",
      "-account_type_regexes       .*\n",
      "-start_name_regexes         .*\n",
      "-trim_name_regexes          \n",
      "-show_name_regexes          .*\n",
      "-hide_name_regexes          \n",
      "-account_displayed_op_only  true\n",
      "-select                     float_ops\n",
      "-output                     stdout:\n",
      "\n",
      "==================Model Analysis Report======================\n",
      "\n",
      "Doc:\n",
      "scope: The nodes in the model graph are organized by their names, which is hierarchical like filesystem.\n",
      "flops: Number of float operations. Note: Please read the implementation for the math behind it.\n",
      "\n",
      "Profile:\n",
      "node name | # float_ops\n",
      "_TFProfRoot (--/2.95b flops)\n",
      "  model_134/conv2d_1885/Conv2D (347.49m/347.49m flops)\n",
      "  model_134/conv2d_1887/Conv2D (308.29m/308.29m flops)\n",
      "  model_134/conv2d_1886/Conv2D (303.30m/303.30m flops)\n",
      "  model_134/conv2d_1879/Conv2D (289.01m/289.01m flops)\n",
      "  model_134/conv2d_1884/Conv2D (281.71m/281.71m flops)\n",
      "  model_134/conv2d_1883/Conv2D (238.47m/238.47m flops)\n",
      "  model_134/conv2d_1881/Conv2D (224.99m/224.99m flops)\n",
      "  model_134/conv2d_1888/Conv2D (178.93m/178.93m flops)\n",
      "  model_134/conv2d_1882/Conv2D (142.84m/142.84m flops)\n",
      "  model_134/conv2d_1877/Conv2D (128.45m/128.45m flops)\n",
      "  model_134/conv2d_1880/Conv2D (114.40m/114.40m flops)\n",
      "  model_134/conv2d_1878/Conv2D (96.34m/96.34m flops)\n",
      "  model_134/conv2d_1889/Conv2D (88.02m/88.02m flops)\n",
      "  model_134/conv2d_1876/Conv2D (51.38m/51.38m flops)\n",
      "  model_134/depthwise_conv2d_1742/depthwise (28.90m/28.90m flops)\n",
      "  model_134/depthwise_conv2d_1744/depthwise (21.68m/21.68m flops)\n",
      "  model_134/depthwise_conv2d_1743/depthwise (9.03m/9.03m flops)\n",
      "  model_134/depthwise_conv2d_1746/depthwise (8.58m/8.58m flops)\n",
      "  model_134/depthwise_conv2d_1751/depthwise (6.86m/6.86m flops)\n",
      "  model_134/depthwise_conv2d_1745/depthwise (6.77m/6.77m flops)\n",
      "  model_134/depthwise_conv2d_1750/depthwise (6.44m/6.44m flops)\n",
      "  model_134/depthwise_conv2d_1752/depthwise (5.62m/5.62m flops)\n",
      "  model_134/depthwise_conv2d_1749/depthwise (5.56m/5.56m flops)\n",
      "  model_134/depthwise_conv2d_1748/depthwise (5.45m/5.45m flops)\n",
      "  model_134/batch_normalization_3620/FusedBatchNormV3 (4.01m/4.01m flops)\n",
      "  model_134/depthwise_conv2d_1747/depthwise (3.33m/3.33m flops)\n",
      "  model_134/batch_normalization_3619/FusedBatchNormV3 (3.21m/3.21m flops)\n",
      "  model_134/batch_normalization_3618/FusedBatchNormV3 (3.21m/3.21m flops)\n",
      "  model_134/batch_normalization_3624/FusedBatchNormV3 (3.01m/3.01m flops)\n",
      "  model_134/batch_normalization_3622/FusedBatchNormV3 (2.41m/2.41m flops)\n",
      "  model_134/batch_normalization_3623/FusedBatchNormV3 (2.41m/2.41m flops)\n",
      "  model_134/conv2d_1877/BiasAdd (2.01m/2.01m flops)\n",
      "  model_134/depthwise_conv2d_1753/depthwise (1.74m/1.74m flops)\n",
      "  model_134/conv2d_1876/BiasAdd (1.61m/1.61m flops)\n",
      "  model_134/depthwise_conv2d_1742/BiasAdd (1.61m/1.61m flops)\n",
      "  model_134/conv2d_1879/BiasAdd (1.51m/1.51m flops)\n",
      "  model_134/batch_normalization_3628/FusedBatchNormV3 (1.48m/1.48m flops)\n",
      "  model_134/depthwise_conv2d_1744/BiasAdd (1.20m/1.20m flops)\n",
      "  model_134/conv2d_1878/BiasAdd (1.20m/1.20m flops)\n",
      "  model_134/batch_normalization_3621/FusedBatchNormV3 (1.00m/1.00m flops)\n",
      "  model_134/batch_normalization_3626/FusedBatchNormV3 (954.26k/954.26k flops)\n",
      "  model_134/batch_normalization_3627/FusedBatchNormV3 (954.26k/954.26k flops)\n",
      "  model_134/depthwise_conv2d_1754/depthwise (814.97k/814.97k flops)\n",
      "  model_134/batch_normalization_3640/FusedBatchNormV3 (777.56k/777.56k flops)\n",
      "  model_134/batch_normalization_3637/FusedBatchNormV3 (764.96k/764.96k flops)\n",
      "  model_134/batch_normalization_3636/FusedBatchNormV3 (764.96k/764.96k flops)\n",
      "  model_134/batch_normalization_3625/FusedBatchNormV3 (753.36k/753.36k flops)\n",
      "  model_134/conv2d_1881/BiasAdd (740.10k/740.10k flops)\n",
      "  model_134/batch_normalization_3634/FusedBatchNormV3 (717.74k/717.74k flops)\n",
      "  model_134/batch_normalization_3635/FusedBatchNormV3 (717.74k/717.74k flops)\n",
      "  model_134/batch_normalization_3638/FusedBatchNormV3 (626.45k/626.45k flops)\n",
      "  model_134/batch_normalization_3639/FusedBatchNormV3 (626.45k/626.45k flops)\n",
      "  model_134/batch_normalization_3633/FusedBatchNormV3 (620.16k/620.16k flops)\n",
      "  model_134/batch_normalization_3632/FusedBatchNormV3 (620.16k/620.16k flops)\n",
      "  model_134/batch_normalization_3631/FusedBatchNormV3 (607.56k/607.56k flops)\n",
      "  model_134/batch_normalization_3630/FusedBatchNormV3 (607.56k/607.56k flops)\n",
      "  model_134/depthwise_conv2d_1743/BiasAdd (501.76k/501.76k flops)\n",
      "  model_134/conv2d_1880/BiasAdd (476.67k/476.67k flops)\n",
      "  model_134/depthwise_conv2d_1746/BiasAdd (476.67k/476.67k flops)\n",
      "  model_134/conv2d_1887/BiasAdd (387.30k/387.30k flops)\n",
      "  model_134/depthwise_conv2d_1751/BiasAdd (381.02k/381.02k flops)\n",
      "  model_134/conv2d_1885/BiasAdd (381.02k/381.02k flops)\n",
      "  model_134/depthwise_conv2d_1745/BiasAdd (376.32k/376.32k flops)\n",
      "  model_134/batch_normalization_3629/FusedBatchNormV3 (371.46k/371.46k flops)\n",
      "  model_134/batch_normalization_3642/FusedBatchNormV3 (367.75k/367.75k flops)\n",
      "  model_134/conv2d_1884/BiasAdd (357.50k/357.50k flops)\n",
      "  model_134/depthwise_conv2d_1750/BiasAdd (357.50k/357.50k flops)\n",
      "  model_134/depthwise_conv2d_1752/BiasAdd (312.03k/312.03k flops)\n",
      "  model_134/conv2d_1886/BiasAdd (312.03k/312.03k flops)\n",
      "  model_134/depthwise_conv2d_1749/BiasAdd (308.90k/308.90k flops)\n",
      "  model_134/conv2d_1883/BiasAdd (308.90k/308.90k flops)\n",
      "  model_134/depthwise_conv2d_1748/BiasAdd (302.62k/302.62k flops)\n",
      "  model_134/conv2d_1882/BiasAdd (302.62k/302.62k flops)\n",
      "  model_134/batch_normalization_3641/FusedBatchNormV3 (196.61k/196.61k flops)\n",
      "  model_134/depthwise_conv2d_1747/BiasAdd (185.02k/185.02k flops)\n",
      "  model_134/conv2d_1888/BiasAdd (181.10k/181.10k flops)\n",
      "  model_134/batch_normalization_3644/FusedBatchNormV3 (101.09k/101.09k flops)\n",
      "  model_134/depthwise_conv2d_1753/BiasAdd (96.82k/96.82k flops)\n",
      "  model_134/batch_normalization_3643/FusedBatchNormV3 (96.10k/96.10k flops)\n",
      "  model_134/global_average_pooling2d_134/Mean (47.63k/47.63k flops)\n",
      "  model_134/conv2d_1889/BiasAdd (47.63k/47.63k flops)\n",
      "  model_134/depthwise_conv2d_1754/BiasAdd (45.28k/45.28k flops)\n",
      "  model_134/dense_134/MatMul (19.44k/19.44k flops)\n",
      "  model_134/dense_134/Softmax (50/50 flops)\n",
      "  model_134/dense_134/BiasAdd (10/10 flops)\n",
      "\n",
      "======================End of Report==========================\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "188.972972\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-30 13:41:49.158378: I tensorflow/core/grappler/devices.cc:66] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0\n",
      "2022-04-30 13:41:49.158495: I tensorflow/core/grappler/clusters/single_machine.cc:357] Starting new session\n",
      "2022-04-30 13:41:49.163691: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:1137] Optimization results for grappler item: graph_to_optimize\n",
      "  function_optimizer: function_optimizer did nothing. time = 0.005ms.\n",
      "  function_optimizer: function_optimizer did nothing. time = 0.001ms.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=========================Options=============================\n",
      "-max_depth                  10000\n",
      "-min_bytes                  0\n",
      "-min_peak_bytes             0\n",
      "-min_residual_bytes         0\n",
      "-min_output_bytes           0\n",
      "-min_micros                 0\n",
      "-min_accelerator_micros     0\n",
      "-min_cpu_micros             0\n",
      "-min_params                 0\n",
      "-min_float_ops              1\n",
      "-min_occurrence             0\n",
      "-step                       -1\n",
      "-order_by                   float_ops\n",
      "-account_type_regexes       .*\n",
      "-start_name_regexes         .*\n",
      "-trim_name_regexes          \n",
      "-show_name_regexes          .*\n",
      "-hide_name_regexes          \n",
      "-account_displayed_op_only  true\n",
      "-select                     float_ops\n",
      "-output                     stdout:\n",
      "\n",
      "==================Model Analysis Report======================\n",
      "\n",
      "Doc:\n",
      "scope: The nodes in the model graph are organized by their names, which is hierarchical like filesystem.\n",
      "flops: Number of float operations. Note: Please read the implementation for the math behind it.\n",
      "\n",
      "Profile:\n",
      "node name | # float_ops\n",
      "_TFProfRoot (--/2.51b flops)\n",
      "  model_135/conv2d_1898/Conv2D (277.30m/277.30m flops)\n",
      "  model_135/conv2d_1897/Conv2D (264.91m/264.91m flops)\n",
      "  model_135/conv2d_1901/Conv2D (262.84m/262.84m flops)\n",
      "  model_135/conv2d_1900/Conv2D (261.40m/261.40m flops)\n",
      "  model_135/conv2d_1899/Conv2D (204.33m/204.33m flops)\n",
      "  model_135/conv2d_1893/Conv2D (193.38m/193.38m flops)\n",
      "  model_135/conv2d_1891/Conv2D (186.25m/186.25m flops)\n",
      "  model_135/conv2d_1895/Conv2D (156.12m/156.12m flops)\n",
      "  model_135/conv2d_1896/Conv2D (136.21m/136.21m flops)\n",
      "  model_135/conv2d_1892/Conv2D (119.32m/119.32m flops)\n",
      "  model_135/conv2d_1902/Conv2D (111.33m/111.33m flops)\n",
      "  model_135/conv2d_1903/Conv2D (73.01m/73.01m flops)\n",
      "  model_135/conv2d_1894/Conv2D (57.78m/57.78m flops)\n",
      "  model_135/conv2d_1890/Conv2D (51.38m/51.38m flops)\n",
      "  model_135/depthwise_conv2d_1755/depthwise (28.90m/28.90m flops)\n",
      "  model_135/depthwise_conv2d_1757/depthwise (18.51m/18.51m flops)\n",
      "  model_135/depthwise_conv2d_1756/depthwise (13.10m/13.10m flops)\n",
      "  model_135/depthwise_conv2d_1762/depthwise (6.97m/6.97m flops)\n",
      "  model_135/depthwise_conv2d_1765/depthwise (6.46m/6.46m flops)\n",
      "  model_135/batch_normalization_3647/FusedBatchNormV3 (5.82m/5.82m flops)\n",
      "  model_135/depthwise_conv2d_1759/depthwise (5.53m/5.53m flops)\n",
      "  model_135/depthwise_conv2d_1758/depthwise (5.31m/5.31m flops)\n",
      "  model_135/depthwise_conv2d_1764/depthwise (5.14m/5.14m flops)\n",
      "  model_135/depthwise_conv2d_1763/depthwise (5.05m/5.05m flops)\n",
      "  model_135/depthwise_conv2d_1761/depthwise (4.83m/4.83m flops)\n",
      "  model_135/depthwise_conv2d_1760/depthwise (3.58m/3.58m flops)\n",
      "  model_135/batch_normalization_3646/FusedBatchNormV3 (3.21m/3.21m flops)\n",
      "  model_135/batch_normalization_3645/FusedBatchNormV3 (3.21m/3.21m flops)\n",
      "  model_135/conv2d_1891/BiasAdd (2.91m/2.91m flops)\n",
      "  model_135/batch_normalization_3651/FusedBatchNormV3 (2.36m/2.36m flops)\n",
      "  model_135/batch_normalization_3649/FusedBatchNormV3 (2.06m/2.06m flops)\n",
      "  model_135/batch_normalization_3650/FusedBatchNormV3 (2.06m/2.06m flops)\n",
      "  model_135/conv2d_1890/BiasAdd (1.61m/1.61m flops)\n",
      "  model_135/depthwise_conv2d_1755/BiasAdd (1.61m/1.61m flops)\n",
      "  model_135/batch_normalization_3655/FusedBatchNormV3 (1.59m/1.59m flops)\n",
      "  model_135/batch_normalization_3648/FusedBatchNormV3 (1.46m/1.46m flops)\n",
      "  model_135/depthwise_conv2d_1766/depthwise (1.29m/1.29m flops)\n",
      "  model_135/conv2d_1893/BiasAdd (1.18m/1.18m flops)\n",
      "  model_135/conv2d_1892/BiasAdd (1.03m/1.03m flops)\n",
      "  model_135/depthwise_conv2d_1757/BiasAdd (1.03m/1.03m flops)\n",
      "  model_135/conv2d_1895/BiasAdd (796.54k/796.54k flops)\n",
      "  model_135/batch_normalization_3659/FusedBatchNormV3 (777.56k/777.56k flops)\n",
      "  model_135/batch_normalization_3660/FusedBatchNormV3 (777.56k/777.56k flops)\n",
      "  model_135/depthwise_conv2d_1756/BiasAdd (727.55k/727.55k flops)\n",
      "  model_135/batch_normalization_3666/FusedBatchNormV3 (720.89k/720.89k flops)\n",
      "  model_135/batch_normalization_3665/FusedBatchNormV3 (720.89k/720.89k flops)\n",
      "  model_135/depthwise_conv2d_1767/depthwise (684.43k/684.43k flops)\n",
      "  model_135/batch_normalization_3654/FusedBatchNormV3 (615.24k/615.24k flops)\n",
      "  model_135/batch_normalization_3653/FusedBatchNormV3 (615.24k/615.24k flops)\n",
      "  model_135/batch_normalization_3652/FusedBatchNormV3 (590.13k/590.13k flops)\n",
      "  model_135/batch_normalization_3667/FusedBatchNormV3 (576.08k/576.08k flops)\n",
      "  model_135/batch_normalization_3663/FusedBatchNormV3 (572.94k/572.94k flops)\n",
      "  model_135/batch_normalization_3664/FusedBatchNormV3 (572.94k/572.94k flops)\n",
      "  model_135/batch_normalization_3661/FusedBatchNormV3 (563.49k/563.49k flops)\n",
      "  model_135/batch_normalization_3662/FusedBatchNormV3 (563.49k/563.49k flops)\n",
      "  model_135/batch_normalization_3658/FusedBatchNormV3 (538.31k/538.31k flops)\n",
      "  model_135/batch_normalization_3657/FusedBatchNormV3 (538.31k/538.31k flops)\n",
      "  model_135/batch_normalization_3656/FusedBatchNormV3 (399.80k/399.80k flops)\n",
      "  model_135/depthwise_conv2d_1762/BiasAdd (387.30k/387.30k flops)\n",
      "  model_135/conv2d_1897/BiasAdd (387.30k/387.30k flops)\n",
      "  model_135/conv2d_1900/BiasAdd (359.07k/359.07k flops)\n",
      "  model_135/depthwise_conv2d_1765/BiasAdd (359.07k/359.07k flops)\n",
      "  model_135/batch_normalization_3669/FusedBatchNormV3 (308.85k/308.85k flops)\n",
      "  model_135/depthwise_conv2d_1759/BiasAdd (307.33k/307.33k flops)\n",
      "  model_135/conv2d_1894/BiasAdd (307.33k/307.33k flops)\n",
      "  model_135/depthwise_conv2d_1758/BiasAdd (294.78k/294.78k flops)\n",
      "  model_135/conv2d_1901/BiasAdd (286.94k/286.94k flops)\n",
      "  model_135/conv2d_1899/BiasAdd (285.38k/285.38k flops)\n",
      "  model_135/depthwise_conv2d_1764/BiasAdd (285.38k/285.38k flops)\n",
      "  model_135/conv2d_1898/BiasAdd (280.67k/280.67k flops)\n",
      "  model_135/depthwise_conv2d_1763/BiasAdd (280.67k/280.67k flops)\n",
      "  model_135/depthwise_conv2d_1761/BiasAdd (268.13k/268.13k flops)\n",
      "  model_135/conv2d_1896/BiasAdd (268.13k/268.13k flops)\n",
      "  model_135/depthwise_conv2d_1760/BiasAdd (199.14k/199.14k flops)\n",
      "  model_135/conv2d_1902/BiasAdd (152.10k/152.10k flops)\n",
      "  model_135/batch_normalization_3668/FusedBatchNormV3 (145.67k/145.67k flops)\n",
      "  model_135/batch_normalization_3671/FusedBatchNormV3 (99.84k/99.84k flops)\n",
      "  model_135/batch_normalization_3670/FusedBatchNormV3 (80.70k/80.70k flops)\n",
      "  model_135/depthwise_conv2d_1766/BiasAdd (71.74k/71.74k flops)\n",
      "  model_135/global_average_pooling2d_135/Mean (47.04k/47.04k flops)\n",
      "  model_135/conv2d_1903/BiasAdd (47.04k/47.04k flops)\n",
      "  model_135/depthwise_conv2d_1767/BiasAdd (38.02k/38.02k flops)\n",
      "  model_135/dense_135/MatMul (19.20k/19.20k flops)\n",
      "  model_135/dense_135/Softmax (50/50 flops)\n",
      "  model_135/dense_135/BiasAdd (10/10 flops)\n",
      "\n",
      "======================End of Report==========================\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "190.312484\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-30 13:41:50.110687: I tensorflow/core/grappler/devices.cc:66] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0\n",
      "2022-04-30 13:41:50.110815: I tensorflow/core/grappler/clusters/single_machine.cc:357] Starting new session\n",
      "2022-04-30 13:41:50.115231: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:1137] Optimization results for grappler item: graph_to_optimize\n",
      "  function_optimizer: function_optimizer did nothing. time = 0.005ms.\n",
      "  function_optimizer: function_optimizer did nothing. time = 0.001ms.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=========================Options=============================\n",
      "-max_depth                  10000\n",
      "-min_bytes                  0\n",
      "-min_peak_bytes             0\n",
      "-min_residual_bytes         0\n",
      "-min_output_bytes           0\n",
      "-min_micros                 0\n",
      "-min_accelerator_micros     0\n",
      "-min_cpu_micros             0\n",
      "-min_params                 0\n",
      "-min_float_ops              1\n",
      "-min_occurrence             0\n",
      "-step                       -1\n",
      "-order_by                   float_ops\n",
      "-account_type_regexes       .*\n",
      "-start_name_regexes         .*\n",
      "-trim_name_regexes          \n",
      "-show_name_regexes          .*\n",
      "-hide_name_regexes          \n",
      "-account_displayed_op_only  true\n",
      "-select                     float_ops\n",
      "-output                     stdout:\n",
      "\n",
      "==================Model Analysis Report======================\n",
      "\n",
      "Doc:\n",
      "scope: The nodes in the model graph are organized by their names, which is hierarchical like filesystem.\n",
      "flops: Number of float operations. Note: Please read the implementation for the math behind it.\n",
      "\n",
      "Profile:\n",
      "node name | # float_ops\n",
      "_TFProfRoot (--/2.70b flops)\n",
      "  model_136/conv2d_1913/Conv2D (322.56m/322.56m flops)\n",
      "  model_136/conv2d_1915/Conv2D (278.61m/278.61m flops)\n",
      "  model_136/conv2d_1914/Conv2D (273.57m/273.57m flops)\n",
      "  model_136/conv2d_1909/Conv2D (246.87m/246.87m flops)\n",
      "  model_136/conv2d_1907/Conv2D (242.85m/242.85m flops)\n",
      "  model_136/conv2d_1912/Conv2D (236.35m/236.35m flops)\n",
      "  model_136/conv2d_1916/Conv2D (162.52m/162.52m flops)\n",
      "  model_136/conv2d_1905/Conv2D (154.14m/154.14m flops)\n",
      "  model_136/conv2d_1911/Conv2D (150.58m/150.58m flops)\n",
      "  model_136/conv2d_1910/Conv2D (116.49m/116.49m flops)\n",
      "  model_136/conv2d_1908/Conv2D (110.39m/110.39m flops)\n",
      "  model_136/conv2d_1906/Conv2D (105.97m/105.97m flops)\n",
      "  model_136/conv2d_1917/Conv2D (89.35m/89.35m flops)\n",
      "  model_136/conv2d_1904/Conv2D (51.38m/51.38m flops)\n",
      "  model_136/depthwise_conv2d_1768/depthwise (28.90m/28.90m flops)\n",
      "  model_136/depthwise_conv2d_1770/depthwise (19.87m/19.87m flops)\n",
      "  model_136/depthwise_conv2d_1769/depthwise (10.84m/10.84m flops)\n",
      "  model_136/depthwise_conv2d_1772/depthwise (9.03m/9.03m flops)\n",
      "  model_136/depthwise_conv2d_1776/depthwise (6.69m/6.69m flops)\n",
      "  model_136/depthwise_conv2d_1771/depthwise (6.21m/6.21m flops)\n",
      "  model_136/depthwise_conv2d_1777/depthwise (6.12m/6.12m flops)\n",
      "  model_136/depthwise_conv2d_1778/depthwise (5.67m/5.67m flops)\n",
      "  model_136/batch_normalization_3674/FusedBatchNormV3 (4.82m/4.82m flops)\n",
      "  model_136/depthwise_conv2d_1775/depthwise (4.49m/4.49m flops)\n",
      "  model_136/depthwise_conv2d_1774/depthwise (4.26m/4.26m flops)\n",
      "  model_136/depthwise_conv2d_1773/depthwise (3.47m/3.47m flops)\n",
      "  model_136/batch_normalization_3673/FusedBatchNormV3 (3.21m/3.21m flops)\n",
      "  model_136/batch_normalization_3672/FusedBatchNormV3 (3.21m/3.21m flops)\n",
      "  model_136/batch_normalization_3678/FusedBatchNormV3 (2.76m/2.76m flops)\n",
      "  model_136/conv2d_1905/BiasAdd (2.41m/2.41m flops)\n",
      "  model_136/batch_normalization_3676/FusedBatchNormV3 (2.21m/2.21m flops)\n",
      "  model_136/batch_normalization_3677/FusedBatchNormV3 (2.21m/2.21m flops)\n",
      "  model_136/conv2d_1904/BiasAdd (1.61m/1.61m flops)\n",
      "  model_136/depthwise_conv2d_1768/BiasAdd (1.61m/1.61m flops)\n",
      "  model_136/depthwise_conv2d_1779/depthwise (1.56m/1.56m flops)\n",
      "  model_136/batch_normalization_3682/FusedBatchNormV3 (1.54m/1.54m flops)\n",
      "  model_136/conv2d_1907/BiasAdd (1.38m/1.38m flops)\n",
      "  model_136/batch_normalization_3675/FusedBatchNormV3 (1.20m/1.20m flops)\n",
      "  model_136/depthwise_conv2d_1770/BiasAdd (1.10m/1.10m flops)\n",
      "  model_136/conv2d_1906/BiasAdd (1.10m/1.10m flops)\n",
      "  model_136/batch_normalization_3681/FusedBatchNormV3 (1.00m/1.00m flops)\n",
      "  model_136/batch_normalization_3680/FusedBatchNormV3 (1.00m/1.00m flops)\n",
      "  model_136/depthwise_conv2d_1780/depthwise (827.32k/827.32k flops)\n",
      "  model_136/conv2d_1909/BiasAdd (771.46k/771.46k flops)\n",
      "  model_136/batch_normalization_3689/FusedBatchNormV3 (746.08k/746.08k flops)\n",
      "  model_136/batch_normalization_3688/FusedBatchNormV3 (746.08k/746.08k flops)\n",
      "  model_136/batch_normalization_3694/FusedBatchNormV3 (695.71k/695.71k flops)\n",
      "  model_136/batch_normalization_3679/FusedBatchNormV3 (690.58k/690.58k flops)\n",
      "  model_136/batch_normalization_3691/FusedBatchNormV3 (683.12k/683.12k flops)\n",
      "  model_136/batch_normalization_3690/FusedBatchNormV3 (683.12k/683.12k flops)\n",
      "  model_136/batch_normalization_3692/FusedBatchNormV3 (632.75k/632.75k flops)\n",
      "  model_136/batch_normalization_3693/FusedBatchNormV3 (632.75k/632.75k flops)\n",
      "  model_136/depthwise_conv2d_1769/BiasAdd (602.11k/602.11k flops)\n",
      "  model_136/depthwise_conv2d_1772/BiasAdd (501.76k/501.76k flops)\n",
      "  model_136/conv2d_1908/BiasAdd (501.76k/501.76k flops)\n",
      "  model_136/batch_normalization_3686/FusedBatchNormV3 (500.53k/500.53k flops)\n",
      "  model_136/batch_normalization_3687/FusedBatchNormV3 (500.53k/500.53k flops)\n",
      "  model_136/batch_normalization_3684/FusedBatchNormV3 (475.35k/475.35k flops)\n",
      "  model_136/batch_normalization_3685/FusedBatchNormV3 (475.35k/475.35k flops)\n",
      "  model_136/batch_normalization_3683/FusedBatchNormV3 (387.20k/387.20k flops)\n",
      "  model_136/batch_normalization_3696/FusedBatchNormV3 (373.32k/373.32k flops)\n",
      "  model_136/depthwise_conv2d_1776/BiasAdd (371.62k/371.62k flops)\n",
      "  model_136/conv2d_1912/BiasAdd (371.62k/371.62k flops)\n",
      "  model_136/conv2d_1915/BiasAdd (346.53k/346.53k flops)\n",
      "  model_136/depthwise_conv2d_1771/BiasAdd (344.96k/344.96k flops)\n",
      "  model_136/conv2d_1913/BiasAdd (340.26k/340.26k flops)\n",
      "  model_136/depthwise_conv2d_1777/BiasAdd (340.26k/340.26k flops)\n",
      "  model_136/conv2d_1914/BiasAdd (315.17k/315.17k flops)\n",
      "  model_136/depthwise_conv2d_1778/BiasAdd (315.17k/315.17k flops)\n",
      "  model_136/conv2d_1911/BiasAdd (249.31k/249.31k flops)\n",
      "  model_136/depthwise_conv2d_1775/BiasAdd (249.31k/249.31k flops)\n",
      "  model_136/depthwise_conv2d_1774/BiasAdd (236.77k/236.77k flops)\n",
      "  model_136/conv2d_1910/BiasAdd (236.77k/236.77k flops)\n",
      "  model_136/depthwise_conv2d_1773/BiasAdd (192.86k/192.86k flops)\n",
      "  model_136/conv2d_1916/BiasAdd (183.85k/183.85k flops)\n",
      "  model_136/batch_normalization_3695/FusedBatchNormV3 (175.92k/175.92k flops)\n",
      "  model_136/batch_normalization_3698/FusedBatchNormV3 (101.09k/101.09k flops)\n",
      "  model_136/batch_normalization_3697/FusedBatchNormV3 (97.55k/97.55k flops)\n",
      "  model_136/depthwise_conv2d_1779/BiasAdd (86.63k/86.63k flops)\n",
      "  model_136/global_average_pooling2d_136/Mean (47.63k/47.63k flops)\n",
      "  model_136/conv2d_1917/BiasAdd (47.63k/47.63k flops)\n",
      "  model_136/depthwise_conv2d_1780/BiasAdd (45.96k/45.96k flops)\n",
      "  model_136/dense_136/MatMul (19.44k/19.44k flops)\n",
      "  model_136/dense_136/Softmax (50/50 flops)\n",
      "  model_136/dense_136/BiasAdd (10/10 flops)\n",
      "\n",
      "======================End of Report==========================\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "213.87846\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-30 13:41:51.169020: I tensorflow/core/grappler/devices.cc:66] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0\n",
      "2022-04-30 13:41:51.169137: I tensorflow/core/grappler/clusters/single_machine.cc:357] Starting new session\n",
      "2022-04-30 13:41:51.174206: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:1137] Optimization results for grappler item: graph_to_optimize\n",
      "  function_optimizer: function_optimizer did nothing. time = 0.006ms.\n",
      "  function_optimizer: function_optimizer did nothing. time = 0.001ms.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=========================Options=============================\n",
      "-max_depth                  10000\n",
      "-min_bytes                  0\n",
      "-min_peak_bytes             0\n",
      "-min_residual_bytes         0\n",
      "-min_output_bytes           0\n",
      "-min_micros                 0\n",
      "-min_accelerator_micros     0\n",
      "-min_cpu_micros             0\n",
      "-min_params                 0\n",
      "-min_float_ops              1\n",
      "-min_occurrence             0\n",
      "-step                       -1\n",
      "-order_by                   float_ops\n",
      "-account_type_regexes       .*\n",
      "-start_name_regexes         .*\n",
      "-trim_name_regexes          \n",
      "-show_name_regexes          .*\n",
      "-hide_name_regexes          \n",
      "-account_displayed_op_only  true\n",
      "-select                     float_ops\n",
      "-output                     stdout:\n",
      "\n",
      "==================Model Analysis Report======================\n",
      "\n",
      "Doc:\n",
      "scope: The nodes in the model graph are organized by their names, which is hierarchical like filesystem.\n",
      "flops: Number of float operations. Note: Please read the implementation for the math behind it.\n",
      "\n",
      "Profile:\n",
      "node name | # float_ops\n",
      "_TFProfRoot (--/2.91b flops)\n",
      "  model_137/conv2d_1921/Conv2D (385.75m/385.75m flops)\n",
      "  model_137/conv2d_1923/Conv2D (331.69m/331.69m flops)\n",
      "  model_137/conv2d_1928/Conv2D (296.69m/296.69m flops)\n",
      "  model_137/conv2d_1926/Conv2D (231.91m/231.91m flops)\n",
      "  model_137/conv2d_1925/Conv2D (207.92m/207.92m flops)\n",
      "  model_137/conv2d_1927/Conv2D (196.44m/196.44m flops)\n",
      "  model_137/conv2d_1929/Conv2D (190.93m/190.93m flops)\n",
      "  model_137/conv2d_1919/Conv2D (186.25m/186.25m flops)\n",
      "  model_137/conv2d_1920/Conv2D (180.43m/180.43m flops)\n",
      "  model_137/conv2d_1922/Conv2D (175.77m/175.77m flops)\n",
      "  model_137/conv2d_1930/Conv2D (105.05m/105.05m flops)\n",
      "  model_137/conv2d_1924/Conv2D (95.40m/95.40m flops)\n",
      "  model_137/conv2d_1931/Conv2D (94.47m/94.47m flops)\n",
      "  model_137/conv2d_1918/Conv2D (51.38m/51.38m flops)\n",
      "  model_137/depthwise_conv2d_1781/depthwise (28.90m/28.90m flops)\n",
      "  model_137/depthwise_conv2d_1783/depthwise (28.00m/28.00m flops)\n",
      "  model_137/depthwise_conv2d_1782/depthwise (13.10m/13.10m flops)\n",
      "  model_137/depthwise_conv2d_1785/depthwise (12.76m/12.76m flops)\n",
      "  model_137/depthwise_conv2d_1788/depthwise (7.20m/7.20m flops)\n",
      "  model_137/depthwise_conv2d_1784/depthwise (7.00m/7.00m flops)\n",
      "  model_137/depthwise_conv2d_1791/depthwise (6.18m/6.18m flops)\n",
      "  model_137/depthwise_conv2d_1790/depthwise (6.10m/6.10m flops)\n",
      "  model_137/batch_normalization_3701/FusedBatchNormV3 (5.82m/5.82m flops)\n",
      "  model_137/depthwise_conv2d_1789/depthwise (4.09m/4.09m flops)\n",
      "  model_137/depthwise_conv2d_1787/depthwise (3.67m/3.67m flops)\n",
      "  model_137/depthwise_conv2d_1786/depthwise (3.30m/3.30m flops)\n",
      "  model_137/batch_normalization_3700/FusedBatchNormV3 (3.21m/3.21m flops)\n",
      "  model_137/batch_normalization_3699/FusedBatchNormV3 (3.21m/3.21m flops)\n",
      "  model_137/batch_normalization_3703/FusedBatchNormV3 (3.11m/3.11m flops)\n",
      "  model_137/batch_normalization_3704/FusedBatchNormV3 (3.11m/3.11m flops)\n",
      "  model_137/batch_normalization_3705/FusedBatchNormV3 (3.11m/3.11m flops)\n",
      "  model_137/conv2d_1919/BiasAdd (2.91m/2.91m flops)\n",
      "  model_137/conv2d_1918/BiasAdd (1.61m/1.61m flops)\n",
      "  model_137/depthwise_conv2d_1781/BiasAdd (1.61m/1.61m flops)\n",
      "  model_137/conv2d_1920/BiasAdd (1.56m/1.56m flops)\n",
      "  model_137/depthwise_conv2d_1783/BiasAdd (1.56m/1.56m flops)\n",
      "  model_137/conv2d_1921/BiasAdd (1.56m/1.56m flops)\n",
      "  model_137/batch_normalization_3709/FusedBatchNormV3 (1.47m/1.47m flops)\n",
      "  model_137/batch_normalization_3702/FusedBatchNormV3 (1.46m/1.46m flops)\n",
      "  model_137/batch_normalization_3707/FusedBatchNormV3 (1.42m/1.42m flops)\n",
      "  model_137/batch_normalization_3708/FusedBatchNormV3 (1.42m/1.42m flops)\n",
      "  model_137/depthwise_conv2d_1792/depthwise (980.78k/980.78k flops)\n",
      "  model_137/depthwise_conv2d_1793/depthwise (850.25k/850.25k flops)\n",
      "  model_137/batch_normalization_3713/FusedBatchNormV3 (802.74k/802.74k flops)\n",
      "  model_137/batch_normalization_3714/FusedBatchNormV3 (802.74k/802.74k flops)\n",
      "  model_137/batch_normalization_3706/FusedBatchNormV3 (778.47k/778.47k flops)\n",
      "  model_137/conv2d_1923/BiasAdd (733.82k/733.82k flops)\n",
      "  model_137/depthwise_conv2d_1782/BiasAdd (727.55k/727.55k flops)\n",
      "  model_137/conv2d_1922/BiasAdd (708.74k/708.74k flops)\n",
      "  model_137/depthwise_conv2d_1785/BiasAdd (708.74k/708.74k flops)\n",
      "  model_137/batch_normalization_3719/FusedBatchNormV3 (689.41k/689.41k flops)\n",
      "  model_137/batch_normalization_3720/FusedBatchNormV3 (689.41k/689.41k flops)\n",
      "  model_137/batch_normalization_3718/FusedBatchNormV3 (679.97k/679.97k flops)\n",
      "  model_137/batch_normalization_3717/FusedBatchNormV3 (679.97k/679.97k flops)\n",
      "  model_137/batch_normalization_3715/FusedBatchNormV3 (456.46k/456.46k flops)\n",
      "  model_137/batch_normalization_3716/FusedBatchNormV3 (456.46k/456.46k flops)\n",
      "  model_137/batch_normalization_3721/FusedBatchNormV3 (437.57k/437.57k flops)\n",
      "  model_137/batch_normalization_3711/FusedBatchNormV3 (409.24k/409.24k flops)\n",
      "  model_137/batch_normalization_3712/FusedBatchNormV3 (409.24k/409.24k flops)\n",
      "  model_137/depthwise_conv2d_1788/BiasAdd (399.84k/399.84k flops)\n",
      "  model_137/conv2d_1925/BiasAdd (399.84k/399.84k flops)\n",
      "  model_137/depthwise_conv2d_1784/BiasAdd (388.86k/388.86k flops)\n",
      "  model_137/batch_normalization_3723/FusedBatchNormV3 (383.67k/383.67k flops)\n",
      "  model_137/batch_normalization_3710/FusedBatchNormV3 (368.32k/368.32k flops)\n",
      "  model_137/depthwise_conv2d_1791/BiasAdd (343.39k/343.39k flops)\n",
      "  model_137/conv2d_1928/BiasAdd (343.39k/343.39k flops)\n",
      "  model_137/depthwise_conv2d_1790/BiasAdd (338.69k/338.69k flops)\n",
      "  model_137/conv2d_1927/BiasAdd (338.69k/338.69k flops)\n",
      "  model_137/conv2d_1926/BiasAdd (227.36k/227.36k flops)\n",
      "  model_137/depthwise_conv2d_1789/BiasAdd (227.36k/227.36k flops)\n",
      "  model_137/conv2d_1929/BiasAdd (217.95k/217.95k flops)\n",
      "  model_137/conv2d_1924/BiasAdd (203.84k/203.84k flops)\n",
      "  model_137/depthwise_conv2d_1787/BiasAdd (203.84k/203.84k flops)\n",
      "  model_137/conv2d_1930/BiasAdd (188.94k/188.94k flops)\n",
      "  model_137/depthwise_conv2d_1786/BiasAdd (183.46k/183.46k flops)\n",
      "  model_137/batch_normalization_3722/FusedBatchNormV3 (110.64k/110.64k flops)\n",
      "  model_137/batch_normalization_3725/FusedBatchNormV3 (104.00k/104.00k flops)\n",
      "  model_137/batch_normalization_3724/FusedBatchNormV3 (100.26k/100.26k flops)\n",
      "  model_137/depthwise_conv2d_1792/BiasAdd (54.49k/54.49k flops)\n",
      "  model_137/global_average_pooling2d_137/Mean (49.00k/49.00k flops)\n",
      "  model_137/conv2d_1931/BiasAdd (49.00k/49.00k flops)\n",
      "  model_137/depthwise_conv2d_1793/BiasAdd (47.24k/47.24k flops)\n",
      "  model_137/dense_137/MatMul (20.00k/20.00k flops)\n",
      "  model_137/dense_137/Softmax (50/50 flops)\n",
      "  model_137/dense_137/BiasAdd (10/10 flops)\n",
      "\n",
      "======================End of Report==========================\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "200.225076\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-30 13:41:52.122000: I tensorflow/core/grappler/devices.cc:66] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0\n",
      "2022-04-30 13:41:52.122118: I tensorflow/core/grappler/clusters/single_machine.cc:357] Starting new session\n",
      "2022-04-30 13:41:52.126419: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:1137] Optimization results for grappler item: graph_to_optimize\n",
      "  function_optimizer: function_optimizer did nothing. time = 0.004ms.\n",
      "  function_optimizer: function_optimizer did nothing. time = 0.001ms.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=========================Options=============================\n",
      "-max_depth                  10000\n",
      "-min_bytes                  0\n",
      "-min_peak_bytes             0\n",
      "-min_residual_bytes         0\n",
      "-min_output_bytes           0\n",
      "-min_micros                 0\n",
      "-min_accelerator_micros     0\n",
      "-min_cpu_micros             0\n",
      "-min_params                 0\n",
      "-min_float_ops              1\n",
      "-min_occurrence             0\n",
      "-step                       -1\n",
      "-order_by                   float_ops\n",
      "-account_type_regexes       .*\n",
      "-start_name_regexes         .*\n",
      "-trim_name_regexes          \n",
      "-show_name_regexes          .*\n",
      "-hide_name_regexes          \n",
      "-account_displayed_op_only  true\n",
      "-select                     float_ops\n",
      "-output                     stdout:\n",
      "\n",
      "==================Model Analysis Report======================\n",
      "\n",
      "Doc:\n",
      "scope: The nodes in the model graph are organized by their names, which is hierarchical like filesystem.\n",
      "flops: Number of float operations. Note: Please read the implementation for the math behind it.\n",
      "\n",
      "Profile:\n",
      "node name | # float_ops\n",
      "_TFProfRoot (--/3.38b flops)\n",
      "  model_138/conv2d_1940/Conv2D (385.60m/385.60m flops)\n",
      "  model_138/conv2d_1941/Conv2D (374.93m/374.93m flops)\n",
      "  model_138/conv2d_1939/Conv2D (360.21m/360.21m flops)\n",
      "  model_138/conv2d_1942/Conv2D (357.96m/357.96m flops)\n",
      "  model_138/conv2d_1943/Conv2D (349.22m/349.22m flops)\n",
      "  model_138/conv2d_1937/Conv2D (294.83m/294.83m flops)\n",
      "  model_138/conv2d_1935/Conv2D (261.02m/261.02m flops)\n",
      "  model_138/conv2d_1938/Conv2D (160.88m/160.88m flops)\n",
      "  model_138/conv2d_1944/Conv2D (157.68m/157.68m flops)\n",
      "  model_138/conv2d_1933/Conv2D (134.87m/134.87m flops)\n",
      "  model_138/conv2d_1936/Conv2D (133.07m/133.07m flops)\n",
      "  model_138/conv2d_1934/Conv2D (107.48m/107.48m flops)\n",
      "  model_138/conv2d_1945/Conv2D (81.63m/81.63m flops)\n",
      "  model_138/conv2d_1932/Conv2D (51.38m/51.38m flops)\n",
      "  model_138/depthwise_conv2d_1794/depthwise (28.90m/28.90m flops)\n",
      "  model_138/depthwise_conv2d_1796/depthwise (23.03m/23.03m flops)\n",
      "  model_138/depthwise_conv2d_1798/depthwise (11.74m/11.74m flops)\n",
      "  model_138/depthwise_conv2d_1795/depthwise (9.48m/9.48m flops)\n",
      "  model_138/depthwise_conv2d_1801/depthwise (7.14m/7.14m flops)\n",
      "  model_138/depthwise_conv2d_1803/depthwise (6.94m/6.94m flops)\n",
      "  model_138/depthwise_conv2d_1802/depthwise (6.86m/6.86m flops)\n",
      "  model_138/depthwise_conv2d_1804/depthwise (6.55m/6.55m flops)\n",
      "  model_138/depthwise_conv2d_1800/depthwise (6.41m/6.41m flops)\n",
      "  model_138/depthwise_conv2d_1797/depthwise (5.76m/5.76m flops)\n",
      "  model_138/batch_normalization_3728/FusedBatchNormV3 (4.22m/4.22m flops)\n",
      "  model_138/batch_normalization_3727/FusedBatchNormV3 (3.21m/3.21m flops)\n",
      "  model_138/batch_normalization_3726/FusedBatchNormV3 (3.21m/3.21m flops)\n",
      "  model_138/depthwise_conv2d_1799/depthwise (3.19m/3.19m flops)\n",
      "  model_138/batch_normalization_3730/FusedBatchNormV3 (2.56m/2.56m flops)\n",
      "  model_138/batch_normalization_3731/FusedBatchNormV3 (2.56m/2.56m flops)\n",
      "  model_138/batch_normalization_3732/FusedBatchNormV3 (2.56m/2.56m flops)\n",
      "  model_138/conv2d_1933/BiasAdd (2.11m/2.11m flops)\n",
      "  model_138/depthwise_conv2d_1805/depthwise (1.69m/1.69m flops)\n",
      "  model_138/conv2d_1932/BiasAdd (1.61m/1.61m flops)\n",
      "  model_138/depthwise_conv2d_1794/BiasAdd (1.61m/1.61m flops)\n",
      "  model_138/batch_normalization_3736/FusedBatchNormV3 (1.42m/1.42m flops)\n",
      "  model_138/batch_normalization_3734/FusedBatchNormV3 (1.31m/1.31m flops)\n",
      "  model_138/batch_normalization_3735/FusedBatchNormV3 (1.31m/1.31m flops)\n",
      "  model_138/conv2d_1934/BiasAdd (1.28m/1.28m flops)\n",
      "  model_138/depthwise_conv2d_1796/BiasAdd (1.28m/1.28m flops)\n",
      "  model_138/conv2d_1935/BiasAdd (1.28m/1.28m flops)\n",
      "  model_138/batch_normalization_3729/FusedBatchNormV3 (1.05m/1.05m flops)\n",
      "  model_138/batch_normalization_3740/FusedBatchNormV3 (796.44k/796.44k flops)\n",
      "  model_138/batch_normalization_3741/FusedBatchNormV3 (796.44k/796.44k flops)\n",
      "  model_138/batch_normalization_3745/FusedBatchNormV3 (774.41k/774.41k flops)\n",
      "  model_138/batch_normalization_3744/FusedBatchNormV3 (774.41k/774.41k flops)\n",
      "  model_138/batch_normalization_3743/FusedBatchNormV3 (764.96k/764.96k flops)\n",
      "  model_138/batch_normalization_3742/FusedBatchNormV3 (764.96k/764.96k flops)\n",
      "  model_138/batch_normalization_3748/FusedBatchNormV3 (755.52k/755.52k flops)\n",
      "  model_138/depthwise_conv2d_1806/depthwise (739.12k/739.12k flops)\n",
      "  model_138/batch_normalization_3747/FusedBatchNormV3 (730.34k/730.34k flops)\n",
      "  model_138/batch_normalization_3746/FusedBatchNormV3 (730.34k/730.34k flops)\n",
      "  model_138/batch_normalization_3739/FusedBatchNormV3 (714.60k/714.60k flops)\n",
      "  model_138/batch_normalization_3738/FusedBatchNormV3 (714.60k/714.60k flops)\n",
      "  model_138/conv2d_1937/BiasAdd (708.74k/708.74k flops)\n",
      "  model_138/depthwise_conv2d_1798/BiasAdd (652.29k/652.29k flops)\n",
      "  model_138/conv2d_1936/BiasAdd (652.29k/652.29k flops)\n",
      "  model_138/batch_normalization_3733/FusedBatchNormV3 (640.36k/640.36k flops)\n",
      "  model_138/depthwise_conv2d_1795/BiasAdd (526.85k/526.85k flops)\n",
      "  model_138/depthwise_conv2d_1801/BiasAdd (396.70k/396.70k flops)\n",
      "  model_138/conv2d_1939/BiasAdd (396.70k/396.70k flops)\n",
      "  model_138/conv2d_1941/BiasAdd (385.73k/385.73k flops)\n",
      "  model_138/depthwise_conv2d_1803/BiasAdd (385.73k/385.73k flops)\n",
      "  model_138/conv2d_1940/BiasAdd (381.02k/381.02k flops)\n",
      "  model_138/depthwise_conv2d_1802/BiasAdd (381.02k/381.02k flops)\n",
      "  model_138/conv2d_1943/BiasAdd (376.32k/376.32k flops)\n",
      "  model_138/conv2d_1942/BiasAdd (363.78k/363.78k flops)\n",
      "  model_138/depthwise_conv2d_1804/BiasAdd (363.78k/363.78k flops)\n",
      "  model_138/depthwise_conv2d_1800/BiasAdd (355.94k/355.94k flops)\n",
      "  model_138/conv2d_1938/BiasAdd (355.94k/355.94k flops)\n",
      "  model_138/batch_normalization_3737/FusedBatchNormV3 (355.72k/355.72k flops)\n",
      "  model_138/batch_normalization_3750/FusedBatchNormV3 (333.52k/333.52k flops)\n",
      "  model_138/depthwise_conv2d_1797/BiasAdd (319.87k/319.87k flops)\n",
      "  model_138/batch_normalization_3749/FusedBatchNormV3 (191.04k/191.04k flops)\n",
      "  model_138/depthwise_conv2d_1799/BiasAdd (177.18k/177.18k flops)\n",
      "  model_138/conv2d_1944/BiasAdd (164.25k/164.25k flops)\n",
      "  model_138/batch_normalization_3752/FusedBatchNormV3 (103.38k/103.38k flops)\n",
      "  model_138/depthwise_conv2d_1805/BiasAdd (94.08k/94.08k flops)\n",
      "  model_138/batch_normalization_3751/FusedBatchNormV3 (87.15k/87.15k flops)\n",
      "  model_138/global_average_pooling2d_138/Mean (48.71k/48.71k flops)\n",
      "  model_138/conv2d_1945/BiasAdd (48.71k/48.71k flops)\n",
      "  model_138/depthwise_conv2d_1806/BiasAdd (41.06k/41.06k flops)\n",
      "  model_138/dense_138/MatMul (19.88k/19.88k flops)\n",
      "  model_138/dense_138/Softmax (50/50 flops)\n",
      "  model_138/dense_138/BiasAdd (10/10 flops)\n",
      "\n",
      "======================End of Report==========================\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "218.2525\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-30 13:41:53.195710: I tensorflow/core/grappler/devices.cc:66] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0\n",
      "2022-04-30 13:41:53.195842: I tensorflow/core/grappler/clusters/single_machine.cc:357] Starting new session\n",
      "2022-04-30 13:41:53.201048: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:1137] Optimization results for grappler item: graph_to_optimize\n",
      "  function_optimizer: function_optimizer did nothing. time = 0.005ms.\n",
      "  function_optimizer: function_optimizer did nothing. time = 0.001ms.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=========================Options=============================\n",
      "-max_depth                  10000\n",
      "-min_bytes                  0\n",
      "-min_peak_bytes             0\n",
      "-min_residual_bytes         0\n",
      "-min_output_bytes           0\n",
      "-min_micros                 0\n",
      "-min_accelerator_micros     0\n",
      "-min_cpu_micros             0\n",
      "-min_params                 0\n",
      "-min_float_ops              1\n",
      "-min_occurrence             0\n",
      "-step                       -1\n",
      "-order_by                   float_ops\n",
      "-account_type_regexes       .*\n",
      "-start_name_regexes         .*\n",
      "-trim_name_regexes          \n",
      "-show_name_regexes          .*\n",
      "-hide_name_regexes          \n",
      "-account_displayed_op_only  true\n",
      "-select                     float_ops\n",
      "-output                     stdout:\n",
      "\n",
      "==================Model Analysis Report======================\n",
      "\n",
      "Doc:\n",
      "scope: The nodes in the model graph are organized by their names, which is hierarchical like filesystem.\n",
      "flops: Number of float operations. Note: Please read the implementation for the math behind it.\n",
      "\n",
      "Profile:\n",
      "node name | # float_ops\n",
      "_TFProfRoot (--/3.37b flops)\n",
      "  model_139/conv2d_1949/Conv2D (398.30m/398.30m flops)\n",
      "  model_139/conv2d_1956/Conv2D (374.90m/374.90m flops)\n",
      "  model_139/conv2d_1955/Conv2D (368.83m/368.83m flops)\n",
      "  model_139/conv2d_1957/Conv2D (354.76m/354.76m flops)\n",
      "  model_139/conv2d_1954/Conv2D (344.45m/344.45m flops)\n",
      "  model_139/conv2d_1953/Conv2D (307.59m/307.59m flops)\n",
      "  model_139/conv2d_1947/Conv2D (192.68m/192.68m flops)\n",
      "  model_139/conv2d_1948/Conv2D (189.67m/189.67m flops)\n",
      "  model_139/conv2d_1951/Conv2D (185.45m/185.45m flops)\n",
      "  model_139/conv2d_1950/Conv2D (132.77m/132.77m flops)\n",
      "  model_139/conv2d_1952/Conv2D (119.77m/119.77m flops)\n",
      "  model_139/conv2d_1958/Conv2D (115.98m/115.98m flops)\n",
      "  model_139/conv2d_1959/Conv2D (52.55m/52.55m flops)\n",
      "  model_139/conv2d_1946/Conv2D (51.38m/51.38m flops)\n",
      "  model_139/depthwise_conv2d_1807/depthwise (28.90m/28.90m flops)\n",
      "  model_139/depthwise_conv2d_1809/depthwise (28.45m/28.45m flops)\n",
      "  model_139/depthwise_conv2d_1808/depthwise (13.55m/13.55m flops)\n",
      "  model_139/depthwise_conv2d_1811/depthwise (9.48m/9.48m flops)\n",
      "  model_139/depthwise_conv2d_1810/depthwise (7.11m/7.11m flops)\n",
      "  model_139/depthwise_conv2d_1817/depthwise (6.97m/6.97m flops)\n",
      "  model_139/depthwise_conv2d_1815/depthwise (6.86m/6.86m flops)\n",
      "  model_139/depthwise_conv2d_1816/depthwise (6.83m/6.83m flops)\n",
      "  model_139/depthwise_conv2d_1814/depthwise (6.38m/6.38m flops)\n",
      "  model_139/depthwise_conv2d_1813/depthwise (6.12m/6.12m flops)\n",
      "  model_139/batch_normalization_3755/FusedBatchNormV3 (6.02m/6.02m flops)\n",
      "  model_139/batch_normalization_3754/FusedBatchNormV3 (3.21m/3.21m flops)\n",
      "  model_139/batch_normalization_3753/FusedBatchNormV3 (3.21m/3.21m flops)\n",
      "  model_139/batch_normalization_3757/FusedBatchNormV3 (3.16m/3.16m flops)\n",
      "  model_139/batch_normalization_3758/FusedBatchNormV3 (3.16m/3.16m flops)\n",
      "  model_139/batch_normalization_3759/FusedBatchNormV3 (3.16m/3.16m flops)\n",
      "  model_139/conv2d_1947/BiasAdd (3.01m/3.01m flops)\n",
      "  model_139/depthwise_conv2d_1812/depthwise (2.48m/2.48m flops)\n",
      "  model_139/depthwise_conv2d_1818/depthwise (1.62m/1.62m flops)\n",
      "  model_139/conv2d_1946/BiasAdd (1.61m/1.61m flops)\n",
      "  model_139/depthwise_conv2d_1807/BiasAdd (1.61m/1.61m flops)\n",
      "  model_139/conv2d_1948/BiasAdd (1.58m/1.58m flops)\n",
      "  model_139/depthwise_conv2d_1809/BiasAdd (1.58m/1.58m flops)\n",
      "  model_139/conv2d_1949/BiasAdd (1.58m/1.58m flops)\n",
      "  model_139/batch_normalization_3756/FusedBatchNormV3 (1.51m/1.51m flops)\n",
      "  model_139/batch_normalization_3763/FusedBatchNormV3 (1.10m/1.10m flops)\n",
      "  model_139/batch_normalization_3761/FusedBatchNormV3 (1.05m/1.05m flops)\n",
      "  model_139/batch_normalization_3762/FusedBatchNormV3 (1.05m/1.05m flops)\n",
      "  model_139/batch_normalization_3760/FusedBatchNormV3 (791.03k/791.03k flops)\n",
      "  model_139/batch_normalization_3774/FusedBatchNormV3 (777.56k/777.56k flops)\n",
      "  model_139/batch_normalization_3773/FusedBatchNormV3 (777.56k/777.56k flops)\n",
      "  model_139/batch_normalization_3770/FusedBatchNormV3 (764.96k/764.96k flops)\n",
      "  model_139/batch_normalization_3769/FusedBatchNormV3 (764.96k/764.96k flops)\n",
      "  model_139/batch_normalization_3772/FusedBatchNormV3 (761.82k/761.82k flops)\n",
      "  model_139/batch_normalization_3771/FusedBatchNormV3 (761.82k/761.82k flops)\n",
      "  model_139/depthwise_conv2d_1808/BiasAdd (752.64k/752.64k flops)\n",
      "  model_139/batch_normalization_3775/FusedBatchNormV3 (720.89k/720.89k flops)\n",
      "  model_139/batch_normalization_3767/FusedBatchNormV3 (711.45k/711.45k flops)\n",
      "  model_139/batch_normalization_3768/FusedBatchNormV3 (711.45k/711.45k flops)\n",
      "  model_139/batch_normalization_3766/FusedBatchNormV3 (683.12k/683.12k flops)\n",
      "  model_139/batch_normalization_3765/FusedBatchNormV3 (683.12k/683.12k flops)\n",
      "  model_139/depthwise_conv2d_1819/depthwise (569.77k/569.77k flops)\n",
      "  model_139/conv2d_1951/BiasAdd (551.94k/551.94k flops)\n",
      "  model_139/depthwise_conv2d_1811/BiasAdd (526.85k/526.85k flops)\n",
      "  model_139/conv2d_1950/BiasAdd (526.85k/526.85k flops)\n",
      "  model_139/depthwise_conv2d_1810/BiasAdd (395.14k/395.14k flops)\n",
      "  model_139/conv2d_1956/BiasAdd (387.30k/387.30k flops)\n",
      "  model_139/depthwise_conv2d_1817/BiasAdd (387.30k/387.30k flops)\n",
      "  model_139/conv2d_1954/BiasAdd (381.02k/381.02k flops)\n",
      "  model_139/depthwise_conv2d_1815/BiasAdd (381.02k/381.02k flops)\n",
      "  model_139/conv2d_1955/BiasAdd (379.46k/379.46k flops)\n",
      "  model_139/depthwise_conv2d_1816/BiasAdd (379.46k/379.46k flops)\n",
      "  model_139/conv2d_1957/BiasAdd (359.07k/359.07k flops)\n",
      "  model_139/conv2d_1953/BiasAdd (354.37k/354.37k flops)\n",
      "  model_139/depthwise_conv2d_1814/BiasAdd (354.37k/354.37k flops)\n",
      "  model_139/depthwise_conv2d_1813/BiasAdd (340.26k/340.26k flops)\n",
      "  model_139/conv2d_1952/BiasAdd (340.26k/340.26k flops)\n",
      "  model_139/batch_normalization_3764/FusedBatchNormV3 (277.02k/277.02k flops)\n",
      "  model_139/batch_normalization_3777/FusedBatchNormV3 (257.11k/257.11k flops)\n",
      "  model_139/batch_normalization_3776/FusedBatchNormV3 (182.28k/182.28k flops)\n",
      "  model_139/depthwise_conv2d_1812/BiasAdd (137.98k/137.98k flops)\n",
      "  model_139/conv2d_1958/BiasAdd (126.62k/126.62k flops)\n",
      "  model_139/depthwise_conv2d_1818/BiasAdd (89.77k/89.77k flops)\n",
      "  model_139/batch_normalization_3779/FusedBatchNormV3 (86.32k/86.32k flops)\n",
      "  model_139/batch_normalization_3778/FusedBatchNormV3 (67.18k/67.18k flops)\n",
      "  model_139/global_average_pooling2d_139/Mean (40.67k/40.67k flops)\n",
      "  model_139/conv2d_1959/BiasAdd (40.67k/40.67k flops)\n",
      "  model_139/depthwise_conv2d_1819/BiasAdd (31.65k/31.65k flops)\n",
      "  model_139/dense_139/MatMul (16.60k/16.60k flops)\n",
      "  model_139/dense_139/Softmax (50/50 flops)\n",
      "  model_139/dense_139/BiasAdd (10/10 flops)\n",
      "\n",
      "======================End of Report==========================\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "181.784308\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-30 13:41:54.129625: I tensorflow/core/grappler/devices.cc:66] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0\n",
      "2022-04-30 13:41:54.129741: I tensorflow/core/grappler/clusters/single_machine.cc:357] Starting new session\n",
      "2022-04-30 13:41:54.134178: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:1137] Optimization results for grappler item: graph_to_optimize\n",
      "  function_optimizer: function_optimizer did nothing. time = 0.006ms.\n",
      "  function_optimizer: function_optimizer did nothing. time = 0.001ms.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=========================Options=============================\n",
      "-max_depth                  10000\n",
      "-min_bytes                  0\n",
      "-min_peak_bytes             0\n",
      "-min_residual_bytes         0\n",
      "-min_output_bytes           0\n",
      "-min_micros                 0\n",
      "-min_accelerator_micros     0\n",
      "-min_cpu_micros             0\n",
      "-min_params                 0\n",
      "-min_float_ops              1\n",
      "-min_occurrence             0\n",
      "-step                       -1\n",
      "-order_by                   float_ops\n",
      "-account_type_regexes       .*\n",
      "-start_name_regexes         .*\n",
      "-trim_name_regexes          \n",
      "-show_name_regexes          .*\n",
      "-hide_name_regexes          \n",
      "-account_displayed_op_only  true\n",
      "-select                     float_ops\n",
      "-output                     stdout:\n",
      "\n",
      "==================Model Analysis Report======================\n",
      "\n",
      "Doc:\n",
      "scope: The nodes in the model graph are organized by their names, which is hierarchical like filesystem.\n",
      "flops: Number of float operations. Note: Please read the implementation for the math behind it.\n",
      "\n",
      "Profile:\n",
      "node name | # float_ops\n",
      "_TFProfRoot (--/2.71b flops)\n",
      "  model_140/conv2d_1970/Conv2D (366.81m/366.81m flops)\n",
      "  model_140/conv2d_1968/Conv2D (325.77m/325.77m flops)\n",
      "  model_140/conv2d_1969/Conv2D (309.81m/309.81m flops)\n",
      "  model_140/conv2d_1965/Conv2D (268.32m/268.32m flops)\n",
      "  model_140/conv2d_1971/Conv2D (245.59m/245.59m flops)\n",
      "  model_140/conv2d_1967/Conv2D (235.11m/235.11m flops)\n",
      "  model_140/conv2d_1963/Conv2D (196.69m/196.69m flops)\n",
      "  model_140/conv2d_1961/Conv2D (122.03m/122.03m flops)\n",
      "  model_140/conv2d_1964/Conv2D (114.33m/114.33m flops)\n",
      "  model_140/conv2d_1966/Conv2D (110.36m/110.36m flops)\n",
      "  model_140/conv2d_1972/Conv2D (84.88m/84.88m flops)\n",
      "  model_140/conv2d_1962/Conv2D (76.27m/76.27m flops)\n",
      "  model_140/conv2d_1960/Conv2D (51.38m/51.38m flops)\n",
      "  model_140/conv2d_1973/Conv2D (49.10m/49.10m flops)\n",
      "  model_140/depthwise_conv2d_1820/depthwise (28.90m/28.90m flops)\n",
      "  model_140/depthwise_conv2d_1822/depthwise (18.06m/18.06m flops)\n",
      "  model_140/depthwise_conv2d_1824/depthwise (10.50m/10.50m flops)\n",
      "  model_140/depthwise_conv2d_1821/depthwise (8.58m/8.58m flops)\n",
      "  model_140/depthwise_conv2d_1830/depthwise (7.08m/7.08m flops)\n",
      "  model_140/depthwise_conv2d_1827/depthwise (6.91m/6.91m flops)\n",
      "  model_140/depthwise_conv2d_1829/depthwise (6.58m/6.58m flops)\n",
      "  model_140/depthwise_conv2d_1828/depthwise (5.98m/5.98m flops)\n",
      "  model_140/depthwise_conv2d_1823/depthwise (5.53m/5.53m flops)\n",
      "  model_140/depthwise_conv2d_1826/depthwise (4.32m/4.32m flops)\n",
      "  model_140/batch_normalization_3782/FusedBatchNormV3 (3.81m/3.81m flops)\n",
      "  model_140/depthwise_conv2d_1825/depthwise (3.25m/3.25m flops)\n",
      "  model_140/batch_normalization_3781/FusedBatchNormV3 (3.21m/3.21m flops)\n",
      "  model_140/batch_normalization_3780/FusedBatchNormV3 (3.21m/3.21m flops)\n",
      "  model_140/batch_normalization_3786/FusedBatchNormV3 (2.46m/2.46m flops)\n",
      "  model_140/batch_normalization_3784/FusedBatchNormV3 (2.01m/2.01m flops)\n",
      "  model_140/batch_normalization_3785/FusedBatchNormV3 (2.01m/2.01m flops)\n",
      "  model_140/conv2d_1961/BiasAdd (1.91m/1.91m flops)\n",
      "  model_140/conv2d_1960/BiasAdd (1.61m/1.61m flops)\n",
      "  model_140/depthwise_conv2d_1820/BiasAdd (1.61m/1.61m flops)\n",
      "  model_140/batch_normalization_3790/FusedBatchNormV3 (1.44m/1.44m flops)\n",
      "  model_140/conv2d_1963/BiasAdd (1.23m/1.23m flops)\n",
      "  model_140/batch_normalization_3788/FusedBatchNormV3 (1.17m/1.17m flops)\n",
      "  model_140/batch_normalization_3789/FusedBatchNormV3 (1.17m/1.17m flops)\n",
      "  model_140/depthwise_conv2d_1831/depthwise (1.10m/1.10m flops)\n",
      "  model_140/conv2d_1962/BiasAdd (1.00m/1.00m flops)\n",
      "  model_140/depthwise_conv2d_1822/BiasAdd (1.00m/1.00m flops)\n",
      "  model_140/batch_normalization_3783/FusedBatchNormV3 (953.57k/953.57k flops)\n",
      "  model_140/batch_normalization_3801/FusedBatchNormV3 (790.15k/790.15k flops)\n",
      "  model_140/batch_normalization_3800/FusedBatchNormV3 (790.15k/790.15k flops)\n",
      "  model_140/batch_normalization_3794/FusedBatchNormV3 (771.26k/771.26k flops)\n",
      "  model_140/batch_normalization_3795/FusedBatchNormV3 (771.26k/771.26k flops)\n",
      "  model_140/batch_normalization_3798/FusedBatchNormV3 (733.48k/733.48k flops)\n",
      "  model_140/batch_normalization_3799/FusedBatchNormV3 (733.48k/733.48k flops)\n",
      "  model_140/conv2d_1965/BiasAdd (721.28k/721.28k flops)\n",
      "  model_140/batch_normalization_3797/FusedBatchNormV3 (667.38k/667.38k flops)\n",
      "  model_140/batch_normalization_3796/FusedBatchNormV3 (667.38k/667.38k flops)\n",
      "  model_140/batch_normalization_3787/FusedBatchNormV3 (615.24k/615.24k flops)\n",
      "  model_140/depthwise_conv2d_1832/depthwise (612.11k/612.11k flops)\n",
      "  model_140/conv2d_1964/BiasAdd (583.30k/583.30k flops)\n",
      "  model_140/depthwise_conv2d_1824/BiasAdd (583.30k/583.30k flops)\n",
      "  model_140/batch_normalization_3802/FusedBatchNormV3 (491.09k/491.09k flops)\n",
      "  model_140/batch_normalization_3792/FusedBatchNormV3 (481.64k/481.64k flops)\n",
      "  model_140/batch_normalization_3793/FusedBatchNormV3 (481.64k/481.64k flops)\n",
      "  model_140/depthwise_conv2d_1821/BiasAdd (476.67k/476.67k flops)\n",
      "  model_140/depthwise_conv2d_1830/BiasAdd (393.57k/393.57k flops)\n",
      "  model_140/conv2d_1970/BiasAdd (393.57k/393.57k flops)\n",
      "  model_140/depthwise_conv2d_1827/BiasAdd (384.16k/384.16k flops)\n",
      "  model_140/conv2d_1967/BiasAdd (384.16k/384.16k flops)\n",
      "  model_140/depthwise_conv2d_1829/BiasAdd (365.34k/365.34k flops)\n",
      "  model_140/conv2d_1969/BiasAdd (365.34k/365.34k flops)\n",
      "  model_140/batch_normalization_3791/FusedBatchNormV3 (362.02k/362.02k flops)\n",
      "  model_140/conv2d_1968/BiasAdd (332.42k/332.42k flops)\n",
      "  model_140/depthwise_conv2d_1828/BiasAdd (332.42k/332.42k flops)\n",
      "  model_140/depthwise_conv2d_1823/BiasAdd (307.33k/307.33k flops)\n",
      "  model_140/batch_normalization_3804/FusedBatchNormV3 (276.21k/276.21k flops)\n",
      "  model_140/conv2d_1971/BiasAdd (244.61k/244.61k flops)\n",
      "  model_140/conv2d_1966/BiasAdd (239.90k/239.90k flops)\n",
      "  model_140/depthwise_conv2d_1826/BiasAdd (239.90k/239.90k flops)\n",
      "  model_140/depthwise_conv2d_1825/BiasAdd (180.32k/180.32k flops)\n",
      "  model_140/conv2d_1972/BiasAdd (136.02k/136.02k flops)\n",
      "  model_140/batch_normalization_3803/FusedBatchNormV3 (124.18k/124.18k flops)\n",
      "  model_140/batch_normalization_3806/FusedBatchNormV3 (75.09k/75.09k flops)\n",
      "  model_140/batch_normalization_3805/FusedBatchNormV3 (72.18k/72.18k flops)\n",
      "  model_140/depthwise_conv2d_1831/BiasAdd (61.15k/61.15k flops)\n",
      "  model_140/global_average_pooling2d_140/Mean (35.38k/35.38k flops)\n",
      "  model_140/conv2d_1973/BiasAdd (35.38k/35.38k flops)\n",
      "  model_140/depthwise_conv2d_1832/BiasAdd (34.01k/34.01k flops)\n",
      "  model_140/dense_140/MatMul (14.44k/14.44k flops)\n",
      "  model_140/dense_140/Softmax (50/50 flops)\n",
      "  model_140/dense_140/BiasAdd (10/10 flops)\n",
      "\n",
      "======================End of Report==========================\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "216.888892\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-30 13:41:55.151951: I tensorflow/core/grappler/devices.cc:66] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0\n",
      "2022-04-30 13:41:55.152044: I tensorflow/core/grappler/clusters/single_machine.cc:357] Starting new session\n",
      "2022-04-30 13:41:55.157350: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:1137] Optimization results for grappler item: graph_to_optimize\n",
      "  function_optimizer: function_optimizer did nothing. time = 0.006ms.\n",
      "  function_optimizer: function_optimizer did nothing. time = 0.001ms.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=========================Options=============================\n",
      "-max_depth                  10000\n",
      "-min_bytes                  0\n",
      "-min_peak_bytes             0\n",
      "-min_residual_bytes         0\n",
      "-min_output_bytes           0\n",
      "-min_micros                 0\n",
      "-min_accelerator_micros     0\n",
      "-min_cpu_micros             0\n",
      "-min_params                 0\n",
      "-min_float_ops              1\n",
      "-min_occurrence             0\n",
      "-step                       -1\n",
      "-order_by                   float_ops\n",
      "-account_type_regexes       .*\n",
      "-start_name_regexes         .*\n",
      "-trim_name_regexes          \n",
      "-show_name_regexes          .*\n",
      "-hide_name_regexes          \n",
      "-account_displayed_op_only  true\n",
      "-select                     float_ops\n",
      "-output                     stdout:\n",
      "\n",
      "==================Model Analysis Report======================\n",
      "\n",
      "Doc:\n",
      "scope: The nodes in the model graph are organized by their names, which is hierarchical like filesystem.\n",
      "flops: Number of float operations. Note: Please read the implementation for the math behind it.\n",
      "\n",
      "Profile:\n",
      "node name | # float_ops\n",
      "_TFProfRoot (--/3.12b flops)\n",
      "  model_141/conv2d_1983/Conv2D (457.23m/457.23m flops)\n",
      "  model_141/conv2d_1984/Conv2D (410.05m/410.05m flops)\n",
      "  model_141/conv2d_1985/Conv2D (366.12m/366.12m flops)\n",
      "  model_141/conv2d_1982/Conv2D (321.15m/321.15m flops)\n",
      "  model_141/conv2d_1979/Conv2D (229.48m/229.48m flops)\n",
      "  model_141/conv2d_1981/Conv2D (219.20m/219.20m flops)\n",
      "  model_141/conv2d_1975/Conv2D (206.44m/206.44m flops)\n",
      "  model_141/conv2d_1977/Conv2D (190.43m/190.43m flops)\n",
      "  model_141/conv2d_1978/Conv2D (136.25m/136.25m flops)\n",
      "  model_141/conv2d_1980/Conv2D (118.89m/118.89m flops)\n",
      "  model_141/conv2d_1986/Conv2D (101.66m/101.66m flops)\n",
      "  model_141/conv2d_1976/Conv2D (93.54m/93.54m flops)\n",
      "  model_141/conv2d_1974/Conv2D (58.98m/58.98m flops)\n",
      "  model_141/conv2d_1987/Conv2D (38.30m/38.30m flops)\n",
      "  model_141/depthwise_conv2d_1833/depthwise (33.18m/33.18m flops)\n",
      "  model_141/depthwise_conv2d_1835/depthwise (15.03m/15.03m flops)\n",
      "  model_141/depthwise_conv2d_1834/depthwise (14.52m/14.52m flops)\n",
      "  model_141/depthwise_conv2d_1837/depthwise (10.76m/10.76m flops)\n",
      "  model_141/depthwise_conv2d_1841/depthwise (8.16m/8.16m flops)\n",
      "  model_141/depthwise_conv2d_1842/depthwise (8.16m/8.16m flops)\n",
      "  model_141/depthwise_conv2d_1836/depthwise (7.39m/7.39m flops)\n",
      "  model_141/depthwise_conv2d_1843/depthwise (7.32m/7.32m flops)\n",
      "  model_141/batch_normalization_3809/FusedBatchNormV3 (6.45m/6.45m flops)\n",
      "  model_141/depthwise_conv2d_1840/depthwise (5.73m/5.73m flops)\n",
      "  model_141/depthwise_conv2d_1839/depthwise (5.57m/5.57m flops)\n",
      "  model_141/batch_normalization_3808/FusedBatchNormV3 (3.69m/3.69m flops)\n",
      "  model_141/batch_normalization_3807/FusedBatchNormV3 (3.69m/3.69m flops)\n",
      "  model_141/batch_normalization_3813/FusedBatchNormV3 (3.28m/3.28m flops)\n",
      "  model_141/conv2d_1975/BiasAdd (3.23m/3.23m flops)\n",
      "  model_141/depthwise_conv2d_1838/depthwise (3.11m/3.11m flops)\n",
      "  model_141/conv2d_1974/BiasAdd (1.84m/1.84m flops)\n",
      "  model_141/depthwise_conv2d_1833/BiasAdd (1.84m/1.84m flops)\n",
      "  model_141/depthwise_conv2d_1844/depthwise (1.82m/1.82m flops)\n",
      "  model_141/batch_normalization_3811/FusedBatchNormV3 (1.67m/1.67m flops)\n",
      "  model_141/batch_normalization_3812/FusedBatchNormV3 (1.67m/1.67m flops)\n",
      "  model_141/conv2d_1977/BiasAdd (1.64m/1.64m flops)\n",
      "  model_141/batch_normalization_3810/FusedBatchNormV3 (1.61m/1.61m flops)\n",
      "  model_141/batch_normalization_3817/FusedBatchNormV3 (1.38m/1.38m flops)\n",
      "  model_141/batch_normalization_3815/FusedBatchNormV3 (1.20m/1.20m flops)\n",
      "  model_141/batch_normalization_3816/FusedBatchNormV3 (1.20m/1.20m flops)\n",
      "  model_141/batch_normalization_3826/FusedBatchNormV3 (910.22k/910.22k flops)\n",
      "  model_141/batch_normalization_3825/FusedBatchNormV3 (910.22k/910.22k flops)\n",
      "  model_141/batch_normalization_3824/FusedBatchNormV3 (910.22k/910.22k flops)\n",
      "  model_141/batch_normalization_3823/FusedBatchNormV3 (910.22k/910.22k flops)\n",
      "  model_141/depthwise_conv2d_1835/BiasAdd (835.20k/835.20k flops)\n",
      "  model_141/conv2d_1976/BiasAdd (835.20k/835.20k flops)\n",
      "  model_141/batch_normalization_3814/FusedBatchNormV3 (821.48k/821.48k flops)\n",
      "  model_141/batch_normalization_3828/FusedBatchNormV3 (816.31k/816.31k flops)\n",
      "  model_141/batch_normalization_3827/FusedBatchNormV3 (816.31k/816.31k flops)\n",
      "  model_141/batch_normalization_3829/FusedBatchNormV3 (812.70k/812.70k flops)\n",
      "  model_141/depthwise_conv2d_1834/BiasAdd (806.40k/806.40k flops)\n",
      "  model_141/conv2d_1979/BiasAdd (691.20k/691.20k flops)\n",
      "  model_141/batch_normalization_3821/FusedBatchNormV3 (639.32k/639.32k flops)\n",
      "  model_141/batch_normalization_3822/FusedBatchNormV3 (639.32k/639.32k flops)\n",
      "  model_141/batch_normalization_3820/FusedBatchNormV3 (621.26k/621.26k flops)\n",
      "  model_141/batch_normalization_3819/FusedBatchNormV3 (621.26k/621.26k flops)\n",
      "  model_141/conv2d_1978/BiasAdd (597.60k/597.60k flops)\n",
      "  model_141/depthwise_conv2d_1837/BiasAdd (597.60k/597.60k flops)\n",
      "  model_141/depthwise_conv2d_1845/depthwise (578.30k/578.30k flops)\n",
      "  model_141/conv2d_1983/BiasAdd (453.60k/453.60k flops)\n",
      "  model_141/depthwise_conv2d_1842/BiasAdd (453.60k/453.60k flops)\n",
      "  model_141/depthwise_conv2d_1841/BiasAdd (453.60k/453.60k flops)\n",
      "  model_141/conv2d_1982/BiasAdd (453.60k/453.60k flops)\n",
      "  model_141/depthwise_conv2d_1836/BiasAdd (410.40k/410.40k flops)\n",
      "  model_141/conv2d_1984/BiasAdd (406.80k/406.80k flops)\n",
      "  model_141/depthwise_conv2d_1843/BiasAdd (406.80k/406.80k flops)\n",
      "  model_141/conv2d_1985/BiasAdd (405.00k/405.00k flops)\n",
      "  model_141/batch_normalization_3818/FusedBatchNormV3 (346.75k/346.75k flops)\n",
      "  model_141/depthwise_conv2d_1840/BiasAdd (318.60k/318.60k flops)\n",
      "  model_141/conv2d_1981/BiasAdd (318.60k/318.60k flops)\n",
      "  model_141/depthwise_conv2d_1839/BiasAdd (309.60k/309.60k flops)\n",
      "  model_141/conv2d_1980/BiasAdd (309.60k/309.60k flops)\n",
      "  model_141/batch_normalization_3831/FusedBatchNormV3 (228.91k/228.91k flops)\n",
      "  model_141/batch_normalization_3830/FusedBatchNormV3 (205.20k/205.20k flops)\n",
      "  model_141/depthwise_conv2d_1838/BiasAdd (172.80k/172.80k flops)\n",
      "  model_141/conv2d_1986/BiasAdd (112.95k/112.95k flops)\n",
      "  model_141/depthwise_conv2d_1844/BiasAdd (101.25k/101.25k flops)\n",
      "  model_141/batch_normalization_3833/FusedBatchNormV3 (79.86k/79.86k flops)\n",
      "  model_141/batch_normalization_3832/FusedBatchNormV3 (67.27k/67.27k flops)\n",
      "  model_141/global_average_pooling2d_141/Mean (38.14k/38.14k flops)\n",
      "  model_141/conv2d_1987/BiasAdd (38.14k/38.14k flops)\n",
      "  model_141/depthwise_conv2d_1845/BiasAdd (32.13k/32.13k flops)\n",
      "  model_141/dense_141/MatMul (11.92k/11.92k flops)\n",
      "  model_141/dense_141/Softmax (50/50 flops)\n",
      "  model_141/dense_141/BiasAdd (10/10 flops)\n",
      "\n",
      "======================End of Report==========================\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "226.06698\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-30 13:41:56.086313: I tensorflow/core/grappler/devices.cc:66] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0\n",
      "2022-04-30 13:41:56.086431: I tensorflow/core/grappler/clusters/single_machine.cc:357] Starting new session\n",
      "2022-04-30 13:41:56.090889: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:1137] Optimization results for grappler item: graph_to_optimize\n",
      "  function_optimizer: function_optimizer did nothing. time = 0.005ms.\n",
      "  function_optimizer: function_optimizer did nothing. time = 0.001ms.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=========================Options=============================\n",
      "-max_depth                  10000\n",
      "-min_bytes                  0\n",
      "-min_peak_bytes             0\n",
      "-min_residual_bytes         0\n",
      "-min_output_bytes           0\n",
      "-min_micros                 0\n",
      "-min_accelerator_micros     0\n",
      "-min_cpu_micros             0\n",
      "-min_params                 0\n",
      "-min_float_ops              1\n",
      "-min_occurrence             0\n",
      "-step                       -1\n",
      "-order_by                   float_ops\n",
      "-account_type_regexes       .*\n",
      "-start_name_regexes         .*\n",
      "-trim_name_regexes          \n",
      "-show_name_regexes          .*\n",
      "-hide_name_regexes          \n",
      "-account_displayed_op_only  true\n",
      "-select                     float_ops\n",
      "-output                     stdout:\n",
      "\n",
      "==================Model Analysis Report======================\n",
      "\n",
      "Doc:\n",
      "scope: The nodes in the model graph are organized by their names, which is hierarchical like filesystem.\n",
      "flops: Number of float operations. Note: Please read the implementation for the math behind it.\n",
      "\n",
      "Profile:\n",
      "node name | # float_ops\n",
      "_TFProfRoot (--/3.06b flops)\n",
      "  model_142/conv2d_1993/Conv2D (420.62m/420.62m flops)\n",
      "  model_142/conv2d_1998/Conv2D (345.38m/345.38m flops)\n",
      "  model_142/conv2d_1997/Conv2D (321.52m/321.52m flops)\n",
      "  model_142/conv2d_1999/Conv2D (301.10m/301.10m flops)\n",
      "  model_142/conv2d_1991/Conv2D (297.56m/297.56m flops)\n",
      "  model_142/conv2d_1996/Conv2D (230.83m/230.83m flops)\n",
      "  model_142/conv2d_1992/Conv2D (208.66m/208.66m flops)\n",
      "  model_142/conv2d_1989/Conv2D (191.69m/191.69m flops)\n",
      "  model_142/conv2d_1995/Conv2D (141.12m/141.12m flops)\n",
      "  model_142/conv2d_1994/Conv2D (128.02m/128.02m flops)\n",
      "  model_142/conv2d_1990/Conv2D (122.80m/122.80m flops)\n",
      "  model_142/conv2d_2000/Conv2D (65.18m/65.18m flops)\n",
      "  model_142/conv2d_1988/Conv2D (58.98m/58.98m flops)\n",
      "  model_142/conv2d_2001/Conv2D (46.02m/46.02m flops)\n",
      "  model_142/depthwise_conv2d_1846/depthwise (33.18m/33.18m flops)\n",
      "  model_142/depthwise_conv2d_1848/depthwise (21.25m/21.25m flops)\n",
      "  model_142/depthwise_conv2d_1850/depthwise (14.90m/14.90m flops)\n",
      "  model_142/depthwise_conv2d_1847/depthwise (13.48m/13.48m flops)\n",
      "  model_142/depthwise_conv2d_1849/depthwise (8.16m/8.16m flops)\n",
      "  model_142/depthwise_conv2d_1856/depthwise (7.97m/7.97m flops)\n",
      "  model_142/depthwise_conv2d_1854/depthwise (7.42m/7.42m flops)\n",
      "  model_142/depthwise_conv2d_1855/depthwise (6.32m/6.32m flops)\n",
      "  model_142/batch_normalization_3836/FusedBatchNormV3 (5.99m/5.99m flops)\n",
      "  model_142/depthwise_conv2d_1852/depthwise (4.54m/4.54m flops)\n",
      "  model_142/depthwise_conv2d_1853/depthwise (4.54m/4.54m flops)\n",
      "  model_142/depthwise_conv2d_1851/depthwise (4.11m/4.11m flops)\n",
      "  model_142/batch_normalization_3835/FusedBatchNormV3 (3.69m/3.69m flops)\n",
      "  model_142/batch_normalization_3834/FusedBatchNormV3 (3.69m/3.69m flops)\n",
      "  model_142/batch_normalization_3840/FusedBatchNormV3 (3.63m/3.63m flops)\n",
      "  model_142/conv2d_1989/BiasAdd (3.00m/3.00m flops)\n",
      "  model_142/batch_normalization_3838/FusedBatchNormV3 (2.36m/2.36m flops)\n",
      "  model_142/batch_normalization_3839/FusedBatchNormV3 (2.36m/2.36m flops)\n",
      "  model_142/conv2d_1988/BiasAdd (1.84m/1.84m flops)\n",
      "  model_142/depthwise_conv2d_1846/BiasAdd (1.84m/1.84m flops)\n",
      "  model_142/batch_normalization_3844/FusedBatchNormV3 (1.83m/1.83m flops)\n",
      "  model_142/conv2d_1991/BiasAdd (1.81m/1.81m flops)\n",
      "  model_142/batch_normalization_3842/FusedBatchNormV3 (1.66m/1.66m flops)\n",
      "  model_142/batch_normalization_3843/FusedBatchNormV3 (1.66m/1.66m flops)\n",
      "  model_142/batch_normalization_3837/FusedBatchNormV3 (1.50m/1.50m flops)\n",
      "  model_142/depthwise_conv2d_1857/depthwise (1.38m/1.38m flops)\n",
      "  model_142/conv2d_1990/BiasAdd (1.18m/1.18m flops)\n",
      "  model_142/depthwise_conv2d_1848/BiasAdd (1.18m/1.18m flops)\n",
      "  model_142/conv2d_1993/BiasAdd (914.40k/914.40k flops)\n",
      "  model_142/batch_normalization_3841/FusedBatchNormV3 (907.96k/907.96k flops)\n",
      "  model_142/batch_normalization_3855/FusedBatchNormV3 (888.55k/888.55k flops)\n",
      "  model_142/batch_normalization_3854/FusedBatchNormV3 (888.55k/888.55k flops)\n",
      "  model_142/conv2d_1992/BiasAdd (828.00k/828.00k flops)\n",
      "  model_142/depthwise_conv2d_1850/BiasAdd (828.00k/828.00k flops)\n",
      "  model_142/batch_normalization_3851/FusedBatchNormV3 (827.15k/827.15k flops)\n",
      "  model_142/batch_normalization_3850/FusedBatchNormV3 (827.15k/827.15k flops)\n",
      "  model_142/depthwise_conv2d_1847/BiasAdd (748.80k/748.80k flops)\n",
      "  model_142/batch_normalization_3852/FusedBatchNormV3 (704.34k/704.34k flops)\n",
      "  model_142/batch_normalization_3853/FusedBatchNormV3 (704.34k/704.34k flops)\n",
      "  model_142/batch_normalization_3856/FusedBatchNormV3 (614.04k/614.04k flops)\n",
      "  model_142/batch_normalization_3849/FusedBatchNormV3 (505.68k/505.68k flops)\n",
      "  model_142/batch_normalization_3848/FusedBatchNormV3 (505.68k/505.68k flops)\n",
      "  model_142/batch_normalization_3847/FusedBatchNormV3 (505.68k/505.68k flops)\n",
      "  model_142/batch_normalization_3846/FusedBatchNormV3 (505.68k/505.68k flops)\n",
      "  model_142/depthwise_conv2d_1858/depthwise (490.75k/490.75k flops)\n",
      "  model_142/batch_normalization_3845/FusedBatchNormV3 (458.72k/458.72k flops)\n",
      "  model_142/depthwise_conv2d_1849/BiasAdd (453.60k/453.60k flops)\n",
      "  model_142/depthwise_conv2d_1856/BiasAdd (442.80k/442.80k flops)\n",
      "  model_142/conv2d_1998/BiasAdd (442.80k/442.80k flops)\n",
      "  model_142/conv2d_1996/BiasAdd (412.20k/412.20k flops)\n",
      "  model_142/depthwise_conv2d_1854/BiasAdd (412.20k/412.20k flops)\n",
      "  model_142/conv2d_1997/BiasAdd (351.00k/351.00k flops)\n",
      "  model_142/depthwise_conv2d_1855/BiasAdd (351.00k/351.00k flops)\n",
      "  model_142/conv2d_1999/BiasAdd (306.00k/306.00k flops)\n",
      "  model_142/conv2d_1995/BiasAdd (252.00k/252.00k flops)\n",
      "  model_142/depthwise_conv2d_1852/BiasAdd (252.00k/252.00k flops)\n",
      "  model_142/depthwise_conv2d_1853/BiasAdd (252.00k/252.00k flops)\n",
      "  model_142/conv2d_1994/BiasAdd (252.00k/252.00k flops)\n",
      "  model_142/depthwise_conv2d_1851/BiasAdd (228.60k/228.60k flops)\n",
      "  model_142/batch_normalization_3858/FusedBatchNormV3 (194.26k/194.26k flops)\n",
      "  model_142/batch_normalization_3857/FusedBatchNormV3 (155.04k/155.04k flops)\n",
      "  model_142/batch_normalization_3860/FusedBatchNormV3 (113.10k/113.10k flops)\n",
      "  model_142/conv2d_2000/BiasAdd (95.85k/95.85k flops)\n",
      "  model_142/depthwise_conv2d_1857/BiasAdd (76.50k/76.50k flops)\n",
      "  model_142/batch_normalization_3859/FusedBatchNormV3 (57.08k/57.08k flops)\n",
      "  model_142/global_average_pooling2d_142/Mean (54.02k/54.02k flops)\n",
      "  model_142/conv2d_2001/BiasAdd (54.02k/54.02k flops)\n",
      "  model_142/depthwise_conv2d_1858/BiasAdd (27.26k/27.26k flops)\n",
      "  model_142/dense_142/MatMul (16.88k/16.88k flops)\n",
      "  model_142/dense_142/Softmax (50/50 flops)\n",
      "  model_142/dense_142/BiasAdd (10/10 flops)\n",
      "\n",
      "======================End of Report==========================\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "186.319668\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-30 13:41:57.110807: I tensorflow/core/grappler/devices.cc:66] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0\n",
      "2022-04-30 13:41:57.110928: I tensorflow/core/grappler/clusters/single_machine.cc:357] Starting new session\n",
      "2022-04-30 13:41:57.116302: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:1137] Optimization results for grappler item: graph_to_optimize\n",
      "  function_optimizer: function_optimizer did nothing. time = 0.006ms.\n",
      "  function_optimizer: function_optimizer did nothing. time = 0ms.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=========================Options=============================\n",
      "-max_depth                  10000\n",
      "-min_bytes                  0\n",
      "-min_peak_bytes             0\n",
      "-min_residual_bytes         0\n",
      "-min_output_bytes           0\n",
      "-min_micros                 0\n",
      "-min_accelerator_micros     0\n",
      "-min_cpu_micros             0\n",
      "-min_params                 0\n",
      "-min_float_ops              1\n",
      "-min_occurrence             0\n",
      "-step                       -1\n",
      "-order_by                   float_ops\n",
      "-account_type_regexes       .*\n",
      "-start_name_regexes         .*\n",
      "-trim_name_regexes          \n",
      "-show_name_regexes          .*\n",
      "-hide_name_regexes          \n",
      "-account_displayed_op_only  true\n",
      "-select                     float_ops\n",
      "-output                     stdout:\n",
      "\n",
      "==================Model Analysis Report======================\n",
      "\n",
      "Doc:\n",
      "scope: The nodes in the model graph are organized by their names, which is hierarchical like filesystem.\n",
      "flops: Number of float operations. Note: Please read the implementation for the math behind it.\n",
      "\n",
      "Profile:\n",
      "node name | # float_ops\n",
      "_TFProfRoot (--/3.10b flops)\n",
      "  model_143/conv2d_2011/Conv2D (451.66m/451.66m flops)\n",
      "  model_143/conv2d_2012/Conv2D (367.20m/367.20m flops)\n",
      "  model_143/conv2d_2010/Conv2D (357.78m/357.78m flops)\n",
      "  model_143/conv2d_2013/Conv2D (334.08m/334.08m flops)\n",
      "  model_143/conv2d_2007/Conv2D (311.39m/311.39m flops)\n",
      "  model_143/conv2d_2009/Conv2D (273.43m/273.43m flops)\n",
      "  model_143/conv2d_2014/Conv2D (202.54m/202.54m flops)\n",
      "  model_143/conv2d_2008/Conv2D (143.48m/143.48m flops)\n",
      "  model_143/conv2d_2015/Conv2D (125.65m/125.65m flops)\n",
      "  model_143/conv2d_2003/Conv2D (117.96m/117.96m flops)\n",
      "  model_143/conv2d_2006/Conv2D (76.38m/76.38m flops)\n",
      "  model_143/conv2d_2005/Conv2D (71.88m/71.88m flops)\n",
      "  model_143/conv2d_2002/Conv2D (58.98m/58.98m flops)\n",
      "  model_143/conv2d_2004/Conv2D (44.24m/44.24m flops)\n",
      "  model_143/depthwise_conv2d_1859/depthwise (33.18m/33.18m flops)\n",
      "  model_143/depthwise_conv2d_1863/depthwise (13.22m/13.22m flops)\n",
      "  model_143/depthwise_conv2d_1861/depthwise (12.44m/12.44m flops)\n",
      "  model_143/depthwise_conv2d_1860/depthwise (8.29m/8.29m flops)\n",
      "  model_143/depthwise_conv2d_1868/depthwise (8.26m/8.26m flops)\n",
      "  model_143/depthwise_conv2d_1867/depthwise (7.97m/7.97m flops)\n",
      "  model_143/depthwise_conv2d_1866/depthwise (6.54m/6.54m flops)\n",
      "  model_143/depthwise_conv2d_1869/depthwise (6.48m/6.48m flops)\n",
      "  model_143/depthwise_conv2d_1865/depthwise (6.09m/6.09m flops)\n",
      "  model_143/batch_normalization_3862/FusedBatchNormV3 (3.69m/3.69m flops)\n",
      "  model_143/batch_normalization_3863/FusedBatchNormV3 (3.69m/3.69m flops)\n",
      "  model_143/batch_normalization_3861/FusedBatchNormV3 (3.69m/3.69m flops)\n",
      "  model_143/depthwise_conv2d_1864/depthwise (3.43m/3.43m flops)\n",
      "  model_143/depthwise_conv2d_1862/depthwise (3.37m/3.37m flops)\n",
      "  model_143/depthwise_conv2d_1870/depthwise (1.88m/1.88m flops)\n",
      "  model_143/depthwise_conv2d_1859/BiasAdd (1.84m/1.84m flops)\n",
      "  model_143/conv2d_2002/BiasAdd (1.84m/1.84m flops)\n",
      "  model_143/conv2d_2003/BiasAdd (1.84m/1.84m flops)\n",
      "  model_143/batch_normalization_3871/FusedBatchNormV3 (1.53m/1.53m flops)\n",
      "  model_143/batch_normalization_3867/FusedBatchNormV3 (1.50m/1.50m flops)\n",
      "  model_143/batch_normalization_3870/FusedBatchNormV3 (1.47m/1.47m flops)\n",
      "  model_143/batch_normalization_3869/FusedBatchNormV3 (1.47m/1.47m flops)\n",
      "  model_143/batch_normalization_3866/FusedBatchNormV3 (1.38m/1.38m flops)\n",
      "  model_143/batch_normalization_3865/FusedBatchNormV3 (1.38m/1.38m flops)\n",
      "  model_143/depthwise_conv2d_1871/depthwise (1.12m/1.12m flops)\n",
      "  model_143/batch_normalization_3864/FusedBatchNormV3 (921.79k/921.79k flops)\n",
      "  model_143/batch_normalization_3879/FusedBatchNormV3 (921.06k/921.06k flops)\n",
      "  model_143/batch_normalization_3880/FusedBatchNormV3 (921.06k/921.06k flops)\n",
      "  model_143/batch_normalization_3878/FusedBatchNormV3 (888.55k/888.55k flops)\n",
      "  model_143/batch_normalization_3877/FusedBatchNormV3 (888.55k/888.55k flops)\n",
      "  model_143/batch_normalization_3883/FusedBatchNormV3 (837.98k/837.98k flops)\n",
      "  model_143/conv2d_2007/BiasAdd (763.20k/763.20k flops)\n",
      "  model_143/conv2d_2005/BiasAdd (748.80k/748.80k flops)\n",
      "  model_143/conv2d_2006/BiasAdd (734.40k/734.40k flops)\n",
      "  model_143/depthwise_conv2d_1863/BiasAdd (734.40k/734.40k flops)\n",
      "  model_143/batch_normalization_3876/FusedBatchNormV3 (729.62k/729.62k flops)\n",
      "  model_143/batch_normalization_3875/FusedBatchNormV3 (729.62k/729.62k flops)\n",
      "  model_143/batch_normalization_3881/FusedBatchNormV3 (722.40k/722.40k flops)\n",
      "  model_143/batch_normalization_3882/FusedBatchNormV3 (722.40k/722.40k flops)\n",
      "  model_143/depthwise_conv2d_1861/BiasAdd (691.20k/691.20k flops)\n",
      "  model_143/conv2d_2004/BiasAdd (691.20k/691.20k flops)\n",
      "  model_143/batch_normalization_3873/FusedBatchNormV3 (679.06k/679.06k flops)\n",
      "  model_143/batch_normalization_3874/FusedBatchNormV3 (679.06k/679.06k flops)\n",
      "  model_143/depthwise_conv2d_1860/BiasAdd (460.80k/460.80k flops)\n",
      "  model_143/conv2d_2011/BiasAdd (459.00k/459.00k flops)\n",
      "  model_143/depthwise_conv2d_1868/BiasAdd (459.00k/459.00k flops)\n",
      "  model_143/conv2d_2010/BiasAdd (442.80k/442.80k flops)\n",
      "  model_143/depthwise_conv2d_1867/BiasAdd (442.80k/442.80k flops)\n",
      "  model_143/batch_normalization_3885/FusedBatchNormV3 (442.32k/442.32k flops)\n",
      "  model_143/conv2d_2013/BiasAdd (417.60k/417.60k flops)\n",
      "  model_143/batch_normalization_3872/FusedBatchNormV3 (382.87k/382.87k flops)\n",
      "  model_143/batch_normalization_3868/FusedBatchNormV3 (374.71k/374.71k flops)\n",
      "  model_143/depthwise_conv2d_1866/BiasAdd (363.60k/363.60k flops)\n",
      "  model_143/conv2d_2009/BiasAdd (363.60k/363.60k flops)\n",
      "  model_143/depthwise_conv2d_1869/BiasAdd (360.00k/360.00k flops)\n",
      "  model_143/conv2d_2012/BiasAdd (360.00k/360.00k flops)\n",
      "  model_143/depthwise_conv2d_1865/BiasAdd (338.40k/338.40k flops)\n",
      "  model_143/conv2d_2008/BiasAdd (338.40k/338.40k flops)\n",
      "  model_143/conv2d_2014/BiasAdd (218.25k/218.25k flops)\n",
      "  model_143/batch_normalization_3884/FusedBatchNormV3 (211.58k/211.58k flops)\n",
      "  model_143/depthwise_conv2d_1864/BiasAdd (190.80k/190.80k flops)\n",
      "  model_143/depthwise_conv2d_1862/BiasAdd (187.20k/187.20k flops)\n",
      "  model_143/batch_normalization_3887/FusedBatchNormV3 (135.61k/135.61k flops)\n",
      "  model_143/batch_normalization_3886/FusedBatchNormV3 (129.98k/129.98k flops)\n",
      "  model_143/depthwise_conv2d_1870/BiasAdd (104.40k/104.40k flops)\n",
      "  model_143/conv2d_2015/BiasAdd (64.77k/64.77k flops)\n",
      "  model_143/global_average_pooling2d_143/Mean (64.77k/64.77k flops)\n",
      "  model_143/depthwise_conv2d_1871/BiasAdd (62.08k/62.08k flops)\n",
      "  model_143/dense_143/MatMul (20.24k/20.24k flops)\n",
      "  model_143/dense_143/Softmax (50/50 flops)\n",
      "  model_143/dense_143/BiasAdd (10/10 flops)\n",
      "\n",
      "======================End of Report==========================\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "209.033436\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-30 13:41:58.061871: I tensorflow/core/grappler/devices.cc:66] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0\n",
      "2022-04-30 13:41:58.061988: I tensorflow/core/grappler/clusters/single_machine.cc:357] Starting new session\n",
      "2022-04-30 13:41:58.066515: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:1137] Optimization results for grappler item: graph_to_optimize\n",
      "  function_optimizer: function_optimizer did nothing. time = 0.005ms.\n",
      "  function_optimizer: function_optimizer did nothing. time = 0.001ms.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=========================Options=============================\n",
      "-max_depth                  10000\n",
      "-min_bytes                  0\n",
      "-min_peak_bytes             0\n",
      "-min_residual_bytes         0\n",
      "-min_output_bytes           0\n",
      "-min_micros                 0\n",
      "-min_accelerator_micros     0\n",
      "-min_cpu_micros             0\n",
      "-min_params                 0\n",
      "-min_float_ops              1\n",
      "-min_occurrence             0\n",
      "-step                       -1\n",
      "-order_by                   float_ops\n",
      "-account_type_regexes       .*\n",
      "-start_name_regexes         .*\n",
      "-trim_name_regexes          \n",
      "-show_name_regexes          .*\n",
      "-hide_name_regexes          \n",
      "-account_displayed_op_only  true\n",
      "-select                     float_ops\n",
      "-output                     stdout:\n",
      "\n",
      "==================Model Analysis Report======================\n",
      "\n",
      "Doc:\n",
      "scope: The nodes in the model graph are organized by their names, which is hierarchical like filesystem.\n",
      "flops: Number of float operations. Note: Please read the implementation for the math behind it.\n",
      "\n",
      "Profile:\n",
      "node name | # float_ops\n",
      "_TFProfRoot (--/2.87b flops)\n",
      "  model_144/conv2d_2027/Conv2D (388.80m/388.80m flops)\n",
      "  model_144/conv2d_2021/Conv2D (367.20m/367.20m flops)\n",
      "  model_144/conv2d_2019/Conv2D (310.46m/310.46m flops)\n",
      "  model_144/conv2d_2026/Conv2D (281.88m/281.88m flops)\n",
      "  model_144/conv2d_2025/Conv2D (186.67m/186.67m flops)\n",
      "  model_144/conv2d_2024/Conv2D (184.52m/184.52m flops)\n",
      "  model_144/conv2d_2023/Conv2D (167.18m/167.18m flops)\n",
      "  model_144/conv2d_2028/Conv2D (164.16m/164.16m flops)\n",
      "  model_144/conv2d_2020/Conv2D (161.57m/161.57m flops)\n",
      "  model_144/conv2d_2017/Conv2D (125.34m/125.34m flops)\n",
      "  model_144/conv2d_2022/Conv2D (121.50m/121.50m flops)\n",
      "  model_144/conv2d_2018/Conv2D (95.96m/95.96m flops)\n",
      "  model_144/conv2d_2029/Conv2D (77.43m/77.43m flops)\n",
      "  model_144/conv2d_2016/Conv2D (58.98m/58.98m flops)\n",
      "  model_144/depthwise_conv2d_1872/depthwise (33.18m/33.18m flops)\n",
      "  model_144/depthwise_conv2d_1874/depthwise (25.40m/25.40m flops)\n",
      "  model_144/depthwise_conv2d_1876/depthwise (13.22m/13.22m flops)\n",
      "  model_144/depthwise_conv2d_1873/depthwise (8.81m/8.81m flops)\n",
      "  model_144/depthwise_conv2d_1882/depthwise (7.29m/7.29m flops)\n",
      "  model_144/depthwise_conv2d_1875/depthwise (7.13m/7.13m flops)\n",
      "  model_144/depthwise_conv2d_1881/depthwise (5.64m/5.64m flops)\n",
      "  model_144/depthwise_conv2d_1879/depthwise (5.57m/5.57m flops)\n",
      "  model_144/depthwise_conv2d_1880/depthwise (4.83m/4.83m flops)\n",
      "  model_144/depthwise_conv2d_1878/depthwise (4.37m/4.37m flops)\n",
      "  model_144/depthwise_conv2d_1877/depthwise (4.05m/4.05m flops)\n",
      "  model_144/batch_normalization_3890/FusedBatchNormV3 (3.92m/3.92m flops)\n",
      "  model_144/batch_normalization_3889/FusedBatchNormV3 (3.69m/3.69m flops)\n",
      "  model_144/batch_normalization_3888/FusedBatchNormV3 (3.69m/3.69m flops)\n",
      "  model_144/batch_normalization_3894/FusedBatchNormV3 (3.17m/3.17m flops)\n",
      "  model_144/batch_normalization_3892/FusedBatchNormV3 (2.82m/2.82m flops)\n",
      "  model_144/batch_normalization_3893/FusedBatchNormV3 (2.82m/2.82m flops)\n",
      "  model_144/conv2d_2017/BiasAdd (1.96m/1.96m flops)\n",
      "  model_144/depthwise_conv2d_1883/depthwise (1.94m/1.94m flops)\n",
      "  model_144/conv2d_2016/BiasAdd (1.84m/1.84m flops)\n",
      "  model_144/depthwise_conv2d_1872/BiasAdd (1.84m/1.84m flops)\n",
      "  model_144/batch_normalization_3898/FusedBatchNormV3 (1.80m/1.80m flops)\n",
      "  model_144/conv2d_2019/BiasAdd (1.58m/1.58m flops)\n",
      "  model_144/batch_normalization_3897/FusedBatchNormV3 (1.47m/1.47m flops)\n",
      "  model_144/batch_normalization_3896/FusedBatchNormV3 (1.47m/1.47m flops)\n",
      "  model_144/depthwise_conv2d_1874/BiasAdd (1.41m/1.41m flops)\n",
      "  model_144/conv2d_2018/BiasAdd (1.41m/1.41m flops)\n",
      "  model_144/batch_normalization_3891/FusedBatchNormV3 (979.40k/979.40k flops)\n",
      "  model_144/conv2d_2021/BiasAdd (900.00k/900.00k flops)\n",
      "  model_144/depthwise_conv2d_1884/depthwise (875.52k/875.52k flops)\n",
      "  model_144/batch_normalization_3910/FusedBatchNormV3 (866.88k/866.88k flops)\n",
      "  model_144/batch_normalization_3909/FusedBatchNormV3 (812.70k/812.70k flops)\n",
      "  model_144/batch_normalization_3908/FusedBatchNormV3 (812.70k/812.70k flops)\n",
      "  model_144/batch_normalization_3895/FusedBatchNormV3 (792.66k/792.66k flops)\n",
      "  model_144/conv2d_2020/BiasAdd (734.40k/734.40k flops)\n",
      "  model_144/depthwise_conv2d_1876/BiasAdd (734.40k/734.40k flops)\n",
      "  model_144/batch_normalization_3907/FusedBatchNormV3 (628.49k/628.49k flops)\n",
      "  model_144/batch_normalization_3906/FusedBatchNormV3 (628.49k/628.49k flops)\n",
      "  model_144/batch_normalization_3903/FusedBatchNormV3 (621.26k/621.26k flops)\n",
      "  model_144/batch_normalization_3902/FusedBatchNormV3 (621.26k/621.26k flops)\n",
      "  model_144/batch_normalization_3905/FusedBatchNormV3 (538.19k/538.19k flops)\n",
      "  model_144/batch_normalization_3904/FusedBatchNormV3 (538.19k/538.19k flops)\n",
      "  model_144/depthwise_conv2d_1873/BiasAdd (489.60k/489.60k flops)\n",
      "  model_144/batch_normalization_3901/FusedBatchNormV3 (487.62k/487.62k flops)\n",
      "  model_144/batch_normalization_3900/FusedBatchNormV3 (487.62k/487.62k flops)\n",
      "  model_144/batch_normalization_3899/FusedBatchNormV3 (451.50k/451.50k flops)\n",
      "  model_144/conv2d_2027/BiasAdd (432.00k/432.00k flops)\n",
      "  model_144/depthwise_conv2d_1882/BiasAdd (405.00k/405.00k flops)\n",
      "  model_144/conv2d_2026/BiasAdd (405.00k/405.00k flops)\n",
      "  model_144/depthwise_conv2d_1875/BiasAdd (396.00k/396.00k flops)\n",
      "  model_144/batch_normalization_3912/FusedBatchNormV3 (346.56k/346.56k flops)\n",
      "  model_144/depthwise_conv2d_1881/BiasAdd (313.20k/313.20k flops)\n",
      "  model_144/conv2d_2025/BiasAdd (313.20k/313.20k flops)\n",
      "  model_144/depthwise_conv2d_1879/BiasAdd (309.60k/309.60k flops)\n",
      "  model_144/conv2d_2023/BiasAdd (309.60k/309.60k flops)\n",
      "  model_144/conv2d_2024/BiasAdd (268.20k/268.20k flops)\n",
      "  model_144/depthwise_conv2d_1880/BiasAdd (268.20k/268.20k flops)\n",
      "  model_144/depthwise_conv2d_1878/BiasAdd (243.00k/243.00k flops)\n",
      "  model_144/conv2d_2022/BiasAdd (243.00k/243.00k flops)\n",
      "  model_144/depthwise_conv2d_1877/BiasAdd (225.00k/225.00k flops)\n",
      "  model_144/batch_normalization_3911/FusedBatchNormV3 (218.88k/218.88k flops)\n",
      "  model_144/conv2d_2028/BiasAdd (171.00k/171.00k flops)\n",
      "  model_144/depthwise_conv2d_1883/BiasAdd (108.00k/108.00k flops)\n",
      "  model_144/batch_normalization_3914/FusedBatchNormV3 (106.66k/106.66k flops)\n",
      "  model_144/batch_normalization_3913/FusedBatchNormV3 (101.84k/101.84k flops)\n",
      "  model_144/global_average_pooling2d_144/Mean (50.94k/50.94k flops)\n",
      "  model_144/conv2d_2029/BiasAdd (50.94k/50.94k flops)\n",
      "  model_144/depthwise_conv2d_1884/BiasAdd (48.64k/48.64k flops)\n",
      "  model_144/dense_144/MatMul (15.92k/15.92k flops)\n",
      "  model_144/dense_144/Softmax (50/50 flops)\n",
      "  model_144/dense_144/BiasAdd (10/10 flops)\n",
      "\n",
      "======================End of Report==========================\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "231.095348\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-30 13:41:59.088633: I tensorflow/core/grappler/devices.cc:66] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0\n",
      "2022-04-30 13:41:59.088746: I tensorflow/core/grappler/clusters/single_machine.cc:357] Starting new session\n",
      "2022-04-30 13:41:59.094150: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:1137] Optimization results for grappler item: graph_to_optimize\n",
      "  function_optimizer: function_optimizer did nothing. time = 0.006ms.\n",
      "  function_optimizer: function_optimizer did nothing. time = 0.001ms.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=========================Options=============================\n",
      "-max_depth                  10000\n",
      "-min_bytes                  0\n",
      "-min_peak_bytes             0\n",
      "-min_residual_bytes         0\n",
      "-min_output_bytes           0\n",
      "-min_micros                 0\n",
      "-min_accelerator_micros     0\n",
      "-min_cpu_micros             0\n",
      "-min_params                 0\n",
      "-min_float_ops              1\n",
      "-min_occurrence             0\n",
      "-step                       -1\n",
      "-order_by                   float_ops\n",
      "-account_type_regexes       .*\n",
      "-start_name_regexes         .*\n",
      "-trim_name_regexes          \n",
      "-show_name_regexes          .*\n",
      "-hide_name_regexes          \n",
      "-account_displayed_op_only  true\n",
      "-select                     float_ops\n",
      "-output                     stdout:\n",
      "\n",
      "==================Model Analysis Report======================\n",
      "\n",
      "Doc:\n",
      "scope: The nodes in the model graph are organized by their names, which is hierarchical like filesystem.\n",
      "flops: Number of float operations. Note: Please read the implementation for the math behind it.\n",
      "\n",
      "Profile:\n",
      "node name | # float_ops\n",
      "_TFProfRoot (--/3.42b flops)\n",
      "  model_145/conv2d_2040/Conv2D (409.54m/409.54m flops)\n",
      "  model_145/conv2d_2035/Conv2D (396.00m/396.00m flops)\n",
      "  model_145/conv2d_2039/Conv2D (365.17m/365.17m flops)\n",
      "  model_145/conv2d_2041/Conv2D (340.42m/340.42m flops)\n",
      "  model_145/conv2d_2038/Conv2D (335.89m/335.89m flops)\n",
      "  model_145/conv2d_2037/Conv2D (262.12m/262.12m flops)\n",
      "  model_145/conv2d_2033/Conv2D (238.12m/238.12m flops)\n",
      "  model_145/conv2d_2031/Conv2D (213.81m/213.81m flops)\n",
      "  model_145/conv2d_2034/Conv2D (167.90m/167.90m flops)\n",
      "  model_145/conv2d_2036/Conv2D (150.30m/150.30m flops)\n",
      "  model_145/conv2d_2032/Conv2D (130.29m/130.29m flops)\n",
      "  model_145/conv2d_2042/Conv2D (102.48m/102.48m flops)\n",
      "  model_145/conv2d_2030/Conv2D (58.98m/58.98m flops)\n",
      "  model_145/conv2d_2043/Conv2D (55.49m/55.49m flops)\n",
      "  model_145/depthwise_conv2d_1885/depthwise (33.18m/33.18m flops)\n",
      "  model_145/depthwise_conv2d_1887/depthwise (20.22m/20.22m flops)\n",
      "  model_145/depthwise_conv2d_1886/depthwise (15.03m/15.03m flops)\n",
      "  model_145/depthwise_conv2d_1889/depthwise (14.26m/14.26m flops)\n",
      "  model_145/depthwise_conv2d_1895/depthwise (7.78m/7.78m flops)\n",
      "  model_145/depthwise_conv2d_1894/depthwise (7.68m/7.68m flops)\n",
      "  model_145/depthwise_conv2d_1892/depthwise (7.06m/7.06m flops)\n",
      "  model_145/depthwise_conv2d_1893/depthwise (6.93m/6.93m flops)\n",
      "  model_145/depthwise_conv2d_1888/depthwise (6.87m/6.87m flops)\n",
      "  model_145/batch_normalization_3917/FusedBatchNormV3 (6.68m/6.68m flops)\n",
      "  model_145/depthwise_conv2d_1891/depthwise (5.41m/5.41m flops)\n",
      "  model_145/depthwise_conv2d_1890/depthwise (4.05m/4.05m flops)\n",
      "  model_145/batch_normalization_3916/FusedBatchNormV3 (3.69m/3.69m flops)\n",
      "  model_145/batch_normalization_3915/FusedBatchNormV3 (3.69m/3.69m flops)\n",
      "  model_145/conv2d_2031/BiasAdd (3.34m/3.34m flops)\n",
      "  model_145/batch_normalization_3921/FusedBatchNormV3 (3.05m/3.05m flops)\n",
      "  model_145/batch_normalization_3919/FusedBatchNormV3 (2.25m/2.25m flops)\n",
      "  model_145/batch_normalization_3920/FusedBatchNormV3 (2.25m/2.25m flops)\n",
      "  model_145/conv2d_2030/BiasAdd (1.84m/1.84m flops)\n",
      "  model_145/depthwise_conv2d_1885/BiasAdd (1.84m/1.84m flops)\n",
      "  model_145/batch_normalization_3925/FusedBatchNormV3 (1.80m/1.80m flops)\n",
      "  model_145/batch_normalization_3918/FusedBatchNormV3 (1.67m/1.67m flops)\n",
      "  model_145/depthwise_conv2d_1896/depthwise (1.60m/1.60m flops)\n",
      "  model_145/batch_normalization_3923/FusedBatchNormV3 (1.59m/1.59m flops)\n",
      "  model_145/batch_normalization_3924/FusedBatchNormV3 (1.59m/1.59m flops)\n",
      "  model_145/conv2d_2033/BiasAdd (1.53m/1.53m flops)\n",
      "  model_145/conv2d_2032/BiasAdd (1.12m/1.12m flops)\n",
      "  model_145/depthwise_conv2d_1887/BiasAdd (1.12m/1.12m flops)\n",
      "  model_145/conv2d_2035/BiasAdd (900.00k/900.00k flops)\n",
      "  model_145/batch_normalization_3935/FusedBatchNormV3 (866.88k/866.88k flops)\n",
      "  model_145/batch_normalization_3936/FusedBatchNormV3 (866.88k/866.88k flops)\n",
      "  model_145/batch_normalization_3934/FusedBatchNormV3 (856.04k/856.04k flops)\n",
      "  model_145/batch_normalization_3933/FusedBatchNormV3 (856.04k/856.04k flops)\n",
      "  model_145/depthwise_conv2d_1886/BiasAdd (835.20k/835.20k flops)\n",
      "  model_145/conv2d_2034/BiasAdd (792.00k/792.00k flops)\n",
      "  model_145/depthwise_conv2d_1889/BiasAdd (792.00k/792.00k flops)\n",
      "  model_145/batch_normalization_3930/FusedBatchNormV3 (787.42k/787.42k flops)\n",
      "  model_145/batch_normalization_3929/FusedBatchNormV3 (787.42k/787.42k flops)\n",
      "  model_145/batch_normalization_3931/FusedBatchNormV3 (772.97k/772.97k flops)\n",
      "  model_145/batch_normalization_3932/FusedBatchNormV3 (772.97k/772.97k flops)\n",
      "  model_145/batch_normalization_3922/FusedBatchNormV3 (763.84k/763.84k flops)\n",
      "  model_145/batch_normalization_3937/FusedBatchNormV3 (711.56k/711.56k flops)\n",
      "  model_145/depthwise_conv2d_1897/depthwise (665.86k/665.86k flops)\n",
      "  model_145/batch_normalization_3927/FusedBatchNormV3 (603.20k/603.20k flops)\n",
      "  model_145/batch_normalization_3928/FusedBatchNormV3 (603.20k/603.20k flops)\n",
      "  model_145/batch_normalization_3926/FusedBatchNormV3 (451.50k/451.50k flops)\n",
      "  model_145/depthwise_conv2d_1895/BiasAdd (432.00k/432.00k flops)\n",
      "  model_145/conv2d_2040/BiasAdd (432.00k/432.00k flops)\n",
      "  model_145/conv2d_2039/BiasAdd (426.60k/426.60k flops)\n",
      "  model_145/depthwise_conv2d_1894/BiasAdd (426.60k/426.60k flops)\n",
      "  model_145/depthwise_conv2d_1892/BiasAdd (392.40k/392.40k flops)\n",
      "  model_145/conv2d_2037/BiasAdd (392.40k/392.40k flops)\n",
      "  model_145/conv2d_2038/BiasAdd (385.20k/385.20k flops)\n",
      "  model_145/depthwise_conv2d_1893/BiasAdd (385.20k/385.20k flops)\n",
      "  model_145/depthwise_conv2d_1888/BiasAdd (381.60k/381.60k flops)\n",
      "  model_145/conv2d_2041/BiasAdd (354.60k/354.60k flops)\n",
      "  model_145/depthwise_conv2d_1891/BiasAdd (300.60k/300.60k flops)\n",
      "  model_145/conv2d_2036/BiasAdd (300.60k/300.60k flops)\n",
      "  model_145/batch_normalization_3939/FusedBatchNormV3 (263.57k/263.57k flops)\n",
      "  model_145/depthwise_conv2d_1890/BiasAdd (225.00k/225.00k flops)\n",
      "  model_145/batch_normalization_3938/FusedBatchNormV3 (179.66k/179.66k flops)\n",
      "  model_145/conv2d_2042/BiasAdd (130.05k/130.05k flops)\n",
      "  model_145/batch_normalization_3941/FusedBatchNormV3 (100.50k/100.50k flops)\n",
      "  model_145/depthwise_conv2d_1896/BiasAdd (88.65k/88.65k flops)\n",
      "  model_145/batch_normalization_3940/FusedBatchNormV3 (77.45k/77.45k flops)\n",
      "  model_145/global_average_pooling2d_145/Mean (48.00k/48.00k flops)\n",
      "  model_145/conv2d_2043/BiasAdd (48.00k/48.00k flops)\n",
      "  model_145/depthwise_conv2d_1897/BiasAdd (36.99k/36.99k flops)\n",
      "  model_145/dense_145/MatMul (15.00k/15.00k flops)\n",
      "  model_145/dense_145/Softmax (50/50 flops)\n",
      "  model_145/dense_145/BiasAdd (10/10 flops)\n",
      "\n",
      "======================End of Report==========================\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "216.875972\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-30 13:42:00.039987: I tensorflow/core/grappler/devices.cc:66] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0\n",
      "2022-04-30 13:42:00.040076: I tensorflow/core/grappler/clusters/single_machine.cc:357] Starting new session\n",
      "2022-04-30 13:42:00.044720: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:1137] Optimization results for grappler item: graph_to_optimize\n",
      "  function_optimizer: function_optimizer did nothing. time = 0.005ms.\n",
      "  function_optimizer: function_optimizer did nothing. time = 0.014ms.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=========================Options=============================\n",
      "-max_depth                  10000\n",
      "-min_bytes                  0\n",
      "-min_peak_bytes             0\n",
      "-min_residual_bytes         0\n",
      "-min_output_bytes           0\n",
      "-min_micros                 0\n",
      "-min_accelerator_micros     0\n",
      "-min_cpu_micros             0\n",
      "-min_params                 0\n",
      "-min_float_ops              1\n",
      "-min_occurrence             0\n",
      "-step                       -1\n",
      "-order_by                   float_ops\n",
      "-account_type_regexes       .*\n",
      "-start_name_regexes         .*\n",
      "-trim_name_regexes          \n",
      "-show_name_regexes          .*\n",
      "-hide_name_regexes          \n",
      "-account_displayed_op_only  true\n",
      "-select                     float_ops\n",
      "-output                     stdout:\n",
      "\n",
      "==================Model Analysis Report======================\n",
      "\n",
      "Doc:\n",
      "scope: The nodes in the model graph are organized by their names, which is hierarchical like filesystem.\n",
      "flops: Number of float operations. Note: Please read the implementation for the math behind it.\n",
      "\n",
      "Profile:\n",
      "node name | # float_ops\n",
      "_TFProfRoot (--/2.91b flops)\n",
      "  model_146/conv2d_2047/Conv2D (407.81m/407.81m flops)\n",
      "  model_146/conv2d_2054/Conv2D (296.70m/296.70m flops)\n",
      "  model_146/conv2d_2049/Conv2D (294.74m/294.74m flops)\n",
      "  model_146/conv2d_2053/Conv2D (268.79m/268.79m flops)\n",
      "  model_146/conv2d_2052/Conv2D (247.71m/247.71m flops)\n",
      "  model_146/conv2d_2055/Conv2D (218.16m/218.16m flops)\n",
      "  model_146/conv2d_2051/Conv2D (169.20m/169.20m flops)\n",
      "  model_146/conv2d_2048/Conv2D (148.61m/148.61m flops)\n",
      "  model_146/conv2d_2045/Conv2D (132.71m/132.71m flops)\n",
      "  model_146/conv2d_2056/Conv2D (129.87m/129.87m flops)\n",
      "  model_146/conv2d_2057/Conv2D (122.64m/122.64m flops)\n",
      "  model_146/conv2d_2046/Conv2D (122.34m/122.34m flops)\n",
      "  model_146/conv2d_2050/Conv2D (107.10m/107.10m flops)\n",
      "  model_146/conv2d_2044/Conv2D (58.98m/58.98m flops)\n",
      "  model_146/depthwise_conv2d_1898/depthwise (33.18m/33.18m flops)\n",
      "  model_146/depthwise_conv2d_1900/depthwise (30.59m/30.59m flops)\n",
      "  model_146/depthwise_conv2d_1902/depthwise (11.15m/11.15m flops)\n",
      "  model_146/depthwise_conv2d_1899/depthwise (9.33m/9.33m flops)\n",
      "  model_146/depthwise_conv2d_1901/depthwise (7.78m/7.78m flops)\n",
      "  model_146/depthwise_conv2d_1907/depthwise (6.61m/6.61m flops)\n",
      "  model_146/depthwise_conv2d_1908/depthwise (6.54m/6.54m flops)\n",
      "  model_146/depthwise_conv2d_1905/depthwise (6.09m/6.09m flops)\n",
      "  model_146/depthwise_conv2d_1906/depthwise (5.93m/5.93m flops)\n",
      "  model_146/batch_normalization_3944/FusedBatchNormV3 (4.15m/4.15m flops)\n",
      "  model_146/depthwise_conv2d_1904/depthwise (4.05m/4.05m flops)\n",
      "  model_146/depthwise_conv2d_1903/depthwise (3.86m/3.86m flops)\n",
      "  model_146/batch_normalization_3943/FusedBatchNormV3 (3.69m/3.69m flops)\n",
      "  model_146/batch_normalization_3942/FusedBatchNormV3 (3.69m/3.69m flops)\n",
      "  model_146/batch_normalization_3948/FusedBatchNormV3 (3.46m/3.46m flops)\n",
      "  model_146/batch_normalization_3946/FusedBatchNormV3 (3.40m/3.40m flops)\n",
      "  model_146/batch_normalization_3947/FusedBatchNormV3 (3.40m/3.40m flops)\n",
      "  model_146/conv2d_2045/BiasAdd (2.07m/2.07m flops)\n",
      "  model_146/conv2d_2044/BiasAdd (1.84m/1.84m flops)\n",
      "  model_146/depthwise_conv2d_1898/BiasAdd (1.84m/1.84m flops)\n",
      "  model_146/conv2d_2047/BiasAdd (1.73m/1.73m flops)\n",
      "  model_146/batch_normalization_3952/FusedBatchNormV3 (1.72m/1.72m flops)\n",
      "  model_146/conv2d_2046/BiasAdd (1.70m/1.70m flops)\n",
      "  model_146/depthwise_conv2d_1900/BiasAdd (1.70m/1.70m flops)\n",
      "  model_146/batch_normalization_3950/FusedBatchNormV3 (1.24m/1.24m flops)\n",
      "  model_146/batch_normalization_3951/FusedBatchNormV3 (1.24m/1.24m flops)\n",
      "  model_146/depthwise_conv2d_1909/depthwise (1.22m/1.22m flops)\n",
      "  model_146/depthwise_conv2d_1910/depthwise (1.11m/1.11m flops)\n",
      "  model_146/batch_normalization_3945/FusedBatchNormV3 (1.04m/1.04m flops)\n",
      "  model_146/batch_normalization_3949/FusedBatchNormV3 (864.72k/864.72k flops)\n",
      "  model_146/conv2d_2049/BiasAdd (856.80k/856.80k flops)\n",
      "  model_146/batch_normalization_3960/FusedBatchNormV3 (736.85k/736.85k flops)\n",
      "  model_146/batch_normalization_3961/FusedBatchNormV3 (736.85k/736.85k flops)\n",
      "  model_146/batch_normalization_3962/FusedBatchNormV3 (729.62k/729.62k flops)\n",
      "  model_146/batch_normalization_3963/FusedBatchNormV3 (729.62k/729.62k flops)\n",
      "  model_146/batch_normalization_3957/FusedBatchNormV3 (679.06k/679.06k flops)\n",
      "  model_146/batch_normalization_3956/FusedBatchNormV3 (679.06k/679.06k flops)\n",
      "  model_146/batch_normalization_3959/FusedBatchNormV3 (661.00k/661.00k flops)\n",
      "  model_146/batch_normalization_3958/FusedBatchNormV3 (661.00k/661.00k flops)\n",
      "  model_146/depthwise_conv2d_1902/BiasAdd (619.20k/619.20k flops)\n",
      "  model_146/conv2d_2048/BiasAdd (619.20k/619.20k flops)\n",
      "  model_146/batch_normalization_3964/FusedBatchNormV3 (541.80k/541.80k flops)\n",
      "  model_146/depthwise_conv2d_1899/BiasAdd (518.40k/518.40k flops)\n",
      "  model_146/batch_normalization_3954/FusedBatchNormV3 (451.50k/451.50k flops)\n",
      "  model_146/batch_normalization_3955/FusedBatchNormV3 (451.50k/451.50k flops)\n",
      "  model_146/batch_normalization_3966/FusedBatchNormV3 (438.67k/438.67k flops)\n",
      "  model_146/depthwise_conv2d_1901/BiasAdd (432.00k/432.00k flops)\n",
      "  model_146/batch_normalization_3953/FusedBatchNormV3 (429.83k/429.83k flops)\n",
      "  model_146/depthwise_conv2d_1907/BiasAdd (367.20k/367.20k flops)\n",
      "  model_146/conv2d_2053/BiasAdd (367.20k/367.20k flops)\n",
      "  model_146/depthwise_conv2d_1908/BiasAdd (363.60k/363.60k flops)\n",
      "  model_146/conv2d_2054/BiasAdd (363.60k/363.60k flops)\n",
      "  model_146/conv2d_2051/BiasAdd (338.40k/338.40k flops)\n",
      "  model_146/depthwise_conv2d_1905/BiasAdd (338.40k/338.40k flops)\n",
      "  model_146/conv2d_2052/BiasAdd (329.40k/329.40k flops)\n",
      "  model_146/depthwise_conv2d_1906/BiasAdd (329.40k/329.40k flops)\n",
      "  model_146/conv2d_2055/BiasAdd (270.00k/270.00k flops)\n",
      "  model_146/depthwise_conv2d_1904/BiasAdd (225.00k/225.00k flops)\n",
      "  model_146/conv2d_2050/BiasAdd (225.00k/225.00k flops)\n",
      "  model_146/conv2d_2056/BiasAdd (216.45k/216.45k flops)\n",
      "  model_146/depthwise_conv2d_1903/BiasAdd (214.20k/214.20k flops)\n",
      "  model_146/batch_normalization_3965/FusedBatchNormV3 (136.80k/136.80k flops)\n",
      "  model_146/batch_normalization_3968/FusedBatchNormV3 (133.46k/133.46k flops)\n",
      "  model_146/batch_normalization_3967/FusedBatchNormV3 (128.91k/128.91k flops)\n",
      "  model_146/depthwise_conv2d_1909/BiasAdd (67.50k/67.50k flops)\n",
      "  model_146/global_average_pooling2d_146/Mean (63.74k/63.74k flops)\n",
      "  model_146/conv2d_2057/BiasAdd (63.74k/63.74k flops)\n",
      "  model_146/depthwise_conv2d_1910/BiasAdd (61.57k/61.57k flops)\n",
      "  model_146/dense_146/MatMul (19.92k/19.92k flops)\n",
      "  model_146/dense_146/Softmax (50/50 flops)\n",
      "  model_146/dense_146/BiasAdd (10/10 flops)\n",
      "\n",
      "======================End of Report==========================\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "224.561164\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-30 13:42:00.979204: I tensorflow/core/grappler/devices.cc:66] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0\n",
      "2022-04-30 13:42:00.979327: I tensorflow/core/grappler/clusters/single_machine.cc:357] Starting new session\n",
      "2022-04-30 13:42:00.983715: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:1137] Optimization results for grappler item: graph_to_optimize\n",
      "  function_optimizer: function_optimizer did nothing. time = 0.005ms.\n",
      "  function_optimizer: function_optimizer did nothing. time = 0.001ms.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=========================Options=============================\n",
      "-max_depth                  10000\n",
      "-min_bytes                  0\n",
      "-min_peak_bytes             0\n",
      "-min_residual_bytes         0\n",
      "-min_output_bytes           0\n",
      "-min_micros                 0\n",
      "-min_accelerator_micros     0\n",
      "-min_cpu_micros             0\n",
      "-min_params                 0\n",
      "-min_float_ops              1\n",
      "-min_occurrence             0\n",
      "-step                       -1\n",
      "-order_by                   float_ops\n",
      "-account_type_regexes       .*\n",
      "-start_name_regexes         .*\n",
      "-trim_name_regexes          \n",
      "-show_name_regexes          .*\n",
      "-hide_name_regexes          \n",
      "-account_displayed_op_only  true\n",
      "-select                     float_ops\n",
      "-output                     stdout:\n",
      "\n",
      "==================Model Analysis Report======================\n",
      "\n",
      "Doc:\n",
      "scope: The nodes in the model graph are organized by their names, which is hierarchical like filesystem.\n",
      "flops: Number of float operations. Note: Please read the implementation for the math behind it.\n",
      "\n",
      "Profile:\n",
      "node name | # float_ops\n",
      "_TFProfRoot (--/3.11b flops)\n",
      "  model_147/conv2d_2061/Conv2D (442.71m/442.71m flops)\n",
      "  model_147/conv2d_2066/Conv2D (435.46m/435.46m flops)\n",
      "  model_147/conv2d_2067/Conv2D (283.39m/283.39m flops)\n",
      "  model_147/conv2d_2063/Conv2D (277.20m/277.20m flops)\n",
      "  model_147/conv2d_2065/Conv2D (257.64m/257.64m flops)\n",
      "  model_147/conv2d_2068/Conv2D (199.56m/199.56m flops)\n",
      "  model_147/conv2d_2069/Conv2D (175.22m/175.22m flops)\n",
      "  model_147/conv2d_2059/Conv2D (147.46m/147.46m flops)\n",
      "  model_147/conv2d_2060/Conv2D (140.54m/140.54m flops)\n",
      "  model_147/conv2d_2062/Conv2D (139.71m/139.71m flops)\n",
      "  model_147/conv2d_2064/Conv2D (127.80m/127.80m flops)\n",
      "  model_147/conv2d_2071/Conv2D (118.00m/118.00m flops)\n",
      "  model_147/conv2d_2070/Conv2D (116.90m/116.90m flops)\n",
      "  model_147/conv2d_2058/Conv2D (58.98m/58.98m flops)\n",
      "  model_147/depthwise_conv2d_1911/depthwise (33.18m/33.18m flops)\n",
      "  model_147/depthwise_conv2d_1913/depthwise (31.62m/31.62m flops)\n",
      "  model_147/depthwise_conv2d_1912/depthwise (10.37m/10.37m flops)\n",
      "  model_147/depthwise_conv2d_1915/depthwise (9.98m/9.98m flops)\n",
      "  model_147/depthwise_conv2d_1914/depthwise (8.16m/8.16m flops)\n",
      "  model_147/depthwise_conv2d_1918/depthwise (8.16m/8.16m flops)\n",
      "  model_147/depthwise_conv2d_1919/depthwise (7.78m/7.78m flops)\n",
      "  model_147/depthwise_conv2d_1921/depthwise (5.48m/5.48m flops)\n",
      "  model_147/depthwise_conv2d_1920/depthwise (5.31m/5.31m flops)\n",
      "  model_147/batch_normalization_3971/FusedBatchNormV3 (4.61m/4.61m flops)\n",
      "  model_147/depthwise_conv2d_1917/depthwise (4.60m/4.60m flops)\n",
      "  model_147/depthwise_conv2d_1916/depthwise (4.05m/4.05m flops)\n",
      "  model_147/batch_normalization_3970/FusedBatchNormV3 (3.69m/3.69m flops)\n",
      "  model_147/batch_normalization_3969/FusedBatchNormV3 (3.69m/3.69m flops)\n",
      "  model_147/batch_normalization_3975/FusedBatchNormV3 (3.63m/3.63m flops)\n",
      "  model_147/batch_normalization_3973/FusedBatchNormV3 (3.51m/3.51m flops)\n",
      "  model_147/batch_normalization_3974/FusedBatchNormV3 (3.51m/3.51m flops)\n",
      "  model_147/conv2d_2059/BiasAdd (2.30m/2.30m flops)\n",
      "  model_147/depthwise_conv2d_1911/BiasAdd (1.84m/1.84m flops)\n",
      "  model_147/conv2d_2058/BiasAdd (1.84m/1.84m flops)\n",
      "  model_147/conv2d_2061/BiasAdd (1.81m/1.81m flops)\n",
      "  model_147/batch_normalization_3979/FusedBatchNormV3 (1.80m/1.80m flops)\n",
      "  model_147/conv2d_2060/BiasAdd (1.76m/1.76m flops)\n",
      "  model_147/depthwise_conv2d_1913/BiasAdd (1.76m/1.76m flops)\n",
      "  model_147/depthwise_conv2d_1922/depthwise (1.17m/1.17m flops)\n",
      "  model_147/batch_normalization_3972/FusedBatchNormV3 (1.15m/1.15m flops)\n",
      "  model_147/batch_normalization_3978/FusedBatchNormV3 (1.11m/1.11m flops)\n",
      "  model_147/batch_normalization_3977/FusedBatchNormV3 (1.11m/1.11m flops)\n",
      "  model_147/depthwise_conv2d_1923/depthwise (1.04m/1.04m flops)\n",
      "  model_147/batch_normalization_3984/FusedBatchNormV3 (910.22k/910.22k flops)\n",
      "  model_147/batch_normalization_3983/FusedBatchNormV3 (910.22k/910.22k flops)\n",
      "  model_147/batch_normalization_3976/FusedBatchNormV3 (907.96k/907.96k flops)\n",
      "  model_147/conv2d_2063/BiasAdd (900.00k/900.00k flops)\n",
      "  model_147/batch_normalization_3986/FusedBatchNormV3 (866.88k/866.88k flops)\n",
      "  model_147/batch_normalization_3985/FusedBatchNormV3 (866.88k/866.88k flops)\n",
      "  model_147/batch_normalization_3989/FusedBatchNormV3 (610.43k/610.43k flops)\n",
      "  model_147/batch_normalization_3990/FusedBatchNormV3 (610.43k/610.43k flops)\n",
      "  model_147/batch_normalization_3988/FusedBatchNormV3 (592.37k/592.37k flops)\n",
      "  model_147/batch_normalization_3987/FusedBatchNormV3 (592.37k/592.37k flops)\n",
      "  model_147/depthwise_conv2d_1912/BiasAdd (576.00k/576.00k flops)\n",
      "  model_147/depthwise_conv2d_1915/BiasAdd (554.40k/554.40k flops)\n",
      "  model_147/conv2d_2062/BiasAdd (554.40k/554.40k flops)\n",
      "  model_147/batch_normalization_3991/FusedBatchNormV3 (520.13k/520.13k flops)\n",
      "  model_147/batch_normalization_3982/FusedBatchNormV3 (512.90k/512.90k flops)\n",
      "  model_147/batch_normalization_3981/FusedBatchNormV3 (512.90k/512.90k flops)\n",
      "  model_147/depthwise_conv2d_1918/BiasAdd (453.60k/453.60k flops)\n",
      "  model_147/depthwise_conv2d_1914/BiasAdd (453.60k/453.60k flops)\n",
      "  model_147/conv2d_2065/BiasAdd (453.60k/453.60k flops)\n",
      "  model_147/batch_normalization_3980/FusedBatchNormV3 (451.50k/451.50k flops)\n",
      "  model_147/depthwise_conv2d_1919/BiasAdd (432.00k/432.00k flops)\n",
      "  model_147/conv2d_2066/BiasAdd (432.00k/432.00k flops)\n",
      "  model_147/batch_normalization_3993/FusedBatchNormV3 (411.31k/411.31k flops)\n",
      "  model_147/depthwise_conv2d_1921/BiasAdd (304.20k/304.20k flops)\n",
      "  model_147/conv2d_2068/BiasAdd (304.20k/304.20k flops)\n",
      "  model_147/conv2d_2067/BiasAdd (295.20k/295.20k flops)\n",
      "  model_147/depthwise_conv2d_1920/BiasAdd (295.20k/295.20k flops)\n",
      "  model_147/conv2d_2069/BiasAdd (259.20k/259.20k flops)\n",
      "  model_147/depthwise_conv2d_1917/BiasAdd (255.60k/255.60k flops)\n",
      "  model_147/conv2d_2064/BiasAdd (255.60k/255.60k flops)\n",
      "  model_147/depthwise_conv2d_1916/BiasAdd (225.00k/225.00k flops)\n",
      "  model_147/conv2d_2070/BiasAdd (202.95k/202.95k flops)\n",
      "  model_147/batch_normalization_3995/FusedBatchNormV3 (136.95k/136.95k flops)\n",
      "  model_147/batch_normalization_3992/FusedBatchNormV3 (131.33k/131.33k flops)\n",
      "  model_147/batch_normalization_3994/FusedBatchNormV3 (120.87k/120.87k flops)\n",
      "  model_147/global_average_pooling2d_147/Mean (65.41k/65.41k flops)\n",
      "  model_147/conv2d_2071/BiasAdd (65.41k/65.41k flops)\n",
      "  model_147/depthwise_conv2d_1922/BiasAdd (64.80k/64.80k flops)\n",
      "  model_147/depthwise_conv2d_1923/BiasAdd (57.73k/57.73k flops)\n",
      "  model_147/dense_147/MatMul (20.44k/20.44k flops)\n",
      "  model_147/dense_147/Softmax (50/50 flops)\n",
      "  model_147/dense_147/BiasAdd (10/10 flops)\n",
      "\n",
      "======================End of Report==========================\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "214.359644\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-30 13:42:02.025072: I tensorflow/core/grappler/devices.cc:66] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0\n",
      "2022-04-30 13:42:02.025190: I tensorflow/core/grappler/clusters/single_machine.cc:357] Starting new session\n",
      "2022-04-30 13:42:02.029998: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:1137] Optimization results for grappler item: graph_to_optimize\n",
      "  function_optimizer: function_optimizer did nothing. time = 0.006ms.\n",
      "  function_optimizer: function_optimizer did nothing. time = 0ms.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=========================Options=============================\n",
      "-max_depth                  10000\n",
      "-min_bytes                  0\n",
      "-min_peak_bytes             0\n",
      "-min_residual_bytes         0\n",
      "-min_output_bytes           0\n",
      "-min_micros                 0\n",
      "-min_accelerator_micros     0\n",
      "-min_cpu_micros             0\n",
      "-min_params                 0\n",
      "-min_float_ops              1\n",
      "-min_occurrence             0\n",
      "-step                       -1\n",
      "-order_by                   float_ops\n",
      "-account_type_regexes       .*\n",
      "-start_name_regexes         .*\n",
      "-trim_name_regexes          \n",
      "-show_name_regexes          .*\n",
      "-hide_name_regexes          \n",
      "-account_displayed_op_only  true\n",
      "-select                     float_ops\n",
      "-output                     stdout:\n",
      "\n",
      "==================Model Analysis Report======================\n",
      "\n",
      "Doc:\n",
      "scope: The nodes in the model graph are organized by their names, which is hierarchical like filesystem.\n",
      "flops: Number of float operations. Note: Please read the implementation for the math behind it.\n",
      "\n",
      "Profile:\n",
      "node name | # float_ops\n",
      "_TFProfRoot (--/2.87b flops)\n",
      "  model_148/conv2d_2082/Conv2D (379.14m/379.14m flops)\n",
      "  model_148/conv2d_2081/Conv2D (372.43m/372.43m flops)\n",
      "  model_148/conv2d_2083/Conv2D (349.85m/349.85m flops)\n",
      "  model_148/conv2d_2080/Conv2D (342.06m/342.06m flops)\n",
      "  model_148/conv2d_2075/Conv2D (323.60m/323.60m flops)\n",
      "  model_148/conv2d_2073/Conv2D (184.32m/184.32m flops)\n",
      "  model_148/conv2d_2079/Conv2D (177.19m/177.19m flops)\n",
      "  model_148/conv2d_2074/Conv2D (152.64m/152.64m flops)\n",
      "  model_148/conv2d_2077/Conv2D (91.93m/91.93m flops)\n",
      "  model_148/conv2d_2084/Conv2D (86.69m/86.69m flops)\n",
      "  model_148/conv2d_2076/Conv2D (85.48m/85.48m flops)\n",
      "  model_148/conv2d_2072/Conv2D (58.98m/58.98m flops)\n",
      "  model_148/conv2d_2078/Conv2D (47.20m/47.20m flops)\n",
      "  model_148/conv2d_2085/Conv2D (42.32m/42.32m flops)\n",
      "  model_148/depthwise_conv2d_1924/depthwise (33.18m/33.18m flops)\n",
      "  model_148/depthwise_conv2d_1926/depthwise (27.48m/27.48m flops)\n",
      "  model_148/depthwise_conv2d_1925/depthwise (12.96m/12.96m flops)\n",
      "  model_148/depthwise_conv2d_1933/depthwise (7.55m/7.55m flops)\n",
      "  model_148/depthwise_conv2d_1934/depthwise (7.32m/7.32m flops)\n",
      "  model_148/depthwise_conv2d_1928/depthwise (7.26m/7.26m flops)\n",
      "  model_148/depthwise_conv2d_1932/depthwise (7.19m/7.19m flops)\n",
      "  model_148/depthwise_conv2d_1931/depthwise (6.93m/6.93m flops)\n",
      "  model_148/depthwise_conv2d_1927/depthwise (6.87m/6.87m flops)\n",
      "  model_148/batch_normalization_3998/FusedBatchNormV3 (5.76m/5.76m flops)\n",
      "  model_148/depthwise_conv2d_1930/depthwise (3.73m/3.73m flops)\n",
      "  model_148/batch_normalization_3997/FusedBatchNormV3 (3.69m/3.69m flops)\n",
      "  model_148/batch_normalization_3996/FusedBatchNormV3 (3.69m/3.69m flops)\n",
      "  model_148/batch_normalization_4000/FusedBatchNormV3 (3.05m/3.05m flops)\n",
      "  model_148/batch_normalization_4001/FusedBatchNormV3 (3.05m/3.05m flops)\n",
      "  model_148/batch_normalization_4002/FusedBatchNormV3 (3.05m/3.05m flops)\n",
      "  model_148/conv2d_2073/BiasAdd (2.88m/2.88m flops)\n",
      "  model_148/depthwise_conv2d_1929/depthwise (1.85m/1.85m flops)\n",
      "  model_148/conv2d_2072/BiasAdd (1.84m/1.84m flops)\n",
      "  model_148/depthwise_conv2d_1924/BiasAdd (1.84m/1.84m flops)\n",
      "  model_148/depthwise_conv2d_1935/depthwise (1.74m/1.74m flops)\n",
      "  model_148/conv2d_2074/BiasAdd (1.53m/1.53m flops)\n",
      "  model_148/depthwise_conv2d_1926/BiasAdd (1.53m/1.53m flops)\n",
      "  model_148/conv2d_2075/BiasAdd (1.53m/1.53m flops)\n",
      "  model_148/batch_normalization_3999/FusedBatchNormV3 (1.44m/1.44m flops)\n",
      "  model_148/batch_normalization_4015/FusedBatchNormV3 (841.60k/841.60k flops)\n",
      "  model_148/batch_normalization_4014/FusedBatchNormV3 (841.60k/841.60k flops)\n",
      "  model_148/batch_normalization_4006/FusedBatchNormV3 (821.48k/821.48k flops)\n",
      "  model_148/batch_normalization_4016/FusedBatchNormV3 (816.31k/816.31k flops)\n",
      "  model_148/batch_normalization_4017/FusedBatchNormV3 (816.31k/816.31k flops)\n",
      "  model_148/batch_normalization_4005/FusedBatchNormV3 (807.07k/807.07k flops)\n",
      "  model_148/batch_normalization_4004/FusedBatchNormV3 (807.07k/807.07k flops)\n",
      "  model_148/batch_normalization_4012/FusedBatchNormV3 (801.86k/801.86k flops)\n",
      "  model_148/batch_normalization_4013/FusedBatchNormV3 (801.86k/801.86k flops)\n",
      "  model_148/batch_normalization_4018/FusedBatchNormV3 (776.58k/776.58k flops)\n",
      "  model_148/batch_normalization_4011/FusedBatchNormV3 (772.97k/772.97k flops)\n",
      "  model_148/batch_normalization_4010/FusedBatchNormV3 (772.97k/772.97k flops)\n",
      "  model_148/batch_normalization_4003/FusedBatchNormV3 (763.84k/763.84k flops)\n",
      "  model_148/depthwise_conv2d_1925/BiasAdd (720.00k/720.00k flops)\n",
      "  model_148/depthwise_conv2d_1936/depthwise (516.10k/516.10k flops)\n",
      "  model_148/conv2d_2081/BiasAdd (419.40k/419.40k flops)\n",
      "  model_148/depthwise_conv2d_1933/BiasAdd (419.40k/419.40k flops)\n",
      "  model_148/batch_normalization_4009/FusedBatchNormV3 (415.38k/415.38k flops)\n",
      "  model_148/batch_normalization_4008/FusedBatchNormV3 (415.38k/415.38k flops)\n",
      "  model_148/conv2d_2077/BiasAdd (410.40k/410.40k flops)\n",
      "  model_148/depthwise_conv2d_1934/BiasAdd (406.80k/406.80k flops)\n",
      "  model_148/conv2d_2082/BiasAdd (406.80k/406.80k flops)\n",
      "  model_148/depthwise_conv2d_1928/BiasAdd (403.20k/403.20k flops)\n",
      "  model_148/conv2d_2076/BiasAdd (403.20k/403.20k flops)\n",
      "  model_148/conv2d_2080/BiasAdd (399.60k/399.60k flops)\n",
      "  model_148/depthwise_conv2d_1932/BiasAdd (399.60k/399.60k flops)\n",
      "  model_148/conv2d_2083/BiasAdd (387.00k/387.00k flops)\n",
      "  model_148/conv2d_2079/BiasAdd (385.20k/385.20k flops)\n",
      "  model_148/depthwise_conv2d_1931/BiasAdd (385.20k/385.20k flops)\n",
      "  model_148/depthwise_conv2d_1927/BiasAdd (381.60k/381.60k flops)\n",
      "  model_148/conv2d_2078/BiasAdd (207.00k/207.00k flops)\n",
      "  model_148/depthwise_conv2d_1930/BiasAdd (207.00k/207.00k flops)\n",
      "  model_148/batch_normalization_4007/FusedBatchNormV3 (205.88k/205.88k flops)\n",
      "  model_148/batch_normalization_4020/FusedBatchNormV3 (204.29k/204.29k flops)\n",
      "  model_148/batch_normalization_4019/FusedBatchNormV3 (196.08k/196.08k flops)\n",
      "  model_148/depthwise_conv2d_1929/BiasAdd (102.60k/102.60k flops)\n",
      "  model_148/conv2d_2084/BiasAdd (100.80k/100.80k flops)\n",
      "  model_148/batch_normalization_4022/FusedBatchNormV3 (98.89k/98.89k flops)\n",
      "  model_148/depthwise_conv2d_1935/BiasAdd (96.75k/96.75k flops)\n",
      "  model_148/batch_normalization_4021/FusedBatchNormV3 (60.03k/60.03k flops)\n",
      "  model_148/global_average_pooling2d_148/Mean (47.23k/47.23k flops)\n",
      "  model_148/conv2d_2085/BiasAdd (47.23k/47.23k flops)\n",
      "  model_148/depthwise_conv2d_1936/BiasAdd (28.67k/28.67k flops)\n",
      "  model_148/dense_148/MatMul (14.76k/14.76k flops)\n",
      "  model_148/dense_148/Softmax (50/50 flops)\n",
      "  model_148/dense_148/BiasAdd (10/10 flops)\n",
      "\n",
      "======================End of Report==========================\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "198.82434\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-30 13:42:02.947915: I tensorflow/core/grappler/devices.cc:66] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0\n",
      "2022-04-30 13:42:02.948029: I tensorflow/core/grappler/clusters/single_machine.cc:357] Starting new session\n",
      "2022-04-30 13:42:02.952408: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:1137] Optimization results for grappler item: graph_to_optimize\n",
      "  function_optimizer: function_optimizer did nothing. time = 0.005ms.\n",
      "  function_optimizer: function_optimizer did nothing. time = 0.001ms.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=========================Options=============================\n",
      "-max_depth                  10000\n",
      "-min_bytes                  0\n",
      "-min_peak_bytes             0\n",
      "-min_residual_bytes         0\n",
      "-min_output_bytes           0\n",
      "-min_micros                 0\n",
      "-min_accelerator_micros     0\n",
      "-min_cpu_micros             0\n",
      "-min_params                 0\n",
      "-min_float_ops              1\n",
      "-min_occurrence             0\n",
      "-step                       -1\n",
      "-order_by                   float_ops\n",
      "-account_type_regexes       .*\n",
      "-start_name_regexes         .*\n",
      "-trim_name_regexes          \n",
      "-show_name_regexes          .*\n",
      "-hide_name_regexes          \n",
      "-account_displayed_op_only  true\n",
      "-select                     float_ops\n",
      "-output                     stdout:\n",
      "\n",
      "==================Model Analysis Report======================\n",
      "\n",
      "Doc:\n",
      "scope: The nodes in the model graph are organized by their names, which is hierarchical like filesystem.\n",
      "flops: Number of float operations. Note: Please read the implementation for the math behind it.\n",
      "\n",
      "Profile:\n",
      "node name | # float_ops\n",
      "_TFProfRoot (--/2.50b flops)\n",
      "  model_149/conv2d_2091/Conv2D (317.95m/317.95m flops)\n",
      "  model_149/conv2d_2095/Conv2D (285.47m/285.47m flops)\n",
      "  model_149/conv2d_2096/Conv2D (264.50m/264.50m flops)\n",
      "  model_149/conv2d_2097/Conv2D (252.69m/252.69m flops)\n",
      "  model_149/conv2d_2094/Conv2D (209.00m/209.00m flops)\n",
      "  model_149/conv2d_2087/Conv2D (191.69m/191.69m flops)\n",
      "  model_149/conv2d_2093/Conv2D (190.11m/190.11m flops)\n",
      "  model_149/conv2d_2092/Conv2D (139.10m/139.10m flops)\n",
      "  model_149/conv2d_2089/Conv2D (113.82m/113.82m flops)\n",
      "  model_149/conv2d_2090/Conv2D (100.68m/100.68m flops)\n",
      "  model_149/conv2d_2098/Conv2D (96.69m/96.69m flops)\n",
      "  model_149/conv2d_2088/Conv2D (77.88m/77.88m flops)\n",
      "  model_149/conv2d_2086/Conv2D (58.98m/58.98m flops)\n",
      "  model_149/conv2d_2099/Conv2D (37.27m/37.27m flops)\n",
      "  model_149/depthwise_conv2d_1937/depthwise (33.18m/33.18m flops)\n",
      "  model_149/depthwise_conv2d_1938/depthwise (13.48m/13.48m flops)\n",
      "  model_149/depthwise_conv2d_1939/depthwise (13.48m/13.48m flops)\n",
      "  model_149/depthwise_conv2d_1941/depthwise (11.92m/11.92m flops)\n",
      "  model_149/depthwise_conv2d_1946/depthwise (7.26m/7.26m flops)\n",
      "  model_149/batch_normalization_4025/FusedBatchNormV3 (5.99m/5.99m flops)\n",
      "  model_149/depthwise_conv2d_1945/depthwise (5.73m/5.73m flops)\n",
      "  model_149/depthwise_conv2d_1944/depthwise (5.31m/5.31m flops)\n",
      "  model_149/depthwise_conv2d_1947/depthwise (5.31m/5.31m flops)\n",
      "  model_149/depthwise_conv2d_1943/depthwise (5.22m/5.22m flops)\n",
      "  model_149/depthwise_conv2d_1940/depthwise (4.92m/4.92m flops)\n",
      "  model_149/depthwise_conv2d_1942/depthwise (3.89m/3.89m flops)\n",
      "  model_149/batch_normalization_4024/FusedBatchNormV3 (3.69m/3.69m flops)\n",
      "  model_149/batch_normalization_4023/FusedBatchNormV3 (3.69m/3.69m flops)\n",
      "  model_149/conv2d_2087/BiasAdd (3.00m/3.00m flops)\n",
      "  model_149/batch_normalization_4029/FusedBatchNormV3 (2.19m/2.19m flops)\n",
      "  model_149/conv2d_2086/BiasAdd (1.84m/1.84m flops)\n",
      "  model_149/depthwise_conv2d_1937/BiasAdd (1.84m/1.84m flops)\n",
      "  model_149/depthwise_conv2d_1948/depthwise (1.73m/1.73m flops)\n",
      "  model_149/batch_normalization_4033/FusedBatchNormV3 (1.73m/1.73m flops)\n",
      "  model_149/batch_normalization_4026/FusedBatchNormV3 (1.50m/1.50m flops)\n",
      "  model_149/batch_normalization_4027/FusedBatchNormV3 (1.50m/1.50m flops)\n",
      "  model_149/batch_normalization_4028/FusedBatchNormV3 (1.50m/1.50m flops)\n",
      "  model_149/batch_normalization_4031/FusedBatchNormV3 (1.33m/1.33m flops)\n",
      "  model_149/batch_normalization_4032/FusedBatchNormV3 (1.33m/1.33m flops)\n",
      "  model_149/conv2d_2089/BiasAdd (1.09m/1.09m flops)\n",
      "  model_149/conv2d_2091/BiasAdd (864.00k/864.00k flops)\n",
      "  model_149/batch_normalization_4042/FusedBatchNormV3 (809.09k/809.09k flops)\n",
      "  model_149/batch_normalization_4041/FusedBatchNormV3 (809.09k/809.09k flops)\n",
      "  model_149/batch_normalization_4045/FusedBatchNormV3 (772.97k/772.97k flops)\n",
      "  model_149/depthwise_conv2d_1939/BiasAdd (748.80k/748.80k flops)\n",
      "  model_149/depthwise_conv2d_1938/BiasAdd (748.80k/748.80k flops)\n",
      "  model_149/conv2d_2088/BiasAdd (748.80k/748.80k flops)\n",
      "  model_149/depthwise_conv2d_1941/BiasAdd (662.40k/662.40k flops)\n",
      "  model_149/conv2d_2090/BiasAdd (662.40k/662.40k flops)\n",
      "  model_149/batch_normalization_4040/FusedBatchNormV3 (639.32k/639.32k flops)\n",
      "  model_149/batch_normalization_4039/FusedBatchNormV3 (639.32k/639.32k flops)\n",
      "  model_149/batch_normalization_4043/FusedBatchNormV3 (592.37k/592.37k flops)\n",
      "  model_149/batch_normalization_4044/FusedBatchNormV3 (592.37k/592.37k flops)\n",
      "  model_149/batch_normalization_4037/FusedBatchNormV3 (592.37k/592.37k flops)\n",
      "  model_149/batch_normalization_4038/FusedBatchNormV3 (592.37k/592.37k flops)\n",
      "  model_149/batch_normalization_4036/FusedBatchNormV3 (581.53k/581.53k flops)\n",
      "  model_149/batch_normalization_4035/FusedBatchNormV3 (581.53k/581.53k flops)\n",
      "  model_149/depthwise_conv2d_1949/depthwise (578.30k/578.30k flops)\n",
      "  model_149/batch_normalization_4030/FusedBatchNormV3 (547.66k/547.66k flops)\n",
      "  model_149/batch_normalization_4034/FusedBatchNormV3 (433.44k/433.44k flops)\n",
      "  model_149/depthwise_conv2d_1946/BiasAdd (403.20k/403.20k flops)\n",
      "  model_149/conv2d_2095/BiasAdd (403.20k/403.20k flops)\n",
      "  model_149/conv2d_2097/BiasAdd (385.20k/385.20k flops)\n",
      "  model_149/depthwise_conv2d_1945/BiasAdd (318.60k/318.60k flops)\n",
      "  model_149/conv2d_2094/BiasAdd (318.60k/318.60k flops)\n",
      "  model_149/depthwise_conv2d_1944/BiasAdd (295.20k/295.20k flops)\n",
      "  model_149/depthwise_conv2d_1947/BiasAdd (295.20k/295.20k flops)\n",
      "  model_149/conv2d_2093/BiasAdd (295.20k/295.20k flops)\n",
      "  model_149/conv2d_2096/BiasAdd (295.20k/295.20k flops)\n",
      "  model_149/depthwise_conv2d_1943/BiasAdd (289.80k/289.80k flops)\n",
      "  model_149/conv2d_2092/BiasAdd (289.80k/289.80k flops)\n",
      "  model_149/depthwise_conv2d_1940/BiasAdd (273.60k/273.60k flops)\n",
      "  model_149/batch_normalization_4047/FusedBatchNormV3 (228.91k/228.91k flops)\n",
      "  model_149/depthwise_conv2d_1942/BiasAdd (216.00k/216.00k flops)\n",
      "  model_149/batch_normalization_4046/FusedBatchNormV3 (195.17k/195.17k flops)\n",
      "  model_149/conv2d_2098/BiasAdd (112.95k/112.95k flops)\n",
      "  model_149/depthwise_conv2d_1948/BiasAdd (96.30k/96.30k flops)\n",
      "  model_149/batch_normalization_4049/FusedBatchNormV3 (77.72k/77.72k flops)\n",
      "  model_149/batch_normalization_4048/FusedBatchNormV3 (67.27k/67.27k flops)\n",
      "  model_149/global_average_pooling2d_149/Mean (37.12k/37.12k flops)\n",
      "  model_149/conv2d_2099/BiasAdd (37.12k/37.12k flops)\n",
      "  model_149/depthwise_conv2d_1949/BiasAdd (32.13k/32.13k flops)\n",
      "  model_149/dense_149/MatMul (11.60k/11.60k flops)\n",
      "  model_149/dense_149/Softmax (50/50 flops)\n",
      "  model_149/dense_149/BiasAdd (10/10 flops)\n",
      "\n",
      "======================End of Report==========================\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "243.855148\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-30 13:42:03.982492: I tensorflow/core/grappler/devices.cc:66] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0\n",
      "2022-04-30 13:42:03.982613: I tensorflow/core/grappler/clusters/single_machine.cc:357] Starting new session\n",
      "2022-04-30 13:42:03.987891: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:1137] Optimization results for grappler item: graph_to_optimize\n",
      "  function_optimizer: function_optimizer did nothing. time = 0.006ms.\n",
      "  function_optimizer: function_optimizer did nothing. time = 0.001ms.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=========================Options=============================\n",
      "-max_depth                  10000\n",
      "-min_bytes                  0\n",
      "-min_peak_bytes             0\n",
      "-min_residual_bytes         0\n",
      "-min_output_bytes           0\n",
      "-min_micros                 0\n",
      "-min_accelerator_micros     0\n",
      "-min_cpu_micros             0\n",
      "-min_params                 0\n",
      "-min_float_ops              1\n",
      "-min_occurrence             0\n",
      "-step                       -1\n",
      "-order_by                   float_ops\n",
      "-account_type_regexes       .*\n",
      "-start_name_regexes         .*\n",
      "-trim_name_regexes          \n",
      "-show_name_regexes          .*\n",
      "-hide_name_regexes          \n",
      "-account_displayed_op_only  true\n",
      "-select                     float_ops\n",
      "-output                     stdout:\n",
      "\n",
      "==================Model Analysis Report======================\n",
      "\n",
      "Doc:\n",
      "scope: The nodes in the model graph are organized by their names, which is hierarchical like filesystem.\n",
      "flops: Number of float operations. Note: Please read the implementation for the math behind it.\n",
      "\n",
      "Profile:\n",
      "node name | # float_ops\n",
      "_TFProfRoot (--/3.73b flops)\n",
      "  model_150/conv2d_2105/Conv2D (457.23m/457.23m flops)\n",
      "  model_150/conv2d_2109/Conv2D (382.52m/382.52m flops)\n",
      "  model_150/conv2d_2108/Conv2D (367.68m/367.68m flops)\n",
      "  model_150/conv2d_2111/Conv2D (344.94m/344.94m flops)\n",
      "  model_150/conv2d_2110/Conv2D (339.09m/339.09m flops)\n",
      "  model_150/conv2d_2107/Conv2D (309.88m/309.88m flops)\n",
      "  model_150/conv2d_2103/Conv2D (302.05m/302.05m flops)\n",
      "  model_150/conv2d_2101/Conv2D (221.18m/221.18m flops)\n",
      "  model_150/conv2d_2104/Conv2D (206.84m/206.84m flops)\n",
      "  model_150/conv2d_2106/Conv2D (175.09m/175.09m flops)\n",
      "  model_150/conv2d_2102/Conv2D (158.98m/158.98m flops)\n",
      "  model_150/conv2d_2112/Conv2D (146.56m/146.56m flops)\n",
      "  model_150/conv2d_2113/Conv2D (63.77m/63.77m flops)\n",
      "  model_150/conv2d_2100/Conv2D (58.98m/58.98m flops)\n",
      "  model_150/depthwise_conv2d_1950/depthwise (33.18m/33.18m flops)\n",
      "  model_150/depthwise_conv2d_1952/depthwise (23.85m/23.85m flops)\n",
      "  model_150/depthwise_conv2d_1954/depthwise (16.33m/16.33m flops)\n",
      "  model_150/depthwise_conv2d_1951/depthwise (15.55m/15.55m flops)\n",
      "  model_150/depthwise_conv2d_1959/depthwise (7.52m/7.52m flops)\n",
      "  model_150/depthwise_conv2d_1958/depthwise (7.42m/7.42m flops)\n",
      "  model_150/depthwise_conv2d_1953/depthwise (7.39m/7.39m flops)\n",
      "  model_150/depthwise_conv2d_1957/depthwise (7.23m/7.23m flops)\n",
      "  model_150/batch_normalization_4052/FusedBatchNormV3 (6.91m/6.91m flops)\n",
      "  model_150/depthwise_conv2d_1960/depthwise (6.58m/6.58m flops)\n",
      "  model_150/depthwise_conv2d_1956/depthwise (6.25m/6.25m flops)\n",
      "  model_150/depthwise_conv2d_1955/depthwise (4.08m/4.08m flops)\n",
      "  model_150/batch_normalization_4051/FusedBatchNormV3 (3.69m/3.69m flops)\n",
      "  model_150/batch_normalization_4050/FusedBatchNormV3 (3.69m/3.69m flops)\n",
      "  model_150/conv2d_2101/BiasAdd (3.46m/3.46m flops)\n",
      "  model_150/batch_normalization_4056/FusedBatchNormV3 (3.28m/3.28m flops)\n",
      "  model_150/batch_normalization_4054/FusedBatchNormV3 (2.65m/2.65m flops)\n",
      "  model_150/batch_normalization_4055/FusedBatchNormV3 (2.65m/2.65m flops)\n",
      "  model_150/depthwise_conv2d_1961/depthwise (1.91m/1.91m flops)\n",
      "  model_150/conv2d_2100/BiasAdd (1.84m/1.84m flops)\n",
      "  model_150/depthwise_conv2d_1950/BiasAdd (1.84m/1.84m flops)\n",
      "  model_150/batch_normalization_4058/FusedBatchNormV3 (1.82m/1.82m flops)\n",
      "  model_150/batch_normalization_4060/FusedBatchNormV3 (1.82m/1.82m flops)\n",
      "  model_150/batch_normalization_4059/FusedBatchNormV3 (1.82m/1.82m flops)\n",
      "  model_150/batch_normalization_4053/FusedBatchNormV3 (1.73m/1.73m flops)\n",
      "  model_150/conv2d_2103/BiasAdd (1.64m/1.64m flops)\n",
      "  model_150/conv2d_2102/BiasAdd (1.32m/1.32m flops)\n",
      "  model_150/depthwise_conv2d_1952/BiasAdd (1.32m/1.32m flops)\n",
      "  model_150/conv2d_2105/BiasAdd (907.20k/907.20k flops)\n",
      "  model_150/conv2d_2104/BiasAdd (907.20k/907.20k flops)\n",
      "  model_150/depthwise_conv2d_1954/BiasAdd (907.20k/907.20k flops)\n",
      "  model_150/depthwise_conv2d_1951/BiasAdd (864.00k/864.00k flops)\n",
      "  model_150/batch_normalization_4072/FusedBatchNormV3 (852.43k/852.43k flops)\n",
      "  model_150/batch_normalization_4069/FusedBatchNormV3 (837.98k/837.98k flops)\n",
      "  model_150/batch_normalization_4068/FusedBatchNormV3 (837.98k/837.98k flops)\n",
      "  model_150/batch_normalization_4066/FusedBatchNormV3 (827.15k/827.15k flops)\n",
      "  model_150/batch_normalization_4067/FusedBatchNormV3 (827.15k/827.15k flops)\n",
      "  model_150/batch_normalization_4057/FusedBatchNormV3 (821.48k/821.48k flops)\n",
      "  model_150/batch_normalization_4065/FusedBatchNormV3 (805.48k/805.48k flops)\n",
      "  model_150/batch_normalization_4064/FusedBatchNormV3 (805.48k/805.48k flops)\n",
      "  model_150/depthwise_conv2d_1962/depthwise (794.88k/794.88k flops)\n",
      "  model_150/batch_normalization_4070/FusedBatchNormV3 (733.24k/733.24k flops)\n",
      "  model_150/batch_normalization_4071/FusedBatchNormV3 (733.24k/733.24k flops)\n",
      "  model_150/batch_normalization_4063/FusedBatchNormV3 (697.12k/697.12k flops)\n",
      "  model_150/batch_normalization_4062/FusedBatchNormV3 (697.12k/697.12k flops)\n",
      "  model_150/batch_normalization_4061/FusedBatchNormV3 (455.11k/455.11k flops)\n",
      "  model_150/conv2d_2111/BiasAdd (424.80k/424.80k flops)\n",
      "  model_150/depthwise_conv2d_1959/BiasAdd (417.60k/417.60k flops)\n",
      "  model_150/conv2d_2109/BiasAdd (417.60k/417.60k flops)\n",
      "  model_150/conv2d_2108/BiasAdd (412.20k/412.20k flops)\n",
      "  model_150/depthwise_conv2d_1958/BiasAdd (412.20k/412.20k flops)\n",
      "  model_150/depthwise_conv2d_1953/BiasAdd (410.40k/410.40k flops)\n",
      "  model_150/depthwise_conv2d_1957/BiasAdd (401.40k/401.40k flops)\n",
      "  model_150/conv2d_2107/BiasAdd (401.40k/401.40k flops)\n",
      "  model_150/depthwise_conv2d_1960/BiasAdd (365.40k/365.40k flops)\n",
      "  model_150/conv2d_2110/BiasAdd (365.40k/365.40k flops)\n",
      "  model_150/depthwise_conv2d_1956/BiasAdd (347.40k/347.40k flops)\n",
      "  model_150/conv2d_2106/BiasAdd (347.40k/347.40k flops)\n",
      "  model_150/batch_normalization_4074/FusedBatchNormV3 (314.64k/314.64k flops)\n",
      "  model_150/depthwise_conv2d_1955/BiasAdd (226.80k/226.80k flops)\n",
      "  model_150/batch_normalization_4073/FusedBatchNormV3 (215.23k/215.23k flops)\n",
      "  model_150/conv2d_2112/BiasAdd (155.25k/155.25k flops)\n",
      "  model_150/depthwise_conv2d_1961/BiasAdd (106.20k/106.20k flops)\n",
      "  model_150/batch_normalization_4076/FusedBatchNormV3 (96.75k/96.75k flops)\n",
      "  model_150/batch_normalization_4075/FusedBatchNormV3 (92.46k/92.46k flops)\n",
      "  model_150/global_average_pooling2d_150/Mean (46.21k/46.21k flops)\n",
      "  model_150/conv2d_2113/BiasAdd (46.21k/46.21k flops)\n",
      "  model_150/depthwise_conv2d_1962/BiasAdd (44.16k/44.16k flops)\n",
      "  model_150/dense_150/MatMul (14.44k/14.44k flops)\n",
      "  model_150/dense_150/Softmax (50/50 flops)\n",
      "  model_150/dense_150/BiasAdd (10/10 flops)\n",
      "\n",
      "======================End of Report==========================\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import csv\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from itertools import product\n",
    "from keras_flops import get_flops\n",
    "\n",
    "\n",
    "model_num = 1\n",
    "input_shape_range =range(32,512,32)\n",
    "\n",
    "with open(\"para_count_MobileNet.csv\",\"w\") as csvfile:\n",
    "         writer = csv.writer(csvfile)\n",
    "         writer.writerows([[\"model_num\", \"input_horizontal\", \"input_vertical\", \"step\", \"number of layers\", \"FLOPs\", \"Total_params\", \"Memory\"],])\n",
    "path = \"../MobileNet_h5\" #\n",
    "files= os.listdir(path) #\n",
    "\n",
    "for shape_x in input_shape_range:\n",
    "    shape_y = shape_x\n",
    "    for step in range(1,11):\n",
    "        file = \"MobileNet_{input_x}_{input_y}_{step}.h5\".format(input_x=shape_x,input_y=shape_y,step=step)\n",
    "        if file in files: #\n",
    "            model_name = str(file)\n",
    "            if not os.path.isdir(file): #\n",
    "                model = keras.models.load_model(\"../MobileNet_h5/{}\".format(model_name))\n",
    "\n",
    "                # how to compute the memory allocated by the activations of a model\n",
    "                batch = 1\n",
    "                shapes_count = int(np.sum([np.prod(np.array([s if isinstance(s, int) \n",
    "                else 1 for s in l.output_shape])) \n",
    "                for l in model.layers]))\n",
    "                memory = (shapes_count * 4 * batch)/10**6\n",
    "                print(memory)\n",
    "                layers_length = len(model.layers)\n",
    "                Total_params = round(model.count_params()/10 ** 6,2)\n",
    "                FLOPs = round(get_flops(model, batch_size=1)/10 ** 9,2)\n",
    "                with open(\"para_count_MobileNet.csv\",\"a+\") as csvfile:\n",
    "                    writer = csv.writer(csvfile)\n",
    "                    writer.writerows([[model_num, shape_x, shape_y, step, layers_length, FLOPs, Total_params, memory],])\n",
    "\n",
    "                    model_num = model_num + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8241605",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
